run_id,run_config,dataset,model,execution_mode,eval_metric,best_params,best_score,score_std,output_metrics,saved_model_path,run_time
202310-0123-3310-3f8d777f-b30c-452d-9c88-2c41df9a5fe2,"{'dataset': 'ageconditions', 'model': 'xgb', 'best_params': {}, 'param_grid': {'n_estimators': [100, 2000], 'max_bin': [256, 32], 'tree_method': ['auto', 'hist'], 'max_depth': [4, 10], 'learning_rate': [0.1, 0.33], 'subsample': [0.7, 1.0], 'colsample_bytree': [0.5, 1.0], 'min_child_weight': [1, 10], 'alpha': [0.0, 5.0], 'gamma': [0.0, 5.0], 'lambda': [0.0, 5.0]}}",ageconditions,xgb,hyperopt_kfold,f1,"{'alpha': 2.3265981446881856, 'colsample_bytree': 0.9979592345326663, 'gamma': 0.0027025058789080444, 'lambda': 1.4583580118278725, 'learning_rate': 0.13914787637481424, 'max_bin': 79, 'max_depth': 5, 'min_child_weight': 4, 'n_estimators': 255, 'subsample': 0.7558105303157286, 'tree_method': 'hist', 'outer_params': {'hyperopt_evals': 50, 'validation_fraction': 0.15, 'early_stopping_rounds': 10, 'verbose': False}}",0.7587959736740224,0.05991146548267298,"{'recall': [0.7272727272727273, 0.6363636363636364, 0.7727272727272727, 0.5714285714285714, 0.6666666666666666], 'precision': [0.8421052631578947, 0.7777777777777778, 0.9444444444444444, 0.8571428571428571, 0.9333333333333333], 'accuracy': [0.928, 0.904, 0.9516129032258065, 0.9112903225806451, 0.9354838709677419], 'f1': [0.7804878048780488, 0.7000000000000001, 0.85, 0.6857142857142857, 0.7777777777777778], 'roc_auc': [0.972639011473963, 0.9285083848190644, 0.9723707664884136, 0.9093851132686084, 0.9856680536292187], 'area_under_pr': [0.8802454489180189, 0.8228066067050674, 0.9282930925993585, 0.7814409858985925, 0.9245285294627401], 'lift': [5.208333333333333, 5.208333333333333, 5.636363636363636, 4.920634920634921, 5.412698412698413]}",./output/modelsaves/ageconditions/xgb/202310-0123-3310-3f8d777f-b30c-452d-9c88-2c41df9a5fe2//202310-0123-3310-3f8d777f-b30c-452d-9c88-2c41df9a5fe2,746.5750734806061
202310-0123-3314-df52c585-d03e-43a5-b9e5-2b31f5965ea6,"{'dataset': 'heloc', 'model': 'node', 'best_params': {}, 'param_grid': {'batch_size': [512, 1024], 'num_layers': [1, 2, 3], 'num_trees': [12, 128], 'additional_tree_output_dim': [2, 3, 4], 'depth': [5, 7], 'choice_function': ['entmax15', 'sparsemax'], 'bin_function': ['entmoid15', 'sparsemoid'], 'input_dropout': [0.0, 0.1], 'embedding_dropout': [0.0, 0.1], 'embed_categorical': [True, False], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",heloc,node,hyperopt_kfold,lift,"{'AdamW_weight_decay': 1.4664629667158877e-05, 'Adam_weight_decay': 5.200269059018598e-05, 'ExponentialLR_gamma': 0.9624375913196498, 'ReduceLROnPlateau_factor': 0.6295791413717579, 'ReduceLROnPlateau_patience': 4, 'additional_tree_output_dim': 4, 'batch_size': 716, 'bin_function': 'entmoid15', 'choice_function': 'sparsemax', 'depth': 7, 'embed_categorical': True, 'embedding_dropout': 0.08075321455838412, 'input_dropout': 0.08401581649848215, 'num_layers': 2, 'num_trees': 74, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 5}}",1.7325748688091298,0.03466653365154124,"{'recall': [0.7252747252747253, 0.6978021978021978, 0.6794871794871795, 0.717032967032967, 0.692942254812099], 'precision': [0.7394957983193278, 0.7398058252427184, 0.7442326980942828, 0.7421800947867299, 0.7529880478087649], 'accuracy': [0.7232313575525813, 0.7141491395793499, 0.7108030592734226, 0.7222753346080306, 0.7211860353897657], 'f1': [0.7323162274618585, 0.7181903864278982, 0.7103877453326951, 0.7293898462971588, 0.7217183770883054], 'roc_auc': [0.7945952380952381, 0.7948946886446887, 0.7960485347985349, 0.7971346153846154, 0.8059908340971585], 'area_under_pr': [0.7945303604002036, 0.7874794059046297, 0.7928165477639978, 0.8054414608986866, 0.803973860439001], 'lift': [1.7415917415917415, 1.7140929246192402, 1.7049266522950732, 1.796589375536744, 1.7056736500028506]}",./output/modelsaves/heloc/node/202310-0123-3314-df52c585-d03e-43a5-b9e5-2b31f5965ea6//202310-0123-3314-df52c585-d03e-43a5-b9e5-2b31f5965ea6,3198.368331193924
202310-0123-4537-4c36be74-91bb-4166-9bc5-f4df1d0af89e,"{'dataset': 'adult', 'model': 'xgb', 'best_params': {}, 'param_grid': {'n_estimators': [100, 1500], 'max_bin': [256, 32], 'tree_method': ['auto', 'hist'], 'max_depth': [4, 10], 'learning_rate': [0.1, 0.33], 'subsample': [0.7, 1.0], 'colsample_bytree': [0.5, 1.0], 'min_child_weight': [1, 10], 'alpha': [0.0, 5.0], 'gamma': [0.0, 5.0], 'lambda': [0.0, 5.0]}}",adult,xgb,hyperopt_kfold,roc_auc,"{'alpha': 1.9227608713131281, 'colsample_bytree': 0.5945328194898489, 'gamma': 0.638624318843618, 'lambda': 2.264078880324862, 'learning_rate': 0.13070893523409546, 'max_bin': 90, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 1292, 'subsample': 0.9363883431513152, 'tree_method': 'auto', 'outer_params': {'hyperopt_evals': 50, 'validation_fraction': 0.15, 'early_stopping_rounds': 10, 'verbose': False}}",0.9285569955393989,0.0013185691322415004,"{'recall': [0.638623326959847, 0.6619897959183674, 0.6409438775510204, 0.6613520408163265, 0.6549744897959183], 'precision': [0.7952380952380952, 0.7887537993920972, 0.7701149425287356, 0.7838246409674982, 0.7986003110419907], 'accuracy': [0.8733302625518194, 0.8759213759213759, 0.8674754299754299, 0.874539312039312, 0.8771498771498771], 'f1': [0.7083775185577943, 0.7198335644937587, 0.6996171249564915, 0.7173988239363543, 0.7196916608269095], 'roc_auc': [0.9290934824399109, 0.9308558147166632, 0.9277810069719635, 0.9270811404051912, 0.9279735331632651], 'area_under_pr': [0.8330970645719281, 0.832709429541261, 0.8231646755499017, 0.8276075548503954, 0.8311894827414094], 'lift': [3.915123959902841, 3.87236276999279, 3.8213266873569705, 3.865983259663312, 3.8851217906517443]}",./output/modelsaves/adult/xgb/202310-0123-4537-4c36be74-91bb-4166-9bc5-f4df1d0af89e//202310-0123-4537-4c36be74-91bb-4166-9bc5-f4df1d0af89e,6617.176292896271
202310-0201-3554-4d86d13b-dac9-45e5-a18f-9f9dfb8f2a4d,"{'dataset': 'housing', 'model': 'xgb', 'best_params': {}, 'param_grid': {'n_estimators': [100, 1500], 'max_bin': [256, 32], 'tree_method': ['auto', 'hist'], 'max_depth': [4, 10], 'learning_rate': [0.1, 0.33], 'subsample': [0.7, 1.0], 'colsample_bytree': [0.5, 1.0], 'min_child_weight': [1, 10], 'alpha': [0.0, 5.0], 'gamma': [0.0, 5.0], 'lambda': [0.0, 5.0]}}",housing,xgb,hyperopt_kfold,r2_score,"{'alpha': 1.250151910503714, 'colsample_bytree': 0.6749303887890425, 'gamma': 0.37422350929976944, 'lambda': 1.6107361888156269, 'learning_rate': 0.11822958982534913, 'max_bin': 95, 'max_depth': 9, 'min_child_weight': 9, 'n_estimators': 376, 'subsample': 0.7914439816464922, 'tree_method': 'auto', 'outer_params': {'hyperopt_evals': 50, 'validation_fraction': 0.15, 'early_stopping_rounds': 10, 'verbose': False}}",0.8595026917246011,0.00687449995615138,"{'mse': [0.1831939792077722, 0.18469418113394823, 0.1955749756272497, 0.1751231285854959, 0.19623430649896184], 'rmse': [0.42801165779423833, 0.4297606090999363, 0.44223859581367353, 0.4184771541978079, 0.44298341560261806], 'r2_score': [0.8602009126542365, 0.8648012693124941, 0.8496793486139866, 0.8686240157580503, 0.8542079122842382]}",./output/modelsaves/housing/xgb/202310-0201-3554-4d86d13b-dac9-45e5-a18f-9f9dfb8f2a4d//202310-0201-3554-4d86d13b-dac9-45e5-a18f-9f9dfb8f2a4d,13935.548591852188
202310-0200-2633-8df8e9cb-8439-45bb-8e75-72b47baccb7c,"{'dataset': 'diabetes', 'model': 'node', 'best_params': {}, 'param_grid': {'batch_size': [512, 1024], 'num_layers': [1, 2, 3], 'num_trees': [12, 128], 'additional_tree_output_dim': [2, 3, 4], 'depth': [5, 7], 'choice_function': ['entmax15', 'sparsemax'], 'bin_function': ['entmoid15', 'sparsemoid'], 'input_dropout': [0.0, 0.1], 'embedding_dropout': [0.0, 0.1], 'embed_categorical': [True, False], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",diabetes,node,hyperopt_kfold,lift,"{'AdamW_weight_decay': 4.327846087518758e-05, 'Adam_weight_decay': 4.020141133995737e-05, 'ExponentialLR_gamma': 0.9606659876846797, 'ReduceLROnPlateau_factor': 0.17657861240783193, 'ReduceLROnPlateau_patience': 5, 'additional_tree_output_dim': 4, 'batch_size': 733, 'bin_function': 'sparsemoid', 'choice_function': 'sparsemax', 'depth': 7, 'embed_categorical': True, 'embedding_dropout': 0.08728907587411235, 'input_dropout': 0.07022166426540487, 'num_layers': 3, 'num_trees': 128, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 5}}",2.427091528331993,0.07279341804917944,"{'recall': [0.5919894366197183, 0.6261558784676354, 0.5548216644649934, 0.6129458388375165, 0.6624119718309859], 'precision': [0.18141354194766657, 0.18212090163934427, 0.181190681622088, 0.16823785351704135, 0.16644547666445478], 'accuracy': [0.6562837771445416, 0.6445241487741364, 0.6705645359406476, 0.6186802928315236, 0.5920011791873434], 'f1': [0.27772042122651247, 0.2821708502827662, 0.2731707317073171, 0.2640113798008535, 0.26604207176948913], 'roc_auc': [0.6785228623010042, 0.6889286980768806, 0.6741630463618671, 0.6764564905186807, 0.6714902632013529], 'area_under_pr': [0.2164251020603022, 0.2347728372350471, 0.21604026614659677, 0.22417944065396794, 0.2081931538092131], 'lift': [2.3948368342734536, 2.4926615579191536, 2.4221976269532415, 2.5146815363460013, 2.3110800861681144]}",./output/modelsaves/diabetes/node/202310-0200-2633-8df8e9cb-8439-45bb-8e75-72b47baccb7c//202310-0200-2633-8df8e9cb-8439-45bb-8e75-72b47baccb7c,18221.282469511032
202310-0205-2810-63fab0a5-f9c5-47b1-9a7b-2180802c619d,"{'dataset': 'breastcancer', 'model': 'xgb', 'best_params': {}, 'param_grid': {'n_estimators': [100, 2000], 'max_bin': [256, 32], 'tree_method': ['auto', 'hist'], 'max_depth': [4, 10], 'learning_rate': [0.1, 0.33], 'subsample': [0.7, 1.0], 'colsample_bytree': [0.5, 1.0], 'min_child_weight': [1, 10], 'alpha': [0.0, 5.0], 'gamma': [0.0, 5.0], 'lambda': [0.0, 5.0]}}",breastcancer,xgb,hyperopt_kfold,f1,"{'alpha': 1.5362069887137089, 'colsample_bytree': 0.504859310559956, 'gamma': 1.4507730674848403, 'lambda': 3.019548664843605, 'learning_rate': 0.19199352781861176, 'max_bin': 75, 'max_depth': 4, 'min_child_weight': 4, 'n_estimators': 494, 'subsample': 0.8242914202753657, 'tree_method': 'hist', 'outer_params': {'hyperopt_evals': 50, 'validation_fraction': 0.15, 'early_stopping_rounds': 10, 'verbose': False}}",0.9707974690174627,0.009947545510745545,"{'recall': [0.9577464788732394, 0.971830985915493, 0.9861111111111112, 0.9722222222222222, 0.9859154929577465], 'precision': [1.0, 0.9324324324324325, 0.9594594594594594, 0.9859154929577465, 0.958904109589041], 'accuracy': [0.9736842105263158, 0.9385964912280702, 0.9649122807017544, 0.9736842105263158, 0.9646017699115044], 'f1': [0.9784172661870503, 0.9517241379310345, 0.9726027397260274, 0.979020979020979, 0.9722222222222222], 'roc_auc': [0.9983622666229938, 0.9834588928922371, 0.9834656084656085, 0.998181216931217, 0.9909456740442656], 'area_under_pr': [0.9990216795445428, 0.9901250616418977, 0.9875695975147962, 0.9988575123580992, 0.994147021537541], 'lift': [1.6056338028169013, 1.6056338028169013, 1.5833333333333335, 1.5833333333333335, 1.591549295774648]}",./output/modelsaves/breastcancer/xgb/202310-0205-2810-63fab0a5-f9c5-47b1-9a7b-2180802c619d//202310-0205-2810-63fab0a5-f9c5-47b1-9a7b-2180802c619d,788.1124703884125
202310-0205-4118-7d538b2c-b256-4e00-a451-0893e49a4864,"{'dataset': 'titanic', 'model': 'xgb', 'best_params': {}, 'param_grid': {'n_estimators': [100, 2000], 'max_bin': [256, 32], 'tree_method': ['auto', 'hist'], 'max_depth': [4, 10], 'learning_rate': [0.1, 0.33], 'subsample': [0.7, 1.0], 'colsample_bytree': [0.5, 1.0], 'min_child_weight': [1, 10], 'alpha': [0.0, 5.0], 'gamma': [0.0, 5.0], 'lambda': [0.0, 5.0]}}",titanic,xgb,hyperopt_kfold,roc_auc,"{'alpha': 0.7964253315853251, 'colsample_bytree': 0.7625091069709334, 'gamma': 1.199211350131553, 'lambda': 2.21423025775779, 'learning_rate': 0.13125920423718612, 'max_bin': 184, 'max_depth': 9, 'min_child_weight': 2, 'n_estimators': 902, 'subsample': 0.9609276619590482, 'tree_method': 'auto', 'outer_params': {'hyperopt_evals': 50, 'validation_fraction': 0.15, 'early_stopping_rounds': 10, 'verbose': False}}",0.8858012893666005,0.02747304361681533,"{'recall': [0.7536231884057971, 0.7205882352941176, 0.6176470588235294, 0.75, 0.7536231884057971], 'precision': [0.8813559322033898, 0.8166666666666667, 0.7777777777777778, 0.8095238095238095, 0.8666666666666667], 'accuracy': [0.8659217877094972, 0.8314606741573034, 0.7865168539325843, 0.8370786516853933, 0.8595505617977528], 'f1': [0.8124999999999999, 0.7656250000000001, 0.6885245901639345, 0.7786259541984734, 0.8062015503875969], 'roc_auc': [0.925098814229249, 0.8968582887700535, 0.8400401069518716, 0.8823529411764706, 0.8846562957053583], 'area_under_pr': [0.8901163314596531, 0.8832791884572412, 0.811105638152329, 0.8779052604328605, 0.8576297162415356], 'lift': [2.441602728047741, 2.6176470588235294, 2.309688581314879, 2.6176470588235294, 2.4279624893435634]}",./output/modelsaves/titanic/xgb/202310-0205-4118-7d538b2c-b256-4e00-a451-0893e49a4864//202310-0205-4118-7d538b2c-b256-4e00-a451-0893e49a4864,1051.967452764511
202310-0215-4132-80cf4027-ced1-4e01-a97c-5433b745ae09,"{'dataset': 'iris', 'model': 'xgb', 'best_params': {}, 'param_grid': {'n_estimators': [100, 2000], 'max_bin': [256, 32], 'tree_method': ['auto', 'hist'], 'max_depth': [4, 10], 'learning_rate': [0.1, 0.33], 'subsample': [0.7, 1.0], 'colsample_bytree': [0.5, 1.0], 'min_child_weight': [1, 10], 'alpha': [0.0, 5.0], 'gamma': [0.0, 5.0], 'lambda': [0.0, 5.0]}}",iris,xgb,hyperopt_kfold,accuracy,"{'alpha': 2.4157432235372833, 'colsample_bytree': 0.6723299691799234, 'gamma': 0.6798647393732932, 'lambda': 2.9031069313425997, 'learning_rate': 0.26649601502704195, 'max_bin': 143, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 1880, 'subsample': 0.8361375951301544, 'tree_method': 'auto', 'outer_params': {'hyperopt_evals': 50, 'validation_fraction': 0.15, 'early_stopping_rounds': 10, 'verbose': False}}",0.9600000000000002,0.038873012632301994,"{'accuracy': [1.0, 0.9666666666666667, 0.9333333333333333, 1.0, 0.9], 'f1': [1.0, 0.9665831244778613, 0.9326599326599326, 1.0, 0.8997493734335841]}",./output/modelsaves/iris/xgb/202310-0215-4132-80cf4027-ced1-4e01-a97c-5433b745ae09//202310-0215-4132-80cf4027-ced1-4e01-a97c-5433b745ae09,88.88271450996399
202310-0215-4138-d3d9ff3a-b423-4f53-ad40-4cd29c3360b3,"{'dataset': 'iris', 'model': 'node', 'best_params': {}, 'param_grid': {'batch_size': [32, 64, 128, 256], 'num_layers': [1, 2, 3], 'num_trees': [12, 128], 'additional_tree_output_dim': [2, 3, 4], 'depth': [5, 7], 'choice_function': ['entmax15', 'sparsemax'], 'bin_function': ['entmoid15', 'sparsemoid'], 'input_dropout': [0.0, 0.1], 'embedding_dropout': [0.0, 0.1], 'embed_categorical': [True, False], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",iris,node,hyperopt_kfold,accuracy,"{'AdamW_weight_decay': 3.9436585596661325e-05, 'Adam_weight_decay': 1.9544553613857148e-05, 'ExponentialLR_gamma': 0.9291768981774606, 'ReduceLROnPlateau_factor': 0.46205097332497386, 'ReduceLROnPlateau_patience': 4, 'additional_tree_output_dim': 3, 'batch_size': 34, 'bin_function': 'entmoid15', 'choice_function': 'entmax15', 'depth': 6, 'embed_categorical': True, 'embedding_dropout': 0.028748327272114373, 'input_dropout': 0.05270698035669344, 'num_layers': 2, 'num_trees': 60, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 5}}",0.9800000000000001,0.02666666666666666,"{'accuracy': [1.0, 1.0, 0.9333333333333333, 1.0, 0.9666666666666667], 'f1': [1.0, 1.0, 0.9333333333333333, 1.0, 0.9665831244778613]}",./output/modelsaves/iris/node/202310-0215-4138-d3d9ff3a-b423-4f53-ad40-4cd29c3360b3//202310-0215-4138-d3d9ff3a-b423-4f53-ad40-4cd29c3360b3,843.8321316242218
202310-0215-5542-9805adc2-e321-4572-bbfd-0469e4da9663,"{'dataset': 'titanic', 'model': 'node', 'best_params': {}, 'param_grid': {'batch_size': [32, 64, 128, 256], 'num_layers': [1, 2, 3], 'num_trees': [12, 128], 'additional_tree_output_dim': [2, 3, 4], 'depth': [5, 7], 'choice_function': ['entmax15', 'sparsemax'], 'bin_function': ['entmoid15', 'sparsemoid'], 'input_dropout': [0.0, 0.1], 'embedding_dropout': [0.0, 0.1], 'embed_categorical': [True, False], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",titanic,node,hyperopt_kfold,roc_auc,"{'AdamW_weight_decay': 1.3322253267102219e-05, 'Adam_weight_decay': 3.466501460547525e-05, 'ExponentialLR_gamma': 0.9753175304954133, 'ReduceLROnPlateau_factor': 0.3942623038432992, 'ReduceLROnPlateau_patience': 3, 'additional_tree_output_dim': 2, 'batch_size': 61, 'bin_function': 'sparsemoid', 'choice_function': 'sparsemax', 'depth': 7, 'embed_categorical': False, 'embedding_dropout': 0.011808212701250532, 'input_dropout': 0.005106959544555053, 'num_layers': 1, 'num_trees': 68, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 5}}",0.881706930043294,0.021915454823087124,"{'recall': [0.7971014492753623, 0.8235294117647058, 0.6911764705882353, 0.7941176470588235, 0.7971014492753623], 'precision': [0.7432432432432432, 0.717948717948718, 0.734375, 0.7714285714285715, 0.8461538461538461], 'accuracy': [0.8156424581005587, 0.8089887640449438, 0.7865168539325843, 0.8314606741573034, 0.8651685393258427], 'f1': [0.7692307692307693, 0.767123287671233, 0.7121212121212122, 0.782608695652174, 0.8208955223880597], 'roc_auc': [0.9113965744400527, 0.8866310160427808, 0.8436497326203207, 0.8788770053475936, 0.8879803217657226], 'area_under_pr': [0.8741943610847764, 0.8612807097317644, 0.8222031046879413, 0.8766054542721209, 0.8408977072901349], 'lift': [2.5942028985507246, 2.6176470588235294, 2.463667820069204, 2.6176470588235294, 2.4279624893435634]}",./output/modelsaves/titanic/node/202310-0215-5542-9805adc2-e321-4572-bbfd-0469e4da9663//202310-0215-5542-9805adc2-e321-4572-bbfd-0469e4da9663,1244.3247609138489
202310-0216-1627-2ca4d0b8-86eb-43fc-91e3-a41eb93a8158,"{'dataset': 'breastcancer', 'model': 'node', 'best_params': {}, 'param_grid': {'batch_size': [32, 64, 128, 256], 'num_layers': [1, 2, 3], 'num_trees': [12, 128], 'additional_tree_output_dim': [2, 3, 4], 'depth': [5, 7], 'choice_function': ['entmax15', 'sparsemax'], 'bin_function': ['entmoid15', 'sparsemoid'], 'input_dropout': [0.0, 0.1], 'embedding_dropout': [0.0, 0.1], 'embed_categorical': [True, False], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",breastcancer,node,hyperopt_kfold,f1,"{'AdamW_weight_decay': 4.664866465780465e-05, 'Adam_weight_decay': 1.754727032738925e-05, 'ExponentialLR_gamma': 0.9177432565481651, 'ReduceLROnPlateau_factor': 0.16566548937803902, 'ReduceLROnPlateau_patience': 5, 'additional_tree_output_dim': 4, 'batch_size': 112, 'bin_function': 'entmoid15', 'choice_function': 'entmax15', 'depth': 7, 'embed_categorical': True, 'embedding_dropout': 0.043825033415070686, 'input_dropout': 0.013330044282393365, 'num_layers': 3, 'num_trees': 39, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 5}}",0.988945567370225,0.009276992991966807,"{'recall': [1.0, 1.0, 0.9861111111111112, 0.9861111111111112, 1.0], 'precision': [1.0, 0.9726027397260274, 0.9594594594594594, 1.0, 0.9861111111111112], 'accuracy': [1.0, 0.9824561403508771, 0.9649122807017544, 0.9912280701754386, 0.9910714285714286], 'f1': [1.0, 0.9861111111111112, 0.9726027397260274, 0.993006993006993, 0.993006993006993], 'roc_auc': [1.0, 0.9918113331149689, 0.9831349206349206, 0.9993386243386243, 0.9972518035039505], 'area_under_pr': [1.0, 0.9945914278271166, 0.9867558972009745, 0.9996246246246245, 0.9983532500019233], 'lift': [1.6056338028169013, 1.6056338028169013, 1.5833333333333335, 1.5833333333333335, 1.5774647887323945]}",./output/modelsaves/breastcancer/node/202310-0216-1627-2ca4d0b8-86eb-43fc-91e3-a41eb93a8158//202310-0216-1627-2ca4d0b8-86eb-43fc-91e3-a41eb93a8158,981.5898666381836
202310-0215-4300-6fdfdc6a-10d3-4d5d-8315-461c871b27c8,"{'dataset': 'diabetes', 'model': 'xgb', 'best_params': {}, 'param_grid': {'n_estimators': [100, 1500], 'max_bin': [256, 32], 'tree_method': ['auto', 'hist'], 'max_depth': [4, 10], 'learning_rate': [0.1, 0.33], 'subsample': [0.7, 1.0], 'colsample_bytree': [0.5, 1.0], 'min_child_weight': [1, 10], 'alpha': [0.0, 5.0], 'gamma': [0.0, 5.0], 'lambda': [0.0, 5.0]}}",diabetes,xgb,hyperopt_kfold,lift,"{'alpha': 0.7542323746808111, 'colsample_bytree': 0.6965580923192364, 'gamma': 0.2165462366078169, 'lambda': 0.24173145551695363, 'learning_rate': 0.15349516995751222, 'max_bin': 52, 'max_depth': 6, 'min_child_weight': 5, 'n_estimators': 306, 'subsample': 0.7983111134333983, 'tree_method': 'hist', 'outer_params': {'hyperopt_evals': 50, 'validation_fraction': 0.15, 'early_stopping_rounds': 10, 'verbose': False}}",2.4957818863348704,0.08679156792934728,"{'recall': [0.025088028169014086, 0.019374724790841038, 0.010568031704095112, 0.013210039630118891, 0.01584507042253521], 'precision': [0.57, 0.5714285714285714, 0.5581395348837209, 0.5769230769230769, 0.5373134328358209], 'accuracy': [0.8890635747273263, 0.8889598584975188, 0.8886650616616715, 0.8888124600795951, 0.888615928855697], 'f1': [0.048060708263069137, 0.037478705281090284, 0.020743301642178046, 0.02582866982350409, 0.0307823856348867], 'roc_auc': [0.6789463171296332, 0.6920695587511678, 0.6780798623190766, 0.6826735205162293, 0.676844044327911], 'area_under_pr': [0.23044418067927447, 0.24872298143608987, 0.22827619433762347, 0.23699597795327165, 0.22621989078656435], 'lift': [2.3992391078658684, 2.651205402592457, 2.4662375838069366, 2.519085532031371, 2.4431418053777207]}",./output/modelsaves/diabetes/xgb/202310-0215-4300-6fdfdc6a-10d3-4d5d-8315-461c871b27c8//202310-0215-4300-6fdfdc6a-10d3-4d5d-8315-461c871b27c8,3686.675400495529
202310-0216-4427-088e5702-0e5d-4cc5-be10-140235026e43,"{'dataset': 'creditcard', 'model': 'xgb', 'best_params': {}, 'param_grid': {'n_estimators': [100, 1500], 'max_bin': [256, 32], 'tree_method': ['auto', 'hist'], 'max_depth': [4, 10], 'learning_rate': [0.1, 0.33], 'subsample': [0.7, 1.0], 'colsample_bytree': [0.5, 1.0], 'min_child_weight': [1, 10], 'alpha': [0.0, 5.0], 'gamma': [0.0, 5.0], 'lambda': [0.0, 5.0]}}",creditcard,xgb,hyperopt_kfold,lift,"{'alpha': 3.726681573346677, 'colsample_bytree': 0.6078442297724492, 'gamma': 0.3407720626123095, 'lambda': 0.9052108766258732, 'learning_rate': 0.15738950787288739, 'max_bin': 147, 'max_depth': 9, 'min_child_weight': 9, 'n_estimators': 533, 'subsample': 0.8356912207102457, 'tree_method': 'auto', 'outer_params': {'hyperopt_evals': 50, 'validation_fraction': 0.15, 'early_stopping_rounds': 10, 'verbose': False}}",9.654741464171641,0.21931586174797246,"{'recall': [0.7575757575757576, 0.8181818181818182, 0.8061224489795918, 0.7755102040816326, 0.7857142857142857], 'precision': [0.9375, 0.9878048780487805, 0.9404761904761905, 0.9382716049382716, 0.9058823529411765], 'accuracy': [0.9994908886626171, 0.9996664442961974, 0.9995786590825302, 0.9995259914678464, 0.999490879724724], 'f1': [0.8379888268156425, 0.8950276243093922, 0.8681318681318683, 0.8491620111731844, 0.8415300546448088], 'roc_auc': [0.9855120503169322, 0.980241452209164, 0.9954907732046269, 0.9700196892854182, 0.9827630821950503], 'area_under_pr': [0.8344785120938257, 0.895671941106917, 0.8705128406651571, 0.8408530314611666, 0.832524265661344], 'lift': [9.798323828169334, 9.495282885030075, 10.000175561797752, 9.387919915157074, 9.592005130703965]}",./output/modelsaves/creditcard/xgb/202310-0216-4427-088e5702-0e5d-4cc5-be10-140235026e43//202310-0216-4427-088e5702-0e5d-4cc5-be10-140235026e43,1457.8515331745148
202310-0217-0845-b5a53099-4376-4e88-9906-0fe55eb48372,"{'dataset': 'heloc', 'model': 'xgb', 'best_params': {}, 'param_grid': {'n_estimators': [100, 1500], 'max_bin': [256, 32], 'tree_method': ['auto', 'hist'], 'max_depth': [4, 10], 'learning_rate': [0.1, 0.33], 'subsample': [0.7, 1.0], 'colsample_bytree': [0.5, 1.0], 'min_child_weight': [1, 10], 'alpha': [0.0, 5.0], 'gamma': [0.0, 5.0], 'lambda': [0.0, 5.0]}}",heloc,xgb,hyperopt_kfold,lift,"{'alpha': 3.2776473039460963, 'colsample_bytree': 0.915199405541038, 'gamma': 2.405566646524979, 'lambda': 3.8098444767263437, 'learning_rate': 0.234992487251094, 'max_bin': 178, 'max_depth': 8, 'min_child_weight': 5, 'n_estimators': 1129, 'subsample': 0.7251171303335975, 'tree_method': 'hist', 'outer_params': {'hyperopt_evals': 50, 'validation_fraction': 0.15, 'early_stopping_rounds': 10, 'verbose': False}}",1.7197461036720043,0.050833514967808587,"{'recall': [0.7573260073260073, 0.7646520146520146, 0.7902930402930403, 0.7783882783882784, 0.7671860678276811], 'precision': [0.7129310344827586, 0.7185886402753873, 0.7050653594771242, 0.704225352112676, 0.7246753246753247], 'accuracy': [0.7141491395793499, 0.7208413001912046, 0.7179732313575525, 0.7136711281070746, 0.7264466762314682], 'f1': [0.7344582593250445, 0.7409050576752438, 0.7452504317789291, 0.7394519356241845, 0.7453250222617988], 'roc_auc': [0.79332326007326, 0.789103021978022, 0.7868891941391942, 0.7920430402930403, 0.803269019248396], 'area_under_pr': [0.7960098194702739, 0.7820623420406503, 0.7766150179671751, 0.7986188760153226, 0.7989678575686101], 'lift': [1.7507580139159085, 1.668261562998405, 1.649929018350071, 1.7782568308884097, 1.7515250922072285]}",./output/modelsaves/heloc/xgb/202310-0217-0845-b5a53099-4376-4e88-9906-0fe55eb48372//202310-0217-0845-b5a53099-4376-4e88-9906-0fe55eb48372,31.726662158966064
202310-0217-2810-13fe6a70-857a-4c81-ab07-46a72d2ccdd4,"{'dataset': 'ageconditions', 'model': 'node', 'best_params': {}, 'param_grid': {'batch_size': [32, 64, 128, 256], 'num_layers': [1, 2, 3], 'num_trees': [12, 128], 'additional_tree_output_dim': [2, 3, 4], 'depth': [5, 7], 'choice_function': ['entmax15', 'sparsemax'], 'bin_function': ['entmoid15', 'sparsemoid'], 'input_dropout': [0.0, 0.1], 'embedding_dropout': [0.0, 0.1], 'embed_categorical': [True, False], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",ageconditions,node,hyperopt_kfold,f1,"{'AdamW_weight_decay': 7.571029527428746e-05, 'Adam_weight_decay': 3.315799853711848e-05, 'ExponentialLR_gamma': 0.9220961598053498, 'ReduceLROnPlateau_factor': 0.4449473705421336, 'ReduceLROnPlateau_patience': 3, 'additional_tree_output_dim': 3, 'batch_size': 64, 'bin_function': 'sparsemoid', 'choice_function': 'entmax15', 'depth': 5, 'embed_categorical': False, 'embedding_dropout': 0.04638023542651057, 'input_dropout': 0.08720492260553112, 'num_layers': 1, 'num_trees': 122, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 5}}",0.7966835483357222,0.0933063259123575,"{'recall': [1.0, 0.9090909090909091, 0.8181818181818182, 0.7619047619047619, 0.9523809523809523], 'precision': [0.7333333333333333, 0.6666666666666666, 0.6428571428571429, 0.64, 0.9523809523809523], 'accuracy': [0.936, 0.904, 0.8870967741935484, 0.8870967741935484, 0.9838709677419355], 'f1': [0.846153846153846, 0.7692307692307692, 0.7200000000000001, 0.6956521739130435, 0.9523809523809523], 'roc_auc': [0.9748455428067079, 0.941747572815534, 0.9420677361853832, 0.9214054553860379, 0.9995376791493297], 'area_under_pr': [0.8758748849852203, 0.870384998779107, 0.7631822307271074, 0.7861756821946033, 0.997835497835498], 'lift': [5.208333333333333, 5.208333333333333, 4.696969696969697, 4.920634920634921, 5.904761904761905]}",./output/modelsaves/ageconditions/node/202310-0217-2810-13fe6a70-857a-4c81-ab07-46a72d2ccdd4//202310-0217-2810-13fe6a70-857a-4c81-ab07-46a72d2ccdd4,1102.7943742275238
202310-0219-2242-d0159178-dc3e-429d-9eac-c80a0f31e020,"{'dataset': 'titanic', 'model': 'autoint', 'best_params': {}, 'param_grid': {'batch_size': [32, 64, 128, 256], 'attn_embed_dim_multiplier': [2, 16], 'num_heads': [2, 8], 'num_attn_blocks': [2, 6], 'attn_dropouts': [0.0, 0.3], 'embedding_dim': [8, 32], 'embedding_initialization': ['kaiming_uniform', 'kaiming_normal'], 'embedding_bias': [True, False], 'share_embedding': [True, False], 'share_embedding_strategy': ['add', 'fraction'], 'shared_embedding_fraction': [0.25, 0.1, 0.5], 'deep_layers': [True, False], 'layers': ['128-64-32', '128-64-32-16', '256-128-64'], 'dropout': [0.0, 0.3], 'activation': ['ReLU', 'LeakyReLU'], 'initialization': ['kaiming', 'xavier'], 'attention_pooling': [True, False], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",titanic,autoint,hyperopt_kfold,roc_auc,"{'AdamW_weight_decay': 2.4443950301449195e-05, 'Adam_weight_decay': 8.37205239448477e-05, 'ExponentialLR_gamma': 0.9286181526711297, 'ReduceLROnPlateau_factor': 0.16395616097315774, 'ReduceLROnPlateau_patience': 3, 'activation': 'ReLU', 'attention_pooling': True, 'attn_dropouts': 0.22240027837880189, 'attn_embed_dim_multiplier': 9, 'batch_size': 132, 'deep_layers': False, 'dropout': 0.022829026620029925, 'embedding_bias': False, 'embedding_dim': 24, 'embedding_initialization': 'kaiming_normal', 'initialization': 'xavier', 'layers': '128-64-32', 'num_attn_blocks': 6, 'num_heads': 6, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'share_embedding': True, 'share_embedding_strategy': 'fraction', 'shared_embedding_fraction': 0.2632366301962227, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 16, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 5}}",0.867249140908131,0.019426577814893018,"{'recall': [0.782608695652174, 0.75, 0.7794117647058824, 0.7794117647058824, 0.8260869565217391], 'precision': [0.7297297297297297, 0.7611940298507462, 0.6883116883116883, 0.6883116883116883, 0.7125], 'accuracy': [0.8044692737430168, 0.8146067415730337, 0.7808988764044944, 0.7808988764044944, 0.8033707865168539], 'f1': [0.7552447552447553, 0.7555555555555554, 0.7310344827586206, 0.7310344827586206, 0.7651006711409397], 'roc_auc': [0.8861001317523056, 0.8776737967914437, 0.830548128342246, 0.866042780748663, 0.8758808669059964], 'area_under_pr': [0.86155782989211, 0.8466684329337787, 0.8010989322182832, 0.8638830182164704, 0.844734002095997], 'lift': [2.5942028985507246, 2.463667820069204, 2.6176470588235294, 2.6176470588235294, 2.4279624893435634]}",./output/modelsaves/titanic/autoint/202310-0219-2242-d0159178-dc3e-429d-9eac-c80a0f31e020//202310-0219-2242-d0159178-dc3e-429d-9eac-c80a0f31e020,1250.759554386139
202310-0217-4633-8bff7d61-90b7-4bf3-87f7-f3ea80cf3ea8,"{'dataset': 'adult', 'model': 'node', 'best_params': {}, 'param_grid': {'batch_size': [512, 1024], 'num_layers': [1, 2, 3], 'num_trees': [12, 128], 'additional_tree_output_dim': [2, 3, 4], 'depth': [5, 7], 'choice_function': ['entmax15', 'sparsemax'], 'bin_function': ['entmoid15', 'sparsemoid'], 'input_dropout': [0.0, 0.1], 'embedding_dropout': [0.0, 0.1], 'embed_categorical': [True, False], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",adult,node,hyperopt_kfold,roc_auc,"{'AdamW_weight_decay': 1.27949813443311e-05, 'Adam_weight_decay': 2.7063879965134595e-05, 'ExponentialLR_gamma': 0.9336709700436032, 'ReduceLROnPlateau_factor': 0.18096785081270378, 'ReduceLROnPlateau_patience': 3, 'additional_tree_output_dim': 2, 'batch_size': 859, 'bin_function': 'sparsemoid', 'choice_function': 'sparsemax', 'depth': 5, 'embed_categorical': True, 'embedding_dropout': 0.0720193989763807, 'input_dropout': 0.05264502798573829, 'num_layers': 3, 'num_trees': 60, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 5}}",0.915726879973643,0.001935032965512214,"{'recall': [0.8534098151688974, 0.8724489795918368, 0.8711734693877551, 0.8692602040816326, 0.8584183673469388], 'precision': [0.5799047206582937, 0.5733445096395641, 0.5812765957446808, 0.561598681499794, 0.581174438687392], 'accuracy': [0.8157531091662829, 0.812960687960688, 0.8178746928746928, 0.8051289926289926, 0.816953316953317], 'f1': [0.6905621454357916, 0.6919575113808801, 0.697294538029607, 0.6823529411764706, 0.6930998970133883], 'roc_auc': [0.9167747606848714, 0.9170247589326993, 0.9158622490258239, 0.9119522581484051, 0.9170203730764149], 'area_under_pr': [0.7989436636932374, 0.7859936243547884, 0.7869652564085591, 0.7847640863395224, 0.7988453251076907], 'lift': [3.704701988116532, 3.604423336154739, 3.6490799084610805, 3.6745979497789905, 3.751152073732719]}",./output/modelsaves/adult/node/202310-0217-4633-8bff7d61-90b7-4bf3-87f7-f3ea80cf3ea8//202310-0217-4633-8bff7d61-90b7-4bf3-87f7-f3ea80cf3ea8,7170.7167983055115
202310-0219-4333-b281db2b-3773-4039-9174-ec436c6b1ef9,"{'dataset': 'breastcancer', 'model': 'autoint', 'best_params': {}, 'param_grid': {'batch_size': [32, 64, 128, 256], 'attn_embed_dim_multiplier': [2, 16], 'num_heads': [2, 8], 'num_attn_blocks': [2, 6], 'attn_dropouts': [0.0, 0.3], 'embedding_dim': [8, 32], 'embedding_initialization': ['kaiming_uniform', 'kaiming_normal'], 'embedding_bias': [True, False], 'share_embedding': [True, False], 'share_embedding_strategy': ['add', 'fraction'], 'shared_embedding_fraction': [0.25, 0.1, 0.5], 'deep_layers': [True, False], 'layers': ['128-64-32', '128-64-32-16', '256-128-64'], 'dropout': [0.0, 0.3], 'activation': ['ReLU', 'LeakyReLU'], 'initialization': ['kaiming', 'xavier'], 'attention_pooling': [True, False], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",breastcancer,autoint,hyperopt_kfold,f1,"{'AdamW_weight_decay': 5.486693527282193e-05, 'Adam_weight_decay': 1.2460695957841637e-05, 'ExponentialLR_gamma': 0.9149241998344151, 'ReduceLROnPlateau_factor': 0.21793495386091802, 'ReduceLROnPlateau_patience': 4, 'activation': 'ReLU', 'attention_pooling': True, 'attn_dropouts': 0.18201398334209026, 'attn_embed_dim_multiplier': 12, 'batch_size': 102, 'deep_layers': False, 'dropout': 0.22216135597378683, 'embedding_bias': True, 'embedding_dim': 8, 'embedding_initialization': 'kaiming_uniform', 'initialization': 'xavier', 'layers': '256-128-64', 'num_attn_blocks': 4, 'num_heads': 2, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>, 'share_embedding': False, 'share_embedding_strategy': 'add', 'shared_embedding_fraction': 0.14263390291925862, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 16, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 5}}",0.9846338605542103,0.005162146241731895,"{'recall': [0.9859154929577465, 0.9859154929577465, 0.9861111111111112, 0.9722222222222222, 1.0], 'precision': [0.9722222222222222, 0.9859154929577465, 0.9726027397260274, 1.0, 0.9861111111111112], 'accuracy': [0.9736842105263158, 0.9824561403508771, 0.9736842105263158, 0.9824561403508771, 0.9911504424778761], 'f1': [0.979020979020979, 0.9859154929577465, 0.9793103448275863, 0.9859154929577464, 0.993006993006993], 'roc_auc': [0.9918113331149688, 0.9983622666229939, 0.9851190476190476, 0.9996693121693121, 0.9986586183769282], 'area_under_pr': [0.99449192816893, 0.9990504529524564, 0.9897246843325376, 0.9998097412480973, 0.9992006779740839], 'lift': [1.6056338028169013, 1.6056338028169013, 1.5833333333333335, 1.5833333333333335, 1.591549295774648]}",./output/modelsaves/breastcancer/autoint/202310-0219-4333-b281db2b-3773-4039-9174-ec436c6b1ef9//202310-0219-4333-b281db2b-3773-4039-9174-ec436c6b1ef9,999.7914414405823
202310-0219-2303-616a3a37-6b52-4c37-ae0c-4529ac83bcfa,"{'dataset': 'housing', 'model': 'categoryembedding', 'best_params': {}, 'param_grid': {'batch_size': [1024, 2048, 4096], 'layers': ['128-64-32', '128-64-32-16', '256-128-64'], 'activation': ['ReLU', 'LeakyReLU', 'Tanh'], 'initialization': ['kaiming', 'xavier'], 'dropout': [0.0, 0.3], 'embedding_dropout': [0.0, 0.3], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",housing,categoryembedding,hyperopt_kfold,r2_score,"{'AdamW_weight_decay': 9.267773189850353e-05, 'Adam_weight_decay': 4.101854042788317e-05, 'ExponentialLR_gamma': 0.9894511479894631, 'ReduceLROnPlateau_factor': 0.7986741176038994, 'ReduceLROnPlateau_patience': 5, 'activation': 'LeakyReLU', 'batch_size': 3328, 'dropout': 0.018818524494155442, 'embedding_dropout': 9.702881981838579e-05, 'initialization': 'kaiming', 'layers': '128-64-32', 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 16, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 5}}",0.6768259960495896,0.012900671198077272,"{'mse': [0.3537762638639207, 0.359386104183407, 0.3577301130028883, 0.34872462136327115, 0.342851242667137], 'rmse': [0.5837238864815232, 0.5872816582441363, 0.5795346503142765, 0.5918992855634923, 0.5809480995711759], 'r2_score': [0.7460165750966714, 0.7383061161034256, 0.7499462365608564, 0.7312768460149719, 0.7485842064720221]}",./output/modelsaves/housing/categoryembedding/202310-0219-2303-616a3a37-6b52-4c37-ae0c-4529ac83bcfa//202310-0219-2303-616a3a37-6b52-4c37-ae0c-4529ac83bcfa,5775.08614897728
202310-0219-4604-06f39b62-8c3d-4783-a9ed-cdb8622e2fa0,"{'dataset': 'housing', 'model': 'node', 'best_params': {}, 'param_grid': {'batch_size': [512, 1024], 'num_layers': [1, 2, 3], 'num_trees': [12, 128], 'additional_tree_output_dim': [2, 3, 4], 'depth': [5, 7], 'choice_function': ['entmax15', 'sparsemax'], 'bin_function': ['entmoid15', 'sparsemoid'], 'input_dropout': [0.0, 0.1], 'embedding_dropout': [0.0, 0.1], 'embed_categorical': [True, False], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",housing,node,hyperopt_kfold,r2_score,"{'AdamW_weight_decay': 5.186618528954418e-05, 'Adam_weight_decay': 1.907886579453724e-05, 'ExponentialLR_gamma': 0.9114313266624429, 'ReduceLROnPlateau_factor': 0.2039685372459998, 'ReduceLROnPlateau_patience': 3, 'additional_tree_output_dim': 4, 'batch_size': 792, 'bin_function': 'sparsemoid', 'choice_function': 'entmax15', 'depth': 7, 'embed_categorical': False, 'embedding_dropout': 0.002826630235855939, 'input_dropout': 0.056440961474163526, 'num_layers': 3, 'num_trees': 43, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 5}}",0.7655644193429781,0.014645777282761611,"{'mse': [0.29766848361477377, 0.3284346952024986, 0.3053202613979258, 0.2836530063766402, 0.3461019162072779], 'rmse': [0.5455900325471258, 0.5730922222491758, 0.5525579258303385, 0.5325908433090455, 0.5883042717907783], 'r2_score': [0.7728430676548281, 0.7595811972391702, 0.7653281539343865, 0.7872057609013869, 0.7428639169851188]}",./output/modelsaves/housing/node/202310-0219-4604-06f39b62-8c3d-4783-a9ed-cdb8622e2fa0//202310-0219-4604-06f39b62-8c3d-4783-a9ed-cdb8622e2fa0,7767.39023399353
202310-0220-5919-125a400d-d513-493e-8b65-7419cbb4003a,"{'dataset': 'heloc', 'model': 'categoryembedding', 'best_params': {}, 'param_grid': {'batch_size': [1024, 2048, 4096], 'layers': ['128-64-32', '128-64-32-16', '256-128-64'], 'activation': ['ReLU', 'LeakyReLU', 'Tanh'], 'initialization': ['kaiming', 'xavier'], 'dropout': [0.0, 0.3], 'embedding_dropout': [0.0, 0.3], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",heloc,categoryembedding,hyperopt_kfold,lift,"{'AdamW_weight_decay': 2.8600375073754828e-05, 'Adam_weight_decay': 5.18466552722249e-05, 'ExponentialLR_gamma': 0.9314269773258598, 'ReduceLROnPlateau_factor': 0.263302128968097, 'ReduceLROnPlateau_patience': 5, 'activation': 'LeakyReLU', 'batch_size': 3340, 'dropout': 0.1117978745920478, 'embedding_dropout': 0.04200572103617551, 'initialization': 'kaiming', 'layers': '256-128-64', 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 16, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 5}}",1.7124114793659875,0.023609101830857397,"{'recall': [0.7298534798534798, 0.7527472527472527, 0.6877289377289377, 0.6932234432234432, 0.6489459211732356], 'precision': [0.7225747960108794, 0.7300177619893428, 0.7341153470185728, 0.7363813229571985, 0.7612903225806451], 'accuracy': [0.7127151051625239, 0.7256214149139579, 0.7069789674952199, 0.7103250478011472, 0.7106647537063606], 'f1': [0.7261958997722096, 0.7412082957619476, 0.7101654846335698, 0.7141509433962265, 0.7006432459178624], 'roc_auc': [0.786430402930403, 0.7904606227106228, 0.7854606227106228, 0.783058608058608, 0.7954601283226398], 'area_under_pr': [0.7886856315016256, 0.7847599202413961, 0.7762639724383145, 0.790673769481528, 0.7916479417133514], 'lift': [1.7140929246192402, 1.7140929246192402, 1.668261562998405, 1.7324254692675742, 1.7331845153254772]}",./output/modelsaves/heloc/categoryembedding/202310-0220-5919-125a400d-d513-493e-8b65-7419cbb4003a//202310-0220-5919-125a400d-d513-493e-8b65-7419cbb4003a,3384.374784231186
202310-0221-5543-33de6074-526a-4b37-9123-622232f7f11e,"{'dataset': 'iris', 'model': 'categoryembedding', 'best_params': {}, 'param_grid': {'batch_size': [32, 64, 128, 256], 'layers': ['128-64-32', '128-64-32-16', '256-128-64'], 'activation': ['ReLU', 'LeakyReLU', 'Tanh'], 'initialization': ['kaiming', 'xavier'], 'dropout': [0.0, 0.3], 'embedding_dropout': [0.0, 0.3], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",iris,categoryembedding,hyperopt_kfold,accuracy,"{'AdamW_weight_decay': 2.0246689238073135e-05, 'Adam_weight_decay': 9.948983447892247e-05, 'ExponentialLR_gamma': 0.9200387567577661, 'ReduceLROnPlateau_factor': 0.13675996229292545, 'ReduceLROnPlateau_patience': 3, 'activation': 'Tanh', 'batch_size': 77, 'dropout': 0.16471739906539257, 'embedding_dropout': 0.0028456381146058918, 'initialization': 'xavier', 'layers': '256-128-64', 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 16, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 5}}",0.9733333333333334,0.02494438257849294,"{'accuracy': [1.0, 0.9666666666666667, 0.9333333333333333, 1.0, 0.9666666666666667], 'f1': [1.0, 0.9665831244778613, 0.9333333333333333, 1.0, 0.9665831244778613]}",./output/modelsaves/iris/categoryembedding/202310-0221-5543-33de6074-526a-4b37-9123-622232f7f11e//202310-0221-5543-33de6074-526a-4b37-9123-622232f7f11e,1200.0065491199493
202310-0222-1543-1e9a4998-b82b-48f0-91ca-3a9e6d2f2ae3,"{'dataset': 'breastcancer', 'model': 'categoryembedding', 'best_params': {}, 'param_grid': {'batch_size': [32, 64, 128, 256], 'layers': ['128-64-32', '128-64-32-16', '256-128-64'], 'activation': ['ReLU', 'LeakyReLU', 'Tanh'], 'initialization': ['kaiming', 'xavier'], 'dropout': [0.0, 0.3], 'embedding_dropout': [0.0, 0.3], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",breastcancer,categoryembedding,hyperopt_kfold,f1,"{'AdamW_weight_decay': 6.143575096803424e-05, 'Adam_weight_decay': 7.151591347942346e-05, 'ExponentialLR_gamma': 0.9557636066793738, 'ReduceLROnPlateau_factor': 0.8987718577363002, 'ReduceLROnPlateau_patience': 5, 'activation': 'Tanh', 'batch_size': 33, 'dropout': 0.047623411120878825, 'embedding_dropout': 0.16888113831912566, 'initialization': 'kaiming', 'layers': '128-64-32', 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 16, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 5}}",0.9888488272632836,0.005552154467889063,"{'recall': [0.9859154929577465, 0.9859154929577465, 1.0, 0.9861111111111112, 1.0], 'precision': [1.0, 0.9722222222222222, 0.972972972972973, 1.0, 0.9861111111111112], 'accuracy': [0.9912280701754386, 0.9736842105263158, 0.9824561403508771, 0.9912280701754386, 0.9911504424778761], 'f1': [0.9929078014184397, 0.979020979020979, 0.9863013698630138, 0.993006993006993, 0.993006993006993], 'roc_auc': [0.9993449066491975, 0.9963969865705863, 0.9897486772486772, 1.0, 0.9983232729711603], 'area_under_pr': [0.9996141230947329, 0.9978814604456268, 0.9927765179560343, 1.0, 0.9989935528705214], 'lift': [1.6056338028169013, 1.6056338028169013, 1.5833333333333335, 1.5833333333333335, 1.591549295774648]}",./output/modelsaves/breastcancer/categoryembedding/202310-0222-1543-1e9a4998-b82b-48f0-91ca-3a9e6d2f2ae3//202310-0222-1543-1e9a4998-b82b-48f0-91ca-3a9e6d2f2ae3,1066.2011215686798
202310-0222-3329-d83d7801-dc1f-4e96-bae7-204063c288d2,"{'dataset': 'titanic', 'model': 'categoryembedding', 'best_params': {}, 'param_grid': {'batch_size': [32, 64, 128, 256], 'layers': ['128-64-32', '128-64-32-16', '256-128-64'], 'activation': ['ReLU', 'LeakyReLU', 'Tanh'], 'initialization': ['kaiming', 'xavier'], 'dropout': [0.0, 0.3], 'embedding_dropout': [0.0, 0.3], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",titanic,categoryembedding,hyperopt_kfold,roc_auc,"{'AdamW_weight_decay': 6.984117601648357e-05, 'Adam_weight_decay': 2.841101080790893e-05, 'ExponentialLR_gamma': 0.9418848645492701, 'ReduceLROnPlateau_factor': 0.7114874278295789, 'ReduceLROnPlateau_patience': 3, 'activation': 'Tanh', 'batch_size': 58, 'dropout': 0.07604384843283163, 'embedding_dropout': 0.0467465519436529, 'initialization': 'kaiming', 'layers': '256-128-64', 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 16, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 5}}",0.8784135667901711,0.027037444707582913,"{'recall': [0.7681159420289855, 0.7352941176470589, 0.7205882352941176, 0.7647058823529411, 0.8405797101449275], 'precision': [0.7910447761194029, 0.746268656716418, 0.7101449275362319, 0.7536231884057971, 0.7435897435897436], 'accuracy': [0.8324022346368715, 0.8033707865168539, 0.7808988764044944, 0.8146067415730337, 0.8258426966292135], 'f1': [0.7794117647058824, 0.7407407407407408, 0.7153284671532847, 0.759124087591241, 0.7891156462585034], 'roc_auc': [0.9138998682476943, 0.8815508021390375, 0.8301470588235295, 0.8810160427807489, 0.8854540619598457], 'area_under_pr': [0.8734210179882217, 0.8670786871529547, 0.8134759052459998, 0.8737127398081815, 0.864155065181826], 'lift': [2.441602728047741, 2.6176470588235294, 2.6176470588235294, 2.6176470588235294, 2.579710144927536]}",./output/modelsaves/titanic/categoryembedding/202310-0222-3329-d83d7801-dc1f-4e96-bae7-204063c288d2//202310-0222-3329-d83d7801-dc1f-4e96-bae7-204063c288d2,1664.3516597747803
202310-0223-5410-f0489c68-6427-4c26-b370-18e6a3d6bf98,"{'dataset': 'ageconditions', 'model': 'categoryembedding', 'best_params': {}, 'param_grid': {'batch_size': [32, 64, 128, 256], 'layers': ['128-64-32', '128-64-32-16', '256-128-64'], 'activation': ['ReLU', 'LeakyReLU', 'Tanh'], 'initialization': ['kaiming', 'xavier'], 'dropout': [0.0, 0.3], 'embedding_dropout': [0.0, 0.3], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",ageconditions,categoryembedding,hyperopt_kfold,f1,"{'AdamW_weight_decay': 1.7981187137084847e-05, 'Adam_weight_decay': 8.157566866520748e-05, 'ExponentialLR_gamma': 0.9590657419134175, 'ReduceLROnPlateau_factor': 0.25566787927439555, 'ReduceLROnPlateau_patience': 3, 'activation': 'Tanh', 'batch_size': 121, 'dropout': 0.06672592034623645, 'embedding_dropout': 0.23762224361966366, 'initialization': 'kaiming', 'layers': '128-64-32', 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 16, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 5}}",0.7233581190602126,0.0603934543865453,"{'recall': [0.8181818181818182, 0.8181818181818182, 0.7272727272727273, 0.8095238095238095, 0.9047619047619048], 'precision': [0.6428571428571429, 0.5, 0.7619047619047619, 0.6538461538461539, 0.7307692307692307], 'accuracy': [0.888, 0.824, 0.9112903225806451, 0.8951612903225806, 0.9274193548387096], 'f1': [0.7200000000000001, 0.6206896551724137, 0.7441860465116279, 0.7234042553191489, 0.8085106382978723], 'roc_auc': [0.944395410414828, 0.8729037952338924, 0.9237967914438503, 0.8700878409616273, 0.975959315765141], 'area_under_pr': [0.7101954211553145, 0.6763698774627889, 0.6780947285482426, 0.7303138964033935, 0.9217789738041984], 'lift': [4.261363636363637, 3.787878787878788, 4.227272727272727, 4.920634920634921, 5.904761904761905]}",./output/modelsaves/ageconditions/categoryembedding/202310-0223-5410-f0489c68-6427-4c26-b370-18e6a3d6bf98//202310-0223-5410-f0489c68-6427-4c26-b370-18e6a3d6bf98,658.5808384418488
202310-0300-0508-c62e0048-56d8-4e0c-9fcd-ead46c79dbf6,"{'dataset': 'diabetes', 'model': 'categoryembedding', 'best_params': {}, 'param_grid': {'batch_size': [1024, 2048, 4096], 'layers': ['128-64-32', '128-64-32-16', '256-128-64'], 'activation': ['ReLU', 'LeakyReLU', 'Tanh'], 'initialization': ['kaiming', 'xavier'], 'dropout': [0.0, 0.3], 'embedding_dropout': [0.0, 0.3], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",diabetes,categoryembedding,hyperopt_kfold,lift,"{'AdamW_weight_decay': 2.499971717191055e-05, 'Adam_weight_decay': 8.55197246787361e-05, 'ExponentialLR_gamma': 0.9125645344689168, 'ReduceLROnPlateau_factor': 0.7513709206124669, 'ReduceLROnPlateau_patience': 3, 'activation': 'LeakyReLU', 'batch_size': 1379, 'dropout': 0.16206704145201048, 'embedding_dropout': 0.01456836751400122, 'initialization': 'xavier', 'layers': '256-128-64', 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 16, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 5}}",2.461435759772783,0.08163776387548663,"{'recall': [0.5999119718309859, 0.615147512109203, 0.5970937912813739, 0.647732276530163, 0.6205985915492958], 'precision': [0.17550862734998712, 0.17949376846974174, 0.18072770891643342, 0.17480689245395128, 0.17128279883381925], 'accuracy': [0.6407585732534146, 0.6432958286247727, 0.6530241242077335, 0.6195155505330909, 0.6224635188915639], 'f1': [0.2715680414425184, 0.2778993435448578, 0.27747084100675257, 0.27531349429159646, 0.2684691546077685], 'roc_auc': [0.6758218209962128, 0.6888026029081957, 0.6771315915835445, 0.680225014368956, 0.67228373872737], 'area_under_pr': [0.22811664849400243, 0.2401881755953904, 0.22174114860455846, 0.23139962665107158, 0.21586575441480754], 'lift': [2.3992391078658684, 2.607165445738761, 2.4221976269532415, 2.4926615579191536, 2.3859150603868917]}",./output/modelsaves/diabetes/categoryembedding/202310-0300-0508-c62e0048-56d8-4e0c-9fcd-ead46c79dbf6//202310-0300-0508-c62e0048-56d8-4e0c-9fcd-ead46c79dbf6,17815.721475839615
202310-0223-5323-65f9477d-27cb-408a-bc85-1835ccfbbc4d,"{'dataset': 'iris', 'model': 'gate', 'best_params': {}, 'param_grid': {'batch_size': [32, 64, 128, 256], 'tree_depth': [4, 7], 'num_trees': [4, 10], 'chain_trees': [False, True], 'gflu_stages': [3, 8], 'gflu_dropout': [0.0, 0.05], 'tree_dropout': [0.0, 0.05], 'tree_wise_attention_dropout': [0.0, 0.05], 'embedding_dropout': [0, 0.2], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",iris,gate,hyperopt_kfold,accuracy,"{'AdamW_weight_decay': 3.2968002746028435e-05, 'Adam_weight_decay': 1.966691046661326e-05, 'ExponentialLR_gamma': 0.9092726596465195, 'ReduceLROnPlateau_factor': 0.3982410911468566, 'ReduceLROnPlateau_patience': 3, 'batch_size': 61, 'chain_trees': True, 'embedding_dropout': 0, 'gflu_dropout': 0.03418410755502854, 'gflu_stages': 4, 'num_trees': 6, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'tree_depth': 5, 'tree_dropout': 0.03161397071527924, 'tree_wise_attention_dropout': 0.0451658763200941, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 5}}",0.9666666666666668,0.04216370213557838,"{'accuracy': [1.0, 1.0, 0.9333333333333333, 1.0, 0.9], 'f1': [1.0, 1.0, 0.9333333333333333, 1.0, 0.8997493734335841]}",./output/modelsaves/iris/gate/202310-0223-5323-65f9477d-27cb-408a-bc85-1835ccfbbc4d//202310-0223-5323-65f9477d-27cb-408a-bc85-1835ccfbbc4d,19163.96044611931
202310-0223-5357-4e0e8986-d45a-46df-8bd8-7a63836f2d3e,"{'dataset': 'diabetes', 'model': 'autoint', 'best_params': {}, 'param_grid': {'batch_size': [1024, 2048, 4096], 'attn_embed_dim_multiplier': [2, 16], 'num_heads': [2, 8], 'num_attn_blocks': [2, 6], 'attn_dropouts': [0.0, 0.3], 'embedding_dim': [8, 32], 'embedding_initialization': ['kaiming_uniform', 'kaiming_normal'], 'embedding_bias': [True, False], 'share_embedding': [True, False], 'share_embedding_strategy': ['add', 'fraction'], 'shared_embedding_fraction': [0.25, 0.1, 0.5], 'deep_layers': [True, False], 'layers': ['128-64-32', '128-64-32-16', '256-128-64'], 'dropout': [0.0, 0.3], 'activation': ['ReLU', 'LeakyReLU'], 'initialization': ['kaiming', 'xavier'], 'attention_pooling': [True, False], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",diabetes,autoint,hyperopt_kfold,lift,"{'AdamW_weight_decay': 7.488898991164218e-05, 'Adam_weight_decay': 9.532495629140001e-05, 'ExponentialLR_gamma': 0.9561703066841265, 'ReduceLROnPlateau_factor': 0.16898955618453693, 'ReduceLROnPlateau_patience': 5, 'activation': 'ReLU', 'attention_pooling': True, 'attn_dropouts': 0.09646786520238941, 'attn_embed_dim_multiplier': 10, 'batch_size': 3339, 'deep_layers': False, 'dropout': 0.2543627780032219, 'embedding_bias': False, 'embedding_dim': 29, 'embedding_initialization': 'kaiming_uniform', 'initialization': 'kaiming', 'layers': '128-64-32', 'num_attn_blocks': 6, 'num_heads': 5, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>, 'share_embedding': False, 'share_embedding_strategy': 'fraction', 'shared_embedding_fraction': 0.4033813001112184, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 16, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 5}}",2.3945131130645207,0.10321623299401805,"{'recall': [0.5704225352112676, 0.6243945398502863, 0.6142668428005285, 0.6340819022457067, 0.596830985915493], 'precision': [0.17407656145063802, 0.17951639448031395, 0.17640364188163885, 0.16840135656648345, 0.1752843846949328], 'accuracy': [0.6499459565687334, 0.6396600009826561, 0.6369576966540559, 0.6097872549501302, 0.641527047609689], 'f1': [0.2667489966038901, 0.27885939036381513, 0.27409372236958446, 0.2661245610792829, 0.27098321342925663], 'roc_auc': [0.6685209037935165, 0.687926426561789, 0.675831725242475, 0.6787115679435008, 0.6661469251046347], 'area_under_pr': [0.2070585913143494, 0.23520629111798647, 0.21257433356463667, 0.2277293065012294, 0.20587193735251413], 'lift': [2.3067913624251655, 2.519085532031371, 2.3781576700995455, 2.5058735449752625, 2.262657455791259]}",./output/modelsaves/diabetes/autoint/202310-0223-5357-4e0e8986-d45a-46df-8bd8-7a63836f2d3e//202310-0223-5357-4e0e8986-d45a-46df-8bd8-7a63836f2d3e,23064.881199359894
202310-0309-2839-643113dd-b54f-4f58-8a0c-5bc7c907d033,"{'dataset': 'iris', 'model': 'autoint', 'best_params': {}, 'param_grid': {'batch_size': [32, 64, 128, 256], 'attn_embed_dim_multiplier': [2, 16], 'num_heads': [2, 8], 'num_attn_blocks': [2, 6], 'attn_dropouts': [0.0, 0.3], 'embedding_dim': [8, 32], 'embedding_initialization': ['kaiming_uniform', 'kaiming_normal'], 'embedding_bias': [True, False], 'share_embedding': [True, False], 'share_embedding_strategy': ['add', 'fraction'], 'shared_embedding_fraction': [0.25, 0.1, 0.5], 'deep_layers': [True, False], 'layers': ['128-64-32', '128-64-32-16', '256-128-64'], 'dropout': [0.0, 0.3], 'activation': ['ReLU', 'LeakyReLU'], 'initialization': ['kaiming', 'xavier'], 'attention_pooling': [True, False], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",iris,autoint,hyperopt_kfold,accuracy,"{'AdamW_weight_decay': 3.384519911050485e-05, 'Adam_weight_decay': 1.4974033595997699e-05, 'ExponentialLR_gamma': 0.9894246271868206, 'ReduceLROnPlateau_factor': 0.10057436825325987, 'ReduceLROnPlateau_patience': 3, 'activation': 'LeakyReLU', 'attention_pooling': True, 'attn_dropouts': 0.06645147850346317, 'attn_embed_dim_multiplier': 15, 'batch_size': 156, 'deep_layers': False, 'dropout': 0.298754236239731, 'embedding_bias': True, 'embedding_dim': 29, 'embedding_initialization': 'kaiming_uniform', 'initialization': 'kaiming', 'layers': '128-64-32', 'num_attn_blocks': 2, 'num_heads': 3, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'share_embedding': False, 'share_embedding_strategy': 'fraction', 'shared_embedding_fraction': 0.1779356178255116, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 16, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 10}}",0.9866666666666667,0.016329931618554516,"{'accuracy': [1.0, 1.0, 0.9666666666666667, 1.0, 0.9666666666666667], 'f1': [1.0, 1.0, 0.9665831244778613, 1.0, 0.9665831244778613]}",./output/modelsaves/iris/autoint/202310-0309-2839-643113dd-b54f-4f58-8a0c-5bc7c907d033//202310-0309-2839-643113dd-b54f-4f58-8a0c-5bc7c907d033,798.458010673523
202310-0310-3443-4141fa35-3208-466e-b908-ee364e5c2eba,"{'dataset': 'iris', 'model': 'mlp', 'best_params': {}, 'param_grid': {'hidden_layer_sizes': [[64, 32, 16], [256, 128, 64, 32], [128, 64, 32, 16]], 'activation': ['relu', 'tanh', 'logistic'], 'solver': ['adam', 'lbfgs'], 'alpha': [0.0001, 0.001, 0.01], 'learning_rate_init': [0.0001, 0.01, 0.1], 'beta_1': [0.99, 0.8], 'beta_2': [0.999, 0.9], 'batch_size': [32, 64, 128, 256]}}",iris,mlp,hyperopt_kfold,accuracy,"{'activation': 'logistic', 'alpha': 0.000389485243183445, 'batch_size': 90, 'beta_1': 0.937898354378537, 'beta_2': 0.9172069184676471, 'hidden_layer_sizes': (128, 64, 32, 16), 'learning_rate_init': 0.007885663539250777, 'solver': 'lbfgs', 'outer_params': {'cv_iterations': 10, 'early_stopping': True, 'cv_size': 5, 'validation_fraction': 0.15, 'hyperopt_evals': 50, 'n_iter_no_change': 50, 'max_iter': 1000}}",0.9666666666666668,0.04216370213557838,"{'accuracy': [1.0, 1.0, 0.9333333333333333, 1.0, 0.9], 'f1': [1.0, 1.0, 0.9326599326599326, 1.0, 0.8997493734335841]}",./output/modelsaves/iris/mlp/202310-0310-3443-4141fa35-3208-466e-b908-ee364e5c2eba//202310-0310-3443-4141fa35-3208-466e-b908-ee364e5c2eba,607.7544503211975
202310-0310-3506-f6ce2aa0-5c7d-4dfd-bf71-a224dfe49ebd,"{'dataset': 'iris', 'model': 'tabtransformer', 'best_params': {}, 'param_grid': {'batch_size': [32, 64, 128, 256], 'embedding_bias': [True, False], 'embedding_initialization': ['kaiming_uniform', 'kaiming_normal'], 'shared_embedding_fraction': [0.125, 0.25, 0.5], 'num_attn_blocks': [4, 10], 'attn_dropout': [0.05, 0.3], 'add_norm_dropout': [0.05, 0.3], 'ff_dropout': [0.05, 0.3], 'ff_hidden_multiplier': [2, 6], 'transformer_activation': ['GEGLU', 'ReGLU', 'SwiGLU'], 'embedding_dropout': [0.05, 0.3], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",iris,tabtransformer,hyperopt_kfold,accuracy,"{'AdamW_weight_decay': 4.501295593182965e-05, 'Adam_weight_decay': 1.3537853615885958e-05, 'ExponentialLR_gamma': 0.9581919041275976, 'ReduceLROnPlateau_factor': 0.8933492167570437, 'ReduceLROnPlateau_patience': 5, 'add_norm_dropout': 0.09962503335511823, 'attn_dropout': 0.2997684118802012, 'batch_size': 79, 'embedding_bias': True, 'embedding_dropout': 0.06475383150617227, 'embedding_initialization': 'kaiming_normal', 'ff_dropout': 0.10021608395860351, 'ff_hidden_multiplier': 5, 'num_attn_blocks': 6, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'shared_embedding_fraction': 0.3724047047208797, 'transformer_activation': 'ReGLU', 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 16, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 10}}",0.9800000000000001,0.039999999999999994,"{'accuracy': [1.0, 1.0, 0.9, 1.0, 1.0], 'f1': [1.0, 1.0, 0.8997493734335841, 1.0, 1.0]}",./output/modelsaves/iris/tabtransformer/202310-0310-3506-f6ce2aa0-5c7d-4dfd-bf71-a224dfe49ebd//202310-0310-3506-f6ce2aa0-5c7d-4dfd-bf71-a224dfe49ebd,2143.196766614914
202310-0310-4450-cb39941c-66ee-4d48-bf25-d64e3261ac93,"{'dataset': 'titanic', 'model': 'mlp', 'best_params': {}, 'param_grid': {'hidden_layer_sizes': [[64, 32, 16], [256, 128, 64, 32], [128, 64, 32, 16]], 'activation': ['relu', 'tanh', 'logistic'], 'solver': ['adam', 'lbfgs'], 'alpha': [0.0001, 0.001, 0.01], 'learning_rate_init': [0.0001, 0.01, 0.1], 'beta_1': [0.99, 0.8], 'beta_2': [0.999, 0.9], 'batch_size': [32, 64, 128, 256]}}",titanic,mlp,hyperopt_kfold,roc_auc,"{'activation': 'relu', 'alpha': 0.0018455106400832948, 'batch_size': 178, 'beta_1': 0.8268211938633007, 'beta_2': 0.9772142825985788, 'hidden_layer_sizes': (256, 128, 64, 32), 'learning_rate_init': 0.014430586073715404, 'solver': 'adam', 'outer_params': {'cv_iterations': 10, 'early_stopping': True, 'cv_size': 5, 'validation_fraction': 0.15, 'hyperopt_evals': 50, 'n_iter_no_change': 50, 'max_iter': 1000}}",0.8590203739689297,0.004392224981033241,"{'recall': [0.7536231884057971, 0.6911764705882353, 0.6911764705882353, 0.7058823529411765, 0.6376811594202898], 'precision': [0.8253968253968254, 0.7704918032786885, 0.7230769230769231, 0.9056603773584906, 0.8979591836734694], 'accuracy': [0.8435754189944135, 0.8033707865168539, 0.7808988764044944, 0.8595505617977528, 0.8314606741573034], 'f1': [0.787878787878788, 0.7286821705426356, 0.7067669172932332, 0.7933884297520662, 0.7457627118644068], 'roc_auc': [0.8606719367588933, 0.8593582887700536, 0.851403743315508, 0.8586898395721925, 0.8649780614280016], 'area_under_pr': [0.8344926351127062, 0.8299462133652511, 0.8126987441690949, 0.8622806689824828, 0.8671321198748098], 'lift': [2.441602728047741, 2.463667820069204, 2.463667820069204, 2.6176470588235294, 2.579710144927536]}",./output/modelsaves/titanic/mlp/202310-0310-4450-cb39941c-66ee-4d48-bf25-d64e3261ac93//202310-0310-4450-cb39941c-66ee-4d48-bf25-d64e3261ac93,2926.2042891979218
202310-0311-3337-e5f9ede4-3f87-4cec-8b52-9e2abbd2c4f9,"{'dataset': 'breastcancer', 'model': 'mlp', 'best_params': {}, 'param_grid': {'hidden_layer_sizes': [[64, 32, 16], [256, 128, 64, 32], [128, 64, 32, 16]], 'activation': ['relu', 'tanh', 'logistic'], 'solver': ['adam', 'lbfgs'], 'alpha': [0.0001, 0.001, 0.01], 'learning_rate_init': [0.0001, 0.01, 0.1], 'beta_1': [0.99, 0.8], 'beta_2': [0.999, 0.9], 'batch_size': [32, 64, 128, 256]}}",breastcancer,mlp,hyperopt_kfold,f1,"{'activation': 'tanh', 'alpha': 0.0007672874280294561, 'batch_size': 206, 'beta_1': 0.848283211273961, 'beta_2': 0.989039761781936, 'hidden_layer_sizes': (64, 32, 16), 'learning_rate_init': 0.029570110933299608, 'solver': 'adam', 'outer_params': {'cv_iterations': 10, 'early_stopping': True, 'cv_size': 5, 'validation_fraction': 0.15, 'hyperopt_evals': 50, 'n_iter_no_change': 50, 'max_iter': 1000}}",0.9847096732407138,0.009166628650812088,"{'recall': [0.971830985915493, 1.0, 0.9861111111111112, 1.0, 1.0], 'precision': [0.9857142857142858, 0.9726027397260274, 0.9594594594594594, 1.0, 0.9726027397260274], 'accuracy': [0.9736842105263158, 0.9824561403508771, 0.9649122807017544, 1.0, 0.9823008849557522], 'f1': [0.9787234042553192, 0.9861111111111112, 0.9726027397260274, 1.0, 0.9861111111111112], 'roc_auc': [0.9990173599737963, 0.9977071732721913, 0.9874338624338624, 1.0, 0.9986586183769282], 'area_under_pr': [0.9994048012645513, 0.9985930775955999, 0.9913970928140821, 1.0, 0.9992006779740839], 'lift': [1.6056338028169013, 1.6056338028169013, 1.5833333333333335, 1.5833333333333335, 1.591549295774648]}",./output/modelsaves/breastcancer/mlp/202310-0311-3337-e5f9ede4-3f87-4cec-8b52-9e2abbd2c4f9//202310-0311-3337-e5f9ede4-3f87-4cec-8b52-9e2abbd2c4f9,585.4486622810364
202310-0311-4322-ff2a1a0c-31e0-48a0-8737-65e163cc5c6d,"{'dataset': 'ageconditions', 'model': 'mlp', 'best_params': {}, 'param_grid': {'hidden_layer_sizes': [[64, 32, 16], [256, 128, 64, 32], [128, 64, 32, 16]], 'activation': ['relu', 'tanh', 'logistic'], 'solver': ['adam', 'lbfgs'], 'alpha': [0.0001, 0.001, 0.01], 'learning_rate_init': [0.0001, 0.01, 0.1], 'beta_1': [0.99, 0.8], 'beta_2': [0.999, 0.9], 'batch_size': [32, 64, 128, 256]}}",ageconditions,mlp,hyperopt_kfold,f1,"{'activation': 'relu', 'alpha': 0.008849613009500636, 'batch_size': 102, 'beta_1': 0.8216644291014927, 'beta_2': 0.9981832607828609, 'hidden_layer_sizes': (256, 128, 64, 32), 'learning_rate_init': 0.0014959558488456285, 'solver': 'lbfgs', 'outer_params': {'cv_iterations': 10, 'early_stopping': True, 'cv_size': 5, 'validation_fraction': 0.15, 'hyperopt_evals': 50, 'n_iter_no_change': 50, 'max_iter': 1000}}",0.7269037195866463,0.08297132982277314,"{'recall': [0.7727272727272727, 0.6363636363636364, 0.5, 0.6666666666666666, 0.8095238095238095], 'precision': [0.85, 0.8235294117647058, 0.7857142857142857, 0.6666666666666666, 0.85], 'accuracy': [0.936, 0.912, 0.8870967741935484, 0.8870967741935484, 0.9435483870967742], 'f1': [0.8095238095238095, 0.717948717948718, 0.6111111111111112, 0.6666666666666666, 0.8292682926829269], 'roc_auc': [0.9417475728155341, 0.9024713150926743, 0.9099821746880571, 0.9251040221914009, 0.9389736477115118], 'area_under_pr': [0.8854978939220826, 0.7872614108452312, 0.7340773327978283, 0.7128059258497605, 0.9002287464693481], 'lift': [5.6818181818181825, 5.208333333333333, 4.227272727272727, 4.428571428571429, 5.904761904761905]}",./output/modelsaves/ageconditions/mlp/202310-0311-4322-ff2a1a0c-31e0-48a0-8737-65e163cc5c6d//202310-0311-4322-ff2a1a0c-31e0-48a0-8737-65e163cc5c6d,636.4119343757629
202310-0311-5359-173fb7e9-62c4-4bb8-82b8-f95a566cb4f6,"{'dataset': 'iris', 'model': 'tabnet', 'best_params': {}, 'param_grid': {'virtual_batch_size_ratio': [0.125, 0.25, 0.5, 1.0], 'batch_size': [32, 64, 128, 256], 'weights': [0, 1], 'mask_type': ['sparsemax', 'entmax'], 'n_d': [6, 32], 'n_steps': [1, 6], 'gamma': [1.0, 2.0], 'n_independent': [1, 3], 'n_shared': [1, 3], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",iris,tabnet,hyperopt_kfold,accuracy,"{'AdamW_weight_decay': 5.156738931047346e-05, 'Adam_weight_decay': 2.43561878417932e-05, 'ExponentialLR_gamma': 0.9366847077963721, 'ReduceLROnPlateau_factor': 0.6919985644348331, 'ReduceLROnPlateau_patience': 4, 'batch_size': 37, 'gamma': 1.9360362856903945, 'mask_type': 'sparsemax', 'n_d': 20, 'n_independent': 1, 'n_shared': 3, 'n_steps': 4, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>, 'virtual_batch_size_ratio': 0.25, 'weights': 0, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 16, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 10}}",0.9733333333333334,0.03265986323710903,"{'accuracy': [1.0, 1.0, 0.9333333333333333, 1.0, 0.9333333333333333], 'f1': [1.0, 1.0, 0.9333333333333333, 1.0, 0.9326599326599326]}",./output/modelsaves/iris/tabnet/202310-0311-5359-173fb7e9-62c4-4bb8-82b8-f95a566cb4f6//202310-0311-5359-173fb7e9-62c4-4bb8-82b8-f95a566cb4f6,3812.544846534729
202310-0311-1050-9b5dfdeb-3cf2-49e3-aecc-616412b18282,"{'dataset': 'titanic', 'model': 'tabtransformer', 'best_params': {}, 'param_grid': {'batch_size': [32, 64, 128, 256], 'embedding_bias': [True, False], 'embedding_initialization': ['kaiming_uniform', 'kaiming_normal'], 'shared_embedding_fraction': [0.125, 0.25, 0.5], 'num_attn_blocks': [4, 10], 'attn_dropout': [0.05, 0.3], 'add_norm_dropout': [0.05, 0.3], 'ff_dropout': [0.05, 0.3], 'ff_hidden_multiplier': [2, 6], 'transformer_activation': ['GEGLU', 'ReGLU', 'SwiGLU'], 'embedding_dropout': [0.05, 0.3], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",titanic,tabtransformer,hyperopt_kfold,roc_auc,"{'AdamW_weight_decay': 1.0281135416111879e-05, 'Adam_weight_decay': 1.2289218851195555e-05, 'ExponentialLR_gamma': 0.9483345950379792, 'ReduceLROnPlateau_factor': 0.24308397638652002, 'ReduceLROnPlateau_patience': 4, 'add_norm_dropout': 0.08608177924350335, 'attn_dropout': 0.10353529201125497, 'batch_size': 162, 'embedding_bias': True, 'embedding_dropout': 0.14718073364490872, 'embedding_initialization': 'kaiming_uniform', 'ff_dropout': 0.1068111369597474, 'ff_hidden_multiplier': 6, 'num_attn_blocks': 7, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>, 'shared_embedding_fraction': 0.24178469855688012, 'transformer_activation': 'GEGLU', 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 16, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 10}}",0.8556348143202597,0.015616554341066636,"{'recall': [0.7101449275362319, 0.7058823529411765, 0.6176470588235294, 0.6617647058823529, 0.8115942028985508], 'precision': [0.7101449275362319, 0.7058823529411765, 0.7241379310344828, 0.8035714285714286, 0.7368421052631579], 'accuracy': [0.776536312849162, 0.7752808988764045, 0.7640449438202247, 0.8089887640449438, 0.8146067415730337], 'f1': [0.7101449275362319, 0.7058823529411765, 0.6666666666666667, 0.7258064516129031, 0.7724137931034482], 'roc_auc': [0.8643610013175229, 0.8429812834224599, 0.8424465240641711, 0.8459893048128341, 0.8823959579843107], 'area_under_pr': [0.8203841518485278, 0.8159583054849707, 0.8120803723287817, 0.8444825137423904, 0.8413720379157963], 'lift': [2.289002557544757, 2.6176470588235294, 2.6176470588235294, 2.6176470588235294, 2.4279624893435634]}",./output/modelsaves/titanic/tabtransformer/202310-0311-1050-9b5dfdeb-3cf2-49e3-aecc-616412b18282//202310-0311-1050-9b5dfdeb-3cf2-49e3-aecc-616412b18282,6553.09139418602
202310-0313-0003-5828de04-bef6-459a-8597-6502b05b4188,"{'dataset': 'breastcancer', 'model': 'tabtransformer', 'best_params': {}, 'param_grid': {'batch_size': [32, 64, 128, 256], 'embedding_bias': [True, False], 'embedding_initialization': ['kaiming_uniform', 'kaiming_normal'], 'shared_embedding_fraction': [0.125, 0.25, 0.5], 'num_attn_blocks': [4, 10], 'attn_dropout': [0.05, 0.3], 'add_norm_dropout': [0.05, 0.3], 'ff_dropout': [0.05, 0.3], 'ff_hidden_multiplier': [2, 6], 'transformer_activation': ['GEGLU', 'ReGLU', 'SwiGLU'], 'embedding_dropout': [0.05, 0.3], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",breastcancer,tabtransformer,hyperopt_kfold,f1,"{'AdamW_weight_decay': 1.4983299066774802e-05, 'Adam_weight_decay': 3.3050480558396946e-05, 'ExponentialLR_gamma': 0.9771603545076043, 'ReduceLROnPlateau_factor': 0.1241198877593532, 'ReduceLROnPlateau_patience': 5, 'add_norm_dropout': 0.1900878635483734, 'attn_dropout': 0.0828385433406772, 'batch_size': 47, 'embedding_bias': True, 'embedding_dropout': 0.0987593348393527, 'embedding_initialization': 'kaiming_uniform', 'ff_dropout': 0.12593431858971033, 'ff_hidden_multiplier': 5, 'num_attn_blocks': 10, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>, 'shared_embedding_fraction': 0.2488767287123551, 'transformer_activation': 'GEGLU', 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 16, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 10}}",0.9875066527866085,0.005084992716339378,"{'recall': [1.0, 0.9859154929577465, 1.0, 1.0, 0.9859154929577465], 'precision': [0.9861111111111112, 0.9859154929577465, 0.96, 0.9863013698630136, 0.9859154929577465], 'accuracy': [0.9912280701754386, 0.9824561403508771, 0.9736842105263158, 0.9912280701754386, 0.9823008849557522], 'f1': [0.993006993006993, 0.9859154929577465, 0.9795918367346939, 0.993103448275862, 0.9859154929577465], 'roc_auc': [0.9996724533245988, 0.9977071732721913, 0.9871031746031745, 1.0, 0.9989939637826961], 'area_under_pr': [0.9998043818466351, 0.9987041326061361, 0.9907106454015269, 0.9999999999999999, 0.9994048012645511], 'lift': [1.6056338028169013, 1.6056338028169013, 1.5833333333333335, 1.5833333333333335, 1.591549295774648]}",./output/modelsaves/breastcancer/tabtransformer/202310-0313-0003-5828de04-bef6-459a-8597-6502b05b4188//202310-0313-0003-5828de04-bef6-459a-8597-6502b05b4188,1078.7344937324524
202310-0305-0204-8f377987-a5ba-4184-9f01-5a9c1b251400,"{'dataset': 'creditcard', 'model': 'categoryembedding', 'best_params': {}, 'param_grid': {'batch_size': [1024, 2048, 4096], 'layers': ['128-64-32', '128-64-32-16', '256-128-64'], 'activation': ['ReLU', 'LeakyReLU', 'Tanh'], 'initialization': ['kaiming', 'xavier'], 'dropout': [0.0, 0.3], 'embedding_dropout': [0.0, 0.3], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",creditcard,categoryembedding,hyperopt_kfold,lift,"{'AdamW_weight_decay': 4.9936400141347456e-05, 'Adam_weight_decay': 7.582175026820124e-05, 'ExponentialLR_gamma': 0.9398703877606966, 'ReduceLROnPlateau_factor': 0.5363256403016615, 'ReduceLROnPlateau_patience': 3, 'activation': 'Tanh', 'batch_size': 3792, 'dropout': 0.14107735794557316, 'embedding_dropout': 0.00938199862390901, 'initialization': 'xavier', 'layers': '256-128-64', 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 16, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 5}}",9.695352715268946,0.12876059108985044,"{'recall': [0.9292929292929293, 0.9494949494949495, 0.9387755102040817, 0.8979591836734694, 0.8877551020408163], 'precision': [0.04081632653061224, 0.06988847583643122, 0.03173508106243532, 0.0641399416909621, 0.05451127819548872], 'accuracy': [0.961921983076437, 0.9779502124223166, 0.9506153332982216, 0.9772827021997507, 0.9733150752269096], 'f1': [0.07819804504887376, 0.13019390581717452, 0.061394728061394725, 0.11972789115646257, 0.10271546635182999], 'roc_auc': [0.988680750845955, 0.9881429528388008, 0.9923117216568142, 0.9744254629907113, 0.9871530642751447], 'area_under_pr': [0.6888051261304006, 0.7579370717786131, 0.7878337204184875, 0.7659037945754635, 0.6804893165480125], 'lift': [9.798323828169334, 9.59629653274316, 9.898132954024305, 9.592005130703965, 9.592005130703965]}",./output/modelsaves/creditcard/categoryembedding/202310-0305-0204-8f377987-a5ba-4184-9f01-5a9c1b251400//202310-0305-0204-8f377987-a5ba-4184-9f01-5a9c1b251400,30081.84154844284
202310-0313-1801-24f485a6-b4e9-45a7-99c1-739ff4de9798,"{'dataset': 'ageconditions', 'model': 'tabtransformer', 'best_params': {}, 'param_grid': {'batch_size': [32, 64, 128, 256], 'embedding_bias': [True, False], 'embedding_initialization': ['kaiming_uniform', 'kaiming_normal'], 'shared_embedding_fraction': [0.125, 0.25, 0.5], 'num_attn_blocks': [4, 10], 'attn_dropout': [0.05, 0.3], 'add_norm_dropout': [0.05, 0.3], 'ff_dropout': [0.05, 0.3], 'ff_hidden_multiplier': [2, 6], 'transformer_activation': ['GEGLU', 'ReGLU', 'SwiGLU'], 'embedding_dropout': [0.05, 0.3], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",ageconditions,tabtransformer,hyperopt_kfold,f1,"{'AdamW_weight_decay': 1.3073155121555143e-05, 'Adam_weight_decay': 1.6725307544615988e-05, 'ExponentialLR_gamma': 0.9479394240314398, 'ReduceLROnPlateau_factor': 0.5137725183487856, 'ReduceLROnPlateau_patience': 5, 'add_norm_dropout': 0.17221736861798337, 'attn_dropout': 0.13103215365271959, 'batch_size': 112, 'embedding_bias': True, 'embedding_dropout': 0.0716893799077964, 'embedding_initialization': 'kaiming_uniform', 'ff_dropout': 0.2839619185700368, 'ff_hidden_multiplier': 4, 'num_attn_blocks': 9, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'shared_embedding_fraction': 0.3985703567693482, 'transformer_activation': 'ReGLU', 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 16, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 10}}",0.7009416782678238,0.025987440000207033,"{'recall': [0.8636363636363636, 0.8181818181818182, 0.7727272727272727, 0.8095238095238095, 0.8571428571428571], 'precision': [0.6333333333333333, 0.5806451612903226, 0.6071428571428571, 0.5862068965517241, 0.6428571428571429], 'accuracy': [0.888, 0.864, 0.8709677419354839, 0.8709677419354839, 0.8951612903225806], 'f1': [0.7307692307692307, 0.679245283018868, 0.68, 0.68, 0.7346938775510204], 'roc_auc': [0.9126213592233009, 0.8473080317740511, 0.8792335115864528, 0.9195561719833564, 0.9167822468793343], 'area_under_pr': [0.8022691976199818, 0.6496889759724752, 0.5713564539904035, 0.7364351014500041, 0.7388418222705733], 'lift': [4.734848484848485, 4.261363636363637, 3.7575757575757573, 3.9365079365079367, 4.920634920634921]}",./output/modelsaves/ageconditions/tabtransformer/202310-0313-1801-24f485a6-b4e9-45a7-99c1-739ff4de9798//202310-0313-1801-24f485a6-b4e9-45a7-99c1-739ff4de9798,1133.3688652515411
202310-0313-3655-c49845db-41ef-4186-bf09-841aa0561f32,"{'dataset': 'iris', 'model': 'gandalf', 'best_params': {}, 'param_grid': {'batch_size': [32, 64, 128, 256], 'gflu_stages': [4, 10], 'gflu_dropout': [0.0, 0.3], 'embedding_dropout': [0.0, 0.3], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",iris,gandalf,hyperopt_kfold,accuracy,"{'AdamW_weight_decay': 4.270355543394315e-05, 'Adam_weight_decay': 2.3603143415207604e-05, 'ExponentialLR_gamma': 0.9250312316270729, 'ReduceLROnPlateau_factor': 0.8893683097454737, 'ReduceLROnPlateau_patience': 4, 'batch_size': 122, 'embedding_dropout': 0.04349797219708555, 'gflu_dropout': 0.29881310115435095, 'gflu_stages': 4, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 16, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 10}}",0.9800000000000001,0.02666666666666666,"{'accuracy': [1.0, 1.0, 0.9333333333333333, 1.0, 0.9666666666666667], 'f1': [1.0, 1.0, 0.9333333333333333, 1.0, 0.9665831244778613]}",./output/modelsaves/iris/gandalf/202310-0313-3655-c49845db-41ef-4186-bf09-841aa0561f32//202310-0313-3655-c49845db-41ef-4186-bf09-841aa0561f32,1863.4715213775635
202310-0312-5731-f7f6386b-0aa2-437d-bc49-4e091538efaf,"{'dataset': 'titanic', 'model': 'tabnet', 'best_params': {}, 'param_grid': {'virtual_batch_size_ratio': [0.125, 0.25, 0.5, 1.0], 'batch_size': [32, 64, 128, 256], 'weights': [0, 1], 'mask_type': ['sparsemax', 'entmax'], 'n_d': [6, 32], 'n_steps': [1, 6], 'gamma': [1.0, 2.0], 'n_independent': [1, 3], 'n_shared': [1, 3], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",titanic,tabnet,hyperopt_kfold,roc_auc,"{'AdamW_weight_decay': 3.0518114945089195e-05, 'Adam_weight_decay': 5.558444026857581e-05, 'ExponentialLR_gamma': 0.9126770808754974, 'ReduceLROnPlateau_factor': 0.24798386878757261, 'ReduceLROnPlateau_patience': 3, 'batch_size': 58, 'gamma': 1.3534686010334578, 'mask_type': 'entmax', 'n_d': 10, 'n_independent': 1, 'n_shared': 1, 'n_steps': 1, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>, 'virtual_batch_size_ratio': 0.5, 'weights': 0, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 16, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 10}}",0.8687105391890231,0.02226928645106577,"{'recall': [0.6231884057971014, 0.7352941176470589, 0.6764705882352942, 0.7647058823529411, 0.8695652173913043], 'precision': [0.86, 0.7142857142857143, 0.71875, 0.7428571428571429, 0.6593406593406593], 'accuracy': [0.8156424581005587, 0.7865168539325843, 0.7752808988764045, 0.8089887640449438, 0.7752808988764045], 'f1': [0.7226890756302521, 0.7246376811594202, 0.696969696969697, 0.7536231884057971, 0.75], 'roc_auc': [0.9061923583662713, 0.8506684491978609, 0.8439171122994653, 0.8636363636363636, 0.8791384124451538], 'area_under_pr': [0.8388479966331724, 0.84604905485849, 0.8201073792097111, 0.8582018978622832, 0.8310131302089075], 'lift': [2.441602728047741, 2.6176470588235294, 2.6176470588235294, 2.6176470588235294, 2.4279624893435634]}",./output/modelsaves/titanic/tabnet/202310-0312-5731-f7f6386b-0aa2-437d-bc49-4e091538efaf//202310-0312-5731-f7f6386b-0aa2-437d-bc49-4e091538efaf,4589.36514043808
202310-0305-1247-18ecab32-c2bb-480a-a9ac-95d76642de74,"{'dataset': 'titanic', 'model': 'gate', 'best_params': {}, 'param_grid': {'batch_size': [32, 64, 128, 256], 'tree_depth': [4, 7], 'num_trees': [4, 10], 'chain_trees': [False, True], 'gflu_stages': [3, 8], 'gflu_dropout': [0.0, 0.05], 'tree_dropout': [0.0, 0.05], 'tree_wise_attention_dropout': [0.0, 0.05], 'embedding_dropout': [0, 0.2], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",titanic,gate,hyperopt_kfold,roc_auc,"{'AdamW_weight_decay': 5.493747562277505e-05, 'Adam_weight_decay': 3.961895563756546e-05, 'ExponentialLR_gamma': 0.9001406622075305, 'ReduceLROnPlateau_factor': 0.1660899475602357, 'ReduceLROnPlateau_patience': 4, 'batch_size': 105, 'chain_trees': True, 'embedding_dropout': 0, 'gflu_dropout': 0.038667476874155664, 'gflu_stages': 4, 'num_trees': 7, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'tree_depth': 4, 'tree_dropout': 0.010685858807269799, 'tree_wise_attention_dropout': 0.0070355743292431884, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 5}}",0.8681734690104783,0.027653304180783402,"{'recall': [0.8115942028985508, 0.7647058823529411, 0.6911764705882353, 0.7352941176470589, 0.8115942028985508], 'precision': [0.7567567567567568, 0.7536231884057971, 0.7230769230769231, 0.7352941176470589, 0.7777777777777778], 'accuracy': [0.8268156424581006, 0.8146067415730337, 0.7808988764044944, 0.797752808988764, 0.8370786516853933], 'f1': [0.7832167832167832, 0.759124087591241, 0.7067669172932332, 0.735294117647059, 0.7943262411347518], 'roc_auc': [0.905862977602108, 0.8605614973262031, 0.8218582887700535, 0.8704545454545454, 0.8821300358994814], 'area_under_pr': [0.8670475532031534, 0.8301096358220079, 0.7847691553084514, 0.8625516756897609, 0.8553674984992917], 'lift': [2.441602728047741, 2.463667820069204, 2.463667820069204, 2.6176470588235294, 2.4279624893435634]}",./output/modelsaves/titanic/gate/202310-0305-1247-18ecab32-c2bb-480a-a9ac-95d76642de74//202310-0305-1247-18ecab32-c2bb-480a-a9ac-95d76642de74,32523.661009788513
202310-0310-3459-aaff1b40-d67b-4673-a227-830b9fff0004,"{'dataset': 'iris', 'model': 's1dcnn', 'best_params': {}, 'param_grid': {'batch_size': [32, 64, 128, 256], 'hidden_size': [1024, 2048, 4096], 'optimizer_fn': {'Adam': {'weight_decay': [1e-05, 0.001], 'learning_rate': [0.0001, 0.01]}, 'AdamW': {'weight_decay': [1e-05, 0.001], 'learning_rate': [0.0001, 0.01]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",iris,s1dcnn,hyperopt_kfold,accuracy,"{'AdamW_learning_rate': 0.007533305910346311, 'AdamW_weight_decay': 2.0120874983312022e-05, 'Adam_learning_rate': 0.00017769505373181943, 'Adam_weight_decay': 0.0007683558237875469, 'ExponentialLR_gamma': 0.9388434108641118, 'ReduceLROnPlateau_factor': 0.38345702967617984, 'ReduceLROnPlateau_patience': 4, 'batch_size': 35, 'hidden_size': 1024, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'outer_params': {'hyperopt_evals': 50, 'max_epochs': 1000, 'early_stopping': True, 'shuffle': True, 'validation_fraction': 0.15, 'early_stopping_patience': 10}}",0.9733333333333333,0.038873012632301994,"{'accuracy': [1.0, 1.0, 0.9, 1.0, 0.9666666666666667], 'f1': [1.0, 1.0, 0.8997493734335841, 1.0, 0.9665831244778613]}",./output/modelsaves/iris/s1dcnn/202310-0310-3459-aaff1b40-d67b-4673-a227-830b9fff0004//202310-0310-3459-aaff1b40-d67b-4673-a227-830b9fff0004,14533.763449907303
202310-0314-0758-137645c1-9941-455a-bc0b-edd418f9d122,"{'dataset': 'titanic', 'model': 'gandalf', 'best_params': {}, 'param_grid': {'batch_size': [32, 64, 128, 256], 'gflu_stages': [4, 10], 'gflu_dropout': [0.0, 0.3], 'embedding_dropout': [0.0, 0.3], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",titanic,gandalf,hyperopt_kfold,roc_auc,"{'AdamW_weight_decay': 1.8741932207211996e-05, 'Adam_weight_decay': 3.816736745734649e-05, 'ExponentialLR_gamma': 0.9172107426966293, 'ReduceLROnPlateau_factor': 0.219770658565823, 'ReduceLROnPlateau_patience': 5, 'batch_size': 180, 'embedding_dropout': 0.24100919859776435, 'gflu_dropout': 0.22337411430571577, 'gflu_stages': 10, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 16, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 10}}",0.8769247692912607,0.022437328635668663,"{'recall': [0.8115942028985508, 0.7794117647058824, 0.6911764705882353, 0.7352941176470589, 0.8115942028985508], 'precision': [0.7777777777777778, 0.726027397260274, 0.6911764705882353, 0.7692307692307693, 0.7567567567567568], 'accuracy': [0.8379888268156425, 0.8033707865168539, 0.7640449438202247, 0.8146067415730337, 0.8258426966292135], 'f1': [0.7943262411347518, 0.75177304964539, 0.6911764705882353, 0.7518796992481205, 0.7832167832167832], 'roc_auc': [0.9113965744400526, 0.8768716577540108, 0.8419117647058824, 0.8700534759358288, 0.8843903736205292], 'area_under_pr': [0.8730089351368684, 0.8482416802259845, 0.8052469911031512, 0.8650575938897049, 0.8515756397662229], 'lift': [2.441602728047741, 2.463667820069204, 2.463667820069204, 2.6176470588235294, 2.2762148337595907]}",./output/modelsaves/titanic/gandalf/202310-0314-0758-137645c1-9941-455a-bc0b-edd418f9d122//202310-0314-0758-137645c1-9941-455a-bc0b-edd418f9d122,3065.438502073288
202310-0314-5904-9ef02555-5ed8-455b-93f1-8a3e854eebc6,"{'dataset': 'breastcancer', 'model': 'gandalf', 'best_params': {}, 'param_grid': {'batch_size': [32, 64, 128, 256], 'gflu_stages': [4, 10], 'gflu_dropout': [0.0, 0.3], 'embedding_dropout': [0.0, 0.3], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",breastcancer,gandalf,hyperopt_kfold,f1,"{'AdamW_weight_decay': 2.3837890787467192e-05, 'Adam_weight_decay': 1.2096910102738744e-05, 'ExponentialLR_gamma': 0.9631502656727748, 'ReduceLROnPlateau_factor': 0.19692898274849846, 'ReduceLROnPlateau_patience': 4, 'batch_size': 84, 'embedding_dropout': 0.26838306804022954, 'gflu_dropout': 0.04748079310604984, 'gflu_stages': 9, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 16, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 10}}",0.9889067004246052,0.005449979738766625,"{'recall': [0.9859154929577465, 1.0, 1.0, 0.9861111111111112, 1.0], 'precision': [1.0, 0.9594594594594594, 0.972972972972973, 1.0, 0.9861111111111112], 'accuracy': [0.9912280701754386, 0.9736842105263158, 0.9824561403508771, 0.9912280701754386, 0.9911504424778761], 'f1': [0.9929078014184397, 0.9793103448275862, 0.9863013698630138, 0.993006993006993, 0.993006993006993], 'roc_auc': [0.9993449066491975, 0.9970520799213888, 0.9837962962962963, 1.0, 0.9989939637826961], 'area_under_pr': [0.9996141230947329, 0.9981629912500206, 0.9881721458121433, 1.0, 0.9994048012645513], 'lift': [1.6056338028169013, 1.6056338028169013, 1.5833333333333335, 1.5833333333333335, 1.591549295774648]}",./output/modelsaves/breastcancer/gandalf/202310-0314-5904-9ef02555-5ed8-455b-93f1-8a3e854eebc6//202310-0314-5904-9ef02555-5ed8-455b-93f1-8a3e854eebc6,2042.5990598201752
202310-0315-3306-75c4e3c8-84da-45c7-bae8-cdc143d29da6,"{'dataset': 'ageconditions', 'model': 'gandalf', 'best_params': {}, 'param_grid': {'batch_size': [32, 64, 128, 256], 'gflu_stages': [4, 10], 'gflu_dropout': [0.0, 0.3], 'embedding_dropout': [0.0, 0.3], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",ageconditions,gandalf,hyperopt_kfold,f1,"{'AdamW_weight_decay': 5.9615011507161995e-05, 'Adam_weight_decay': 5.7147491844042206e-05, 'ExponentialLR_gamma': 0.9308439521263807, 'ReduceLROnPlateau_factor': 0.15291156992064192, 'ReduceLROnPlateau_patience': 5, 'batch_size': 49, 'embedding_dropout': 0.18834271745030104, 'gflu_dropout': 0.22168983770251444, 'gflu_stages': 10, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 16, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 10}}",0.7706217370669197,0.06276270226024905,"{'recall': [0.8636363636363636, 0.8181818181818182, 0.8181818181818182, 0.8095238095238095, 0.9047619047619048], 'precision': [0.7307692307692307, 0.6666666666666666, 0.6666666666666666, 0.6296296296296297, 0.8636363636363636], 'accuracy': [0.92, 0.896, 0.8951612903225806, 0.8870967741935484, 0.9596774193548387], 'f1': [0.7916666666666666, 0.7346938775510203, 0.7346938775510203, 0.7083333333333334, 0.8837209302325582], 'roc_auc': [0.9580759046778464, 0.9258605472197705, 0.927807486631016, 0.927877947295423, 0.9699491447064262], 'area_under_pr': [0.8217036734116604, 0.8226023644085843, 0.7215795281625214, 0.7745255199964474, 0.931047020697618], 'lift': [5.208333333333333, 5.208333333333333, 4.227272727272727, 4.920634920634921, 5.904761904761905]}",./output/modelsaves/ageconditions/gandalf/202310-0315-3306-75c4e3c8-84da-45c7-bae8-cdc143d29da6//202310-0315-3306-75c4e3c8-84da-45c7-bae8-cdc143d29da6,1866.302979707718
202310-0316-3651-ea355973-51cb-4444-b425-d2379c5f43c2,"{'dataset': 'iris', 'model': 'gandalf', 'best_params': {}, 'param_grid': {'batch_size': [32, 64, 128, 256], 'gflu_stages': [4, 10], 'gflu_dropout': [0.0, 0.3], 'embedding_dropout': [0.0, 0.3], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",iris,gandalf,hyperopt_kfold,accuracy,"{'AdamW_weight_decay': 4.270355543394315e-05, 'Adam_weight_decay': 2.3603143415207604e-05, 'ExponentialLR_gamma': 0.9250312316270729, 'ReduceLROnPlateau_factor': 0.8893683097454737, 'ReduceLROnPlateau_patience': 4, 'batch_size': 122, 'embedding_dropout': 0.04349797219708555, 'gflu_dropout': 0.29881310115435095, 'gflu_stages': 4, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 16, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 10}}",0.9800000000000001,0.02666666666666666,"{'accuracy': [1.0, 1.0, 0.9333333333333333, 1.0, 0.9666666666666667], 'f1': [1.0, 1.0, 0.9333333333333333, 1.0, 0.9665831244778613]}",./output/modelsaves/iris/gandalf/202310-0316-3651-ea355973-51cb-4444-b425-d2379c5f43c2//202310-0316-3651-ea355973-51cb-4444-b425-d2379c5f43c2,1682.336877822876
202310-0317-0453-22b276f6-1aad-4e07-a6c0-5adb43ffeb71,"{'dataset': 'titanic', 'model': 'gandalf', 'best_params': {}, 'param_grid': {'batch_size': [32, 64, 128, 256], 'gflu_stages': [4, 10], 'gflu_dropout': [0.0, 0.3], 'embedding_dropout': [0.0, 0.3], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",titanic,gandalf,hyperopt_kfold,roc_auc,"{'AdamW_weight_decay': 1.8741932207211996e-05, 'Adam_weight_decay': 3.816736745734649e-05, 'ExponentialLR_gamma': 0.9172107426966293, 'ReduceLROnPlateau_factor': 0.219770658565823, 'ReduceLROnPlateau_patience': 5, 'batch_size': 180, 'embedding_dropout': 0.24100919859776435, 'gflu_dropout': 0.22337411430571577, 'gflu_stages': 10, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 16, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 10}}",0.8769247692912607,0.022437328635668663,"{'recall': [0.8115942028985508, 0.7794117647058824, 0.6911764705882353, 0.7352941176470589, 0.8115942028985508], 'precision': [0.7777777777777778, 0.726027397260274, 0.6911764705882353, 0.7692307692307693, 0.7567567567567568], 'accuracy': [0.8379888268156425, 0.8033707865168539, 0.7640449438202247, 0.8146067415730337, 0.8258426966292135], 'f1': [0.7943262411347518, 0.75177304964539, 0.6911764705882353, 0.7518796992481205, 0.7832167832167832], 'roc_auc': [0.9113965744400526, 0.8768716577540108, 0.8419117647058824, 0.8700534759358288, 0.8843903736205292], 'area_under_pr': [0.8730089351368684, 0.8482416802259845, 0.8052469911031512, 0.8650575938897049, 0.8515756397662229], 'lift': [2.441602728047741, 2.463667820069204, 2.463667820069204, 2.6176470588235294, 2.2762148337595907]}",./output/modelsaves/titanic/gandalf/202310-0317-0453-22b276f6-1aad-4e07-a6c0-5adb43ffeb71//202310-0317-0453-22b276f6-1aad-4e07-a6c0-5adb43ffeb71,2805.8322265148163
202310-0316-3641-a044b352-0f7c-4b4e-a7b3-ff035aded875,"{'dataset': 'titanic', 'model': 's1dcnn', 'best_params': {}, 'param_grid': {'batch_size': [32, 64, 128, 256], 'hidden_size': [1024, 2048, 4096], 'optimizer_fn': {'Adam': {'weight_decay': [1e-05, 0.001], 'learning_rate': [0.0001, 0.01]}, 'AdamW': {'weight_decay': [1e-05, 0.001], 'learning_rate': [0.0001, 0.01]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",titanic,s1dcnn,hyperopt_kfold,roc_auc,"{'AdamW_learning_rate': 0.0005369055388103744, 'AdamW_weight_decay': 0.00031989605187642803, 'Adam_learning_rate': 0.0001023586915118886, 'Adam_weight_decay': 9.67668961332305e-05, 'ExponentialLR_gamma': 0.9820110762373098, 'ReduceLROnPlateau_factor': 0.7774923898508599, 'ReduceLROnPlateau_patience': 3, 'batch_size': 89, 'hidden_size': 4096, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'outer_params': {'hyperopt_evals': 50, 'max_epochs': 1000, 'early_stopping': True, 'shuffle': True, 'validation_fraction': 0.15, 'early_stopping_patience': 10}}",0.8594737942317661,0.022807245309943814,"{'recall': [0.6956521739130435, 0.7058823529411765, 0.5882352941176471, 0.7205882352941176, 0.6521739130434783], 'precision': [0.8727272727272727, 0.7384615384615385, 0.7407407407407407, 0.8448275862068966, 0.8653846153846154], 'accuracy': [0.8435754189944135, 0.7921348314606742, 0.7640449438202247, 0.8426966292134831, 0.8258426966292135], 'f1': [0.7741935483870968, 0.7218045112781954, 0.6557377049180328, 0.7777777777777778, 0.743801652892562], 'roc_auc': [0.8889328063241108, 0.8524732620320855, 0.8217245989304813, 0.8586898395721925, 0.87554846429996], 'area_under_pr': [0.83762652673093, 0.8169631231843616, 0.7869704697125534, 0.8593893695422353, 0.8476957684996593], 'lift': [2.441602728047741, 2.463667820069204, 2.463667820069204, 2.6176470588235294, 2.4279624893435634]}",./output/modelsaves/titanic/s1dcnn/202310-0316-3641-a044b352-0f7c-4b4e-a7b3-ff035aded875//202310-0316-3641-a044b352-0f7c-4b4e-a7b3-ff035aded875,6824.392486810684
202310-0317-5139-2ed642f8-f1d8-49d7-9122-18020a8a1e43,"{'dataset': 'titanic', 'model': 'fttransformer', 'best_params': {}, 'param_grid': {'batch_size': [32, 64, 128, 256], 'num_heads': [4, 10], 'input_embed_dim_multiplier': [2, 6], 'embedding_initialization': ['kaiming_uniform', 'kaiming_normal'], 'embedding_dropout': [0.05, 0.2], 'shared_embedding_fraction': [0.125, 0.25, 0.5], 'num_attn_blocks': [4, 8], 'attn_dropout': [0.05, 0.2], 'add_norm_dropout': [0.05, 0.2], 'ff_dropout': [0.05, 0.2], 'ff_hidden_multiplier': [4, 32], 'transformer_activation': ['GEGLU', 'ReGLU', 'SwiGLU'], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",titanic,fttransformer,hyperopt_kfold,roc_auc,"{'AdamW_weight_decay': 4.446756799780423e-05, 'Adam_weight_decay': 1.7229682896114413e-05, 'ExponentialLR_gamma': 0.9486468678624151, 'ReduceLROnPlateau_factor': 0.5525020514051779, 'ReduceLROnPlateau_patience': 4, 'add_norm_dropout': 0.0847619517203962, 'attn_dropout': 0.05226608749890687, 'batch_size': 115, 'embedding_dropout': 0.08626623414566427, 'embedding_initialization': 'kaiming_uniform', 'ff_dropout': 0.09773252167406458, 'ff_hidden_multiplier': 27, 'input_embed_dim_multiplier': 6, 'num_attn_blocks': 8, 'num_heads': 10, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>, 'shared_embedding_fraction': 0.2989857803723279, 'transformer_activation': 'GEGLU', 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 16, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 10, 'attn_feature_importance': False}}",0.8787545247638164,0.024506012882456716,"{'recall': [0.7971014492753623, 0.7352941176470589, 0.6764705882352942, 0.7794117647058824, 0.8115942028985508], 'precision': [0.8088235294117647, 0.78125, 0.7419354838709677, 0.7361111111111112, 0.7466666666666667], 'accuracy': [0.8491620111731844, 0.8202247191011236, 0.7865168539325843, 0.8089887640449438, 0.8202247191011236], 'f1': [0.8029197080291971, 0.7575757575757576, 0.7076923076923077, 0.7571428571428572, 0.7777777777777779], 'roc_auc': [0.9162055335968379, 0.8767379679144385, 0.8394385026737967, 0.8760695187165776, 0.8853211009174312], 'area_under_pr': [0.8875705003476015, 0.8539614424684967, 0.8143444041626403, 0.8670709305485991, 0.8603066587083806], 'lift': [2.5942028985507246, 2.6176470588235294, 2.463667820069204, 2.6176470588235294, 2.4279624893435634]}",./output/modelsaves/titanic/fttransformer/202310-0317-5139-2ed642f8-f1d8-49d7-9122-18020a8a1e43//202310-0317-5139-2ed642f8-f1d8-49d7-9122-18020a8a1e43,4356.419471025467
202310-0314-1451-e443f9e9-0a99-42ee-8dba-d5971ad49b8b,"{'dataset': 'breastcancer', 'model': 'gate', 'best_params': {}, 'param_grid': {'batch_size': [32, 64, 128, 256], 'tree_depth': [4, 7], 'num_trees': [4, 10], 'chain_trees': [False, True], 'gflu_stages': [3, 8], 'gflu_dropout': [0.0, 0.05], 'tree_dropout': [0.0, 0.05], 'tree_wise_attention_dropout': [0.0, 0.05], 'embedding_dropout': [0, 0.2], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",breastcancer,gate,hyperopt_kfold,f1,"{'AdamW_weight_decay': 2.084850753684019e-05, 'Adam_weight_decay': 9.742659197216048e-05, 'ExponentialLR_gamma': 0.9413668606403313, 'ReduceLROnPlateau_factor': 0.12672135640291163, 'ReduceLROnPlateau_patience': 4, 'batch_size': 53, 'chain_trees': False, 'embedding_dropout': 0, 'gflu_dropout': 0.02962414063792255, 'gflu_stages': 6, 'num_trees': 9, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'tree_depth': 4, 'tree_dropout': 0.03626895389054083, 'tree_wise_attention_dropout': 0.04912261495844525, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 5}}",0.9916856897891382,0.008052657215023093,"{'recall': [1.0, 1.0, 0.9861111111111112, 1.0, 1.0], 'precision': [1.0, 0.9726027397260274, 0.9726027397260274, 1.0, 0.9861111111111112], 'accuracy': [1.0, 0.9824561403508771, 0.9736842105263158, 1.0, 0.9911504424778761], 'f1': [1.0, 0.9861111111111112, 0.9793103448275863, 1.0, 0.993006993006993], 'roc_auc': [1.0, 1.0, 0.9811507936507936, 1.0, 1.0], 'area_under_pr': [1.0, 1.0, 0.9863322148486232, 1.0, 1.0], 'lift': [1.6056338028169013, 1.6056338028169013, 1.5833333333333335, 1.5833333333333335, 1.591549295774648]}",./output/modelsaves/breastcancer/gate/202310-0314-1451-e443f9e9-0a99-42ee-8dba-d5971ad49b8b//202310-0314-1451-e443f9e9-0a99-42ee-8dba-d5971ad49b8b,21211.696928977966
202310-0319-0415-289ccd3b-269f-444f-80cb-8b52c8833444,"{'dataset': 'ageconditions', 'model': 'fttransformer', 'best_params': {}, 'param_grid': {'batch_size': [32, 64, 128, 256], 'num_heads': [4, 10], 'input_embed_dim_multiplier': [2, 6], 'embedding_initialization': ['kaiming_uniform', 'kaiming_normal'], 'embedding_dropout': [0.05, 0.2], 'shared_embedding_fraction': [0.125, 0.25, 0.5], 'num_attn_blocks': [4, 8], 'attn_dropout': [0.05, 0.2], 'add_norm_dropout': [0.05, 0.2], 'ff_dropout': [0.05, 0.2], 'ff_hidden_multiplier': [4, 32], 'transformer_activation': ['GEGLU', 'ReGLU', 'SwiGLU'], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",ageconditions,fttransformer,hyperopt_kfold,f1,"{'AdamW_weight_decay': 3.12792199732821e-05, 'Adam_weight_decay': 1.1045082472811707e-05, 'ExponentialLR_gamma': 0.9052607122042954, 'ReduceLROnPlateau_factor': 0.2012229847371212, 'ReduceLROnPlateau_patience': 3, 'add_norm_dropout': 0.0648393993426874, 'attn_dropout': 0.05896528607428793, 'batch_size': 206, 'embedding_dropout': 0.1427998385894946, 'embedding_initialization': 'kaiming_uniform', 'ff_dropout': 0.06536404301516033, 'ff_hidden_multiplier': 28, 'input_embed_dim_multiplier': 6, 'num_attn_blocks': 4, 'num_heads': 8, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>, 'shared_embedding_fraction': 0.44938662823106235, 'transformer_activation': 'GEGLU', 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 16, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 10, 'attn_feature_importance': False}}",0.720452118839855,0.08419651111149956,"{'recall': [0.8636363636363636, 0.6363636363636364, 0.7272727272727273, 0.9047619047619048, 0.9047619047619048], 'precision': [0.5757575757575758, 0.56, 0.6666666666666666, 0.6785714285714286, 0.7916666666666666], 'accuracy': [0.864, 0.848, 0.8870967741935484, 0.9112903225806451, 0.9435483870967742], 'f1': [0.6909090909090909, 0.5957446808510639, 0.6956521739130435, 0.7755102040816326, 0.8444444444444444], 'roc_auc': [0.9201235657546337, 0.798323036187114, 0.9131016042780749, 0.957004160887656, 0.9870550161812298], 'area_under_pr': [0.8439742670950678, 0.6647530527349652, 0.6970679554988588, 0.8021822245074526, 0.9422160382980651], 'lift': [5.208333333333333, 3.787878787878788, 4.227272727272727, 4.920634920634921, 5.904761904761905]}",./output/modelsaves/ageconditions/fttransformer/202310-0319-0415-289ccd3b-269f-444f-80cb-8b52c8833444//202310-0319-0415-289ccd3b-269f-444f-80cb-8b52c8833444,4049.106560945511
202310-0318-3025-597a9e99-ca98-4883-8911-3ff3934d0a41,"{'dataset': 'breastcancer', 'model': 's1dcnn', 'best_params': {}, 'param_grid': {'batch_size': [32, 64, 128, 256], 'hidden_size': [1024, 2048, 4096], 'optimizer_fn': {'Adam': {'weight_decay': [1e-05, 0.001], 'learning_rate': [0.0001, 0.01]}, 'AdamW': {'weight_decay': [1e-05, 0.001], 'learning_rate': [0.0001, 0.01]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",breastcancer,s1dcnn,hyperopt_kfold,f1,"{'AdamW_learning_rate': 0.0023574430452262558, 'AdamW_weight_decay': 5.302171733679487e-05, 'Adam_learning_rate': 0.00018625513088363458, 'Adam_weight_decay': 3.491008115141241e-05, 'ExponentialLR_gamma': 0.9351231266601521, 'ReduceLROnPlateau_factor': 0.4539267724585503, 'ReduceLROnPlateau_patience': 5, 'batch_size': 43, 'hidden_size': 4096, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'outer_params': {'hyperopt_evals': 50, 'max_epochs': 1000, 'early_stopping': True, 'shuffle': True, 'validation_fraction': 0.15, 'early_stopping_patience': 10}}",0.984590293368478,0.005319941554258664,"{'recall': [0.9577464788732394, 1.0, 1.0, 0.9861111111111112, 0.9859154929577465], 'precision': [1.0, 0.9594594594594594, 0.972972972972973, 1.0, 0.9859154929577465], 'accuracy': [0.9736842105263158, 0.9736842105263158, 0.9824561403508771, 0.9912280701754386, 0.9823008849557522], 'f1': [0.9784172661870503, 0.9793103448275862, 0.9863013698630138, 0.993006993006993, 0.9859154929577465], 'roc_auc': [0.9990173599737963, 0.9967245332459875, 0.9867724867724867, 1.0, 0.9983232729711602], 'area_under_pr': [0.9994048012645513, 0.9979429208274855, 0.9907496525051835, 1.0, 0.9990104192221814], 'lift': [1.6056338028169013, 1.6056338028169013, 1.5833333333333335, 1.5833333333333335, 1.591549295774648]}",./output/modelsaves/breastcancer/s1dcnn/202310-0318-3025-597a9e99-ca98-4883-8911-3ff3934d0a41//202310-0318-3025-597a9e99-ca98-4883-8911-3ff3934d0a41,7928.940709352493
202310-0320-1145-7691dee7-d63a-4763-8a58-0820f308ca44,"{'dataset': 'iris', 'model': 'fttransformer', 'best_params': {}, 'param_grid': {'batch_size': [32, 64, 128, 256], 'num_heads': [4, 10], 'input_embed_dim_multiplier': [2, 6], 'embedding_initialization': ['kaiming_uniform', 'kaiming_normal'], 'embedding_dropout': [0.05, 0.2], 'shared_embedding_fraction': [0.125, 0.25, 0.5], 'num_attn_blocks': [4, 8], 'attn_dropout': [0.05, 0.2], 'add_norm_dropout': [0.05, 0.2], 'ff_dropout': [0.05, 0.2], 'ff_hidden_multiplier': [4, 32], 'transformer_activation': ['GEGLU', 'ReGLU', 'SwiGLU'], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",iris,fttransformer,hyperopt_kfold,accuracy,"{'AdamW_weight_decay': 2.7916124161202693e-05, 'Adam_weight_decay': 2.8228328474744527e-05, 'ExponentialLR_gamma': 0.9744848105001896, 'ReduceLROnPlateau_factor': 0.4462753041065219, 'ReduceLROnPlateau_patience': 4, 'add_norm_dropout': 0.05541092699769702, 'attn_dropout': 0.1896538897072602, 'batch_size': 102, 'embedding_dropout': 0.05255434014700438, 'embedding_initialization': 'kaiming_uniform', 'ff_dropout': 0.06578129810139584, 'ff_hidden_multiplier': 5, 'input_embed_dim_multiplier': 6, 'num_attn_blocks': 6, 'num_heads': 8, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>, 'shared_embedding_fraction': 0.1401251518483394, 'transformer_activation': 'ReGLU', 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 16, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 10, 'attn_feature_importance': False}}",0.9800000000000001,0.02666666666666666,"{'accuracy': [1.0, 1.0, 0.9333333333333333, 1.0, 0.9666666666666667], 'f1': [1.0, 1.0, 0.9326599326599326, 1.0, 0.9665831244778613]}",./output/modelsaves/iris/fttransformer/202310-0320-1145-7691dee7-d63a-4763-8a58-0820f308ca44//202310-0320-1145-7691dee7-d63a-4763-8a58-0820f308ca44,2459.149832010269
202310-0320-5244-02483461-0654-4349-90d0-ad922f4a8967,"{'dataset': 'ageconditions', 'model': 'gandalf', 'best_params': {}, 'param_grid': {'batch_size': [32, 64, 128, 256], 'gflu_stages': [4, 10], 'gflu_dropout': [0.0, 0.3], 'embedding_dropout': [0.0, 0.3], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",ageconditions,gandalf,hyperopt_kfold,f1,"{'AdamW_weight_decay': 5.9615011507161995e-05, 'Adam_weight_decay': 5.7147491844042206e-05, 'ExponentialLR_gamma': 0.9308439521263807, 'ReduceLROnPlateau_factor': 0.15291156992064192, 'ReduceLROnPlateau_patience': 5, 'batch_size': 49, 'embedding_dropout': 0.18834271745030104, 'gflu_dropout': 0.22168983770251444, 'gflu_stages': 10, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 16, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 10}}",0.7706217370669197,0.06276270226024905,"{'recall': [0.8636363636363636, 0.8181818181818182, 0.8181818181818182, 0.8095238095238095, 0.9047619047619048], 'precision': [0.7307692307692307, 0.6666666666666666, 0.6666666666666666, 0.6296296296296297, 0.8636363636363636], 'accuracy': [0.92, 0.896, 0.8951612903225806, 0.8870967741935484, 0.9596774193548387], 'f1': [0.7916666666666666, 0.7346938775510203, 0.7346938775510203, 0.7083333333333334, 0.8837209302325582], 'roc_auc': [0.9580759046778464, 0.9258605472197705, 0.927807486631016, 0.927877947295423, 0.9699491447064262], 'area_under_pr': [0.8217036734116604, 0.8226023644085843, 0.7215795281625214, 0.7745255199964474, 0.931047020697618], 'lift': [5.208333333333333, 5.208333333333333, 4.227272727272727, 4.920634920634921, 5.904761904761905]}",./output/modelsaves/ageconditions/gandalf/202310-0320-5244-02483461-0654-4349-90d0-ad922f4a8967//202310-0320-5244-02483461-0654-4349-90d0-ad922f4a8967,1992.4490702152252
202310-0321-2556-8e24f473-1d86-4508-bfb2-b246e3c01f3f,"{'dataset': 'breastcancer', 'model': 'fttransformer', 'best_params': {}, 'param_grid': {'batch_size': [32, 64, 128, 256], 'num_heads': [4, 10], 'input_embed_dim_multiplier': [2, 6], 'embedding_initialization': ['kaiming_uniform', 'kaiming_normal'], 'embedding_dropout': [0.05, 0.2], 'shared_embedding_fraction': [0.125, 0.25, 0.5], 'num_attn_blocks': [4, 8], 'attn_dropout': [0.05, 0.2], 'add_norm_dropout': [0.05, 0.2], 'ff_dropout': [0.05, 0.2], 'ff_hidden_multiplier': [4, 32], 'transformer_activation': ['GEGLU', 'ReGLU', 'SwiGLU'], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",breastcancer,fttransformer,hyperopt_kfold,f1,"{'AdamW_weight_decay': 2.029459754000432e-05, 'Adam_weight_decay': 2.2455105982961252e-05, 'ExponentialLR_gamma': 0.9455570888192831, 'ReduceLROnPlateau_factor': 0.1906757713703933, 'ReduceLROnPlateau_patience': 3, 'add_norm_dropout': 0.11956939061805583, 'attn_dropout': 0.05500720564419531, 'batch_size': 61, 'embedding_dropout': 0.10515242055453193, 'embedding_initialization': 'kaiming_normal', 'ff_dropout': 0.12899939524109866, 'ff_hidden_multiplier': 12, 'input_embed_dim_multiplier': 2, 'num_attn_blocks': 5, 'num_heads': 8, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>, 'shared_embedding_fraction': 0.3003171623402166, 'transformer_activation': 'SwiGLU', 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 16, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 10, 'attn_feature_importance': False}}",0.9888493633612624,0.005503782752682333,"{'recall': [1.0, 0.9859154929577465, 0.9861111111111112, 0.9861111111111112, 1.0], 'precision': [0.9861111111111112, 0.9859154929577465, 0.9726027397260274, 1.0, 0.9861111111111112], 'accuracy': [0.9912280701754386, 0.9824561403508771, 0.9736842105263158, 0.9912280701754386, 0.9911504424778761], 'f1': [0.993006993006993, 0.9859154929577465, 0.9793103448275863, 0.993006993006993, 0.993006993006993], 'roc_auc': [1.0, 0.998689813298395, 0.9844576719576719, 1.0, 0.9986586183769282], 'area_under_pr': [1.0, 0.9992145425126487, 0.9886163797075935, 1.0, 0.9992006779740839], 'lift': [1.6056338028169013, 1.6056338028169013, 1.5833333333333335, 1.5833333333333335, 1.591549295774648]}",./output/modelsaves/breastcancer/fttransformer/202310-0321-2556-8e24f473-1d86-4508-bfb2-b246e3c01f3f//202310-0321-2556-8e24f473-1d86-4508-bfb2-b246e3c01f3f,3014.9686148166656
202310-0322-1611-46149d81-1443-412b-88d9-597f45defae7,"{'dataset': 'breastcancer', 'model': 'gandalf', 'best_params': {}, 'param_grid': {'batch_size': [32, 64, 128, 256], 'gflu_stages': [4, 10], 'gflu_dropout': [0.0, 0.3], 'embedding_dropout': [0.0, 0.3], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",breastcancer,gandalf,hyperopt_kfold,f1,"{'AdamW_weight_decay': 2.3837890787467192e-05, 'Adam_weight_decay': 1.2096910102738744e-05, 'ExponentialLR_gamma': 0.9631502656727748, 'ReduceLROnPlateau_factor': 0.19692898274849846, 'ReduceLROnPlateau_patience': 4, 'batch_size': 84, 'embedding_dropout': 0.26838306804022954, 'gflu_dropout': 0.04748079310604984, 'gflu_stages': 9, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 16, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 10}}",0.9889067004246052,0.005449979738766625,"{'recall': [0.9859154929577465, 1.0, 1.0, 0.9861111111111112, 1.0], 'precision': [1.0, 0.9594594594594594, 0.972972972972973, 1.0, 0.9861111111111112], 'accuracy': [0.9912280701754386, 0.9736842105263158, 0.9824561403508771, 0.9912280701754386, 0.9911504424778761], 'f1': [0.9929078014184397, 0.9793103448275862, 0.9863013698630138, 0.993006993006993, 0.993006993006993], 'roc_auc': [0.9993449066491975, 0.9970520799213888, 0.9837962962962963, 1.0, 0.9989939637826961], 'area_under_pr': [0.9996141230947329, 0.9981629912500206, 0.9881721458121433, 1.0, 0.9994048012645513], 'lift': [1.6056338028169013, 1.6056338028169013, 1.5833333333333335, 1.5833333333333335, 1.591549295774648]}",./output/modelsaves/breastcancer/gandalf/202310-0322-1611-46149d81-1443-412b-88d9-597f45defae7//202310-0322-1611-46149d81-1443-412b-88d9-597f45defae7,2227.384269475937
202310-0320-4234-c518eafb-f2cb-495f-acad-47140ad58f78,"{'dataset': 'ageconditions', 'model': 's1dcnn', 'best_params': {}, 'param_grid': {'batch_size': [32, 64, 128, 256], 'hidden_size': [1024, 2048, 4096], 'optimizer_fn': {'Adam': {'weight_decay': [1e-05, 0.001], 'learning_rate': [0.0001, 0.01]}, 'AdamW': {'weight_decay': [1e-05, 0.001], 'learning_rate': [0.0001, 0.01]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",ageconditions,s1dcnn,hyperopt_kfold,f1,"{'AdamW_learning_rate': 0.00044767387618610034, 'AdamW_weight_decay': 4.063946817593354e-05, 'Adam_learning_rate': 0.0009521188238728633, 'Adam_weight_decay': 0.00035212679589927245, 'ExponentialLR_gamma': 0.9215793606179761, 'ReduceLROnPlateau_factor': 0.27461943195227345, 'ReduceLROnPlateau_patience': 4, 'batch_size': 39, 'hidden_size': 1024, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'outer_params': {'hyperopt_evals': 50, 'max_epochs': 1000, 'early_stopping': True, 'shuffle': True, 'validation_fraction': 0.15, 'early_stopping_patience': 10}}",0.7316017316017316,0.06744083026792175,"{'recall': [0.8181818181818182, 0.6818181818181818, 0.6818181818181818, 0.7142857142857143, 0.8095238095238095], 'precision': [0.8181818181818182, 0.6521739130434783, 0.6818181818181818, 0.6521739130434783, 0.8095238095238095], 'accuracy': [0.936, 0.88, 0.8870967741935484, 0.8870967741935484, 0.9354838709677419], 'f1': [0.8181818181818182, 0.6666666666666666, 0.6818181818181818, 0.6818181818181819, 0.8095238095238095], 'roc_auc': [0.9646954986760813, 0.8929832303618712, 0.9148841354723707, 0.8964401294498382, 0.965788257050393], 'area_under_pr': [0.767327430390335, 0.6883905061617445, 0.707809825670253, 0.5930110368670026, 0.8869740845055971], 'lift': [4.261363636363637, 4.261363636363637, 4.696969696969697, 4.428571428571429, 5.412698412698413]}",./output/modelsaves/ageconditions/s1dcnn/202310-0320-4234-c518eafb-f2cb-495f-acad-47140ad58f78//202310-0320-4234-c518eafb-f2cb-495f-acad-47140ad58f78,9146.698411226273
202310-0309-4158-3d88b612-7446-4062-9870-a6df6bc0ad09,"{'dataset': 'creditcard', 'model': 'autoint', 'best_params': {}, 'param_grid': {'batch_size': [1024, 2048, 4096], 'attn_embed_dim_multiplier': [2, 16], 'num_heads': [2, 8], 'num_attn_blocks': [2, 6], 'attn_dropouts': [0.0, 0.3], 'embedding_dim': [8, 32], 'embedding_initialization': ['kaiming_uniform', 'kaiming_normal'], 'embedding_bias': [True, False], 'share_embedding': [True, False], 'share_embedding_strategy': ['add', 'fraction'], 'shared_embedding_fraction': [0.25, 0.1, 0.5], 'deep_layers': [True, False], 'layers': ['128-64-32', '128-64-32-16', '256-128-64'], 'dropout': [0.0, 0.3], 'activation': ['ReLU', 'LeakyReLU'], 'initialization': ['kaiming', 'xavier'], 'attention_pooling': [True, False], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",creditcard,autoint,hyperopt_kfold,lift,"{'AdamW_weight_decay': 1.601533180119409e-05, 'Adam_weight_decay': 2.7234679770877924e-05, 'ExponentialLR_gamma': 0.9454234062258264, 'ReduceLROnPlateau_factor': 0.6813473561199678, 'ReduceLROnPlateau_patience': 4, 'activation': 'ReLU', 'attention_pooling': True, 'attn_dropouts': 0.0004919069394333064, 'attn_embed_dim_multiplier': 5, 'batch_size': 2858, 'deep_layers': True, 'dropout': 0.09134220239469389, 'embedding_bias': False, 'embedding_dim': 20, 'embedding_initialization': 'kaiming_normal', 'initialization': 'kaiming', 'layers': '256-128-64', 'num_attn_blocks': 4, 'num_heads': 5, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>, 'share_embedding': True, 'share_embedding_strategy': 'add', 'shared_embedding_fraction': 0.12541604708700752, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 16, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 8}}",9.553110440422339,0.18911658779685891,"{'recall': [0.8686868686868687, 0.9393939393939394, 0.9489795918367347, 0.9183673469387755, 0.8673469387755102], 'precision': [0.088659793814433, 0.048538622129436326, 0.05090311986863711, 0.03697617091207888, 0.07246376811594203], 'accuracy': [0.9842526596678487, 0.9678908746181665, 0.9694703393549973, 0.958708590087955, 0.9806709854110708], 'f1': [0.16089803554724041, 0.09230769230769231, 0.09662337662337663, 0.07109004739336493, 0.13375295043273014], 'roc_auc': [0.9850636040513465, 0.9841929130746112, 0.9956010454055881, 0.9794857816154617, 0.9814023106736671], 'area_under_pr': [0.7294419964804062, 0.731811905691459, 0.7629059454990631, 0.7671167044731543, 0.728264410539653], 'lift': [9.59629653274316, 9.495282885030075, 9.898132954024305, 9.387919915157074, 9.387919915157074]}",./output/modelsaves/creditcard/autoint/202310-0309-4158-3d88b612-7446-4062-9870-a6df6bc0ad09//202310-0309-4158-3d88b612-7446-4062-9870-a6df6bc0ad09,57120.861974954605
202310-0401-3359-37f88c0a-ea27-4368-aacf-02c25e4a9a5c,"{'dataset': 'ageconditions', 'model': 'autoint', 'best_params': {}, 'param_grid': {'batch_size': [32, 64, 128, 256], 'attn_embed_dim_multiplier': [2, 16], 'num_heads': [2, 8], 'num_attn_blocks': [2, 6], 'attn_dropouts': [0.0, 0.3], 'embedding_dim': [8, 32], 'embedding_initialization': ['kaiming_uniform', 'kaiming_normal'], 'embedding_bias': [True, False], 'share_embedding': [True, False], 'share_embedding_strategy': ['add', 'fraction'], 'shared_embedding_fraction': [0.25, 0.1, 0.5], 'deep_layers': [True, False], 'layers': ['128-64-32', '128-64-32-16', '256-128-64'], 'dropout': [0.0, 0.3], 'activation': ['ReLU', 'LeakyReLU'], 'initialization': ['kaiming', 'xavier'], 'attention_pooling': [True, False], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",ageconditions,autoint,hyperopt_kfold,f1,"{'AdamW_weight_decay': 1.0984221499639716e-05, 'Adam_weight_decay': 1.319608864273046e-05, 'ExponentialLR_gamma': 0.9235795267757555, 'ReduceLROnPlateau_factor': 0.6497225637061429, 'ReduceLROnPlateau_patience': 5, 'activation': 'ReLU', 'attention_pooling': True, 'attn_dropouts': 0.29970216893258317, 'attn_embed_dim_multiplier': 15, 'batch_size': 130, 'deep_layers': True, 'dropout': 0.06818792277669376, 'embedding_bias': True, 'embedding_dim': 20, 'embedding_initialization': 'kaiming_normal', 'initialization': 'xavier', 'layers': '256-128-64', 'num_attn_blocks': 3, 'num_heads': 2, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>, 'share_embedding': True, 'share_embedding_strategy': 'fraction', 'shared_embedding_fraction': 0.35763830156919896, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 16, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 10}}",0.7250547259005037,0.06566011092471022,"{'recall': [0.6818181818181818, 0.8181818181818182, 0.8181818181818182, 0.8095238095238095, 0.8571428571428571], 'precision': [0.6, 0.6, 0.75, 0.6071428571428571, 0.782608695652174], 'accuracy': [0.864, 0.872, 0.9193548387096774, 0.8790322580645161, 0.9354838709677419], 'f1': [0.6382978723404256, 0.6923076923076923, 0.7826086956521738, 0.6938775510204083, 0.8181818181818182], 'roc_auc': [0.8870255957634599, 0.8790820829655781, 0.928698752228164, 0.9195561719833564, 0.9639389736477114], 'area_under_pr': [0.7271544846367896, 0.6849921561201442, 0.7620361728263501, 0.7301032469927016, 0.8583179764645259], 'lift': [4.261363636363637, 4.261363636363637, 4.227272727272727, 4.920634920634921, 5.412698412698413]}",./output/modelsaves/ageconditions/autoint/202310-0401-3359-37f88c0a-ea27-4368-aacf-02c25e4a9a5c//202310-0401-3359-37f88c0a-ea27-4368-aacf-02c25e4a9a5c,1425.5598788261414
202310-0320-0822-440abe03-2d68-421f-9caa-4faa97ad5ecb,"{'dataset': 'ageconditions', 'model': 'gate', 'best_params': {}, 'param_grid': {'batch_size': [32, 64, 128, 256], 'tree_depth': [4, 7], 'num_trees': [4, 10], 'chain_trees': [False, True], 'gflu_stages': [3, 8], 'gflu_dropout': [0.0, 0.05], 'tree_dropout': [0.0, 0.05], 'tree_wise_attention_dropout': [0.0, 0.05], 'embedding_dropout': [0, 0.2], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",ageconditions,gate,hyperopt_kfold,f1,"{'AdamW_weight_decay': 5.624568251935357e-05, 'Adam_weight_decay': 4.2481596513078924e-05, 'ExponentialLR_gamma': 0.9416589960753103, 'ReduceLROnPlateau_factor': 0.19010287932104614, 'ReduceLROnPlateau_patience': 5, 'batch_size': 71, 'chain_trees': True, 'embedding_dropout': 0, 'gflu_dropout': 0.021196378590909587, 'gflu_stages': 3, 'num_trees': 6, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'tree_depth': 6, 'tree_dropout': 0.00010009629170096984, 'tree_wise_attention_dropout': 0.005880590360773447, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 5}}",0.7232636928289102,0.10955665938456796,"{'recall': [0.8181818181818182, 0.8181818181818182, 0.6818181818181818, 0.5714285714285714, 0.9523809523809523], 'precision': [0.8181818181818182, 0.5294117647058824, 0.75, 0.5714285714285714, 0.8], 'accuracy': [0.936, 0.84, 0.904, 0.856, 0.952], 'f1': [0.8181818181818182, 0.6428571428571428, 0.7142857142857143, 0.5714285714285714, 0.8695652173913043], 'roc_auc': [0.9704324801412181, 0.9148278905560459, 0.9020300088261254, 0.8557692307692307, 0.9871794871794871], 'area_under_pr': [0.8483068255742754, 0.7940282326501718, 0.7730721251735372, 0.6815435651856694, 0.9343674309873378], 'lift': [4.261363636363637, 5.208333333333333, 4.734848484848485, 4.464285714285714, 5.456349206349206]}",./output/modelsaves/ageconditions/gate/202310-0320-0822-440abe03-2d68-421f-9caa-4faa97ad5ecb//202310-0320-0822-440abe03-2d68-421f-9caa-4faa97ad5ecb,27518.370559692383
202310-0400-2228-04048ee7-d601-443e-8103-ea8860a5320b,"{'dataset': 'creditcard', 'model': 'tabtransformer', 'best_params': {}, 'param_grid': {'batch_size': [1024, 2048, 4096], 'embedding_bias': [True, False], 'embedding_initialization': ['kaiming_uniform', 'kaiming_normal'], 'shared_embedding_fraction': [0.125, 0.25, 0.5], 'num_attn_blocks': [4, 10], 'attn_dropout': [0.05, 0.3], 'add_norm_dropout': [0.05, 0.3], 'ff_dropout': [0.05, 0.3], 'ff_hidden_multiplier': [2, 6], 'transformer_activation': ['GEGLU', 'ReGLU', 'SwiGLU'], 'embedding_dropout': [0.05, 0.3], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",creditcard,tabtransformer,hyperopt_kfold,lift,"{'AdamW_weight_decay': 1.7329503453962286e-05, 'Adam_weight_decay': 7.419737634170797e-05, 'ExponentialLR_gamma': 0.9290571281595368, 'ReduceLROnPlateau_factor': 0.20269628664088354, 'ReduceLROnPlateau_patience': 4, 'add_norm_dropout': 0.19290551956134752, 'attn_dropout': 0.10485881709374144, 'batch_size': 3629, 'embedding_bias': False, 'embedding_dropout': 0.14878218841393676, 'embedding_initialization': 'kaiming_normal', 'ff_dropout': 0.0502771038885033, 'ff_hidden_multiplier': 6, 'num_attn_blocks': 7, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>, 'shared_embedding_fraction': 0.3205701508996826, 'transformer_activation': 'ReGLU', 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 16, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 8}}",8.981260252866893,0.7994225149557291,"{'recall': [0.898989898989899, 0.9292929292929293, 0.9285714285714286, 0.8571428571428571, 0.8469387755102041], 'precision': [0.0430159497341711, 0.10442678774120318, 0.04975396391470749, 0.0025620691758677485, 0.002538692114761118], 'accuracy': [0.965064428917524, 0.9860257715670095, 0.9693650041256299, 0.42564210600235247, 0.42722213444286444], 'f1': [0.08210332103321033, 0.1877551020408163, 0.09444732745199792, 0.0051088675343632164, 0.005062210295193949], 'roc_auc': [0.9872966870399296, 0.9830160635957024, 0.983970872347321, 0.8564047781151045, 0.8543331142843504], 'area_under_pr': [0.5890250961760117, 0.6686145303590593, 0.7185878788691377, 0.5814273287537344, 0.533071414579346], 'lift': [9.798323828169334, 9.495282885030075, 9.592005130703965, 7.959323406328823, 8.06136601410227]}",./output/modelsaves/creditcard/tabtransformer/202310-0400-2228-04048ee7-d601-443e-8103-ea8860a5320b//202310-0400-2228-04048ee7-d601-443e-8103-ea8860a5320b,31761.623249530792
202310-0313-2326-1b89b3c4-bbff-475f-be7e-3301e31e804a,"{'dataset': 'covertype', 'model': 'categoryembedding', 'best_params': {}, 'param_grid': {'batch_size': [1024, 2048, 4096], 'layers': ['128-64-32', '128-64-32-16', '256-128-64'], 'activation': ['ReLU', 'LeakyReLU', 'Tanh'], 'initialization': ['kaiming', 'xavier'], 'dropout': [0.0, 0.3], 'embedding_dropout': [0.0, 0.3], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",covertype,categoryembedding,hyperopt_kfold,accuracy,"{'AdamW_weight_decay': 1.963760672315473e-05, 'Adam_weight_decay': 4.101854042788317e-05, 'ExponentialLR_gamma': 0.9883050184314528, 'ReduceLROnPlateau_factor': 0.16547387971926772, 'ReduceLROnPlateau_patience': 3, 'activation': 'LeakyReLU', 'batch_size': 3263, 'dropout': 0.04123266038322592, 'embedding_dropout': 0.0008387667290010517, 'initialization': 'kaiming', 'layers': '256-128-64', 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 16, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 5}}",0.8634110742985953,0.009302240849005107,"{'accuracy': [0.8540113517072042, 0.8590441621294616, 0.8808049535603715, 0.8644354293441514, 0.8587594747517882], 'f1': [0.8577607541234898, 0.8636529180702942, 0.8831465322129318, 0.8676971393836224, 0.8628035895877931]}",./output/modelsaves/covertype/categoryembedding/202310-0313-2326-1b89b3c4-bbff-475f-be7e-3301e31e804a//202310-0313-2326-1b89b3c4-bbff-475f-be7e-3301e31e804a,75829.85431170464
202310-0411-0702-f99c211b-0824-4b55-8f57-ed8d2d70b759,"{'dataset': 'adult', 'model': 'autoint', 'best_params': {}, 'param_grid': {'batch_size': [1024, 2048, 4096], 'attn_embed_dim_multiplier': [2, 16], 'num_heads': [2, 8], 'num_attn_blocks': [2, 6], 'attn_dropouts': [0.0, 0.3], 'embedding_dim': [8, 32], 'embedding_initialization': ['kaiming_uniform', 'kaiming_normal'], 'embedding_bias': [True, False], 'share_embedding': [True, False], 'share_embedding_strategy': ['add', 'fraction'], 'shared_embedding_fraction': [0.25, 0.1, 0.5], 'deep_layers': [True, False], 'layers': ['128-64-32', '128-64-32-16', '256-128-64'], 'dropout': [0.0, 0.3], 'activation': ['ReLU', 'LeakyReLU'], 'initialization': ['kaiming', 'xavier'], 'attention_pooling': [True, False], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",adult,autoint,hyperopt_kfold,roc_auc,"{'AdamW_weight_decay': 4.400053273044934e-05, 'Adam_weight_decay': 2.1274163723902545e-05, 'ExponentialLR_gamma': 0.967022716486249, 'ReduceLROnPlateau_factor': 0.33072803792945477, 'ReduceLROnPlateau_patience': 4, 'activation': 'LeakyReLU', 'attention_pooling': True, 'attn_dropouts': 0.08583666140757923, 'attn_embed_dim_multiplier': 11, 'batch_size': 2619, 'deep_layers': False, 'dropout': 0.20634435972889065, 'embedding_bias': False, 'embedding_dim': 27, 'embedding_initialization': 'kaiming_normal', 'initialization': 'kaiming', 'layers': '256-128-64', 'num_attn_blocks': 4, 'num_heads': 6, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'share_embedding': True, 'share_embedding_strategy': 'fraction', 'shared_embedding_fraction': 0.13686098177731834, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 16, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 8}}",0.9166538456296163,0.0021960328566957054,"{'recall': [0.8629700446144041, 0.8705357142857143, 0.875, 0.8813775510204082, 0.8533163265306123], 'precision': [0.5708263069139966, 0.588869715271786, 0.5759865659109992, 0.5547972701726215, 0.5799739921976593], 'accuracy': [0.8106863196683556, 0.8224815724815725, 0.8148034398034398, 0.8011363636363636, 0.8158783783783784], 'f1': [0.6871352448617102, 0.7025218733916623, 0.6946835443037974, 0.6809559004680956, 0.6905806451612904], 'roc_auc': [0.9167588398604846, 0.9182273865249984, 0.917297842984281, 0.9124500528366688, 0.9185351059416486], 'area_under_pr': [0.7995913629930015, 0.7923438354129583, 0.7894110270967508, 0.783058863581576, 0.80061454386288], 'lift': [3.730207681666388, 3.6490799084610805, 3.661838929120035, 3.6363208878021256, 3.770290604721151]}",./output/modelsaves/adult/autoint/202310-0411-0702-f99c211b-0824-4b55-8f57-ed8d2d70b759//202310-0411-0702-f99c211b-0824-4b55-8f57-ed8d2d70b759,9656.677675962448
202310-0413-4758-9bd06ddd-68b9-4dec-adc4-b5ec6091307b,"{'dataset': 'housing', 'model': 'autoint', 'best_params': {}, 'param_grid': {'batch_size': [1024, 2048, 4096], 'attn_embed_dim_multiplier': [2, 16], 'num_heads': [2, 8], 'num_attn_blocks': [2, 6], 'attn_dropouts': [0.0, 0.3], 'embedding_dim': [8, 32], 'embedding_initialization': ['kaiming_uniform', 'kaiming_normal'], 'embedding_bias': [True, False], 'share_embedding': [True, False], 'share_embedding_strategy': ['add', 'fraction'], 'shared_embedding_fraction': [0.25, 0.1, 0.5], 'deep_layers': [True, False], 'layers': ['128-64-32', '128-64-32-16', '256-128-64'], 'dropout': [0.0, 0.3], 'activation': ['ReLU', 'LeakyReLU'], 'initialization': ['kaiming', 'xavier'], 'attention_pooling': [True, False], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",housing,autoint,hyperopt_kfold,r2_score,"{'AdamW_weight_decay': 4.4857997761907134e-05, 'Adam_weight_decay': 2.455981033129329e-05, 'ExponentialLR_gamma': 0.9899831810607054, 'ReduceLROnPlateau_factor': 0.358441840165887, 'ReduceLROnPlateau_patience': 3, 'activation': 'ReLU', 'attention_pooling': False, 'attn_dropouts': 0.16738520300605977, 'attn_embed_dim_multiplier': 8, 'batch_size': 2984, 'deep_layers': True, 'dropout': 0.13091506328522076, 'embedding_bias': False, 'embedding_dim': 23, 'embedding_initialization': 'kaiming_normal', 'initialization': 'xavier', 'layers': '256-128-64', 'num_attn_blocks': 5, 'num_heads': 4, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'share_embedding': True, 'share_embedding_strategy': 'add', 'shared_embedding_fraction': 0.33099864850507843, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 16, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 8}}",0.7163675024381873,0.008503206648153011,"{'mse': [0.4604151644558812, 0.4498201573364801, 0.4398964578022797, 0.4435119965620261, 0.4736769768328411], 'rmse': [0.6785389925832422, 0.6706863330473345, 0.6632469056107836, 0.6659669635665316, 0.688241946435148], 'r2_score': [0.7064184765303629, 0.7264249751892891, 0.7195653144858104, 0.7232494496190329, 0.7061792963664404]}",./output/modelsaves/housing/autoint/202310-0413-4758-9bd06ddd-68b9-4dec-adc4-b5ec6091307b//202310-0413-4758-9bd06ddd-68b9-4dec-adc4-b5ec6091307b,8843.43004655838
202310-0416-1522-42db46f6-368a-422f-af04-d24c9e4bf7fe,"{'dataset': 'heloc', 'model': 'autoint', 'best_params': {}, 'param_grid': {'batch_size': [1024, 2048, 4096], 'attn_embed_dim_multiplier': [2, 16], 'num_heads': [2, 8], 'num_attn_blocks': [2, 6], 'attn_dropouts': [0.0, 0.3], 'embedding_dim': [8, 32], 'embedding_initialization': ['kaiming_uniform', 'kaiming_normal'], 'embedding_bias': [True, False], 'share_embedding': [True, False], 'share_embedding_strategy': ['add', 'fraction'], 'shared_embedding_fraction': [0.25, 0.1, 0.5], 'deep_layers': [True, False], 'layers': ['128-64-32', '128-64-32-16', '256-128-64'], 'dropout': [0.0, 0.3], 'activation': ['ReLU', 'LeakyReLU'], 'initialization': ['kaiming', 'xavier'], 'attention_pooling': [True, False], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",heloc,autoint,hyperopt_kfold,lift,"{'AdamW_weight_decay': 5.661435441653901e-05, 'Adam_weight_decay': 2.4334640134083908e-05, 'ExponentialLR_gamma': 0.9829536237667388, 'ReduceLROnPlateau_factor': 0.19875662089953874, 'ReduceLROnPlateau_patience': 4, 'activation': 'ReLU', 'attention_pooling': True, 'attn_dropouts': 0.17671374013279456, 'attn_embed_dim_multiplier': 3, 'batch_size': 2594, 'deep_layers': True, 'dropout': 0.1821383878487001, 'embedding_bias': False, 'embedding_dim': 21, 'embedding_initialization': 'kaiming_uniform', 'initialization': 'kaiming', 'layers': '128-64-32', 'num_attn_blocks': 4, 'num_heads': 6, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'share_embedding': True, 'share_embedding_strategy': 'add', 'shared_embedding_fraction': 0.29410093423217215, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 16, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 8}}",1.7215777516901547,0.031488307216784105,"{'recall': [0.7554945054945055, 0.7472527472527473, 0.7481684981684982, 0.7152014652014652, 0.7525206232813932], 'precision': [0.7217847769028871, 0.7398005439709883, 0.7230088495575221, 0.7381852551984878, 0.7369838420107719], 'accuracy': [0.7203632887189293, 0.7308795411089866, 0.7189292543021033, 0.7189292543021033, 0.7307508369201339], 'f1': [0.7382550335570469, 0.7435079726651481, 0.7353735373537353, 0.7265116279069768, 0.744671201814059], 'roc_auc': [0.7951996336996336, 0.7957619047619048, 0.7909111721611721, 0.7936327838827839, 0.8052337305224564], 'area_under_pr': [0.7993374702324682, 0.7848981921143912, 0.7834483464410156, 0.7987351960959883, 0.8032655947928518], 'lift': [1.7507580139159085, 1.668261562998405, 1.7049266522950732, 1.7507580139159085, 1.7331845153254772]}",./output/modelsaves/heloc/autoint/202310-0416-1522-42db46f6-368a-422f-af04-d24c9e4bf7fe//202310-0416-1522-42db46f6-368a-422f-af04-d24c9e4bf7fe,4244.879081249237
202310-0400-2228-2d8ea6c4-6f90-4101-8757-bdfd1a28b8ff,"{'dataset': 'creditcard', 'model': 'node', 'best_params': {}, 'param_grid': {'batch_size': [512, 1024], 'num_layers': [1, 2, 3], 'num_trees': [12, 128], 'additional_tree_output_dim': [2, 3, 4], 'depth': [5, 7], 'choice_function': ['entmax15', 'sparsemax'], 'bin_function': ['entmoid15', 'sparsemoid'], 'input_dropout': [0.0, 0.1], 'embedding_dropout': [0.0, 0.1], 'embed_categorical': [True, False], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",creditcard,node,hyperopt_kfold,lift,"{'AdamW_weight_decay': 7.17401447789401e-05, 'Adam_weight_decay': 2.5870229044550827e-05, 'ExponentialLR_gamma': 0.9322233227034595, 'ReduceLROnPlateau_factor': 0.18876279514234512, 'ReduceLROnPlateau_patience': 4, 'additional_tree_output_dim': 4, 'batch_size': 617, 'bin_function': 'entmoid15', 'choice_function': 'entmax15', 'depth': 7, 'embed_categorical': False, 'embedding_dropout': 0.021239889309716663, 'input_dropout': 0.020983982145314155, 'num_layers': 1, 'num_trees': 67, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 8}}",9.573313169964955,0.14994108412375545,"{'recall': [0.898989898989899, 0.9090909090909091, 0.9183673469387755, 0.9081632653061225, 0.8673469387755102], 'precision': [0.03896672504378284, 0.11568123393316196, 0.10404624277456648, 0.13126843657817108, 0.08056872037914692], 'accuracy': [0.9612899827955479, 0.9877637723394543, 0.9862537525675462, 0.9895015888063763, 0.9827425782552975], 'f1': [0.07469576164498531, 0.20524515393386547, 0.18691588785046728, 0.22938144329896903, 0.1474414570685169], 'roc_auc': [0.9842801331642933, 0.9815439803305376, 0.9931342320442941, 0.9755613833032994, 0.9816939173889839], 'area_under_pr': [0.6230823196548351, 0.7884317648834676, 0.7614568579720509, 0.7826544583831195, 0.6890189936174345], 'lift': [9.495282885030075, 9.697310180456247, 9.796090346250859, 9.387919915157074, 9.48996252293052]}",./output/modelsaves/creditcard/node/202310-0400-2228-2d8ea6c4-6f90-4101-8757-bdfd1a28b8ff//202310-0400-2228-2d8ea6c4-6f90-4101-8757-bdfd1a28b8ff,68256.09827232361
202310-0419-2617-c0862efe-7fa7-4686-b72e-e89c634d2efa,"{'dataset': 'iris', 'model': 'resnet', 'best_params': {}, 'param_grid': {'batch_size': [32, 64, 128, 256], 'resnet_depth': ['resnet18', 'resnet34', 'resnet50'], 'optimizer_fn': {'Adam': {'weight_decay': [1e-05, 0.001], 'learning_rate': [0.0001, 0.001]}, 'AdamW': {'weight_decay': [1e-05, 0.001], 'learning_rate': [0.0001, 0.001]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",iris,resnet,hyperopt_kfold,accuracy,"{'AdamW_learning_rate': 0.0007450029975279926, 'AdamW_weight_decay': 9.166987910726041e-05, 'Adam_learning_rate': 0.0005780546450052875, 'Adam_weight_decay': 0.0002699111583238274, 'ExponentialLR_gamma': 0.9574825542310041, 'ReduceLROnPlateau_factor': 0.4155630057833172, 'ReduceLROnPlateau_patience': 4, 'batch_size': 197, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'resnet_depth': 'resnet18', 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>, 'outer_params': {'hyperopt_evals': 50, 'max_epochs': 1000, 'early_stopping': True, 'early_stopping_patience': 10, 'validation_fraction': 0.15}}",0.9733333333333334,0.038873012632301994,"{'accuracy': [1.0, 1.0, 0.9666666666666667, 1.0, 0.9], 'f1': [1.0, 1.0, 0.9665831244778613, 1.0, 0.8997493734335841]}",./output/modelsaves/iris/resnet/202310-0419-2617-c0862efe-7fa7-4686-b72e-e89c634d2efa//202310-0419-2617-c0862efe-7fa7-4686-b72e-e89c634d2efa,24980.575709342957
202310-0409-1149-5281f52c-f817-4e4f-8cec-5a526de588db,"{'dataset': 'covertype', 'model': 'gandalf', 'best_params': {}, 'param_grid': {'batch_size': [1024, 2048, 4096], 'gflu_stages': [4, 10], 'gflu_dropout': [0.0, 0.3], 'embedding_dropout': [0.0, 0.3], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",covertype,gandalf,hyperopt_kfold,accuracy,"{'AdamW_weight_decay': 7.165104179309722e-05, 'Adam_weight_decay': 1.6282103177013785e-05, 'ExponentialLR_gamma': 0.9564405135455273, 'ReduceLROnPlateau_factor': 0.6148011248531614, 'ReduceLROnPlateau_patience': 4, 'batch_size': 2951, 'embedding_dropout': 0.03585398775219553, 'gflu_dropout': 0.017349106923398104, 'gflu_stages': 7, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 16, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 8}}",0.9060143450351943,0.00726166628088425,"{'accuracy': [0.9089016600537337, 0.9155901925198392, 0.9053236539624925, 0.893277819294687, 0.9069783993452191], 'f1': [0.9111918483095484, 0.9176780483580919, 0.9085569043602068, 0.8969756714657936, 0.9090156996982148]}",./output/modelsaves/covertype/gandalf/202310-0409-1149-5281f52c-f817-4e4f-8cec-5a526de588db//202310-0409-1149-5281f52c-f817-4e4f-8cec-5a526de588db,91644.51011705399
202310-0511-2413-4542eee0-2711-42c3-ae68-ba7b979f4e6b,"{'dataset': 'heloc', 'model': 'mlp', 'best_params': {}, 'param_grid': {'hidden_layer_sizes': [[64, 32, 16], [256, 128, 64, 32], [128, 64, 32, 16]], 'activation': ['relu', 'tanh', 'logistic'], 'solver': ['adam', 'lbfgs'], 'alpha': [0.0001, 0.001, 0.01], 'learning_rate_init': [0.0001, 0.01, 0.1], 'beta_1': [0.99, 0.8], 'beta_2': [0.999, 0.9], 'batch_size': [512, 1024, 2048]}}",heloc,mlp,hyperopt_kfold,lift,"{'activation': 'relu', 'alpha': 0.0002689693425232626, 'batch_size': 1425, 'beta_1': 0.8638864698727106, 'beta_2': 0.9540668089429838, 'hidden_layer_sizes': (256, 128, 64, 32), 'learning_rate_init': 0.00297504835718297, 'solver': 'adam', 'outer_params': {'cv_iterations': 10, 'early_stopping': True, 'cv_size': 5, 'validation_fraction': 0.15, 'hyperopt_evals': 50, 'n_iter_no_change': 30, 'max_iter': 1000}}",1.701409542906962,0.02217802589483308,"{'recall': [0.7261904761904762, 0.7554945054945055, 0.7756410256410257, 0.7994505494505495, 0.7873510540788268], 'precision': [0.7248628884826326, 0.7313829787234043, 0.7070116861435726, 0.6984, 0.7267343485617598], 'accuracy': [0.7131931166347992, 0.7275334608030593, 0.7151051625239006, 0.7151051625239006, 0.7345767575322812], 'f1': [0.7255260750228728, 0.7432432432432433, 0.7397379912663755, 0.7455166524338173, 0.7558293004839419], 'roc_auc': [0.7860879120879121, 0.7909230769230768, 0.7828388278388279, 0.788540293040293, 0.7997250229147572], 'area_under_pr': [0.7894509284106048, 0.7827815617357561, 0.7721031361351073, 0.7931760583265084, 0.7919769758374331], 'lift': [1.7324254692675742, 1.6865941076467392, 1.668261562998405, 1.7140929246192402, 1.7056736500028506]}",./output/modelsaves/heloc/mlp/202310-0511-2413-4542eee0-2711-42c3-ae68-ba7b979f4e6b//202310-0511-2413-4542eee0-2711-42c3-ae68-ba7b979f4e6b,4728.474800825119
202310-0512-0112-1fd0553b-af55-478a-a4b9-0132e3963f96,"{'dataset': 'adult', 'model': 'mlp', 'best_params': {}, 'param_grid': {'hidden_layer_sizes': [[64, 32, 16], [256, 128, 64, 32], [128, 64, 32, 16]], 'activation': ['relu', 'tanh', 'logistic'], 'solver': ['adam', 'lbfgs'], 'alpha': [0.0001, 0.001, 0.01], 'learning_rate_init': [0.0001, 0.01, 0.1], 'beta_1': [0.99, 0.8], 'beta_2': [0.999, 0.9], 'batch_size': [512, 1024, 2048]}}",adult,mlp,hyperopt_kfold,roc_auc,"{'activation': 'logistic', 'alpha': 0.0014319302577397478, 'batch_size': 1533, 'beta_1': 0.8296661735538197, 'beta_2': 0.9082381933723106, 'hidden_layer_sizes': (64, 32, 16), 'learning_rate_init': 0.0017925474361585993, 'solver': 'adam', 'outer_params': {'cv_iterations': 10, 'early_stopping': True, 'cv_size': 5, 'validation_fraction': 0.15, 'hyperopt_evals': 50, 'n_iter_no_change': 30, 'max_iter': 1000}}",0.9088590818084754,0.0026972448248462344,"{'recall': [0.6360739324410453, 0.6371173469387755, 0.5950255102040817, 0.6167091836734694, 0.6728316326530612], 'precision': [0.7279358132749818, 0.7239130434782609, 0.7210200927357032, 0.7178916109873794, 0.7038025350233489], 'accuracy': [0.8550591125441425, 0.8541154791154791, 0.847051597051597, 0.8493550368550369, 0.8530405405405406], 'f1': [0.6789115646258503, 0.6777476255088195, 0.6519916142557652, 0.6634648370497428, 0.6879686990544506], 'roc_auc': [0.9088762914560218, 0.9115993257132949, 0.9102136531190146, 0.9037553507446668, 0.9098507880093784], 'area_under_pr': [0.7817475080956386, 0.7737934654642852, 0.7685362745154489, 0.7570229162314412, 0.7824477638767632], 'lift': [3.6919491413416043, 3.578905294836829, 3.598043825825261, 3.5087306812125774, 3.687356970437945]}",./output/modelsaves/adult/mlp/202310-0512-0112-1fd0553b-af55-478a-a4b9-0132e3963f96//202310-0512-0112-1fd0553b-af55-478a-a4b9-0132e3963f96,13720.003951311111
202310-0512-4301-a1b7d294-757b-471b-ba7d-205f654a1100,"{'dataset': 'heloc', 'model': 's1dcnn', 'best_params': {}, 'param_grid': {'batch_size': [1024, 4096], 'hidden_size': [2048, 4096], 'optimizer_fn': {'Adam': {'weight_decay': [1e-05, 0.001], 'learning_rate': [0.0001, 0.01]}, 'AdamW': {'weight_decay': [1e-05, 0.001], 'learning_rate': [0.0001, 0.01]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",heloc,s1dcnn,hyperopt_kfold,lift,"{'AdamW_learning_rate': 0.0003101076677310251, 'AdamW_weight_decay': 9.84294099445203e-05, 'Adam_learning_rate': 0.0001615333323495279, 'Adam_weight_decay': 3.270671473320069e-05, 'ExponentialLR_gamma': 0.9116451716443046, 'ReduceLROnPlateau_factor': 0.20417216747075947, 'ReduceLROnPlateau_patience': 5, 'batch_size': 1729, 'hidden_size': 4096, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>, 'outer_params': {'hyperopt_evals': 50, 'max_epochs': 1000, 'early_stopping': True, 'shuffle': True, 'validation_fraction': 0.15, 'early_stopping_patience': 6, 'tol': 1e-05}}",1.7142439306074793,0.0201533661504794,"{'recall': [0.5714285714285714, 0.5732600732600732, 0.6181318681318682, 0.5741758241758241, 0.5270394133822182], 'precision': [0.7918781725888325, 0.7884130982367759, 0.7653061224489796, 0.7876884422110553, 0.7876712328767124], 'accuracy': [0.6978967495219885, 0.6969407265774379, 0.7017208413001912, 0.6969407265774379, 0.6791009086561454], 'f1': [0.6638297872340426, 0.6638388123011665, 0.6838905775075987, 0.6641949152542374, 0.6315211422295443], 'roc_auc': [0.7849038461538461, 0.79355173992674, 0.788032967032967, 0.7775682234432234, 0.7912140238313474], 'area_under_pr': [0.7842106852637425, 0.7922331945811466, 0.7833666791319146, 0.7835792204040535, 0.786081258737445], 'lift': [1.6865941076467392, 1.7415917415917415, 1.695760379970906, 1.7232591969434075, 1.724014226884602]}",./output/modelsaves/heloc/s1dcnn/202310-0512-4301-a1b7d294-757b-471b-ba7d-205f654a1100//202310-0512-4301-a1b7d294-757b-471b-ba7d-205f654a1100,18948.726698875427
202310-0519-4500-8b279457-b135-4ba7-b547-bb7e68778407,"{'dataset': 'heloc', 'model': 'tabnet', 'best_params': {}, 'param_grid': {'virtual_batch_size_ratio': [0.125, 0.25, 0.5, 1.0], 'batch_size': [1024, 2048, 4096], 'weights': [0, 1], 'mask_type': ['sparsemax', 'entmax'], 'n_d': [6, 32], 'n_steps': [1, 6], 'gamma': [1.0, 2.0], 'n_independent': [1, 3], 'n_shared': [1, 3], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",heloc,tabnet,hyperopt_kfold,lift,"{'AdamW_weight_decay': 7.724352747284916e-05, 'Adam_weight_decay': 1.5168022316546395e-05, 'ExponentialLR_gamma': 0.9393376525909657, 'ReduceLROnPlateau_factor': 0.6173526196335072, 'ReduceLROnPlateau_patience': 5, 'batch_size': 1966, 'gamma': 1.507742315225935, 'mask_type': 'entmax', 'n_d': 32, 'n_independent': 1, 'n_shared': 1, 'n_steps': 1, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'virtual_batch_size_ratio': 0.25, 'weights': 0, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 16, 'tol': 1e-05, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 8}}",1.7032444038184789,0.022139103017265953,"{'recall': [0.7362637362637363, 0.7793040293040293, 0.6840659340659341, 0.7893772893772893, 0.7314390467461045], 'precision': [0.7262872628726287, 0.7248722316865417, 0.747, 0.7088815789473685, 0.7354838709677419], 'accuracy': [0.7174952198852772, 0.7304015296367112, 0.7141491395793499, 0.7208413001912046, 0.7226207556193209], 'f1': [0.7312414733969986, 0.7511032656663724, 0.7141491395793498, 0.7469670710571924, 0.7334558823529411], 'roc_auc': [0.7930128205128205, 0.7934725274725275, 0.7933882783882784, 0.7890714285714286, 0.7989802933088909], 'area_under_pr': [0.7942795520181463, 0.7851421008146248, 0.7813328801684029, 0.7877633951895391, 0.7927714889905365], 'lift': [1.7232591969434075, 1.6865941076467392, 1.668261562998405, 1.7140929246192402, 1.724014226884602]}",./output/modelsaves/heloc/tabnet/202310-0519-4500-8b279457-b135-4ba7-b547-bb7e68778407//202310-0519-4500-8b279457-b135-4ba7-b547-bb7e68778407,6817.078661441803
202310-0521-3837-a53cf685-b4ab-483f-8d5e-68f6486352c0,"{'dataset': 'heloc', 'model': 'gate', 'best_params': {}, 'param_grid': {'batch_size': [1024, 2048, 4096], 'tree_depth': [4, 6], 'num_trees': [4, 8], 'chain_trees': [False, True], 'gflu_stages': [3, 8], 'gflu_dropout': [0.0, 0.05], 'tree_dropout': [0.0, 0.05], 'tree_wise_attention_dropout': [0.0, 0.05], 'embedding_dropout': [0, 0.2], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",heloc,gate,hyperopt_kfold,lift,"{'AdamW_weight_decay': 8.811872456315357e-05, 'Adam_weight_decay': 1.1235353557315217e-05, 'ExponentialLR_gamma': 0.9700095769381296, 'ReduceLROnPlateau_factor': 0.4282618160844072, 'ReduceLROnPlateau_patience': 3, 'batch_size': 2493, 'chain_trees': True, 'embedding_dropout': 0, 'gflu_dropout': 0.017945005885411366, 'gflu_stages': 3, 'num_trees': 5, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'tree_depth': 4, 'tree_dropout': 0.018422663985711667, 'tree_wise_attention_dropout': 0.0419344478847622, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 16, 'tol': 1e-05, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 8}}",1.6977430339772952,0.02280015257758037,"{'recall': [0.7298534798534798, 0.7426739926739927, 0.7344322344322345, 0.7664835164835165, 0.7332722273143905], 'precision': [0.7325367647058824, 0.7406392694063927, 0.7212230215827338, 0.7111299915038233, 0.7373271889400922], 'accuracy': [0.719885277246654, 0.7299235181644359, 0.7131931166347992, 0.7155831739961759, 0.7245337159253945], 'f1': [0.7311926605504587, 0.7416552354823961, 0.7277676950998184, 0.7377699427060379, 0.7352941176470588], 'roc_auc': [0.7897326007326007, 0.7906236263736264, 0.7895586080586081, 0.78457326007326, 0.8012305224564619], 'area_under_pr': [0.7937415614495604, 0.7816703729002499, 0.781105498428461, 0.7900787175664995, 0.7975371191761405], 'lift': [1.7140929246192402, 1.659095290674238, 1.6865941076467392, 1.7232591969434075, 1.7056736500028506]}",./output/modelsaves/heloc/gate/202310-0521-3837-a53cf685-b4ab-483f-8d5e-68f6486352c0//202310-0521-3837-a53cf685-b4ab-483f-8d5e-68f6486352c0,31036.82971405983
202310-0519-4454-dec45387-5756-4c85-920b-ccd3fe1244a4,"{'dataset': 'adult', 'model': 'gate', 'best_params': {}, 'param_grid': {'batch_size': [1024, 2048, 4096], 'tree_depth': [4, 6], 'num_trees': [4, 8], 'chain_trees': [False, True], 'gflu_stages': [3, 8], 'gflu_dropout': [0.0, 0.05], 'tree_dropout': [0.0, 0.05], 'tree_wise_attention_dropout': [0.0, 0.05], 'embedding_dropout': [0, 0.2], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",adult,gate,hyperopt_kfold,roc_auc,"{'AdamW_weight_decay': 6.085833563139353e-05, 'Adam_weight_decay': 8.568426480646662e-05, 'ExponentialLR_gamma': 0.9825221269523422, 'ReduceLROnPlateau_factor': 0.30423726282015157, 'ReduceLROnPlateau_patience': 5, 'batch_size': 1421, 'chain_trees': False, 'embedding_dropout': 0, 'gflu_dropout': 0.0271827149438309, 'gflu_stages': 6, 'num_trees': 7, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'tree_depth': 5, 'tree_dropout': 0.04160306944828655, 'tree_wise_attention_dropout': 0.00838833114834594, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 16, 'tol': 1e-05, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 8}}",0.9157013138171308,0.0022694616312051953,"{'recall': [0.8776290630975143, 0.8494897959183674, 0.8832908163265306, 0.8654336734693877, 0.8711734693877551], 'precision': [0.5565885206143897, 0.5906873614190687, 0.5589184826472962, 0.5623704931620389, 0.575885328836425], 'accuracy': [0.8020881314294488, 0.8220208845208845, 0.8040540540540541, 0.8054361179361179, 0.8144963144963145], 'f1': [0.6811773435567648, 0.6968349463771906, 0.684626791893228, 0.6817382567194172, 0.6934010152284265], 'roc_auc': [0.9144423921406045, 0.9181111613334654, 0.9161162417029918, 0.912006178381547, 0.9178305955270458], 'area_under_pr': [0.7937619309360047, 0.7935372954926658, 0.7899544574043141, 0.7876651822902568, 0.7997547874164055], 'lift': [3.71745483489146, 3.661838929120035, 3.6682184394495128, 3.6937364807674222, 3.7001159910968995]}",./output/modelsaves/adult/gate/202310-0519-4454-dec45387-5756-4c85-920b-ccd3fe1244a4//202310-0519-4454-dec45387-5756-4c85-920b-ccd3fe1244a4,52064.75595879555
202310-0610-1239-f54e8d7d-b051-462e-9ce9-f0e65e5bf8d9,"{'dataset': 'adult', 'model': 'fttransformer', 'best_params': {}, 'param_grid': {'batch_size': [1024, 2048, 4096], 'num_heads': [4, 10], 'input_embed_dim_multiplier': [2, 6], 'embedding_initialization': ['kaiming_uniform', 'kaiming_normal'], 'embedding_dropout': [0.05, 0.2], 'shared_embedding_fraction': [0.125, 0.25, 0.5], 'num_attn_blocks': [4, 8], 'attn_dropout': [0.05, 0.2], 'add_norm_dropout': [0.05, 0.2], 'ff_dropout': [0.05, 0.2], 'ff_hidden_multiplier': [4, 32], 'transformer_activation': ['GEGLU', 'ReGLU', 'SwiGLU'], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",adult,fttransformer,hyperopt_kfold,roc_auc,"{'AdamW_weight_decay': 1.0080171280429594e-05, 'Adam_weight_decay': 4.7018697246784746e-05, 'ExponentialLR_gamma': 0.916400729275698, 'ReduceLROnPlateau_factor': 0.27285190270351406, 'ReduceLROnPlateau_patience': 4, 'add_norm_dropout': 0.06116720170610435, 'attn_dropout': 0.16652804788921044, 'batch_size': 3019, 'embedding_dropout': 0.0674193489774384, 'embedding_initialization': 'kaiming_normal', 'ff_dropout': 0.1908468821492046, 'ff_hidden_multiplier': 22, 'input_embed_dim_multiplier': 6, 'num_attn_blocks': 5, 'num_heads': 5, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'shared_embedding_fraction': 0.22202369809932618, 'transformer_activation': 'ReGLU', 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 16, 'tol': 1e-05, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 8, 'attn_feature_importance': False}}",0.9170973261584493,0.0021070212535249273,"{'recall': [0.8508604206500956, 0.8622448979591837, 0.8737244897959183, 0.8622448979591837, 0.8679846938775511], 'precision': [0.5751831107281344, 0.5827586206896552, 0.5763567522086663, 0.5692631578947368, 0.5757191201353637], 'accuracy': [0.8126823276523876, 0.8181818181818182, 0.8149570024570024, 0.8097358722358723, 0.8141891891891891], 'f1': [0.6863753213367609, 0.6954732510288067, 0.694550063371356, 0.6857722546284555, 0.6922685656154628], 'roc_auc': [0.9172177721262074, 0.9184083030967243, 0.9180720756142263, 0.9130115714368269, 0.9187769085182618], 'area_under_pr': [0.8016379299767707, 0.795710642491579, 0.7938014664702666, 0.7901288823472712, 0.8043851440429997], 'lift': [3.774842645378635, 3.687356970437945, 3.687356970437945, 3.7128750117558544, 3.763911094391674]}",./output/modelsaves/adult/fttransformer/202310-0610-1239-f54e8d7d-b051-462e-9ce9-f0e65e5bf8d9//202310-0610-1239-f54e8d7d-b051-462e-9ce9-f0e65e5bf8d9,24557.6790869236
202310-0612-5206-e7d99bda-531a-4b3c-8c08-6d1d95614b30,"{'dataset': 'adult', 'model': 'xgb', 'best_params': {}, 'param_grid': {'n_estimators': [100, 3000], 'max_bin': [256, 32], 'tree_method': ['auto', 'hist'], 'max_depth': [4, 10], 'learning_rate': [0.1, 0.33], 'subsample': [0.7, 1.0], 'colsample_bytree': [0.5, 1.0], 'min_child_weight': [1, 10], 'alpha': [0.0, 5.0], 'gamma': [0.0, 5.0], 'lambda': [0.0, 5.0]}}",adult,xgb,hyperopt_kfold,roc_auc,"{'alpha': 0.00034232502997113244, 'colsample_bytree': 0.9838252119568848, 'gamma': 3.335944060603294, 'lambda': 3.452036253324029, 'learning_rate': 0.18991004507456793, 'max_bin': 224, 'max_depth': 6, 'min_child_weight': 1, 'n_estimators': 322, 'subsample': 0.9849061643828134, 'tree_method': 'auto', 'outer_params': {'hyperopt_evals': 50, 'validation_fraction': 0.15, 'early_stopping_rounds': 50, 'verbose': False}}",0.9290598560865211,0.0011048296965003503,"{'recall': [0.655831739961759, 0.6626275510204082, 0.6428571428571429, 0.6645408163265306, 0.6690051020408163], 'precision': [0.7903225806451613, 0.7865253595760787, 0.7636363636363637, 0.7787742899850523, 0.7893152746425884], 'accuracy': [0.8751727314601566, 0.875460687960688, 0.8660933660933661, 0.8737714987714987, 0.8773034398034398], 'f1': [0.7168234064785788, 0.7192800276912427, 0.698060941828255, 0.7171369580178941, 0.7241974456334139], 'roc_auc': [0.9293245599922446, 0.9307724189493759, 0.9282519705394292, 0.9275360439989102, 0.9294142869526453], 'area_under_pr': [0.8332507364408496, 0.834157985323707, 0.823827242498386, 0.8278688093572011, 0.8337890426276985], 'lift': [3.915123959902841, 3.8851217906517443, 3.8213266873569705, 3.87236276999279, 3.9106398319696543]}",./output/modelsaves/adult/xgb/202310-0612-5206-e7d99bda-531a-4b3c-8c08-6d1d95614b30//202310-0612-5206-e7d99bda-531a-4b3c-8c08-6d1d95614b30,17561.268737077713
202310-0617-4447-d526a9cf-d361-430e-872b-a51248fef807,"{'dataset': 'iris', 'model': 'xgb', 'best_params': {}, 'param_grid': {'n_estimators': [100, 4000], 'max_bin': [256, 32], 'tree_method': ['auto', 'hist'], 'max_depth': [4, 10], 'learning_rate': [0.1, 0.33], 'subsample': [0.7, 1.0], 'colsample_bytree': [0.5, 1.0], 'min_child_weight': [1, 10], 'alpha': [0.0, 5.0], 'gamma': [0.0, 5.0], 'lambda': [0.0, 5.0]}}",iris,xgb,hyperopt_kfold,accuracy,"{'alpha': 1.3673996872518472, 'colsample_bytree': 0.9120778118988749, 'gamma': 1.0298897137772414, 'lambda': 1.2946192978306854, 'learning_rate': 0.17272674114586117, 'max_bin': 76, 'max_depth': 8, 'min_child_weight': 1, 'n_estimators': 2348, 'subsample': 0.8122093457283494, 'tree_method': 'auto', 'outer_params': {'hyperopt_evals': 50, 'validation_fraction': 0.15, 'early_stopping_rounds': 50, 'verbose': False}}",0.9666666666666668,0.029814239699997188,"{'accuracy': [1.0, 0.9666666666666667, 0.9333333333333333, 1.0, 0.9333333333333333], 'f1': [1.0, 0.9665831244778613, 0.9326599326599326, 1.0, 0.9333333333333333]}",./output/modelsaves/iris/xgb/202310-0617-4447-d526a9cf-d361-430e-872b-a51248fef807//202310-0617-4447-d526a9cf-d361-430e-872b-a51248fef807,2581.4944779872894
202310-0618-2748-d0b79882-2735-4445-ae8b-11472177809f,"{'dataset': 'breastcancer', 'model': 'xgb', 'best_params': {}, 'param_grid': {'n_estimators': [100, 4000], 'max_bin': [256, 32], 'tree_method': ['auto', 'hist'], 'max_depth': [4, 10], 'learning_rate': [0.1, 0.33], 'subsample': [0.7, 1.0], 'colsample_bytree': [0.5, 1.0], 'min_child_weight': [1, 10], 'alpha': [0.0, 5.0], 'gamma': [0.0, 5.0], 'lambda': [0.0, 5.0]}}",breastcancer,xgb,hyperopt_kfold,f1,"{'alpha': 0.34423130329471086, 'colsample_bytree': 0.5471975993782503, 'gamma': 2.6812051513707518, 'lambda': 3.247498383019023, 'learning_rate': 0.22620319030174296, 'max_bin': 98, 'max_depth': 6, 'min_child_weight': 8, 'n_estimators': 808, 'subsample': 0.8770803082183882, 'tree_method': 'hist', 'outer_params': {'hyperopt_evals': 50, 'validation_fraction': 0.15, 'early_stopping_rounds': 50, 'verbose': False}}",0.9694674506088214,0.01541135889553781,"{'recall': [0.9859154929577465, 0.971830985915493, 1.0, 0.9305555555555556, 0.9859154929577465], 'precision': [1.0, 0.92, 0.9473684210526315, 1.0, 0.958904109589041], 'accuracy': [0.9912280701754386, 0.9298245614035088, 0.9649122807017544, 0.956140350877193, 0.9646017699115044], 'f1': [0.9929078014184397, 0.9452054794520549, 0.972972972972973, 0.9640287769784173, 0.9722222222222222], 'roc_auc': [0.9993449066491975, 0.982640026203734, 0.974537037037037, 0.9973544973544973, 0.994634473507713], 'area_under_pr': [0.9996141230947326, 0.9880469383763291, 0.9523992346899753, 0.9985219884409543, 0.9967805706052434], 'lift': [1.6056338028169013, 1.6056338028169013, 1.4393939393939394, 1.5833333333333335, 1.591549295774648]}",./output/modelsaves/breastcancer/xgb/202310-0618-2748-d0b79882-2735-4445-ae8b-11472177809f//202310-0618-2748-d0b79882-2735-4445-ae8b-11472177809f,1748.8570799827576
202310-0618-5657-b7be8266-6fe1-4fbb-9180-e5b717a6c6d0,"{'dataset': 'ageconditions', 'model': 'xgb', 'best_params': {}, 'param_grid': {'n_estimators': [100, 4000], 'max_bin': [256, 32], 'tree_method': ['auto', 'hist'], 'max_depth': [4, 10], 'learning_rate': [0.1, 0.33], 'subsample': [0.7, 1.0], 'colsample_bytree': [0.5, 1.0], 'min_child_weight': [1, 10], 'alpha': [0.0, 5.0], 'gamma': [0.0, 5.0], 'lambda': [0.0, 5.0]}}",ageconditions,xgb,hyperopt_kfold,f1,"{'alpha': 1.6194708327323444, 'colsample_bytree': 0.7539902964453788, 'gamma': 0.030804297401789763, 'lambda': 2.139166301022567, 'learning_rate': 0.11267548139193784, 'max_bin': 156, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 1686, 'subsample': 0.8126306176419349, 'tree_method': 'auto', 'outer_params': {'hyperopt_evals': 50, 'validation_fraction': 0.15, 'early_stopping_rounds': 50, 'verbose': False}}",0.7912654933773242,0.05715724138567995,"{'recall': [0.7272727272727273, 0.8181818181818182, 0.7272727272727273, 0.5714285714285714, 0.7142857142857143], 'precision': [0.8421052631578947, 0.8571428571428571, 1.0, 0.8571428571428571, 0.9375], 'accuracy': [0.928, 0.944, 0.9516129032258065, 0.9112903225806451, 0.9435483870967742], 'f1': [0.7804878048780488, 0.8372093023255814, 0.8421052631578948, 0.6857142857142857, 0.8108108108108109], 'roc_auc': [0.9761694616063549, 0.9505736981465137, 0.9861853832442068, 0.9084604715672677, 0.9912159038372631], 'area_under_pr': [0.8927050993772776, 0.9084655525177767, 0.9505847437735981, 0.7281790195587973, 0.9538855513668028], 'lift': [4.734848484848485, 5.6818181818181825, 5.636363636363636, 5.412698412698413, 5.412698412698413]}",./output/modelsaves/ageconditions/xgb/202310-0618-5657-b7be8266-6fe1-4fbb-9180-e5b717a6c6d0//202310-0618-5657-b7be8266-6fe1-4fbb-9180-e5b717a6c6d0,3145.7162325382233
202310-0617-0157-58cd2541-98cf-4734-9568-e7f0be3388d7,"{'dataset': 'adult', 'model': 'categoryembedding', 'best_params': {}, 'param_grid': {'batch_size': [1024, 2048, 4096], 'layers': ['128-64-32', '100-50-24', '128-64-32-16', '256-128-64'], 'activation': ['ReLU', 'LeakyReLU'], 'initialization': ['kaiming', 'xavier'], 'dropout': [0.0, 0.3], 'embedding_dropout': [0.0, 0.3], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",adult,categoryembedding,hyperopt_kfold,roc_auc,"{'AdamW_weight_decay': 3.2353211415467476e-05, 'Adam_weight_decay': 6.863556223483215e-05, 'ExponentialLR_gamma': 0.9291394144954743, 'ReduceLROnPlateau_factor': 0.6102437850215172, 'ReduceLROnPlateau_patience': 3, 'activation': 'LeakyReLU', 'batch_size': 2135, 'dropout': 0.1825873002340433, 'embedding_dropout': 0.09660671347854821, 'initialization': 'kaiming', 'layers': '128-64-32', 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 16, 'tol': 1e-05, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 8}}",0.914399583960169,0.0024636088563920917,"{'recall': [0.8655194391332058, 0.8756377551020408, 0.8698979591836735, 0.8858418367346939, 0.8673469387755102], 'precision': [0.565597667638484, 0.5737567906393648, 0.5695198329853862, 0.5485781990521327, 0.5740818910932883], 'accuracy': [0.8074619990787656, 0.8134213759213759, 0.8103501228501229, 0.796990171990172, 0.8131142506142506], 'f1': [0.6841309823677582, 0.693259277960111, 0.6883673984355286, 0.677560975609756, 0.6908813817627635], 'roc_auc': [0.9145028525992068, 0.9167178779885741, 0.9144932168862691, 0.9098412423221716, 0.9164427300046233], 'area_under_pr': [0.7888543292580339, 0.7903062634881839, 0.7838878260914703, 0.771952516144618, 0.7951307875933192], 'lift': [3.6919491413416043, 3.661838929120035, 3.623561867143171, 3.642700398131603, 3.7128750117558544]}",./output/modelsaves/adult/categoryembedding/202310-0617-0157-58cd2541-98cf-4734-9568-e7f0be3388d7//202310-0617-0157-58cd2541-98cf-4734-9568-e7f0be3388d7,11120.084553480148
202310-0619-4923-a1408895-2517-47b0-9772-f6729f1a7a0c,"{'dataset': 'titanic', 'model': 'xgb', 'best_params': {}, 'param_grid': {'n_estimators': [100, 4000], 'max_bin': [256, 32], 'tree_method': ['auto', 'hist'], 'max_depth': [4, 10], 'learning_rate': [0.1, 0.33], 'subsample': [0.7, 1.0], 'colsample_bytree': [0.5, 1.0], 'min_child_weight': [1, 10], 'alpha': [0.0, 5.0], 'gamma': [0.0, 5.0], 'lambda': [0.0, 5.0]}}",titanic,xgb,hyperopt_kfold,roc_auc,"{'alpha': 0.3026939842593672, 'colsample_bytree': 0.9199928706208111, 'gamma': 0.010468759200970235, 'lambda': 3.419722228580705, 'learning_rate': 0.2529671925620052, 'max_bin': 108, 'max_depth': 9, 'min_child_weight': 8, 'n_estimators': 3709, 'subsample': 0.964125141122677, 'tree_method': 'auto', 'outer_params': {'hyperopt_evals': 50, 'validation_fraction': 0.15, 'early_stopping_rounds': 50, 'verbose': False}}",0.8865325271059217,0.02697006471004758,"{'recall': [0.7101449275362319, 0.7794117647058824, 0.6470588235294118, 0.7352941176470589, 0.7101449275362319], 'precision': [0.875, 0.8153846153846154, 0.7457627118644068, 0.819672131147541, 0.8596491228070176], 'accuracy': [0.8491620111731844, 0.848314606741573, 0.7808988764044944, 0.8370786516853933, 0.8426966292134831], 'f1': [0.7839999999999999, 0.7969924812030074, 0.6929133858267716, 0.7751937984496124, 0.7777777777777778], 'roc_auc': [0.9260210803689064, 0.9044117647058824, 0.8469251336898397, 0.8816176470588236, 0.873687009706156], 'area_under_pr': [0.8893492386203218, 0.8882202052232868, 0.8192410983735806, 0.8725528999848599, 0.8206372431577571], 'lift': [2.5942028985507246, 2.6176470588235294, 2.6176470588235294, 2.6176470588235294, 2.2762148337595907]}",./output/modelsaves/titanic/xgb/202310-0619-4923-a1408895-2517-47b0-9772-f6729f1a7a0c//202310-0619-4923-a1408895-2517-47b0-9772-f6729f1a7a0c,3785.9541256427765
202310-0620-5229-f0576282-44fb-43d5-976e-8a92780fdf47,"{'dataset': 'heloc', 'model': 'xgb', 'best_params': {}, 'param_grid': {'n_estimators': [100, 3000], 'max_bin': [256, 32], 'tree_method': ['auto', 'hist'], 'max_depth': [4, 10], 'learning_rate': [0.1, 0.33], 'subsample': [0.7, 1.0], 'colsample_bytree': [0.5, 1.0], 'min_child_weight': [1, 10], 'alpha': [0.0, 5.0], 'gamma': [0.0, 5.0], 'lambda': [0.0, 5.0]}}",heloc,xgb,hyperopt_kfold,lift,"{'alpha': 3.661910075411913, 'colsample_bytree': 0.6781529154712795, 'gamma': 3.9882005109447087, 'lambda': 3.2248202056558313, 'learning_rate': 0.186561148351133, 'max_bin': 183, 'max_depth': 10, 'min_child_weight': 8, 'n_estimators': 2139, 'subsample': 0.7655212959072701, 'tree_method': 'auto', 'outer_params': {'hyperopt_evals': 50, 'validation_fraction': 0.15, 'early_stopping_rounds': 50, 'verbose': False}}",1.7252474735131884,0.041727688160951376,"{'recall': [0.7692307692307693, 0.7756410256410257, 0.7939560439560439, 0.7838827838827839, 0.7818515123739689], 'precision': [0.7253886010362695, 0.7226962457337884, 0.7089125102207686, 0.7062706270627063, 0.7284372331340735], 'accuracy': [0.7275334608030593, 0.7275334608030593, 0.7222753346080306, 0.7170172084130019, 0.7340985174557628], 'f1': [0.7466666666666666, 0.7482332155477033, 0.7490280777537797, 0.7430555555555555, 0.7541998231653404], 'roc_auc': [0.7956222527472527, 0.7906126373626374, 0.791375, 0.7948305860805862, 0.8079175068744271], 'area_under_pr': [0.7951162165922114, 0.7853161034569087, 0.7829183139017455, 0.7995530642702433, 0.80547389550593], 'lift': [1.7415917415917415, 1.695760379970906, 1.659095290674238, 1.7599242862400757, 1.7698656690889796]}",./output/modelsaves/heloc/xgb/202310-0620-5229-f0576282-44fb-43d5-976e-8a92780fdf47//202310-0620-5229-f0576282-44fb-43d5-976e-8a92780fdf47,5458.409160614014
202310-0620-0717-e4038c25-d166-4d2d-a772-743974c3be69,"{'dataset': 'adult', 'model': 'gandalf', 'best_params': {}, 'param_grid': {'batch_size': [1024, 2048, 4096], 'gflu_stages': [4, 10], 'gflu_dropout': [0.0, 0.3], 'embedding_dropout': [0.0, 0.3], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",adult,gandalf,hyperopt_kfold,roc_auc,"{'AdamW_weight_decay': 6.653740679922717e-05, 'Adam_weight_decay': 3.3511696669861616e-05, 'ExponentialLR_gamma': 0.9187707489112762, 'ReduceLROnPlateau_factor': 0.5634901279554888, 'ReduceLROnPlateau_patience': 3, 'batch_size': 3728, 'embedding_dropout': 0.06956726954067619, 'gflu_dropout': 0.2994972677853775, 'gflu_stages': 9, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 16, 'tol': 1e-05, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 8}}",0.915045959893298,0.0020046268090897898,"{'recall': [0.8591459528362014, 0.8673469387755102, 0.8673469387755102, 0.8584183673469388, 0.8616071428571429], 'precision': [0.5678180286436394, 0.5811965811965812, 0.5819426615318785, 0.5679324894514768, 0.5686026936026936], 'accuracy': [0.8085367726086289, 0.8175675675675675, 0.8180282555282555, 0.8086609336609336, 0.8092751842751843], 'f1': [0.6837433426325134, 0.6960081883316274, 0.6965428937259923, 0.6835957338750634, 0.6850912778904664], 'roc_auc': [0.9150789672889581, 0.9169454265322634, 0.9167917280686547, 0.9113804843842876, 0.9150331931923255], 'area_under_pr': [0.7960105660961458, 0.7877469958638375, 0.7894383584450011, 0.7795119748626922, 0.7937567917282523], 'lift': [3.711078411503996, 3.6363208878021256, 3.6937364807674222, 3.6363208878021256, 3.751152073732719]}",./output/modelsaves/adult/gandalf/202310-0620-0717-e4038c25-d166-4d2d-a772-743974c3be69//202310-0620-0717-e4038c25-d166-4d2d-a772-743974c3be69,12292.77177143097
202310-0622-2327-23ca205e-7ed6-4079-be51-5e90740661af,"{'dataset': 'heloc', 'model': 'xgb', 'best_params': {}, 'param_grid': {'n_estimators': [100, 3000], 'max_bin': [256, 32], 'tree_method': ['auto', 'hist'], 'max_depth': [4, 10], 'learning_rate': [0.1, 0.33], 'subsample': [0.7, 1.0], 'colsample_bytree': [0.5, 1.0], 'min_child_weight': [1, 10], 'alpha': [0.0, 5.0], 'gamma': [0.0, 5.0], 'lambda': [0.0, 5.0]}}",heloc,xgb,hyperopt_kfold,lift,"{'alpha': 3.661910075411913, 'colsample_bytree': 0.6781529154712795, 'gamma': 3.9882005109447087, 'lambda': 3.2248202056558313, 'learning_rate': 0.186561148351133, 'max_bin': 183, 'max_depth': 10, 'min_child_weight': 8, 'n_estimators': 2139, 'subsample': 0.7655212959072701, 'tree_method': 'auto', 'outer_params': {'hyperopt_evals': 50, 'validation_fraction': 0.15, 'early_stopping_rounds': 50, 'verbose': False}}",1.7252474735131884,0.041727688160951376,"{'recall': [0.7692307692307693, 0.7756410256410257, 0.7939560439560439, 0.7838827838827839, 0.7818515123739689], 'precision': [0.7253886010362695, 0.7226962457337884, 0.7089125102207686, 0.7062706270627063, 0.7284372331340735], 'accuracy': [0.7275334608030593, 0.7275334608030593, 0.7222753346080306, 0.7170172084130019, 0.7340985174557628], 'f1': [0.7466666666666666, 0.7482332155477033, 0.7490280777537797, 0.7430555555555555, 0.7541998231653404], 'roc_auc': [0.7956222527472527, 0.7906126373626374, 0.791375, 0.7948305860805862, 0.8079175068744271], 'area_under_pr': [0.7951162165922114, 0.7853161034569087, 0.7829183139017455, 0.7995530642702433, 0.80547389550593], 'lift': [1.7415917415917415, 1.695760379970906, 1.659095290674238, 1.7599242862400757, 1.7698656690889796]}",./output/modelsaves/heloc/xgb/202310-0622-2327-23ca205e-7ed6-4079-be51-5e90740661af//202310-0622-2327-23ca205e-7ed6-4079-be51-5e90740661af,5838.879620790482
202310-0700-2030-9ab3af44-a0cc-4ef3-b3b3-d1d9a9cfd7da,"{'dataset': 'creditcard', 'model': 'xgb', 'best_params': {}, 'param_grid': {'n_estimators': [100, 3000], 'max_bin': [256, 32], 'tree_method': ['auto', 'hist'], 'max_depth': [4, 10], 'learning_rate': [0.1, 0.33], 'subsample': [0.7, 1.0], 'colsample_bytree': [0.5, 1.0], 'min_child_weight': [1, 10], 'alpha': [0.0, 5.0], 'gamma': [0.0, 5.0], 'lambda': [0.0, 5.0]}}",creditcard,xgb,hyperopt_kfold,lift,"{'alpha': 3.7397504040820206, 'colsample_bytree': 0.5728433719553481, 'gamma': 0.9748932753719578, 'lambda': 1.9210770944775741, 'learning_rate': 0.1486828919151858, 'max_bin': 119, 'max_depth': 7, 'min_child_weight': 6, 'n_estimators': 2397, 'subsample': 0.7153561363941683, 'tree_method': 'hist', 'outer_params': {'hyperopt_evals': 50, 'validation_fraction': 0.15, 'early_stopping_rounds': 50, 'verbose': False}}",9.674944193714257,0.22664616068120852,"{'recall': [0.7373737373737373, 0.8080808080808081, 0.8061224489795918, 0.7857142857142857, 0.8061224489795918], 'precision': [0.9240506329113924, 0.9876543209876543, 0.9404761904761905, 0.927710843373494, 0.9294117647058824], 'accuracy': [0.9994382219725431, 0.9996488887328394, 0.9995786590825302, 0.9995259914678464, 0.9995611032109689], 'f1': [0.8202247191011236, 0.888888888888889, 0.8681318681318683, 0.850828729281768, 0.8633879781420767], 'roc_auc': [0.9867286906310525, 0.9809289987613327, 0.9959973613629894, 0.9754157593959274, 0.9885858850864968], 'area_under_pr': [0.8330517316131453, 0.8921035692321337, 0.8728095234810285, 0.8301762862197559, 0.8331944806125371], 'lift': [9.89933747588242, 9.495282885030075, 10.000175561797752, 9.48996252293052, 9.48996252293052]}",./output/modelsaves/creditcard/xgb/202310-0700-2030-9ab3af44-a0cc-4ef3-b3b3-d1d9a9cfd7da//202310-0700-2030-9ab3af44-a0cc-4ef3-b3b3-d1d9a9cfd7da,16534.57975411415
202310-0623-3209-f513342b-e5b1-47d4-8e2e-0675b8f6bb1e,"{'dataset': 'adult', 'model': 'tabtransformer', 'best_params': {}, 'param_grid': {'batch_size': [1024, 2048, 4096], 'embedding_bias': [True, False], 'embedding_initialization': ['kaiming_uniform', 'kaiming_normal'], 'shared_embedding_fraction': [0.125, 0.25, 0.5], 'num_attn_blocks': [4, 10], 'attn_dropout': [0.05, 0.3], 'add_norm_dropout': [0.05, 0.3], 'ff_dropout': [0.05, 0.3], 'ff_hidden_multiplier': [2, 6], 'transformer_activation': ['GEGLU', 'ReGLU', 'SwiGLU'], 'embedding_dropout': [0.05, 0.3], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",adult,tabtransformer,hyperopt_kfold,roc_auc,"{'AdamW_weight_decay': 1.0961491420612025e-05, 'Adam_weight_decay': 9.26468591250698e-05, 'ExponentialLR_gamma': 0.9041220493854117, 'ReduceLROnPlateau_factor': 0.8818598879258814, 'ReduceLROnPlateau_patience': 3, 'add_norm_dropout': 0.2930824888578767, 'attn_dropout': 0.2567778389554387, 'batch_size': 1571, 'embedding_bias': False, 'embedding_dropout': 0.05832554843292806, 'embedding_initialization': 'kaiming_normal', 'ff_dropout': 0.07890959483289993, 'ff_hidden_multiplier': 2, 'num_attn_blocks': 4, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'shared_embedding_fraction': 0.2645468756515514, 'transformer_activation': 'GEGLU', 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 16, 'tol': 1e-05, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 8}}",0.9073480077780337,0.002309012173722961,"{'recall': [0.8413001912045889, 0.8711734693877551, 0.8647959183673469, 0.8373724489795918, 0.8424744897959183], 'precision': [0.5692108667529108, 0.5686927560366362, 0.5687919463087249, 0.5853767275969683, 0.5738488271068636], 'accuracy': [0.8083832335329342, 0.8098894348894349, 0.8095823095823096, 0.8180282555282555, 0.8114250614250614], 'f1': [0.6790123456790124, 0.6881612090680101, 0.6862348178137652, 0.6890579900288639, 0.6826873385012919], 'roc_auc': [0.9062832596979091, 0.9101071026104617, 0.9075333789462386, 0.9035699838187703, 0.9092463138167889], 'area_under_pr': [0.7672345517534366, 0.7662111412913065, 0.7595802668526587, 0.7566996001150424, 0.7782751119554807], 'lift': [3.5899263671421817, 3.547007743189442, 3.4959716605536224, 3.547007743189442, 3.6745979497789905]}",./output/modelsaves/adult/tabtransformer/202310-0623-3209-f513342b-e5b1-47d4-8e2e-0675b8f6bb1e//202310-0623-3209-f513342b-e5b1-47d4-8e2e-0675b8f6bb1e,24421.670785188675
202310-0713-4218-4fe94042-bec2-4739-8589-9999a03292b0,"{'dataset': 'heloc', 'model': 'xgb', 'best_params': {}, 'param_grid': {'n_estimators': [100, 4000], 'max_bin': [256, 32], 'tree_method': ['auto', 'hist'], 'max_depth': [4, 9], 'learning_rate': [0.1, 0.33], 'subsample': [0.7, 1.0], 'colsample_bytree': [0.5, 1.0], 'min_child_weight': [1, 10], 'alpha': [0.0, 5.0], 'gamma': [0.0, 5.0], 'lambda': [0.0, 5.0]}}",heloc,xgb,hyperopt_kfold,lift,"{'alpha': 1.7970722321729704, 'colsample_bytree': 0.5223356482950038, 'gamma': 4.645518817522314, 'lambda': 3.237719964525147, 'learning_rate': 0.2138483643824069, 'max_bin': 132, 'max_depth': 8, 'min_child_weight': 8, 'n_estimators': 3427, 'subsample': 0.8083370857637746, 'tree_method': 'hist', 'outer_params': {'hyperopt_evals': 50, 'validation_fraction': 0.15, 'early_stopping_rounds': 50, 'verbose': False}}",1.717908029867121,0.024872942050309935,"{'recall': [0.7664835164835165, 0.7646520146520146, 0.7847985347985348, 0.7866300366300366, 0.7781851512373968], 'precision': [0.7172236503856041, 0.7161234991423671, 0.7129783693843594, 0.7064144736842105, 0.7281303602058319], 'accuracy': [0.7203632887189293, 0.7189292543021033, 0.722753346080306, 0.7179732313575525, 0.7326637972262076], 'f1': [0.7410358565737052, 0.7395925597874224, 0.7471665213600697, 0.744367417677643, 0.7523260965883917], 'roc_auc': [0.7946126373626373, 0.7888031135531136, 0.7955302197802196, 0.7936973443223443, 0.8066260311640696], 'area_under_pr': [0.7949143720700798, 0.7826811286867799, 0.7907480464765585, 0.7992799484183438, 0.8013007182268551], 'lift': [1.7324254692675742, 1.7049266522950732, 1.695760379970906, 1.7599242862400757, 1.6965033615619751]}",./output/modelsaves/heloc/xgb/202310-0713-4218-4fe94042-bec2-4739-8589-9999a03292b0//202310-0713-4218-4fe94042-bec2-4739-8589-9999a03292b0,852.9263298511505
202310-0713-5631-71344ac8-f457-42e5-a3d1-e853b4842952,"{'dataset': 'diabetes', 'model': 'xgb', 'best_params': {}, 'param_grid': {'n_estimators': [100, 4000], 'max_bin': [256, 32], 'tree_method': ['auto', 'hist'], 'max_depth': [4, 9], 'learning_rate': [0.1, 0.33], 'subsample': [0.7, 1.0], 'colsample_bytree': [0.5, 1.0], 'min_child_weight': [1, 10], 'alpha': [0.0, 5.0], 'gamma': [0.0, 5.0], 'lambda': [0.0, 5.0]}}",diabetes,xgb,hyperopt_kfold,lift,"{'alpha': 1.206124119501308, 'colsample_bytree': 0.8688302262681821, 'gamma': 3.450008239902506, 'lambda': 0.43594187035423554, 'learning_rate': 0.24244006189377976, 'max_bin': 40, 'max_depth': 7, 'min_child_weight': 4, 'n_estimators': 3636, 'subsample': 0.9278100530404447, 'tree_method': 'auto', 'outer_params': {'hyperopt_evals': 50, 'validation_fraction': 0.15, 'early_stopping_rounds': 50, 'verbose': False}}",2.4790457559888646,0.07307244531172322,"{'recall': [0.02420774647887324, 0.019815059445178335, 0.01805372082782915, 0.01805372082782915, 0.020246478873239437], 'precision': [0.5238095238095238, 0.6164383561643836, 0.5857142857142857, 0.6307692307692307, 0.5054945054945055], 'accuracy': [0.8886214011987815, 0.8892546553333661, 0.8890089913034933, 0.8892546553333661, 0.8884193976317988], 'f1': [0.04627681952040387, 0.038395904436860064, 0.03502776591200342, 0.0351027397260274, 0.03893355903512483], 'roc_auc': [0.6764061358389246, 0.6882778517026331, 0.6777891226089708, 0.6788450296221368, 0.6766257144103491], 'area_under_pr': [0.22687382229316677, 0.24590924647536014, 0.23114970466921467, 0.2349293275298863, 0.22592958360305754], 'lift': [2.4212504758279407, 2.5587214931996964, 2.4045816442117633, 2.5763374759411746, 2.4343376907637473]}",./output/modelsaves/diabetes/xgb/202310-0713-5631-71344ac8-f457-42e5-a3d1-e853b4842952//202310-0713-5631-71344ac8-f457-42e5-a3d1-e853b4842952,6892.0683851242065
202310-0715-5541-cadcfb9c-5da8-4735-8ac0-60f1b025ba06,"{'dataset': 'diabetes', 'model': 'mlp', 'best_params': {}, 'param_grid': {'hidden_layer_sizes': [[64, 32, 16], [256, 128, 64, 32], [128, 64, 32, 16]], 'activation': ['relu', 'tanh', 'logistic'], 'solver': ['adam', 'lbfgs'], 'alpha': [0.0001, 0.001, 0.01], 'learning_rate_init': [0.0001, 0.01, 0.1], 'beta_1': [0.99, 0.8], 'beta_2': [0.999, 0.9], 'batch_size': [512, 1024, 2048]}}",diabetes,mlp,hyperopt_kfold,lift,"{'activation': 'relu', 'alpha': 0.001166541946267438, 'batch_size': 1717, 'beta_1': 0.8241486250395531, 'beta_2': 0.9569518947208439, 'hidden_layer_sizes': (256, 128, 64, 32), 'learning_rate_init': 0.018722472963866806, 'solver': 'adam', 'outer_params': {'cv_iterations': 10, 'early_stopping': True, 'cv_size': 5, 'validation_fraction': 0.15, 'hyperopt_evals': 50, 'n_iter_no_change': 30, 'max_iter': 1000}}",2.3628028366842395,0.10698971194758518,"{'recall': [0.018926056338028168, 0.009687362395420519, 0.0, 0.023337736679876705, 0.022887323943661973], 'precision': [0.5058823529411764, 0.6111111111111112, 0.0, 0.43089430894308944, 0.48598130841121495], 'accuracy': [0.8884248796305394, 0.8888124600795951, 0.8884193976317988, 0.8875841399302314, 0.8882228664079006], 'f1': [0.03648705982180739, 0.01907238838318162, 0.0, 0.04427736006683375, 0.043715846994535526], 'roc_auc': [0.6633009920767833, 0.671976520095766, 0.6638397045486458, 0.6612825880397781, 0.6553792850015308], 'area_under_pr': [0.2167137122870088, 0.23055019488038747, 0.2112809889932581, 0.22158668298958495, 0.20793206346876372], 'lift': [2.3111936360175798, 2.5102775406606317, 2.24603779953846, 2.4706415794923062, 2.2758636277122193]}",./output/modelsaves/diabetes/mlp/202310-0715-5541-cadcfb9c-5da8-4735-8ac0-60f1b025ba06//202310-0715-5541-cadcfb9c-5da8-4735-8ac0-60f1b025ba06,17734.947410583496
202310-0706-1911-9e0a63b8-c74d-495d-8120-c6de005c243c,"{'dataset': 'adult', 'model': 'catboost', 'best_params': {}, 'param_grid': {'iterations': [200, 3000], 'learning_rate': [0.001, 0.1], 'depth': [4, 10], 'l2_leaf_reg': [0.5, 5.0], 'min_child_samples': [1, 100], 'bagging_temperature': [0.1, 2.0]}}",adult,catboost,hyperopt_kfold,roc_auc,"{'bagging_temperature': 0.25708300205375, 'depth': 10, 'iterations': 1848, 'l2_leaf_reg': 2.399403553302777, 'learning_rate': 0.026795124851896494, 'min_child_samples': 62, 'outer_params': {'hyperopt_evals': 50, 'validation_fraction': 0.15, 'early_stopping_rounds': 50, 'verbose': False}}",0.9311435417698763,0.0009862386593000605,"{'recall': [0.651370299553856, 0.6511479591836735, 0.6575255102040817, 0.6658163265306123, 0.6658163265306123], 'precision': [0.799061767005473, 0.7939346811819595, 0.77344336084021, 0.7808526551982049, 0.7927107061503417], 'accuracy': [0.8765545831414094, 0.8753071253071253, 0.8711609336609336, 0.874539312039312, 0.8776105651105651], 'f1': [0.7176966292134832, 0.7154870357393133, 0.710789382971389, 0.7187607573149742, 0.723743500866551], 'roc_auc': [0.9324278316120795, 0.9313044620153887, 0.9314018538240539, 0.9293779101446404, 0.9312056512532199], 'area_under_pr': [0.8395692944901101, 0.8345536933136203, 0.830537137677952, 0.8329486516618481, 0.8367355152657378], 'lift': [3.940629653452697, 3.8851217906517443, 3.8596037493338353, 3.9170193422991315, 3.9106398319696543]}",./output/modelsaves/adult/catboost/202310-0706-1911-9e0a63b8-c74d-495d-8120-c6de005c243c//202310-0706-1911-9e0a63b8-c74d-495d-8120-c6de005c243c,60976.9850358963
202310-0720-5116-e1554215-a4fb-4027-bd3d-5b9e91305d46,"{'dataset': 'housing', 'model': 'mlp', 'best_params': {}, 'param_grid': {'hidden_layer_sizes': [[64, 32, 16], [256, 128, 64, 32], [128, 64, 32, 16]], 'activation': ['relu', 'tanh', 'logistic'], 'solver': ['adam', 'lbfgs'], 'alpha': [0.0001, 0.001, 0.01], 'learning_rate_init': [0.0001, 0.01, 0.1], 'beta_1': [0.99, 0.8], 'beta_2': [0.999, 0.9], 'batch_size': [512, 1024, 2048]}}",housing,mlp,hyperopt_kfold,r2_score,"{'activation': 'tanh', 'alpha': 0.00047870365490089217, 'batch_size': 677, 'beta_1': 0.8640622417680885, 'beta_2': 0.9698781636749819, 'hidden_layer_sizes': (256, 128, 64, 32), 'learning_rate_init': 0.0006066730036592176, 'solver': 'adam', 'outer_params': {'cv_iterations': 10, 'early_stopping': True, 'cv_size': 5, 'validation_fraction': 0.15, 'hyperopt_evals': 50, 'n_iter_no_change': 30, 'max_iter': 1000}}",0.8144623482558805,0.006206121349352601,"{'mse': [0.2431399592135577, 0.25231268122352185, 0.24316457268206154, 0.23398061130224015, 0.26249163398259817], 'rmse': [0.49309224209427355, 0.5023073573256934, 0.49311719974267937, 0.48371542388292743, 0.5123393738359352], 'r2_score': [0.814454904346008, 0.815303578984756, 0.8131015645414906, 0.8244695983240287, 0.8049820950831191]}",./output/modelsaves/housing/mlp/202310-0720-5116-e1554215-a4fb-4027-bd3d-5b9e91305d46//202310-0720-5116-e1554215-a4fb-4027-bd3d-5b9e91305d46,25385.745649814606
202310-0803-5422-ca2c2661-2c23-46a2-90bc-dc90fc93651d,"{'dataset': 'creditcard', 'model': 'mlp', 'best_params': {}, 'param_grid': {'hidden_layer_sizes': [[64, 32, 16], [256, 128, 64, 32], [128, 64, 32, 16]], 'activation': ['relu', 'tanh', 'logistic'], 'solver': ['adam', 'lbfgs'], 'alpha': [0.0001, 0.001, 0.01], 'learning_rate_init': [0.0001, 0.01, 0.1], 'beta_1': [0.99, 0.8], 'beta_2': [0.999, 0.9], 'batch_size': [512, 1024, 2048]}}",creditcard,mlp,hyperopt_kfold,lift,"{'activation': 'logistic', 'alpha': 0.00034330928583443753, 'batch_size': 1527, 'beta_1': 0.9308397899283865, 'beta_2': 0.9688614244364229, 'hidden_layer_sizes': (64, 32, 16), 'learning_rate_init': 0.001200755070327402, 'solver': 'adam', 'outer_params': {'cv_iterations': 10, 'early_stopping': True, 'cv_size': 5, 'validation_fraction': 0.15, 'hyperopt_evals': 50, 'n_iter_no_change': 30, 'max_iter': 1000}}",9.45106783264889,0.19015101254301978,"{'recall': [0.7777777777777778, 0.7474747474747475, 0.7857142857142857, 0.7857142857142857, 0.7959183673469388], 'precision': [0.8279569892473119, 0.8604651162790697, 0.9166666666666666, 0.875, 0.8297872340425532], 'accuracy': [0.9993328885923949, 0.9993504441557529, 0.9995084355962852, 0.9994382121100402, 0.9993679886237953], 'f1': [0.8020833333333334, 0.7999999999999999, 0.8461538461538461, 0.8279569892473119, 0.8125], 'roc_auc': [0.9805499200008811, 0.9836221632820475, 0.9847146040590937, 0.9686608019920417, 0.9727196085686793], 'area_under_pr': [0.7597332254970018, 0.8558399197935552, 0.8238192841267311, 0.7989538571105143, 0.7439987146724114], 'lift': [9.495282885030075, 9.59629653274316, 9.592005130703965, 9.48996252293052, 9.081792091836734]}",./output/modelsaves/creditcard/mlp/202310-0803-5422-ca2c2661-2c23-46a2-90bc-dc90fc93651d//202310-0803-5422-ca2c2661-2c23-46a2-90bc-dc90fc93651d,14088.509017705917
202310-0810-5146-d784ee2d-9ac6-431a-91f4-8959941c054a,"{'dataset': 'adult', 'model': 's1dcnn', 'best_params': {}, 'param_grid': {'batch_size': [1024, 4096], 'hidden_size': [2048, 4096], 'optimizer_fn': {'Adam': {'weight_decay': [1e-05, 0.001], 'learning_rate': [0.0001, 0.01]}, 'AdamW': {'weight_decay': [1e-05, 0.001], 'learning_rate': [0.0001, 0.01]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",adult,s1dcnn,hyperopt_kfold,roc_auc,"{'AdamW_learning_rate': 0.0008667467437041766, 'AdamW_weight_decay': 0.0006969970591454644, 'Adam_learning_rate': 0.00010334709753916676, 'Adam_weight_decay': 3.363005226218266e-05, 'ExponentialLR_gamma': 0.9893111139390387, 'ReduceLROnPlateau_factor': 0.21352231673288244, 'ReduceLROnPlateau_patience': 3, 'batch_size': 2414, 'hidden_size': 2048, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'outer_params': {'hyperopt_evals': 50, 'max_epochs': 1000, 'early_stopping': True, 'shuffle': True, 'validation_fraction': 0.15, 'early_stopping_patience': 6, 'tol': 1e-05}}",0.9007776483048273,0.0025999442685434664,"{'recall': [0.758444869343531, 0.7582908163265306, 0.7512755102040817, 0.7525510204081632, 0.75], 'precision': [0.6363636363636364, 0.6413160733549083, 0.6357258499730167, 0.6178010471204188, 0.6305630026809651], 'accuracy': [0.8374021188392445, 0.8396805896805897, 0.836455773955774, 0.8283169533169533, 0.8339987714987716], 'f1': [0.6920616458272754, 0.6949152542372881, 0.6886875182695118, 0.6785508913168488, 0.6851150597145352], 'roc_auc': [0.9026304940380058, 0.9034980686752858, 0.9008906771142922, 0.8959879347673534, 0.9008810669291989], 'area_under_pr': [0.7551436121928606, 0.73475050005956, 0.7284650650308577, 0.720082269016036, 0.7452602972155215], 'lift': [3.5516678268173982, 3.5342487225304873, 3.4066585159409386, 3.5023511708831, 3.598043825825261]}",./output/modelsaves/adult/s1dcnn/202310-0810-5146-d784ee2d-9ac6-431a-91f4-8959941c054a//202310-0810-5146-d784ee2d-9ac6-431a-91f4-8959941c054a,20398.23456311226
202310-0820-3535-b3d8243a-477e-4f0b-b913-cb40efd10017,"{'dataset': 'heloc', 'model': 'gandalf', 'best_params': {}, 'param_grid': {'batch_size': [1024, 2048, 4096], 'gflu_stages': [4, 10], 'gflu_dropout': [0.0, 0.3], 'embedding_dropout': [0.0, 0.3], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",heloc,gandalf,hyperopt_kfold,lift,"{'AdamW_weight_decay': 4.4548976241453895e-05, 'Adam_weight_decay': 5.069643761024396e-05, 'ExponentialLR_gamma': 0.919001822074483, 'ReduceLROnPlateau_factor': 0.8855520082152866, 'ReduceLROnPlateau_patience': 5, 'batch_size': 1411, 'embedding_dropout': 0.25756005649366975, 'gflu_dropout': 0.19375846211549852, 'gflu_stages': 10, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 16, 'tol': 1e-05, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 8}}",1.7179088330904626,0.03094268783427687,"{'recall': [0.7554945054945055, 0.7655677655677655, 0.7646520146520146, 0.7747252747252747, 0.7543538038496792], 'precision': [0.7287985865724381, 0.7320490367775832, 0.7185886402753873, 0.7109243697478992, 0.7361359570661896], 'accuracy': [0.7256214149139579, 0.731357552581262, 0.7208413001912046, 0.7179732313575525, 0.7307508369201339], 'f1': [0.7419064748201438, 0.748433303491495, 0.7409050576752438, 0.7414548641542507, 0.7451335445903123], 'roc_auc': [0.797076923076923, 0.7925302197802198, 0.7898516483516484, 0.7897188644688645, 0.8036947754353804], 'area_under_pr': [0.7986270882443177, 0.7850923796721581, 0.7804504032688063, 0.7974241415414346, 0.7996291238120828], 'lift': [1.7507580139159085, 1.7140929246192402, 1.668261562998405, 1.7507580139159085, 1.7056736500028506]}",./output/modelsaves/heloc/gandalf/202310-0820-3535-b3d8243a-477e-4f0b-b913-cb40efd10017//202310-0820-3535-b3d8243a-477e-4f0b-b913-cb40efd10017,5504.630442380905
202310-0816-3144-e96275a4-7b98-4766-9ba5-604cfefe62ed,"{'dataset': 'adult', 'model': 'tabnet', 'best_params': {}, 'param_grid': {'virtual_batch_size_ratio': [0.125, 0.25, 0.5, 1.0], 'batch_size': [1024, 2048, 4096], 'weights': [0, 1], 'mask_type': ['sparsemax', 'entmax'], 'n_d': [6, 32], 'n_steps': [1, 6], 'gamma': [1.0, 2.0], 'n_independent': [1, 3], 'n_shared': [1, 3], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",adult,tabnet,hyperopt_kfold,roc_auc,"{'AdamW_weight_decay': 2.7812420638341295e-05, 'Adam_weight_decay': 2.1595408954895077e-05, 'ExponentialLR_gamma': 0.935423324797419, 'ReduceLROnPlateau_factor': 0.3306415445930194, 'ReduceLROnPlateau_patience': 5, 'batch_size': 2979, 'gamma': 1.2004963582062698, 'mask_type': 'entmax', 'n_d': 21, 'n_independent': 2, 'n_shared': 1, 'n_steps': 1, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'virtual_batch_size_ratio': 0.25, 'weights': 1, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 16, 'tol': 1e-05, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 8}}",0.9133619366094073,0.0022877467746160417,"{'recall': [0.8833652007648184, 0.857780612244898, 0.8431122448979592, 0.8743622448979592, 0.8788265306122449], 'precision': [0.5392996108949416, 0.5852915578764143, 0.5920286609941783, 0.544912559618442, 0.5560936238902341], 'accuracy': [0.7901120835252572, 0.8194103194103194, 0.8223280098280098, 0.793918918918919, 0.8019041769041769], 'f1': [0.6697269871949747, 0.6958096223486808, 0.6956064193633256, 0.6714005876591577, 0.6811665842807711], 'roc_auc': [0.9109040372632372, 0.9150480277062283, 0.9160024674311472, 0.910357999389076, 0.9144971512573475], 'area_under_pr': [0.7794010010255545, 0.7872808914514202, 0.7871068594017863, 0.7749782764534439, 0.7922144034137797], 'lift': [3.6600670244042846, 3.623561867143171, 3.687356970437945, 3.598043825825261, 3.7256340324148094]}",./output/modelsaves/adult/tabnet/202310-0816-3144-e96275a4-7b98-4766-9ba5-604cfefe62ed//202310-0816-3144-e96275a4-7b98-4766-9ba5-604cfefe62ed,22988.500727176666
202310-0822-0719-22a7fb83-2ab3-42ce-8b97-b5111fbc7103,"{'dataset': 'heloc', 'model': 'tabtransformer', 'best_params': {}, 'param_grid': {'batch_size': [1024, 2048, 4096], 'embedding_bias': [True, False], 'embedding_initialization': ['kaiming_uniform', 'kaiming_normal'], 'shared_embedding_fraction': [0.125, 0.25, 0.5], 'num_attn_blocks': [4, 10], 'attn_dropout': [0.05, 0.3], 'add_norm_dropout': [0.05, 0.3], 'ff_dropout': [0.05, 0.3], 'ff_hidden_multiplier': [2, 6], 'transformer_activation': ['GEGLU', 'ReGLU', 'SwiGLU'], 'embedding_dropout': [0.05, 0.3], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",heloc,tabtransformer,hyperopt_kfold,lift,"{'AdamW_weight_decay': 1.9799201888338036e-05, 'Adam_weight_decay': 8.811872456315357e-05, 'ExponentialLR_gamma': 0.9043497660780678, 'ReduceLROnPlateau_factor': 0.5623521765150563, 'ReduceLROnPlateau_patience': 4, 'add_norm_dropout': 0.06551660390794939, 'attn_dropout': 0.11780721055888699, 'batch_size': 1157, 'embedding_bias': True, 'embedding_dropout': 0.09511490526729735, 'embedding_initialization': 'kaiming_uniform', 'ff_dropout': 0.058650150533868045, 'ff_hidden_multiplier': 3, 'num_attn_blocks': 7, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>, 'shared_embedding_fraction': 0.20832480855732974, 'transformer_activation': 'SwiGLU', 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 16, 'tol': 1e-05, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 8}}",1.6922432705827948,0.02823256418238948,"{'recall': [0.728021978021978, 0.7527472527472527, 0.7591575091575091, 0.6767399267399268, 0.7277726856095326], 'precision': [0.7227272727272728, 0.7339285714285714, 0.7061328790459966, 0.7449596774193549, 0.723792160437557], 'accuracy': [0.7122370936902486, 0.7284894837476099, 0.7093690248565966, 0.7103250478011472, 0.7130559540889526], 'f1': [0.7253649635036495, 0.7432188065099458, 0.7316857899382172, 0.7092130518234167, 0.7257769652650824], 'roc_auc': [0.7803287545787545, 0.785481684981685, 0.7783443223443223, 0.7724981684981685, 0.7866214482126488], 'area_under_pr': [0.7770886440534175, 0.7805578562880324, 0.7679365717395586, 0.7788191857173852, 0.7825629400639922], 'lift': [1.6865941076467392, 1.7049266522950732, 1.640762746025904, 1.7232591969434075, 1.7056736500028506]}",./output/modelsaves/heloc/tabtransformer/202310-0822-0719-22a7fb83-2ab3-42ce-8b97-b5111fbc7103//202310-0822-0719-22a7fb83-2ab3-42ce-8b97-b5111fbc7103,3218.4877808094025
202310-0822-5452-d31a1f09-dadd-497d-a926-7636a88d73cb,"{'dataset': 'breastcancer', 'model': 'tabnet', 'best_params': {}, 'param_grid': {'batch_size': [128, 256], 'weights': [0, 1], 'mask_type': ['sparsemax', 'entmax'], 'n_d': [6, 32], 'n_steps': [1, 6], 'gamma': [1.0, 2.0], 'n_independent': [1, 3], 'n_shared': [1, 3], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",breastcancer,tabnet,hyperopt_kfold,f1,"{'AdamW_weight_decay': 6.614862412652319e-05, 'Adam_weight_decay': 9.911418777315595e-05, 'ExponentialLR_gamma': 0.9607814643483336, 'ReduceLROnPlateau_factor': 0.4719275285585291, 'ReduceLROnPlateau_patience': 5, 'batch_size': 153, 'gamma': 1.3033626684134796, 'mask_type': 'entmax', 'n_d': 29, 'n_independent': 2, 'n_shared': 2, 'n_steps': 3, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'weights': 1, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 32, 'tol': 1e-05, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 10}}",0.9790557972928793,0.008818852433573998,"{'recall': [0.971830985915493, 0.9859154929577465, 1.0, 0.9583333333333334, 0.9859154929577465], 'precision': [0.9857142857142858, 0.9722222222222222, 0.96, 0.971830985915493, 1.0], 'accuracy': [0.9736842105263158, 0.9736842105263158, 0.9736842105263158, 0.956140350877193, 0.9911504424778761], 'f1': [0.9787234042553192, 0.979020979020979, 0.9795918367346939, 0.965034965034965, 0.9929078014184397], 'roc_auc': [0.998689813298395, 0.9934490664919752, 0.9745370370370371, 0.9980158730158729, 1.0], 'area_under_pr': [0.9992006779740839, 0.9959280107675542, 0.975741667499569, 0.9988583046516837, 1.0], 'lift': [1.6056338028169013, 1.6056338028169013, 1.5833333333333335, 1.5833333333333335, 1.591549295774648]}",./output/modelsaves/breastcancer/tabnet/202310-0822-5452-d31a1f09-dadd-497d-a926-7636a88d73cb//202310-0822-5452-d31a1f09-dadd-497d-a926-7636a88d73cb,2225.9408628940582
202310-0823-3158-be703557-a32f-49bd-b07f-7dc0e6c8184c,"{'dataset': 'ageconditions', 'model': 'tabnet', 'best_params': {}, 'param_grid': {'batch_size': [128, 256], 'weights': [0, 1], 'mask_type': ['sparsemax', 'entmax'], 'n_d': [6, 32], 'n_steps': [1, 6], 'gamma': [1.0, 2.0], 'n_independent': [1, 3], 'n_shared': [1, 3], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",ageconditions,tabnet,hyperopt_kfold,f1,"{'AdamW_weight_decay': 6.114152271727713e-05, 'Adam_weight_decay': 7.538815124048828e-05, 'ExponentialLR_gamma': 0.9596684203499806, 'ReduceLROnPlateau_factor': 0.17159754213661513, 'ReduceLROnPlateau_patience': 4, 'batch_size': 141, 'gamma': 1.1952550171834833, 'mask_type': 'entmax', 'n_d': 10, 'n_independent': 2, 'n_shared': 3, 'n_steps': 2, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>, 'weights': 1, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 32, 'tol': 1e-05, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 10}}",0.6508195787284394,0.09040726892122694,"{'recall': [0.8181818181818182, 0.7727272727272727, 0.7727272727272727, 0.7142857142857143, 0.7142857142857143], 'precision': [0.72, 0.4594594594594595, 0.5666666666666667, 0.4166666666666667, 0.75], 'accuracy': [0.912, 0.8, 0.8548387096774194, 0.782258064516129, 0.9112903225806451], 'f1': [0.7659574468085107, 0.576271186440678, 0.6538461538461539, 0.5263157894736842, 0.7317073170731706], 'roc_auc': [0.9254192409532216, 0.8329655781112092, 0.9090909090909091, 0.8615349052242256, 0.8465094775774388], 'area_under_pr': [0.7269667518469629, 0.4768457198388587, 0.6774273837334472, 0.6262833738337013, 0.7311074848517247], 'lift': [3.787878787878788, 2.8409090909090913, 4.227272727272727, 3.9365079365079367, 5.412698412698413]}",./output/modelsaves/ageconditions/tabnet/202310-0823-3158-be703557-a32f-49bd-b07f-7dc0e6c8184c//202310-0823-3158-be703557-a32f-49bd-b07f-7dc0e6c8184c,2152.4078097343445
202310-0823-0058-77a2c7eb-8974-4c47-9680-c1396dc35315,"{'dataset': 'diabetes', 'model': 's1dcnn', 'best_params': {}, 'param_grid': {'batch_size': [1024, 4096], 'hidden_size': [2048, 4096], 'optimizer_fn': {'Adam': {'weight_decay': [1e-05, 0.001], 'learning_rate': [0.0001, 0.01]}, 'AdamW': {'weight_decay': [1e-05, 0.001], 'learning_rate': [0.0001, 0.01]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",diabetes,s1dcnn,hyperopt_kfold,lift,"{'AdamW_learning_rate': 0.001041456929198908, 'AdamW_weight_decay': 7.057079025745615e-05, 'Adam_learning_rate': 0.0039551010499371654, 'Adam_weight_decay': 0.00011615608085031654, 'ExponentialLR_gamma': 0.9853977528014267, 'ReduceLROnPlateau_factor': 0.25726949517536735, 'ReduceLROnPlateau_patience': 3, 'batch_size': 1216, 'hidden_size': 2048, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'outer_params': {'hyperopt_evals': 50, 'max_epochs': 1000, 'early_stopping': True, 'shuffle': True, 'validation_fraction': 0.15, 'early_stopping_patience': 6, 'tol': 1e-05}}",2.4306196748737263,0.11698054563772876,"{'recall': [0.3301056338028169, 0.289740202553941, 0.3333333333333333, 0.3998238661382651, 0.2962147887323944], 'precision': [0.2197480222677996, 0.27450980392156865, 0.2366364488902782, 0.22688655672163918, 0.24437182280319536], 'accuracy': [0.7943893092266876, 0.8353068343733111, 0.8056306195646833, 0.7810150837714341, 0.8191912740136589], 'f1': [0.2638522427440633, 0.28191945158526144, 0.276782449725777, 0.2894946596524789, 0.2678074015121369], 'roc_auc': [0.6564434287814043, 0.6709022394238956, 0.6353398829764754, 0.6619736275534454, 0.6499842064387875], 'area_under_pr': [0.1931903575565883, 0.21931522310925683, 0.18735106153136627, 0.2071635912118037, 0.19549537835594855], 'lift': [2.3067913624251655, 2.5983574543680223, 2.3737536744141767, 2.5411055104582183, 2.3330903727030488]}",./output/modelsaves/diabetes/s1dcnn/202310-0823-0058-77a2c7eb-8974-4c47-9680-c1396dc35315//202310-0823-0058-77a2c7eb-8974-4c47-9680-c1396dc35315,20355.742332220078
202310-0900-1414-53d1fd47-fa21-481e-904f-eb976cf78376,"{'dataset': 'diabetes', 'model': 'gandalf', 'best_params': {}, 'param_grid': {'batch_size': [1024, 2048, 4096], 'gflu_stages': [4, 10], 'gflu_dropout': [0.0, 0.3], 'embedding_dropout': [0.0, 0.3], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",diabetes,gandalf,hyperopt_kfold,lift,"{'AdamW_weight_decay': 1.0061129338886695e-05, 'Adam_weight_decay': 3.334555574968094e-05, 'ExponentialLR_gamma': 0.9723430620503429, 'ReduceLROnPlateau_factor': 0.8984420799078079, 'ReduceLROnPlateau_patience': 4, 'batch_size': 1285, 'embedding_dropout': 0.26837305816028917, 'gflu_dropout': 0.054091706769779965, 'gflu_stages': 7, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 16, 'tol': 1e-05, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 8}}",2.510757626328937,0.10011011388176974,"{'recall': [0.5752640845070423, 0.6538969616908851, 0.5904887714663144, 0.61074416556583, 0.6672535211267606], 'precision': [0.18193207126948774, 0.17476756502294927, 0.1785619174434088, 0.17763831967213115, 0.16801507259226423], 'accuracy': [0.663849857521863, 0.6168623790104653, 0.6512062103866751, 0.6410848523559181, 0.5940156242322999], 'f1': [0.27643824027072755, 0.27581723625557203, 0.27420509150393624, 0.27522571683698777, 0.2684373616644533], 'roc_auc': [0.6782188627979581, 0.6909729837326517, 0.6786976507189154, 0.6839242199693933, 0.6757987554634817], 'area_under_pr': [0.22679707559471138, 0.249969052591164, 0.2283274510613294, 0.23676402594965176, 0.218768128759807], 'lift': [2.4212504758279407, 2.655609398277826, 2.479449570863045, 2.5983574543680223, 2.399121232307852]}",./output/modelsaves/diabetes/gandalf/202310-0900-1414-53d1fd47-fa21-481e-904f-eb976cf78376//202310-0900-1414-53d1fd47-fa21-481e-904f-eb976cf78376,42572.48122358322
202310-0913-1543-d8529bd0-1140-4a7a-9806-8387a4e91329,"{'dataset': 'iris', 'model': 'catboost', 'best_params': {}, 'param_grid': {'iterations': [200, 4000], 'learning_rate': [0.001, 0.1], 'depth': [4, 10], 'l2_leaf_reg': [0.5, 5.0], 'min_child_samples': [1, 100], 'bagging_temperature': [0.1, 2.0]}}",iris,catboost,hyperopt_kfold,accuracy,"{'bagging_temperature': 0.14161684015220416, 'depth': 7, 'iterations': 2890, 'l2_leaf_reg': 1.5026055453331348, 'learning_rate': 0.0012464158759539635, 'min_child_samples': 67, 'outer_params': {'hyperopt_evals': 50, 'validation_fraction': 0.15, 'early_stopping_rounds': 50, 'verbose': False}}",0.9600000000000002,0.038873012632301994,"{'accuracy': [1.0, 0.9666666666666667, 0.9333333333333333, 1.0, 0.9], 'f1': [1.0, 0.9665831244778613, 0.9326599326599326, 1.0, 0.8997493734335841]}",./output/modelsaves/iris/catboost/202310-0913-1543-d8529bd0-1140-4a7a-9806-8387a4e91329//202310-0913-1543-d8529bd0-1140-4a7a-9806-8387a4e91329,316.4541051387787
202310-0913-2100-b4dd1a12-1bce-4456-9702-049b53823dc1,"{'dataset': 'titanic', 'model': 'catboost', 'best_params': {}, 'param_grid': {'iterations': [200, 4000], 'learning_rate': [0.001, 0.1], 'depth': [4, 10], 'l2_leaf_reg': [0.5, 5.0], 'min_child_samples': [1, 100], 'bagging_temperature': [0.1, 2.0]}}",titanic,catboost,hyperopt_kfold,roc_auc,"{'bagging_temperature': 1.9270989577352229, 'depth': 6, 'iterations': 2932, 'l2_leaf_reg': 0.5841035192283774, 'learning_rate': 0.09439930746752542, 'min_child_samples': 43, 'outer_params': {'hyperopt_evals': 50, 'validation_fraction': 0.15, 'early_stopping_rounds': 50, 'verbose': False}}",0.8836935528825883,0.021153876613135128,"{'recall': [0.7101449275362319, 0.7647058823529411, 0.6029411764705882, 0.7352941176470589, 0.7101449275362319], 'precision': [0.8305084745762712, 0.8253968253968254, 0.7321428571428571, 0.8064516129032258, 0.7903225806451613], 'accuracy': [0.8324022346368715, 0.848314606741573, 0.7640449438202247, 0.8314606741573034, 0.8146067415730337], 'f1': [0.7656250000000001, 0.7938931297709922, 0.6612903225806451, 0.7692307692307693, 0.7480916030534351], 'roc_auc': [0.9110013175230566, 0.8871657754010694, 0.8462566844919786, 0.8923128342245988, 0.8817311527722378], 'area_under_pr': [0.8682343142501084, 0.8368105572982717, 0.8161698506441898, 0.8816774582931126, 0.8586514138703502], 'lift': [2.441602728047741, 2.463667820069204, 2.463667820069204, 2.6176470588235294, 2.4279624893435634]}",./output/modelsaves/titanic/catboost/202310-0913-2100-b4dd1a12-1bce-4456-9702-049b53823dc1//202310-0913-2100-b4dd1a12-1bce-4456-9702-049b53823dc1,378.460816860199
202310-0913-2718-f69427e8-d0a0-433c-9ffd-9a297b36adac,"{'dataset': 'breastcancer', 'model': 'catboost', 'best_params': {}, 'param_grid': {'iterations': [200, 4000], 'learning_rate': [0.001, 0.1], 'depth': [4, 10], 'l2_leaf_reg': [0.5, 5.0], 'min_child_samples': [1, 100], 'bagging_temperature': [0.1, 2.0]}}",breastcancer,catboost,hyperopt_kfold,f1,"{'bagging_temperature': 0.9928196516799518, 'depth': 4, 'iterations': 3832, 'l2_leaf_reg': 1.6892173684593075, 'learning_rate': 0.05673035133721847, 'min_child_samples': 97, 'outer_params': {'hyperopt_evals': 50, 'validation_fraction': 0.15, 'early_stopping_rounds': 50, 'verbose': False}}",0.9778494645214051,0.010898157836217297,"{'recall': [1.0, 0.9859154929577465, 1.0, 0.9583333333333334, 0.9859154929577465], 'precision': [0.9861111111111112, 0.9333333333333333, 0.96, 1.0, 0.9722222222222222], 'accuracy': [0.9912280701754386, 0.9473684210526315, 0.9736842105263158, 0.9736842105263158, 0.9734513274336283], 'f1': [0.993006993006993, 0.9589041095890412, 0.9795918367346939, 0.9787234042553191, 0.979020979020979], 'roc_auc': [0.9993449066491975, 0.9934490664919751, 0.9857804232804233, 1.0, 0.9979879275653923], 'area_under_pr': [0.9996060085080121, 0.9961513760001102, 0.989678170148699, 1.0, 0.9988032941186187], 'lift': [1.6056338028169013, 1.6056338028169013, 1.5833333333333335, 1.5833333333333335, 1.591549295774648]}",./output/modelsaves/breastcancer/catboost/202310-0913-2718-f69427e8-d0a0-433c-9ffd-9a297b36adac//202310-0913-2718-f69427e8-d0a0-433c-9ffd-9a297b36adac,1247.8069279193878
202310-0913-5101-7bdf8be6-c177-424b-b52e-2b0f7d48b099,"{'dataset': 'ageconditions', 'model': 'catboost', 'best_params': {}, 'param_grid': {'iterations': [200, 4000], 'learning_rate': [0.001, 0.1], 'depth': [4, 10], 'l2_leaf_reg': [0.5, 5.0], 'min_child_samples': [1, 100], 'bagging_temperature': [0.1, 2.0]}}",ageconditions,catboost,hyperopt_kfold,f1,"{'bagging_temperature': 0.14228166126511824, 'depth': 5, 'iterations': 1047, 'l2_leaf_reg': 1.4054889582047796, 'learning_rate': 0.008231059874437023, 'min_child_samples': 58, 'outer_params': {'hyperopt_evals': 50, 'validation_fraction': 0.15, 'early_stopping_rounds': 50, 'verbose': False}}",0.796043579868997,0.05043997440325303,"{'recall': [0.6363636363636364, 0.7272727272727273, 0.7272727272727273, 0.7142857142857143, 0.8095238095238095], 'precision': [0.8235294117647058, 0.8421052631578947, 0.9411764705882353, 0.8823529411764706, 0.9444444444444444], 'accuracy': [0.912, 0.928, 0.9435483870967742, 0.9354838709677419, 0.9596774193548387], 'f1': [0.717948717948718, 0.7804878048780488, 0.8205128205128205, 0.7894736842105262, 0.8717948717948718], 'roc_auc': [0.9801412180052957, 0.939541041482789, 0.983065953654189, 0.9269533055940822, 0.9884419787332409], 'area_under_pr': [0.8957697773431414, 0.8792300715268138, 0.9403353514655455, 0.7982725043290424, 0.9438481871503765], 'lift': [5.208333333333333, 5.6818181818181825, 5.636363636363636, 5.412698412698413, 5.412698412698413]}",./output/modelsaves/ageconditions/catboost/202310-0913-5101-7bdf8be6-c177-424b-b52e-2b0f7d48b099//202310-0913-5101-7bdf8be6-c177-424b-b52e-2b0f7d48b099,1949.837218761444
202310-0914-2330-519f04b9-a6a5-4b91-8040-21bf344da446,"{'dataset': 'housing', 'model': 'catboost', 'best_params': {}, 'param_grid': {'iterations': [200, 3000], 'learning_rate': [0.001, 0.1], 'depth': [4, 10], 'l2_leaf_reg': [0.5, 5.0], 'min_child_samples': [1, 100], 'bagging_temperature': [0.1, 2.0]}}",housing,catboost,hyperopt_kfold,r2_score,"{'bagging_temperature': 0.2518874209581551, 'depth': 6, 'iterations': 2628, 'l2_leaf_reg': 3.1596960622691075, 'learning_rate': 0.07548534949064327, 'min_child_samples': 2, 'outer_params': {'hyperopt_evals': 50, 'validation_fraction': 0.15, 'early_stopping_rounds': 50, 'verbose': False}}",0.8643339522181556,0.005859118736891047,"{'mse': [0.1809707564876559, 0.1794489257284938, 0.18656527025486608, 0.1690365888697555, 0.18663862518596908], 'rmse': [0.4254065778612925, 0.42361412361782014, 0.4319320204093071, 0.41114059501556827, 0.4320169269669524], 'r2_score': [0.8618974995649129, 0.8686408698272224, 0.8566042876356028, 0.873190089652697, 0.8613370144103425]}",./output/modelsaves/housing/catboost/202310-0914-2330-519f04b9-a6a5-4b91-8040-21bf344da446//202310-0914-2330-519f04b9-a6a5-4b91-8040-21bf344da446,1448.4474880695343
202310-0914-4739-df60be3d-3e74-441c-a1be-d020434ccafb,"{'dataset': 'heloc', 'model': 'catboost', 'best_params': {}, 'param_grid': {'iterations': [200, 3000], 'learning_rate': [0.001, 0.1], 'depth': [4, 10], 'l2_leaf_reg': [0.5, 5.0], 'min_child_samples': [1, 100], 'bagging_temperature': [0.1, 2.0]}}",heloc,catboost,hyperopt_kfold,lift,"{'bagging_temperature': 0.10092833200123712, 'depth': 9, 'iterations': 1619, 'l2_leaf_reg': 1.6940429042188316, 'learning_rate': 0.022840836438434018, 'min_child_samples': 87, 'outer_params': {'hyperopt_evals': 50, 'validation_fraction': 0.15, 'early_stopping_rounds': 50, 'verbose': False}}",1.7380794515436804,0.020744735145788902,"{'recall': [0.7646520146520146, 0.7710622710622711, 0.7838827838827839, 0.7783882783882784, 0.7717690192483959], 'precision': [0.722318339100346, 0.7190435525192144, 0.7133333333333334, 0.700164744645799, 0.7328111401218451], 'accuracy': [0.7237093690248566, 0.7232313575525813, 0.722753346080306, 0.7103250478011472, 0.7340985174557628], 'f1': [0.7428825622775801, 0.7441449403446753, 0.7469458987783597, 0.7372072853425846, 0.7517857142857143], 'roc_auc': [0.7994761904761905, 0.7913076923076923, 0.7953553113553113, 0.7948782051282053, 0.8094133822181484], 'area_under_pr': [0.7992924238329239, 0.7874884528781249, 0.7860136815549479, 0.8011317771999326, 0.8069167580414109], 'lift': [1.7415917415917415, 1.7140929246192402, 1.7140929246192402, 1.7599242862400757, 1.760695380648104]}",./output/modelsaves/heloc/catboost/202310-0914-4739-df60be3d-3e74-441c-a1be-d020434ccafb//202310-0914-4739-df60be3d-3e74-441c-a1be-d020434ccafb,611.7427039146423
202310-0916-0414-0da97cdc-ff60-4454-8a57-20007ac8b663,"{'dataset': 'housing', 'model': 'tabnet', 'best_params': {}, 'param_grid': {'batch_size': [1024, 2048, 4096], 'gflu_stages': [4, 10], 'gflu_dropout': [0.0, 0.3], 'embedding_dropout': [0.0, 0.3], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",housing,tabnet,hyperopt_kfold,r2_score,"{'AdamW_weight_decay': 8.31010482625794e-05, 'Adam_weight_decay': 4.47521088976304e-05, 'ExponentialLR_gamma': 0.9783296554292222, 'ReduceLROnPlateau_factor': 0.8855162492084347, 'ReduceLROnPlateau_patience': 4, 'batch_size': 1524, 'embedding_dropout': 0.027019952006565658, 'gflu_dropout': 0.2998221190742538, 'gflu_stages': 10, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 16, 'tol': 1e-05, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 8}}",0.6986824462634139,0.016701763194999306,"{'mse': [0.42880843840491634, 0.4247839609263091, 0.38226742301024047, 0.37028513760316834, 0.39950026757636026], 'rmse': [0.6548346649383463, 0.6517545250524227, 0.618277787899776, 0.608510589557132, 0.6320603353924056], 'r2_score': [0.6727674752499397, 0.6890521835552732, 0.7061858867871147, 0.7222150221063885, 0.7031916636183533]}",./output/modelsaves/housing/tabnet/202310-0916-0414-0da97cdc-ff60-4454-8a57-20007ac8b663//202310-0916-0414-0da97cdc-ff60-4454-8a57-20007ac8b663,18841.79612970352
202310-0917-1014-8e93e287-da86-4143-b9d2-031f4d72fde7,"{'dataset': 'diabetes', 'model': 'resnet', 'best_params': {}, 'param_grid': {'batch_size': [1024, 2048, 4096], 'resnet_depth': ['resnet18', 'resnet34', 'resnet50'], 'optimizer_fn': {'Adam': {'weight_decay': [1e-05, 0.001], 'learning_rate': [0.0001, 0.001]}, 'AdamW': {'weight_decay': [1e-05, 0.001], 'learning_rate': [0.0001, 0.001]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",diabetes,resnet,hyperopt_kfold,lift,"{'AdamW_learning_rate': 0.00017092424644772874, 'AdamW_weight_decay': 4.738322975457727e-05, 'Adam_learning_rate': 0.0007419107207355485, 'Adam_weight_decay': 6.952584553615308e-05, 'ExponentialLR_gamma': 0.9052252997797481, 'ReduceLROnPlateau_factor': 0.8915636700785553, 'ReduceLROnPlateau_patience': 4, 'batch_size': 4094, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'resnet_depth': 'resnet34', 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>, 'outer_params': {'hyperopt_evals': 50, 'max_epochs': 1000, 'early_stopping': True, 'early_stopping_patience': 4, 'tol': 0.0001, 'validation_fraction': 0.15}}",2.284425967694336,0.09998953461961736,"{'recall': [0.0, 0.0, 0.0, 0.0, 0.0], 'precision': [0.0, 0.0, 0.0, 0.0, 0.0], 'accuracy': [0.888375749238479, 0.8884193976317988, 0.8884193976317988, 0.8884193976317988, 0.8883702648258242], 'f1': [0.0, 0.0, 0.0, 0.0, 0.0], 'roc_auc': [0.6503514262491218, 0.6759796764200232, 0.650743255284369, 0.656836795787827, 0.6508654740093679], 'area_under_pr': [0.20375134749064638, 0.2307503746100058, 0.20011432227008338, 0.2144347030964539, 0.20142996589500023], 'lift': [2.2231481641692907, 2.4662375838069366, 2.2240178211116124, 2.3165017305043722, 2.1922245388794686]}",./output/modelsaves/diabetes/resnet/202310-0917-1014-8e93e287-da86-4143-b9d2-031f4d72fde7//202310-0917-1014-8e93e287-da86-4143-b9d2-031f4d72fde7,49792.67940020561
202310-0912-0955-20083f2c-1c09-4147-be95-b779e431d57c,"{'dataset': 'covertype', 'model': 'tabtransformer', 'best_params': {}, 'param_grid': {'batch_size': [1024, 2048, 4096], 'embedding_bias': [True, False], 'embedding_initialization': ['kaiming_uniform', 'kaiming_normal'], 'shared_embedding_fraction': [0.125, 0.25, 0.5], 'num_attn_blocks': [4, 10], 'attn_dropout': [0.05, 0.3], 'add_norm_dropout': [0.05, 0.3], 'ff_dropout': [0.05, 0.3], 'ff_hidden_multiplier': [2, 6], 'transformer_activation': ['GEGLU', 'ReGLU', 'SwiGLU'], 'embedding_dropout': [0.05, 0.3], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",covertype,tabtransformer,hyperopt_kfold,accuracy,"{'AdamW_weight_decay': 2.262300123336867e-05, 'Adam_weight_decay': 2.4070813123445432e-05, 'ExponentialLR_gamma': 0.9740070834316623, 'ReduceLROnPlateau_factor': 0.3792727151585615, 'ReduceLROnPlateau_patience': 4, 'add_norm_dropout': 0.08784639711842174, 'attn_dropout': 0.05235560038681807, 'batch_size': 3299, 'embedding_bias': False, 'embedding_dropout': 0.10286066586455964, 'embedding_initialization': 'kaiming_uniform', 'ff_dropout': 0.252176464737774, 'ff_hidden_multiplier': 4, 'num_attn_blocks': 4, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'shared_embedding_fraction': 0.35492808934005693, 'transformer_activation': 'SwiGLU', 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 16, 'tol': 1e-05, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 8}}",0.6081755316632734,0.020401088192293665,"{'accuracy': [0.5938473035247229, 0.5964378491868617, 0.60232731931248, 0.5996939610690011, 0.6485712252233017], 'f1': [0.6237090894500815, 0.6250743452961824, 0.6302180240093848, 0.6293654779051726, 0.6669323583456646]}",./output/modelsaves/covertype/tabtransformer/202310-0912-0955-20083f2c-1c09-4147-be95-b779e431d57c//202310-0912-0955-20083f2c-1c09-4147-be95-b779e431d57c,75136.8723359108
202310-1010-2751-61cd9f0f-b398-4688-ab17-d2a3f7f66924,"{'dataset': 'adult', 'model': 'resnet', 'best_params': {}, 'param_grid': {'batch_size': [1024, 2048, 4096], 'resnet_depth': ['resnet18', 'resnet34', 'resnet50'], 'optimizer_fn': {'Adam': {'weight_decay': [1e-05, 0.001], 'learning_rate': [0.0001, 0.001]}, 'AdamW': {'weight_decay': [1e-05, 0.001], 'learning_rate': [0.0001, 0.001]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",adult,resnet,hyperopt_kfold,roc_auc,"{'AdamW_learning_rate': 0.0009513909937632767, 'AdamW_weight_decay': 0.0008961405474186418, 'Adam_learning_rate': 0.0009073965217033742, 'Adam_weight_decay': 1.0058975677141504e-05, 'ExponentialLR_gamma': 0.9480799338440119, 'ReduceLROnPlateau_factor': 0.518891328983621, 'ReduceLROnPlateau_patience': 3, 'batch_size': 4053, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'resnet_depth': 'resnet34', 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>, 'outer_params': {'hyperopt_evals': 50, 'max_epochs': 1000, 'early_stopping': True, 'early_stopping_patience': 4, 'tol': 0.0001, 'validation_fraction': 0.15}}",0.9043154802025818,0.0035073006392117466,"{'recall': [0.3435309114085405, 0.33290816326530615, 0.34119897959183676, 0.21237244897959184, 0.19579081632653061], 'precision': [0.8637820512820513, 0.8656716417910447, 0.8492063492063492, 0.9098360655737705, 0.9475308641975309], 'accuracy': [0.8288039306003377, 0.8269348894348895, 0.8267813267813268, 0.8052825552825553, 0.8037469287469288], 'f1': [0.49156406748746007, 0.48088438507600184, 0.48680618744313015, 0.34436401240951403, 0.324524312896406], 'roc_auc': [0.9047015548006376, 0.9066771050046232, 0.9069115548221717, 0.8974745465540584, 0.905812639831418], 'area_under_pr': [0.7651143596100276, 0.7645403696585165, 0.7611740020169813, 0.7469418376550035, 0.7701619141897703], 'lift': [3.5389149800424704, 3.5597667638483963, 3.5151101915420546, 3.483212639894668, 3.6490799084610805]}",./output/modelsaves/adult/resnet/202310-1010-2751-61cd9f0f-b398-4688-ab17-d2a3f7f66924//202310-1010-2751-61cd9f0f-b398-4688-ab17-d2a3f7f66924,29141.365272521973
202310-1012-1819-effe5949-d7e0-49d3-b5a5-a51a3fec8cbe,"{'dataset': 'diabetes', 'model': 'tabnet', 'best_params': {}, 'param_grid': {'virtual_batch_size_ratio': [0.125, 0.25, 0.5, 1.0], 'batch_size': [1024, 2048, 4096], 'weights': [0, 1], 'mask_type': ['sparsemax', 'entmax'], 'n_d': [6, 24], 'n_steps': [3, 7], 'gamma': [1.0, 2.0], 'n_independent': [2, 3], 'n_shared': [2, 3], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",diabetes,tabnet,hyperopt_kfold,lift,"{'AdamW_weight_decay': 3.665035561251228e-05, 'Adam_weight_decay': 2.222985520352012e-05, 'ExponentialLR_gamma': 0.9000076988965221, 'ReduceLROnPlateau_factor': 0.3810704666294629, 'ReduceLROnPlateau_patience': 5, 'batch_size': 3051, 'gamma': 1.2038826535437848, 'mask_type': 'entmax', 'n_d': 16, 'n_independent': 2, 'n_shared': 2, 'n_steps': 3, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'virtual_batch_size_ratio': 0.25, 'weights': 0, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 16, 'tol': 0.001, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 3}}",2.3936293871884695,0.09521420363110131,"{'recall': [0.5224471830985915, 0.6358432408630559, 0.6283575517393218, 0.6155878467635403, 0.551056338028169], 'precision': [0.18113840988860064, 0.17000235460324936, 0.17292777508482793, 0.17017650639074863, 0.16841538875437181], 'accuracy': [0.6830598408175297, 0.6129808873384759, 0.6232005109811821, 0.6221687220557166, 0.6461455313712966], 'f1': [0.2690084985835694, 0.2682768230376219, 0.2712154328613513, 0.26664123593362576, 0.2579847516999794], 'roc_auc': [0.6676076151912026, 0.6707251144317309, 0.6760568482217926, 0.6623412224880335, 0.6531719230403716], 'area_under_pr': [0.19869821266139237, 0.22785884518080934, 0.216024762161311, 0.22063951856057062, 0.19769291999283994], 'lift': [2.3640209191265527, 2.5411055104582183, 2.4001776485263937, 2.417793631267872, 2.2450492265633115]}",./output/modelsaves/diabetes/tabnet/202310-1012-1819-effe5949-d7e0-49d3-b5a5-a51a3fec8cbe//202310-1012-1819-effe5949-d7e0-49d3-b5a5-a51a3fec8cbe,26016.111689567566
202310-1012-5004-01bae7b1-a0a2-4ae6-a1e9-166b8861d5d9,"{'dataset': 'iris', 'model': 'catboost', 'best_params': {}, 'param_grid': {'iterations': [50, 1000], 'learning_rate': [0.001, 0.1], 'depth': [4, 12], 'l2_leaf_reg': [0.5, 5.0], 'min_child_samples': [1, 10], 'bagging_temperature': [0.1, 2.0]}}",iris,catboost,hyperopt_kfold,accuracy,"{'bagging_temperature': 0.14228166126511824, 'depth': 6, 'iterations': 262, 'l2_leaf_reg': 1.4054889582047796, 'learning_rate': 0.008231059874437023, 'min_child_samples': 6, 'outer_params': {'hyperopt_evals': 50, 'validation_fraction': 0.15, 'early_stopping_rounds': 100, 'verbose': False}}",0.9600000000000002,0.038873012632301994,"{'accuracy': [1.0, 0.9666666666666667, 0.9333333333333333, 1.0, 0.9], 'f1': [1.0, 0.9665831244778613, 0.9326599326599326, 1.0, 0.8997493734335841]}",./output/modelsaves/iris/catboost/202310-1012-5004-01bae7b1-a0a2-4ae6-a1e9-166b8861d5d9//202310-1012-5004-01bae7b1-a0a2-4ae6-a1e9-166b8861d5d9,134.4465639591217
202310-1012-5218-6430a85d-ca3a-42c6-ab0b-3be660d9486c,"{'dataset': 'breastcancer', 'model': 'catboost', 'best_params': {}, 'param_grid': {'iterations': [50, 1000], 'learning_rate': [0.001, 0.1], 'depth': [4, 12], 'l2_leaf_reg': [0.5, 5.0], 'min_child_samples': [1, 10], 'bagging_temperature': [0.1, 2.0]}}",breastcancer,catboost,hyperopt_kfold,f1,"{'bagging_temperature': 0.9928196516799518, 'depth': 4, 'iterations': 958, 'l2_leaf_reg': 1.6892173684593075, 'learning_rate': 0.05673035133721847, 'min_child_samples': 10, 'outer_params': {'hyperopt_evals': 50, 'validation_fraction': 0.15, 'early_stopping_rounds': 100, 'verbose': False}}",0.9778494645214051,0.010898157836217297,"{'recall': [1.0, 0.9859154929577465, 1.0, 0.9583333333333334, 0.9859154929577465], 'precision': [0.9861111111111112, 0.9333333333333333, 0.96, 1.0, 0.9722222222222222], 'accuracy': [0.9912280701754386, 0.9473684210526315, 0.9736842105263158, 0.9736842105263158, 0.9734513274336283], 'f1': [0.993006993006993, 0.9589041095890412, 0.9795918367346939, 0.9787234042553191, 0.979020979020979], 'roc_auc': [0.9993449066491975, 0.9934490664919751, 0.9857804232804233, 1.0, 0.9979879275653923], 'area_under_pr': [0.9996060085080121, 0.9961513760001102, 0.989678170148699, 1.0, 0.9988032941186187], 'lift': [1.6056338028169013, 1.6056338028169013, 1.5833333333333335, 1.5833333333333335, 1.591549295774648]}",./output/modelsaves/breastcancer/catboost/202310-1012-5218-6430a85d-ca3a-42c6-ab0b-3be660d9486c//202310-1012-5218-6430a85d-ca3a-42c6-ab0b-3be660d9486c,2292.853511095047
202310-1013-3031-09fc2b37-d53b-43f7-b477-c5f0eb5fdf50,"{'dataset': 'iris', 'model': 'xgb', 'best_params': {}, 'param_grid': {'n_estimators': [100, 1000], 'max_bin': [128, 32], 'tree_method': ['auto', 'hist'], 'max_depth': [4, 12], 'learning_rate': [0.1, 0.33], 'subsample': [0.9, 1.0], 'colsample_bytree': [0.8, 1.0], 'min_child_weight': [1, 10], 'alpha': [0.0, 5.0], 'gamma': [0.0, 5.0], 'lambda': [0.0, 5.0]}}",iris,xgb,hyperopt_kfold,accuracy,"{'alpha': 2.9698529989450178, 'colsample_bytree': 0.9797301055762344, 'gamma': 0.011988357458747378, 'lambda': 2.8639961165915446, 'learning_rate': 0.1942847593149101, 'max_bin': 63, 'max_depth': 7, 'min_child_weight': 2, 'n_estimators': 465, 'subsample': 0.999215752536224, 'tree_method': 'auto', 'outer_params': {'hyperopt_evals': 50, 'validation_fraction': 0.15, 'early_stopping_rounds': 100, 'verbose': False}}",0.9733333333333334,0.02494438257849294,"{'accuracy': [1.0, 0.9666666666666667, 0.9333333333333333, 1.0, 0.9666666666666667], 'f1': [1.0, 0.9665831244778613, 0.9326599326599326, 1.0, 0.9665831244778613]}",./output/modelsaves/iris/xgb/202310-1013-3031-09fc2b37-d53b-43f7-b477-c5f0eb5fdf50//202310-1013-3031-09fc2b37-d53b-43f7-b477-c5f0eb5fdf50,29.13872790336609
202310-1013-3100-95ae27ab-3a5e-4c2c-99e2-1c45a2553ef6,"{'dataset': 'breastcancer', 'model': 'xgb', 'best_params': {}, 'param_grid': {'n_estimators': [100, 1000], 'max_bin': [128, 32], 'tree_method': ['auto', 'hist'], 'max_depth': [4, 12], 'learning_rate': [0.1, 0.33], 'subsample': [0.9, 1.0], 'colsample_bytree': [0.8, 1.0], 'min_child_weight': [1, 10], 'alpha': [0.0, 5.0], 'gamma': [0.0, 5.0], 'lambda': [0.0, 5.0]}}",breastcancer,xgb,hyperopt_kfold,f1,"{'alpha': 1.1985226600140277, 'colsample_bytree': 0.9139910048831039, 'gamma': 1.173412645836684, 'lambda': 4.362079992679666, 'learning_rate': 0.27524927784745207, 'max_bin': 91, 'max_depth': 11, 'min_child_weight': 2, 'n_estimators': 469, 'subsample': 0.9197785508359548, 'tree_method': 'auto', 'outer_params': {'hyperopt_evals': 50, 'validation_fraction': 0.15, 'early_stopping_rounds': 100, 'verbose': False}}",0.9694206980100193,0.009203173336373802,"{'recall': [0.971830985915493, 0.971830985915493, 0.9861111111111112, 0.9583333333333334, 0.9859154929577465], 'precision': [0.9857142857142858, 0.9324324324324325, 0.9594594594594594, 0.9857142857142858, 0.958904109589041], 'accuracy': [0.9736842105263158, 0.9385964912280702, 0.9649122807017544, 0.9649122807017544, 0.9646017699115044], 'f1': [0.9787234042553192, 0.9517241379310345, 0.9726027397260274, 0.971830985915493, 0.9722222222222222], 'roc_auc': [0.9970520799213888, 0.9867343596462497, 0.9884259259259259, 0.9976851851851852, 0.9889336016096579], 'area_under_pr': [0.998298802072208, 0.9919705141079349, 0.9919490142107384, 0.9986321559274999, 0.9925203298722862], 'lift': [1.6056338028169013, 1.6056338028169013, 1.5833333333333335, 1.5833333333333335, 1.591549295774648]}",./output/modelsaves/breastcancer/xgb/202310-1013-3100-95ae27ab-3a5e-4c2c-99e2-1c45a2553ef6//202310-1013-3100-95ae27ab-3a5e-4c2c-99e2-1c45a2553ef6,55.840697050094604
202310-1019-3155-8701d720-7784-42c4-b4b8-12122c69571c,"{'dataset': 'breastcancer', 'model': 'resnet', 'best_params': {}, 'param_grid': {'batch_size': [32, 64, 128, 256], 'resnet_depth': ['resnet18', 'resnet34', 'resnet50'], 'optimizer_fn': {'Adam': {'weight_decay': [1e-05, 0.001], 'learning_rate': [0.0001, 0.001]}, 'AdamW': {'weight_decay': [1e-05, 0.001], 'learning_rate': [0.0001, 0.001]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",breastcancer,resnet,hyperopt_kfold,f1,"{'AdamW_learning_rate': 0.00015403614624797968, 'AdamW_weight_decay': 0.00025927901848250856, 'Adam_learning_rate': 0.00036756124520780727, 'Adam_weight_decay': 4.69369938343694e-05, 'ExponentialLR_gamma': 0.9351257849762318, 'ReduceLROnPlateau_factor': 0.5417141748927462, 'ReduceLROnPlateau_patience': 4, 'batch_size': 40, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'resnet_depth': 'resnet34', 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>, 'outer_params': {'hyperopt_evals': 50, 'max_epochs': 1000, 'early_stopping': True, 'early_stopping_patience': 10, 'tol': 0.0001, 'validation_fraction': 0.15}}",0.9764460512597308,0.01252952466630442,"{'recall': [0.9577464788732394, 1.0, 0.9722222222222222, 0.9722222222222222, 1.0], 'precision': [1.0, 0.9342105263157895, 0.9459459459459459, 1.0, 0.9861111111111112], 'accuracy': [0.9736842105263158, 0.956140350877193, 0.9473684210526315, 0.9824561403508771, 0.9911504424778761], 'f1': [0.9784172661870503, 0.9659863945578232, 0.9589041095890412, 0.9859154929577464, 0.993006993006993], 'roc_auc': [1.0, 0.9893547330494595, 0.9794973544973545, 1.0, 0.9844064386317907], 'area_under_pr': [0.9999999999999998, 0.9926088218221272, 0.9790622554463009, 1.0, 0.981124431667723], 'lift': [1.6056338028169013, 1.6056338028169013, 1.5833333333333335, 1.5833333333333335, 1.591549295774648]}",./output/modelsaves/breastcancer/resnet/202310-1019-3155-8701d720-7784-42c4-b4b8-12122c69571c//202310-1019-3155-8701d720-7784-42c4-b4b8-12122c69571c,27057.12552189827
202310-1103-0252-6c3afd03-3725-4ff3-a57c-c3de17cb14d1,"{'dataset': 'creditcard', 'model': 'tabnet', 'best_params': {}, 'param_grid': {'virtual_batch_size_ratio': [0.125, 0.25, 0.5, 1.0], 'batch_size': [1024, 2048, 4096], 'weights': [0, 1], 'mask_type': ['sparsemax', 'entmax'], 'n_d': [6, 24], 'n_steps': [3, 7], 'gamma': [1.0, 2.0], 'n_independent': [2, 3], 'n_shared': [2, 3], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",creditcard,tabnet,hyperopt_kfold,lift,"{'AdamW_weight_decay': 3.477856070047425e-05, 'Adam_weight_decay': 3.421876146973406e-05, 'ExponentialLR_gamma': 0.9027956055208904, 'ReduceLROnPlateau_factor': 0.1957819296498551, 'ReduceLROnPlateau_patience': 3, 'batch_size': 2023, 'gamma': 1.3712181013191895, 'mask_type': 'entmax', 'n_d': 14, 'n_independent': 2, 'n_shared': 2, 'n_steps': 5, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>, 'virtual_batch_size_ratio': 0.25, 'weights': 1, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 16, 'tol': 0.001, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 3}}",8.75944181192225,0.7452769612074207,"{'recall': [1.0, 0.9191919191919192, 0.8673469387755102, 0.6836734693877551, 0.826530612244898], 'precision': [0.0017383975135647684, 0.1262135922330097, 0.05670446964643095, 0.07452725250278086, 0.04900181488203267], 'accuracy': [0.001966223096099154, 0.9887995505775781, 0.9749477712821053, 0.9848492828426467, 0.9721037200891838], 'f1': [0.0034707614640302905, 0.2219512195121951, 0.10644959298685035, 0.13440320962888663, 0.09251856082238721], 'roc_auc': [0.9109020138248284, 0.9795007919974945, 0.9850356406213717, 0.873411730378098, 0.9392974413619272], 'area_under_pr': [0.10564290173270528, 0.7248520990508971, 0.5028476224291344, 0.4250806553841273, 0.3677189570536205], 'lift': [8.485146407899217, 9.495282885030075, 9.387919915157074, 7.449110367461591, 8.979749484063287]}",./output/modelsaves/creditcard/tabnet/202310-1103-0252-6c3afd03-3725-4ff3-a57c-c3de17cb14d1//202310-1103-0252-6c3afd03-3725-4ff3-a57c-c3de17cb14d1,28567.095775604248
202310-1112-1543-026b30ed-6bc6-4e35-a61c-af02a8ddd008,"{'dataset': 'diabetes', 'model': 'catboost', 'best_params': {}, 'param_grid': {'iterations': [200, 3000], 'learning_rate': [0.001, 0.1], 'depth': [4, 10], 'l2_leaf_reg': [0.5, 5.0], 'min_child_samples': [1, 100], 'bagging_temperature': [0.1, 2.0]}}",diabetes,catboost,hyperopt_kfold,lift,"{'bagging_temperature': 0.5953059649955964, 'depth': 10, 'iterations': 2991, 'l2_leaf_reg': 4.813342307635321, 'learning_rate': 0.005917020876182678, 'min_child_samples': 52, 'outer_params': {'hyperopt_evals': 50, 'validation_fraction': 0.15, 'early_stopping_rounds': 50, 'verbose': False}}",2.513395070470535,0.07834220909083607,"{'recall': [0.013204225352112676, 0.012769704975781594, 0.007926023778071334, 0.010127697049757816, 0.014084507042253521], 'precision': [0.5660377358490566, 0.6170212765957447, 0.5454545454545454, 0.6216216216216216, 0.5714285714285714], 'accuracy': [0.8887196619829026, 0.8889598584975188, 0.8885667960497224, 0.8888615928855697, 0.8887633272736206], 'f1': [0.025806451612903226, 0.025021570319240728, 0.015624999999999997, 0.01993067590987868, 0.027491408934707903], 'roc_auc': [0.6799166619282113, 0.6934440155715115, 0.6830540220632939, 0.6851769649988741, 0.677722086487177], 'area_under_pr': [0.22925587877539347, 0.2500682451891498, 0.2348925320166975, 0.2443552678365704, 0.22820289302480457], 'lift': [2.4300550230127693, 2.5939534586826527, 2.4750455751776754, 2.6203774327948697, 2.4475438626847077]}",./output/modelsaves/diabetes/catboost/202310-1112-1543-026b30ed-6bc6-4e35-a61c-af02a8ddd008//202310-1112-1543-026b30ed-6bc6-4e35-a61c-af02a8ddd008,17172.809494256973
202310-1117-0156-73e5dc26-7c72-4cd6-b907-78a4a3b02ffb,"{'dataset': 'covertype', 'model': 'catboost', 'best_params': {}, 'param_grid': {'iterations': [200, 3000], 'learning_rate': [0.001, 0.1], 'depth': [4, 10], 'l2_leaf_reg': [0.5, 5.0], 'min_child_samples': [1, 100], 'bagging_temperature': [0.1, 2.0]}}",covertype,catboost,hyperopt_kfold,accuracy,"{'bagging_temperature': 0.2688542208650529, 'depth': 9, 'iterations': 2023, 'l2_leaf_reg': 1.4883116798146068, 'learning_rate': 0.08326674401684082, 'min_child_samples': 16, 'outer_params': {'hyperopt_evals': 50, 'validation_fraction': 0.15, 'early_stopping_rounds': 50, 'verbose': False}}",0.9420236211896708,0.0009694275595322269,"{'accuracy': [0.9422094905965873, 0.9429913526209032, 0.9429023878153803, 0.9403402014163197, 0.9416746734991638], 'f1': [0.9420533263488293, 0.9428546908312456, 0.9427685586069143, 0.9401735485039312, 0.9415314232798179]}",./output/modelsaves/covertype/catboost/202310-1117-0156-73e5dc26-7c72-4cd6-b907-78a4a3b02ffb//202310-1117-0156-73e5dc26-7c72-4cd6-b907-78a4a3b02ffb,6510.114036083221
202310-1118-5026-a1a51882-088a-4c08-aff8-eca39bda1498,"{'dataset': 'creditcard', 'model': 'catboost', 'best_params': {}, 'param_grid': {'iterations': [200, 3000], 'learning_rate': [0.001, 0.1], 'depth': [4, 10], 'l2_leaf_reg': [0.5, 5.0], 'min_child_samples': [1, 100], 'bagging_temperature': [0.1, 2.0]}}",creditcard,catboost,hyperopt_kfold,lift,"{'bagging_temperature': 1.9189374212123842, 'depth': 8, 'iterations': 2572, 'l2_leaf_reg': 4.7018024566979815, 'learning_rate': 0.011796489198818875, 'min_child_samples': 41, 'outer_params': {'hyperopt_evals': 50, 'validation_fraction': 0.15, 'early_stopping_rounds': 50, 'verbose': False}}",9.655153048195784,0.16444635887654727,"{'recall': [0.7474747474747475, 0.797979797979798, 0.8163265306122449, 0.7857142857142857, 0.8163265306122449], 'precision': [0.9367088607594937, 1.0, 0.963855421686747, 0.9506172839506173, 0.9302325581395349], 'accuracy': [0.9994733330992591, 0.9996488887328394, 0.9996313266972139, 0.9995611032109689, 0.9995786590825302], 'f1': [0.8314606741573033, 0.8876404494382023, 0.8839779005524863, 0.8603351955307262, 0.8695652173913043], 'roc_auc': [0.985315583068076, 0.9855196887361916, 0.9946568677239638, 0.9674053677887454, 0.9905555314294615], 'area_under_pr': [0.8447766214332391, 0.8955018729384124, 0.8714823731723628, 0.8579042223952141, 0.8434850675519047], 'lift': [9.59629653274316, 9.495282885030075, 9.898132954024305, 9.48996252293052, 9.796090346250859]}",./output/modelsaves/creditcard/catboost/202310-1118-5026-a1a51882-088a-4c08-aff8-eca39bda1498//202310-1118-5026-a1a51882-088a-4c08-aff8-eca39bda1498,2094.5717544555664
202310-1120-0359-15e889a6-ffdd-4b62-87da-cbac4a46ebe3,"{'dataset': 'titanic', 'model': 'resnet', 'best_params': {}, 'param_grid': {'batch_size': [32, 64, 128, 256], 'resnet_depth': ['resnet18', 'resnet34', 'resnet50'], 'optimizer_fn': {'Adam': {'weight_decay': [1e-05, 0.001], 'learning_rate': [0.0001, 0.001]}, 'AdamW': {'weight_decay': [1e-05, 0.001], 'learning_rate': [0.0001, 0.001]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",titanic,resnet,hyperopt_kfold,roc_auc,"{'AdamW_learning_rate': 0.00014194472482598677, 'AdamW_weight_decay': 3.49785527429041e-05, 'Adam_learning_rate': 0.00023539065760010136, 'Adam_weight_decay': 0.0005285123765969554, 'ExponentialLR_gamma': 0.9101542293134589, 'ReduceLROnPlateau_factor': 0.16919512815817458, 'ReduceLROnPlateau_patience': 3, 'batch_size': 133, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>, 'resnet_depth': 'resnet34', 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>, 'outer_params': {'hyperopt_evals': 10, 'max_epochs': 1000, 'early_stopping': True, 'early_stopping_patience': 10, 'tol': 0.0001, 'validation_fraction': 0.15}}",0.8616199578790793,0.01570910674870464,"{'recall': [0.5072463768115942, 0.6176470588235294, 0.6323529411764706, 0.6764705882352942, 0.6811594202898551], 'precision': [0.9210526315789473, 0.84, 0.7543859649122807, 0.8363636363636363, 0.8703703703703703], 'accuracy': [0.7932960893854749, 0.8089887640449438, 0.7808988764044944, 0.8258426966292135, 0.8370786516853933], 'f1': [0.6542056074766355, 0.711864406779661, 0.688, 0.7479674796747968, 0.7642276422764227], 'roc_auc': [0.8853096179183135, 0.8457219251336897, 0.8427139037433157, 0.8677807486631015, 0.8665735939369765], 'area_under_pr': [0.8382039002840695, 0.828141826492668, 0.8088591658539951, 0.8583184191733833, 0.8577756930128045], 'lift': [2.441602728047741, 2.6176470588235294, 2.463667820069204, 2.6176470588235294, 2.579710144927536]}",./output/modelsaves/titanic/resnet/202310-1120-0359-15e889a6-ffdd-4b62-87da-cbac4a46ebe3//202310-1120-0359-15e889a6-ffdd-4b62-87da-cbac4a46ebe3,3765.083344221115
202310-1121-0644-3579d0dd-025a-413b-a027-f2d7aa6f8dd5,"{'dataset': 'ageconditions', 'model': 'resnet', 'best_params': {}, 'param_grid': {'batch_size': [32, 64, 128, 256], 'resnet_depth': ['resnet18', 'resnet34', 'resnet50'], 'optimizer_fn': {'Adam': {'weight_decay': [1e-05, 0.001], 'learning_rate': [0.0001, 0.001]}, 'AdamW': {'weight_decay': [1e-05, 0.001], 'learning_rate': [0.0001, 0.001]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",ageconditions,resnet,hyperopt_kfold,f1,"{'AdamW_learning_rate': 0.0007450029975279926, 'AdamW_weight_decay': 9.166987910726041e-05, 'Adam_learning_rate': 0.0005780546450052875, 'Adam_weight_decay': 0.0002699111583238274, 'ExponentialLR_gamma': 0.9574825542310041, 'ReduceLROnPlateau_factor': 0.4155630057833172, 'ReduceLROnPlateau_patience': 4, 'batch_size': 197, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'resnet_depth': 'resnet18', 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>, 'outer_params': {'hyperopt_evals': 10, 'max_epochs': 1000, 'early_stopping': True, 'early_stopping_patience': 10, 'tol': 0.0001, 'validation_fraction': 0.15}}",0.5346296462575533,0.13975265721064506,"{'recall': [0.6818181818181818, 0.18181818181818182, 0.45454545454545453, 0.42857142857142855, 0.6190476190476191], 'precision': [0.75, 0.8, 0.7692307692307693, 0.5625, 0.5909090909090909], 'accuracy': [0.904, 0.848, 0.8790322580645161, 0.8467741935483871, 0.8629032258064516], 'f1': [0.7142857142857143, 0.2962962962962963, 0.5714285714285714, 0.4864864864864864, 0.6046511627906977], 'roc_auc': [0.8892321270962048, 0.7983230361871139, 0.8859180035650625, 0.7799352750809062, 0.9098474341192787], 'area_under_pr': [0.7712206086973761, 0.482498991463414, 0.698324606355338, 0.5419050748146489, 0.7459090578053584], 'lift': [4.734848484848485, 3.31439393939394, 4.227272727272727, 3.9365079365079367, 4.920634920634921]}",./output/modelsaves/ageconditions/resnet/202310-1121-0644-3579d0dd-025a-413b-a027-f2d7aa6f8dd5//202310-1121-0644-3579d0dd-025a-413b-a027-f2d7aa6f8dd5,3301.529345035553
202310-1120-0043-5a85f3a9-e015-4d46-b998-2316157b5d37,"{'dataset': 'diabetes', 'model': 'fttransformer', 'best_params': {}, 'param_grid': {'batch_size': [1024, 2048], 'num_heads': [4, 6], 'input_embed_dim_multiplier': [2, 4], 'embedding_initialization': ['kaiming_uniform', 'kaiming_normal'], 'embedding_dropout': [0.05, 0.2], 'shared_embedding_fraction': [0.125, 0.25, 0.5], 'num_attn_blocks': [4, 6], 'attn_dropout': [0.05, 0.2], 'add_norm_dropout': [0.05, 0.2], 'ff_dropout': [0.05, 0.2], 'ff_hidden_multiplier': [4, 32], 'transformer_activation': ['GEGLU', 'ReGLU', 'SwiGLU'], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",diabetes,fttransformer,hyperopt_kfold,lift,"{'AdamW_weight_decay': 2.057273421257847e-05, 'Adam_weight_decay': 1.6223095621381666e-05, 'ExponentialLR_gamma': 0.949593376453696, 'ReduceLROnPlateau_factor': 0.3775558867618324, 'ReduceLROnPlateau_patience': 4, 'add_norm_dropout': 0.07968044900534835, 'attn_dropout': 0.12647229304997543, 'batch_size': 1115, 'embedding_dropout': 0.05769697471109714, 'embedding_initialization': 'kaiming_normal', 'ff_dropout': 0.15009980002038528, 'ff_hidden_multiplier': 23, 'input_embed_dim_multiplier': 2, 'num_attn_blocks': 5, 'num_heads': 5, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'shared_embedding_fraction': 0.44375063807617815, 'transformer_activation': 'ReGLU', 'outer_params': {'hyperopt_evals': 10, 'auto_lr_find': True, 'precision': 16, 'tol': 0.001, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 3, 'attn_feature_importance': False}}",2.31701786182013,0.11807368365101673,"{'recall': [0.6342429577464789, 0.6006164685160722, 0.6415675913694407, 0.5592250110083664, 0.5871478873239436], 'precision': [0.1672275734014158, 0.18269488347173854, 0.1709491962923853, 0.18265496907809578, 0.1663756547767523], 'accuracy': [0.6066129507713471, 0.6556281629243846, 0.6128334889205522, 0.6715963248661131, 0.625509752861986], 'f1': [0.26467076866562583, 0.28016842970114, 0.2699647952566241, 0.2753686036426713, 0.25928085519922256], 'roc_auc': [0.6674937097004103, 0.6852946830454988, 0.6757881836894415, 0.6734092027848476, 0.6490623838851928], 'area_under_pr': [0.21301886602870007, 0.23274330363576817, 0.21360600014371606, 0.2237116849087431, 0.19469168964671063], 'lift': [2.2231481641692907, 2.364945683043437, 2.3253097218751115, 2.5058735449752625, 2.1658121950375473]}",./output/modelsaves/diabetes/fttransformer/202310-1120-0043-5a85f3a9-e015-4d46-b998-2316157b5d37//202310-1120-0043-5a85f3a9-e015-4d46-b998-2316157b5d37,8843.831639289856
202310-1122-0146-ee796837-a52d-45f6-bd17-e9107b639edf,"{'dataset': 'heloc', 'model': 'resnet', 'best_params': {}, 'param_grid': {'batch_size': [32, 64, 128, 256], 'resnet_depth': ['resnet18', 'resnet34', 'resnet50'], 'optimizer_fn': {'Adam': {'weight_decay': [1e-05, 0.001], 'learning_rate': [0.0001, 0.001]}, 'AdamW': {'weight_decay': [1e-05, 0.001], 'learning_rate': [0.0001, 0.001]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",heloc,resnet,hyperopt_kfold,lift,"{'AdamW_learning_rate': 0.0007450029975279926, 'AdamW_weight_decay': 9.166987910726041e-05, 'Adam_learning_rate': 0.0005780546450052875, 'Adam_weight_decay': 0.0002699111583238274, 'ExponentialLR_gamma': 0.9574825542310041, 'ReduceLROnPlateau_factor': 0.4155630057833172, 'ReduceLROnPlateau_patience': 4, 'batch_size': 197, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'resnet_depth': 'resnet18', 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>, 'outer_params': {'hyperopt_evals': 10, 'max_epochs': 1000, 'early_stopping': True, 'early_stopping_patience': 10, 'tol': 0.0001, 'validation_fraction': 0.15}}",1.6335775212614423,0.06631978458928135,"{'recall': [0.771978021978022, 0.7747252747252747, 0.8608058608058609, 0.7490842490842491, 0.7516040329972502], 'precision': [0.6943986820428336, 0.7121212121212122, 0.6676136363636364, 0.699743370402053, 0.7288888888888889], 'accuracy': [0.7036328871892925, 0.7189292543021033, 0.7036328871892925, 0.7012428298279159, 0.7245337159253945], 'f1': [0.7311361665221162, 0.7421052631578946, 0.752, 0.7235736399823087, 0.740072202166065], 'roc_auc': [0.7754331501831502, 0.7741694139194141, 0.7697518315018315, 0.7680054945054945, 0.7882584784601284], 'area_under_pr': [0.7752963336280357, 0.7690222372570503, 0.7466350197831966, 0.7722538636351828, 0.7785269455208095], 'lift': [1.668261562998405, 1.5949313844050685, 1.521601205811732, 1.695760379970906, 1.6873330731210998]}",./output/modelsaves/heloc/resnet/202310-1122-0146-ee796837-a52d-45f6-bd17-e9107b639edf//202310-1122-0146-ee796837-a52d-45f6-bd17-e9107b639edf,3939.0753314495087
202310-1123-0725-cc9a26c0-adfe-46e2-935c-6565494cf356,"{'dataset': 'ageconditions', 'model': 'resnet', 'best_params': {}, 'param_grid': {'batch_size': [32, 64, 128, 256], 'resnet_depth': ['resnet18', 'resnet34', 'resnet50'], 'optimizer_fn': {'Adam': {'weight_decay': [1e-05, 0.001], 'learning_rate': [0.0001, 0.001]}, 'AdamW': {'weight_decay': [1e-05, 0.001], 'learning_rate': [0.0001, 0.001]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",ageconditions,resnet,hyperopt_kfold,f1,"{'AdamW_learning_rate': 0.0007450029975279926, 'AdamW_weight_decay': 9.166987910726041e-05, 'Adam_learning_rate': 0.0005780546450052875, 'Adam_weight_decay': 0.0002699111583238274, 'ExponentialLR_gamma': 0.9574825542310041, 'ReduceLROnPlateau_factor': 0.4155630057833172, 'ReduceLROnPlateau_patience': 4, 'batch_size': 197, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'resnet_depth': 'resnet18', 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>, 'outer_params': {'hyperopt_evals': 10, 'max_epochs': 1000, 'early_stopping': True, 'early_stopping_patience': 10, 'tol': 0.0001, 'validation_fraction': 0.15}}",0.5152834140114694,0.09860327306860842,"{'recall': [0.8181818181818182, 0.2727272727272727, 0.5, 0.38095238095238093, 0.38095238095238093], 'precision': [0.5625, 0.5454545454545454, 0.4583333333333333, 0.8, 1.0], 'accuracy': [0.856, 0.832, 0.8064516129032258, 0.8790322580645161, 0.8951612903225806], 'f1': [0.6666666666666666, 0.3636363636363636, 0.4782608695652174, 0.5161290322580645, 0.5517241379310345], 'roc_auc': [0.9024713150926743, 0.8208296557811121, 0.767825311942959, 0.8307905686546463, 0.9167822468793343], 'area_under_pr': [0.7617167766798487, 0.5361676701032438, 0.5310940293560347, 0.6355123627768555, 0.7525126772649244], 'lift': [4.734848484848485, 2.8409090909090913, 4.227272727272727, 3.9365079365079367, 4.428571428571429]}",./output/modelsaves/ageconditions/resnet/202310-1123-0725-cc9a26c0-adfe-46e2-935c-6565494cf356//202310-1123-0725-cc9a26c0-adfe-46e2-935c-6565494cf356,3041.025647163391
202310-1200-2741-69f4ef5b-4cba-4f20-9922-678731c65e13,"{'dataset': 'creditcard', 'model': 'resnet', 'best_params': {}, 'param_grid': {'batch_size': [2048, 4096], 'resnet_depth': ['resnet18', 'resnet34', 'resnet50'], 'optimizer_fn': {'Adam': {'weight_decay': [1e-05, 0.001], 'learning_rate': [0.0001, 0.001]}, 'AdamW': {'weight_decay': [1e-05, 0.001], 'learning_rate': [0.0001, 0.001]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",creditcard,resnet,hyperopt_kfold,lift,"{'AdamW_learning_rate': 0.0007450029975279926, 'AdamW_weight_decay': 9.166987910726041e-05, 'Adam_learning_rate': 0.0005780546450052875, 'Adam_weight_decay': 0.0002699111583238274, 'ExponentialLR_gamma': 0.9574825542310041, 'ReduceLROnPlateau_factor': 0.4155630057833172, 'ReduceLROnPlateau_patience': 4, 'batch_size': 3554, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'resnet_depth': 'resnet18', 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>, 'outer_params': {'hyperopt_evals': 10, 'max_epochs': 1000, 'early_stopping': True, 'early_stopping_patience': 2, 'tol': 1e-07, 'validation_fraction': 0.15}}",9.122783069362123,0.18748006160402192,"{'recall': [0.0, 0.0, 0.0], 'precision': [0.0, 0.0, 0.0], 'accuracy': [0.9982619992275552, 0.9982619992275552, 0.9982795245869981], 'f1': [0.0, 0.0, 0.0], 'roc_auc': [0.9479317381116442, 0.9650584951923256, 0.9696289362868936], 'area_under_pr': [0.4845790935542396, 0.40000297728434964, 0.5692865867799576], 'lift': [8.990214646464647, 8.990214646464647, 9.387919915157074]}",./output/modelsaves/creditcard/resnet/202310-1200-2741-69f4ef5b-4cba-4f20-9922-678731c65e13//202310-1200-2741-69f4ef5b-4cba-4f20-9922-678731c65e13,8849.52667927742
202310-1202-5511-d4a67650-faba-4409-a78b-03b1bae0f805,"{'dataset': 'heloc', 'model': 'fttransformer', 'best_params': {}, 'param_grid': {'batch_size': [1024, 2048], 'num_heads': [4, 6], 'input_embed_dim_multiplier': [2, 4], 'embedding_initialization': ['kaiming_uniform', 'kaiming_normal'], 'embedding_dropout': [0.05, 0.2], 'shared_embedding_fraction': [0.125, 0.25, 0.5], 'num_attn_blocks': [4, 6], 'attn_dropout': [0.05, 0.2], 'add_norm_dropout': [0.05, 0.2], 'ff_dropout': [0.05, 0.2], 'ff_hidden_multiplier': [4, 32], 'transformer_activation': ['GEGLU', 'ReGLU', 'SwiGLU'], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",heloc,fttransformer,hyperopt_kfold,lift,"{'AdamW_weight_decay': 3.50162004441386e-05, 'Adam_weight_decay': 5.509617091794048e-05, 'ExponentialLR_gamma': 0.9239617580583868, 'ReduceLROnPlateau_factor': 0.8429781843421452, 'ReduceLROnPlateau_patience': 4, 'add_norm_dropout': 0.07600584760308673, 'attn_dropout': 0.057513332374261934, 'batch_size': 1445, 'embedding_dropout': 0.05910524719636577, 'embedding_initialization': 'kaiming_uniform', 'ff_dropout': 0.13109152742207308, 'ff_hidden_multiplier': 25, 'input_embed_dim_multiplier': 4, 'num_attn_blocks': 4, 'num_heads': 6, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>, 'shared_embedding_fraction': 0.4215616321619067, 'transformer_activation': 'SwiGLU', 'outer_params': {'hyperopt_evals': 10, 'auto_lr_find': True, 'precision': 16, 'tol': 0.001, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 3, 'attn_feature_importance': False}}",1.6927049558628504,0.026283752006258616,"{'recall': [0.75, 0.75, 0.7591575091575091], 'precision': [0.7209507042253521, 0.7371737173717372, 0.7146551724137931], 'accuracy': [0.7179732313575525, 0.7299235181644359, 0.7160611854684512], 'f1': [0.7351885098743268, 0.7435315478892419, 0.736234458259325], 'roc_auc': [0.7893163919413919, 0.7909478021978023, 0.7902087912087912], 'area_under_pr': [0.7904933907350301, 0.7832750141003889, 0.7841667231352061], 'lift': [1.7232591969434075, 1.659095290674238, 1.695760379970906]}",./output/modelsaves/heloc/fttransformer/202310-1202-5511-d4a67650-faba-4409-a78b-03b1bae0f805//202310-1202-5511-d4a67650-faba-4409-a78b-03b1bae0f805,986.4224421977997
202310-1200-2553-f1637f9b-fe43-4806-aecd-ba7727b5ec11,"{'dataset': 'covertype', 'model': 'autoint', 'best_params': {}, 'param_grid': {'batch_size': [1024, 2048, 3500], 'attn_embed_dim_multiplier': [2, 16], 'num_heads': [2, 8], 'num_attn_blocks': [2, 6], 'attn_dropouts': [0.0, 0.3], 'embedding_dim': [8, 32], 'embedding_initialization': ['kaiming_uniform', 'kaiming_normal'], 'embedding_bias': [True, False], 'share_embedding': [True, False], 'share_embedding_strategy': ['add', 'fraction'], 'shared_embedding_fraction': [0.25, 0.1, 0.5], 'deep_layers': [True, False], 'layers': ['128-64-32', '128-64-32-16', '256-128-64'], 'dropout': [0.0, 0.3], 'activation': ['ReLU', 'LeakyReLU'], 'initialization': ['kaiming', 'xavier'], 'attention_pooling': [True, False], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",covertype,autoint,hyperopt_kfold,accuracy,"{'AdamW_weight_decay': 1.601533180119409e-05, 'Adam_weight_decay': 2.7234679770877924e-05, 'ExponentialLR_gamma': 0.9454234062258264, 'ReduceLROnPlateau_factor': 0.6813473561199678, 'ReduceLROnPlateau_patience': 4, 'activation': 'ReLU', 'attention_pooling': True, 'attn_dropouts': 0.0004919069394333064, 'attn_embed_dim_multiplier': 5, 'batch_size': 2502, 'deep_layers': True, 'dropout': 0.09134220239469389, 'embedding_bias': False, 'embedding_dim': 20, 'embedding_initialization': 'kaiming_normal', 'initialization': 'kaiming', 'layers': '256-128-64', 'num_attn_blocks': 4, 'num_heads': 5, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>, 'share_embedding': True, 'share_embedding_strategy': 'add', 'shared_embedding_fraction': 0.12541604708700752, 'outer_params': {'hyperopt_evals': 10, 'auto_lr_find': True, 'precision': 16, 'tol': 0.001, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 3}}",0.7295960728901846,0.02126710175895365,"{'accuracy': [0.7245342775296693, 0.7578022134443614, 0.7064517276965232], 'f1': [0.7385668804688833, 0.7676049764310051, 0.7214625630108473]}",./output/modelsaves/covertype/autoint/202310-1200-2553-f1637f9b-fe43-4806-aecd-ba7727b5ec11//202310-1200-2553-f1637f9b-fe43-4806-aecd-ba7727b5ec11,17201.261152505875
202310-1205-1235-df1daaf8-a968-459e-8095-9228364fd9f8,"{'dataset': 'covertype', 'model': 'tabtransformer', 'best_params': {}, 'param_grid': {'batch_size': [1024, 2048, 4096], 'embedding_bias': [True, False], 'embedding_initialization': ['kaiming_uniform', 'kaiming_normal'], 'shared_embedding_fraction': [0.125, 0.25, 0.5], 'num_attn_blocks': [4, 7], 'attn_dropout': [0.05, 0.3], 'add_norm_dropout': [0.05, 0.3], 'ff_dropout': [0.05, 0.3], 'ff_hidden_multiplier': [2, 6], 'transformer_activation': ['GEGLU', 'ReGLU', 'SwiGLU'], 'embedding_dropout': [0.05, 0.3], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",covertype,tabtransformer,hyperopt_kfold,accuracy,"{'AdamW_weight_decay': 5.509617091794048e-05, 'Adam_weight_decay': 1.886637643451584e-05, 'ExponentialLR_gamma': 0.9871931594015758, 'ReduceLROnPlateau_factor': 0.38030435555994974, 'ReduceLROnPlateau_patience': 4, 'add_norm_dropout': 0.05991712425379951, 'attn_dropout': 0.10451098537919767, 'batch_size': 1395, 'embedding_bias': True, 'embedding_dropout': 0.17378353462074458, 'embedding_initialization': 'kaiming_normal', 'ff_dropout': 0.19733411011862137, 'ff_hidden_multiplier': 2, 'num_attn_blocks': 7, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>, 'shared_embedding_fraction': 0.4215616321619067, 'transformer_activation': 'SwiGLU', 'outer_params': {'hyperopt_evals': 10, 'auto_lr_find': True, 'precision': 16, 'tol': 0.001, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 3}}",0.601226641118132,0.014470964246803627,"{'accuracy': [0.5809476362471754, 0.6137504003416249, 0.6089818867655955], 'f1': [0.6059219605893346, 0.6404240016616, 0.6333548197665231]}",./output/modelsaves/covertype/tabtransformer/202310-1205-1235-df1daaf8-a968-459e-8095-9228364fd9f8//202310-1205-1235-df1daaf8-a968-459e-8095-9228364fd9f8,1984.7088243961334
202310-1200-2737-02618050-a548-4304-9c87-4c2c7006726b,"{'dataset': 'covertype', 'model': 'resnet', 'best_params': {}, 'param_grid': {'batch_size': [2048, 4096], 'resnet_depth': ['resnet18', 'resnet34', 'resnet50'], 'optimizer_fn': {'Adam': {'weight_decay': [1e-05, 0.001], 'learning_rate': [0.0001, 0.001]}, 'AdamW': {'weight_decay': [1e-05, 0.001], 'learning_rate': [0.0001, 0.001]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",covertype,resnet,hyperopt_kfold,accuracy,"{'AdamW_learning_rate': 0.0001349378561912732, 'AdamW_weight_decay': 0.00011816315017494548, 'Adam_learning_rate': 0.0004461692923421005, 'Adam_weight_decay': 0.0002330044965633414, 'ExponentialLR_gamma': 0.9256856122463702, 'ReduceLROnPlateau_factor': 0.17683146045726797, 'ReduceLROnPlateau_patience': 4, 'batch_size': 2420, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'resnet_depth': 'resnet50', 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>, 'outer_params': {'hyperopt_evals': 10, 'max_epochs': 1000, 'early_stopping': True, 'early_stopping_patience': 4, 'tol': 0.0001, 'validation_fraction': 0.15}}",0.8721522848753508,0.01801432872681734,"{'accuracy': [0.8918563066028504, 0.8483150065833956, 0.8762855414398064], 'f1': [0.8940628826283468, 0.8555270131161463, 0.8810683932916202]}",./output/modelsaves/covertype/resnet/202310-1200-2737-02618050-a548-4304-9c87-4c2c7006726b//202310-1200-2737-02618050-a548-4304-9c87-4c2c7006726b,21064.967564821243
202310-1205-4539-021d9cc7-836b-4d3a-9cf6-dbf386d254d1,"{'dataset': 'covertype', 'model': 'node', 'best_params': {}, 'param_grid': {'batch_size': [800, 1500], 'num_layers': [1, 2, 3], 'num_trees': [12, 128], 'additional_tree_output_dim': [2, 3, 4], 'depth': [5, 7], 'choice_function': ['entmax15', 'sparsemax'], 'bin_function': ['entmoid15', 'sparsemoid'], 'input_dropout': [0.0, 0.1], 'embedding_dropout': [0.0, 0.1], 'embed_categorical': [True, False], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",covertype,node,hyperopt_kfold,accuracy,"{'AdamW_weight_decay': 3.6581529548235036e-05, 'Adam_weight_decay': 2.207952127245591e-05, 'ExponentialLR_gamma': 0.9700432059772548, 'ReduceLROnPlateau_factor': 0.687321461894709, 'ReduceLROnPlateau_patience': 4, 'additional_tree_output_dim': 2, 'batch_size': 1148, 'bin_function': 'sparsemoid', 'choice_function': 'entmax15', 'depth': 6, 'embed_categorical': True, 'embedding_dropout': 0.03248613807965938, 'input_dropout': 0.07775608742740031, 'num_layers': 1, 'num_trees': 82, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>, 'outer_params': {'hyperopt_evals': 10, 'auto_lr_find': True, 'precision': 16, 'tol': 0.001, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 3}}",0.6252408727821233,0.011437586582449734,"{'accuracy': [0.6374036973115315, 0.6283940073306999, 0.6099249137041386], 'f1': [0.6641251376036511, 0.6535537290630345, 0.6349225238581878]}",./output/modelsaves/covertype/node/202310-1205-4539-021d9cc7-836b-4d3a-9cf6-dbf386d254d1//202310-1205-4539-021d9cc7-836b-4d3a-9cf6-dbf386d254d1,3741.9469377994537
202310-1206-1842-5b589599-5996-483c-9726-a9e3a476541e,"{'dataset': 'covertype', 'model': 'tabnet', 'best_params': {}, 'param_grid': {'virtual_batch_size_ratio': [0.125, 0.25, 0.5, 1.0], 'batch_size': [2048, 4096], 'weights': [0, 1], 'mask_type': ['sparsemax', 'entmax'], 'n_d': [6, 24], 'n_steps': [3, 7], 'gamma': [1.0, 2.0], 'n_independent': [2, 3], 'n_shared': [2, 3], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",covertype,tabnet,hyperopt_kfold,accuracy,"{'AdamW_weight_decay': 3.414080659002421e-05, 'Adam_weight_decay': 8.836094935673395e-05, 'ExponentialLR_gamma': 0.9470402491809715, 'ReduceLROnPlateau_factor': 0.5627972344479412, 'ReduceLROnPlateau_patience': 3, 'batch_size': 2605, 'gamma': 1.293956593540399, 'mask_type': 'entmax', 'n_d': 8, 'n_independent': 2, 'n_shared': 2, 'n_steps': 5, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>, 'virtual_batch_size_ratio': 0.5, 'weights': 1, 'outer_params': {'hyperopt_evals': 10, 'auto_lr_find': True, 'precision': 16, 'tol': 0.001, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 3}}",0.7208714106146458,0.028966225008818767,"{'accuracy': [0.7549419070156397, 0.6841393544713711, 0.7235329703569268], 'f1': [0.7657052245006513, 0.6996090677110041, 0.7362129906594728]}",./output/modelsaves/covertype/tabnet/202310-1206-1842-5b589599-5996-483c-9726-a9e3a476541e//202310-1206-1842-5b589599-5996-483c-9726-a9e3a476541e,8295.33382511139
202310-1208-3657-f67940de-ad49-4b00-94da-f41afaa79b05,"{'dataset': 'diabetes', 'model': 'tabtransformer', 'best_params': {}, 'param_grid': {'batch_size': [2048, 4096], 'embedding_bias': [True, False], 'embedding_initialization': ['kaiming_uniform', 'kaiming_normal'], 'shared_embedding_fraction': [0.125, 0.25, 0.5], 'num_attn_blocks': [4, 7], 'attn_dropout': [0.05, 0.3], 'add_norm_dropout': [0.05, 0.3], 'ff_dropout': [0.05, 0.3], 'ff_hidden_multiplier': [2, 6], 'transformer_activation': ['GEGLU', 'ReGLU', 'SwiGLU'], 'embedding_dropout': [0.05, 0.3], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",diabetes,tabtransformer,hyperopt_kfold,lift,"{'AdamW_weight_decay': 1.4983299066774802e-05, 'Adam_weight_decay': 3.3050480558396946e-05, 'ExponentialLR_gamma': 0.9771603545076043, 'ReduceLROnPlateau_factor': 0.1241198877593532, 'ReduceLROnPlateau_patience': 5, 'add_norm_dropout': 0.1900878635483734, 'attn_dropout': 0.0828385433406772, 'batch_size': 2188, 'embedding_bias': True, 'embedding_dropout': 0.0987593348393527, 'embedding_initialization': 'kaiming_uniform', 'ff_dropout': 0.12593431858971033, 'ff_hidden_multiplier': 5, 'num_attn_blocks': 7, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>, 'shared_embedding_fraction': 0.2488767287123551, 'transformer_activation': 'GEGLU', 'outer_params': {'hyperopt_evals': 10, 'auto_lr_find': True, 'precision': 16, 'tol': 0.001, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 3}}",2.1136619111580504,0.126313051200304,"{'recall': [0.59375, 0.43549097313958607, 0.6111845002201673], 'precision': [0.14950681591488418, 0.1849289454001496, 0.1755628636478624], 'accuracy': [0.5776260194556353, 0.7228418414975679, 0.6363681029823613], 'f1': [0.23886675520141656, 0.25961412258826616, 0.272771936720055], 'roc_auc': [0.6244826726368609, 0.6383560974319689, 0.6729847578751158], 'area_under_pr': [0.1898919369334225, 0.20560825993384668, 0.20866715560151478], 'lift': [1.963414022216839, 2.105109937606635, 2.272461773650677]}",./output/modelsaves/diabetes/tabtransformer/202310-1208-3657-f67940de-ad49-4b00-94da-f41afaa79b05//202310-1208-3657-f67940de-ad49-4b00-94da-f41afaa79b05,6100.848531961441
202310-1206-4801-0f04f205-d716-4497-bb53-aada5d975092,"{'dataset': 'covertype', 'model': 'fttransformer', 'best_params': {}, 'param_grid': {'batch_size': [1024, 2048], 'num_heads': [4, 6], 'input_embed_dim_multiplier': [2, 4], 'embedding_initialization': ['kaiming_uniform', 'kaiming_normal'], 'embedding_dropout': [0.05, 0.2], 'shared_embedding_fraction': [0.125, 0.25, 0.5], 'num_attn_blocks': [4, 6], 'attn_dropout': [0.05, 0.2], 'add_norm_dropout': [0.05, 0.2], 'ff_dropout': [0.05, 0.2], 'ff_hidden_multiplier': [4, 32], 'transformer_activation': ['GEGLU', 'ReGLU', 'SwiGLU'], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",covertype,fttransformer,hyperopt_kfold,accuracy,"{'AdamW_weight_decay': 1.5902503871981568e-05, 'Adam_weight_decay': 6.216305843929241e-05, 'ExponentialLR_gamma': 0.9538892667853907, 'ReduceLROnPlateau_factor': 0.14546463443290394, 'ReduceLROnPlateau_patience': 4, 'add_norm_dropout': 0.11251074059500109, 'attn_dropout': 0.1687338107309195, 'batch_size': 1586, 'embedding_dropout': 0.09823172341532053, 'embedding_initialization': 'kaiming_normal', 'ff_dropout': 0.11486585783248299, 'ff_hidden_multiplier': 30, 'input_embed_dim_multiplier': 4, 'num_attn_blocks': 6, 'num_heads': 6, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'shared_embedding_fraction': 0.27856228981842884, 'transformer_activation': 'GEGLU', 'outer_params': {'hyperopt_evals': 10, 'auto_lr_find': True, 'precision': 16, 'tol': 0.001, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 3, 'attn_feature_importance': False}}",0.6964776329262596,0.010299145275330464,"{'accuracy': [0.692222835079978, 0.7106686594783104, 0.6865414042204904], 'f1': [0.7040683652982346, 0.7245730843036432, 0.7031337046083339]}",./output/modelsaves/covertype/fttransformer/202310-1206-4801-0f04f205-d716-4497-bb53-aada5d975092//202310-1206-4801-0f04f205-d716-4497-bb53-aada5d975092,13438.879693746567
202310-1212-3851-06782628-74e9-4f71-ba5f-a419281c7dd1,"{'dataset': 'heloc', 'model': 'fttransformer', 'best_params': {}, 'param_grid': {'batch_size': [1024, 2048], 'num_heads': [4, 6], 'input_embed_dim_multiplier': [2, 4], 'embedding_initialization': ['kaiming_uniform', 'kaiming_normal'], 'embedding_dropout': [0.05, 0.2], 'shared_embedding_fraction': [0.125, 0.25, 0.5], 'num_attn_blocks': [4, 6], 'attn_dropout': [0.05, 0.2], 'add_norm_dropout': [0.05, 0.2], 'ff_dropout': [0.05, 0.2], 'ff_hidden_multiplier': [4, 32], 'transformer_activation': ['GEGLU', 'ReGLU', 'SwiGLU'], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",heloc,fttransformer,hyperopt_kfold,lift,"{'AdamW_weight_decay': 5.89724355075594e-05, 'Adam_weight_decay': 3.6353468280006496e-05, 'ExponentialLR_gamma': 0.9669651952828615, 'ReduceLROnPlateau_factor': 0.5724455082699984, 'ReduceLROnPlateau_patience': 4, 'add_norm_dropout': 0.14281064212522587, 'attn_dropout': 0.12406179651634368, 'batch_size': 1917, 'embedding_dropout': 0.09741573042093715, 'embedding_initialization': 'kaiming_uniform', 'ff_dropout': 0.13483741168452423, 'ff_hidden_multiplier': 22, 'input_embed_dim_multiplier': 4, 'num_attn_blocks': 5, 'num_heads': 5, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'shared_embedding_fraction': 0.14335608354291454, 'transformer_activation': 'SwiGLU', 'outer_params': {'hyperopt_evals': 5, 'auto_lr_find': True, 'precision': 16, 'tol': 1e-06, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 3, 'attn_feature_importance': False}}",1.6988158040789616,0.01883489915670754,"{'recall': [0.7481684981684982, 0.760989010989011, 0.7857142857142857], 'precision': [0.7294642857142857, 0.733451015004413, 0.713216957605985], 'accuracy': [0.7237093690248566, 0.7308795411089866, 0.7232313575525813], 'f1': [0.7386980108499095, 0.7469662921348316, 0.7477124183006536], 'roc_auc': [0.7962513736263737, 0.7942513736263737, 0.7950283882783884], 'area_under_pr': [0.7999962128776024, 0.7869270219988738, 0.7875705342237121], 'lift': [1.7232591969434075, 1.695760379970906, 1.677427835322572]}",./output/modelsaves/heloc/fttransformer/202310-1212-3851-06782628-74e9-4f71-ba5f-a419281c7dd1//202310-1212-3851-06782628-74e9-4f71-ba5f-a419281c7dd1,512.6445336341858
202310-1212-5515-8ed627f8-cddd-4e2a-bebe-dd5b636c631e,"{'dataset': 'creditcard', 'model': 'gandalf', 'best_params': {}, 'param_grid': {'batch_size': [2048, 4096], 'gflu_stages': [4, 10], 'gflu_dropout': [0.0, 0.3], 'embedding_dropout': [0.0, 0.3], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",creditcard,gandalf,hyperopt_kfold,lift,"{'AdamW_weight_decay': 7.450029975279925e-05, 'Adam_weight_decay': 3.0277034053430755e-05, 'ExponentialLR_gamma': 0.9677929364269089, 'ReduceLROnPlateau_factor': 0.4817989869231816, 'ReduceLROnPlateau_patience': 4, 'batch_size': 3376, 'embedding_dropout': 0.13080795787243416, 'gflu_dropout': 0.2205774795680876, 'gflu_stages': 5, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>, 'outer_params': {'hyperopt_evals': 5, 'auto_lr_find': True, 'precision': 16, 'tol': 1e-06, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 3}}",9.696565686483423,0.08156718164574076,"{'recall': [0.9292929292929293, 0.9191919191919192, 0.9285714285714286], 'precision': [0.034392523364485984, 0.12674094707520892, 0.04589006555723651], 'accuracy': [0.954531090902707, 0.9888522172676522, 0.9666613999051983], 'f1': [0.06633020908435473, 0.22276621787025705, 0.08745795290725612], 'roc_auc': [0.9866304570066243, 0.9874630447058915, 0.9896555882434221], 'area_under_pr': [0.735024561983721, 0.7065855902478484, 0.7661590696335816], 'lift': [9.59629653274316, 9.697310180456247, 9.796090346250859]}",./output/modelsaves/creditcard/gandalf/202310-1212-5515-8ed627f8-cddd-4e2a-bebe-dd5b636c631e//202310-1212-5515-8ed627f8-cddd-4e2a-bebe-dd5b636c631e,922.9975018501282
