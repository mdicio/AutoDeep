run_id,run_config,dataset,model,execution_mode,eval_metric,best_params,best_score,score_std,output_metrics,saved_model_path,run_time
202310-0123-3310-3f8d777f-b30c-452d-9c88-2c41df9a5fe2,"{'dataset': 'ageconditions', 'model': 'xgb', 'best_params': {}, 'param_grid': {'n_estimators': [100, 2000], 'max_bin': [256, 32], 'tree_method': ['auto', 'hist'], 'max_depth': [4, 10], 'learning_rate': [0.1, 0.33], 'subsample': [0.7, 1.0], 'colsample_bytree': [0.5, 1.0], 'min_child_weight': [1, 10], 'alpha': [0.0, 5.0], 'gamma': [0.0, 5.0], 'lambda': [0.0, 5.0]}}",ageconditions,xgb,hyperopt_kfold,f1,"{'alpha': 2.3265981446881856, 'colsample_bytree': 0.9979592345326663, 'gamma': 0.0027025058789080444, 'lambda': 1.4583580118278725, 'learning_rate': 0.13914787637481424, 'max_bin': 79, 'max_depth': 5, 'min_child_weight': 4, 'n_estimators': 255, 'subsample': 0.7558105303157286, 'tree_method': 'hist', 'outer_params': {'hyperopt_evals': 50, 'validation_fraction': 0.15, 'early_stopping_rounds': 10, 'verbose': False}}",0.7587959736740224,0.05991146548267298,"{'recall': [0.7272727272727273, 0.6363636363636364, 0.7727272727272727, 0.5714285714285714, 0.6666666666666666], 'precision': [0.8421052631578947, 0.7777777777777778, 0.9444444444444444, 0.8571428571428571, 0.9333333333333333], 'accuracy': [0.928, 0.904, 0.9516129032258065, 0.9112903225806451, 0.9354838709677419], 'f1': [0.7804878048780488, 0.7000000000000001, 0.85, 0.6857142857142857, 0.7777777777777778], 'roc_auc': [0.972639011473963, 0.9285083848190644, 0.9723707664884136, 0.9093851132686084, 0.9856680536292187], 'area_under_pr': [0.8802454489180189, 0.8228066067050674, 0.9282930925993585, 0.7814409858985925, 0.9245285294627401], 'lift': [5.208333333333333, 5.208333333333333, 5.636363636363636, 4.920634920634921, 5.412698412698413]}",./output/modelsaves/ageconditions/xgb/202310-0123-3310-3f8d777f-b30c-452d-9c88-2c41df9a5fe2//202310-0123-3310-3f8d777f-b30c-452d-9c88-2c41df9a5fe2,746.5750734806061
202310-0123-3314-df52c585-d03e-43a5-b9e5-2b31f5965ea6,"{'dataset': 'heloc', 'model': 'node', 'best_params': {}, 'param_grid': {'batch_size': [512, 1024], 'num_layers': [1, 2, 3], 'num_trees': [12, 128], 'additional_tree_output_dim': [2, 3, 4], 'depth': [5, 7], 'choice_function': ['entmax15', 'sparsemax'], 'bin_function': ['entmoid15', 'sparsemoid'], 'input_dropout': [0.0, 0.1], 'embedding_dropout': [0.0, 0.1], 'embed_categorical': [True, False], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",heloc,node,hyperopt_kfold,lift,"{'AdamW_weight_decay': 1.4664629667158877e-05, 'Adam_weight_decay': 5.200269059018598e-05, 'ExponentialLR_gamma': 0.9624375913196498, 'ReduceLROnPlateau_factor': 0.6295791413717579, 'ReduceLROnPlateau_patience': 4, 'additional_tree_output_dim': 4, 'batch_size': 716, 'bin_function': 'entmoid15', 'choice_function': 'sparsemax', 'depth': 7, 'embed_categorical': True, 'embedding_dropout': 0.08075321455838412, 'input_dropout': 0.08401581649848215, 'num_layers': 2, 'num_trees': 74, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 5}}",1.7325748688091298,0.03466653365154124,"{'recall': [0.7252747252747253, 0.6978021978021978, 0.6794871794871795, 0.717032967032967, 0.692942254812099], 'precision': [0.7394957983193278, 0.7398058252427184, 0.7442326980942828, 0.7421800947867299, 0.7529880478087649], 'accuracy': [0.7232313575525813, 0.7141491395793499, 0.7108030592734226, 0.7222753346080306, 0.7211860353897657], 'f1': [0.7323162274618585, 0.7181903864278982, 0.7103877453326951, 0.7293898462971588, 0.7217183770883054], 'roc_auc': [0.7945952380952381, 0.7948946886446887, 0.7960485347985349, 0.7971346153846154, 0.8059908340971585], 'area_under_pr': [0.7945303604002036, 0.7874794059046297, 0.7928165477639978, 0.8054414608986866, 0.803973860439001], 'lift': [1.7415917415917415, 1.7140929246192402, 1.7049266522950732, 1.796589375536744, 1.7056736500028506]}",./output/modelsaves/heloc/node/202310-0123-3314-df52c585-d03e-43a5-b9e5-2b31f5965ea6//202310-0123-3314-df52c585-d03e-43a5-b9e5-2b31f5965ea6,3198.368331193924
202310-0123-4537-4c36be74-91bb-4166-9bc5-f4df1d0af89e,"{'dataset': 'adult', 'model': 'xgb', 'best_params': {}, 'param_grid': {'n_estimators': [100, 1500], 'max_bin': [256, 32], 'tree_method': ['auto', 'hist'], 'max_depth': [4, 10], 'learning_rate': [0.1, 0.33], 'subsample': [0.7, 1.0], 'colsample_bytree': [0.5, 1.0], 'min_child_weight': [1, 10], 'alpha': [0.0, 5.0], 'gamma': [0.0, 5.0], 'lambda': [0.0, 5.0]}}",adult,xgb,hyperopt_kfold,roc_auc,"{'alpha': 1.9227608713131281, 'colsample_bytree': 0.5945328194898489, 'gamma': 0.638624318843618, 'lambda': 2.264078880324862, 'learning_rate': 0.13070893523409546, 'max_bin': 90, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 1292, 'subsample': 0.9363883431513152, 'tree_method': 'auto', 'outer_params': {'hyperopt_evals': 50, 'validation_fraction': 0.15, 'early_stopping_rounds': 10, 'verbose': False}}",0.9285569955393989,0.0013185691322415004,"{'recall': [0.638623326959847, 0.6619897959183674, 0.6409438775510204, 0.6613520408163265, 0.6549744897959183], 'precision': [0.7952380952380952, 0.7887537993920972, 0.7701149425287356, 0.7838246409674982, 0.7986003110419907], 'accuracy': [0.8733302625518194, 0.8759213759213759, 0.8674754299754299, 0.874539312039312, 0.8771498771498771], 'f1': [0.7083775185577943, 0.7198335644937587, 0.6996171249564915, 0.7173988239363543, 0.7196916608269095], 'roc_auc': [0.9290934824399109, 0.9308558147166632, 0.9277810069719635, 0.9270811404051912, 0.9279735331632651], 'area_under_pr': [0.8330970645719281, 0.832709429541261, 0.8231646755499017, 0.8276075548503954, 0.8311894827414094], 'lift': [3.915123959902841, 3.87236276999279, 3.8213266873569705, 3.865983259663312, 3.8851217906517443]}",./output/modelsaves/adult/xgb/202310-0123-4537-4c36be74-91bb-4166-9bc5-f4df1d0af89e//202310-0123-4537-4c36be74-91bb-4166-9bc5-f4df1d0af89e,6617.176292896271
202310-0201-3554-4d86d13b-dac9-45e5-a18f-9f9dfb8f2a4d,"{'dataset': 'housing', 'model': 'xgb', 'best_params': {}, 'param_grid': {'n_estimators': [100, 1500], 'max_bin': [256, 32], 'tree_method': ['auto', 'hist'], 'max_depth': [4, 10], 'learning_rate': [0.1, 0.33], 'subsample': [0.7, 1.0], 'colsample_bytree': [0.5, 1.0], 'min_child_weight': [1, 10], 'alpha': [0.0, 5.0], 'gamma': [0.0, 5.0], 'lambda': [0.0, 5.0]}}",housing,xgb,hyperopt_kfold,r2_score,"{'alpha': 1.250151910503714, 'colsample_bytree': 0.6749303887890425, 'gamma': 0.37422350929976944, 'lambda': 1.6107361888156269, 'learning_rate': 0.11822958982534913, 'max_bin': 95, 'max_depth': 9, 'min_child_weight': 9, 'n_estimators': 376, 'subsample': 0.7914439816464922, 'tree_method': 'auto', 'outer_params': {'hyperopt_evals': 50, 'validation_fraction': 0.15, 'early_stopping_rounds': 10, 'verbose': False}}",0.8595026917246011,0.00687449995615138,"{'mse': [0.1831939792077722, 0.18469418113394823, 0.1955749756272497, 0.1751231285854959, 0.19623430649896184], 'rmse': [0.42801165779423833, 0.4297606090999363, 0.44223859581367353, 0.4184771541978079, 0.44298341560261806], 'r2_score': [0.8602009126542365, 0.8648012693124941, 0.8496793486139866, 0.8686240157580503, 0.8542079122842382]}",./output/modelsaves/housing/xgb/202310-0201-3554-4d86d13b-dac9-45e5-a18f-9f9dfb8f2a4d//202310-0201-3554-4d86d13b-dac9-45e5-a18f-9f9dfb8f2a4d,13935.548591852188
202310-0200-2633-8df8e9cb-8439-45bb-8e75-72b47baccb7c,"{'dataset': 'diabetes', 'model': 'node', 'best_params': {}, 'param_grid': {'batch_size': [512, 1024], 'num_layers': [1, 2, 3], 'num_trees': [12, 128], 'additional_tree_output_dim': [2, 3, 4], 'depth': [5, 7], 'choice_function': ['entmax15', 'sparsemax'], 'bin_function': ['entmoid15', 'sparsemoid'], 'input_dropout': [0.0, 0.1], 'embedding_dropout': [0.0, 0.1], 'embed_categorical': [True, False], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",diabetes,node,hyperopt_kfold,lift,"{'AdamW_weight_decay': 4.327846087518758e-05, 'Adam_weight_decay': 4.020141133995737e-05, 'ExponentialLR_gamma': 0.9606659876846797, 'ReduceLROnPlateau_factor': 0.17657861240783193, 'ReduceLROnPlateau_patience': 5, 'additional_tree_output_dim': 4, 'batch_size': 733, 'bin_function': 'sparsemoid', 'choice_function': 'sparsemax', 'depth': 7, 'embed_categorical': True, 'embedding_dropout': 0.08728907587411235, 'input_dropout': 0.07022166426540487, 'num_layers': 3, 'num_trees': 128, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 5}}",2.427091528331993,0.07279341804917944,"{'recall': [0.5919894366197183, 0.6261558784676354, 0.5548216644649934, 0.6129458388375165, 0.6624119718309859], 'precision': [0.18141354194766657, 0.18212090163934427, 0.181190681622088, 0.16823785351704135, 0.16644547666445478], 'accuracy': [0.6562837771445416, 0.6445241487741364, 0.6705645359406476, 0.6186802928315236, 0.5920011791873434], 'f1': [0.27772042122651247, 0.2821708502827662, 0.2731707317073171, 0.2640113798008535, 0.26604207176948913], 'roc_auc': [0.6785228623010042, 0.6889286980768806, 0.6741630463618671, 0.6764564905186807, 0.6714902632013529], 'area_under_pr': [0.2164251020603022, 0.2347728372350471, 0.21604026614659677, 0.22417944065396794, 0.2081931538092131], 'lift': [2.3948368342734536, 2.4926615579191536, 2.4221976269532415, 2.5146815363460013, 2.3110800861681144]}",./output/modelsaves/diabetes/node/202310-0200-2633-8df8e9cb-8439-45bb-8e75-72b47baccb7c//202310-0200-2633-8df8e9cb-8439-45bb-8e75-72b47baccb7c,18221.282469511032
202310-0205-2810-63fab0a5-f9c5-47b1-9a7b-2180802c619d,"{'dataset': 'breastcancer', 'model': 'xgb', 'best_params': {}, 'param_grid': {'n_estimators': [100, 2000], 'max_bin': [256, 32], 'tree_method': ['auto', 'hist'], 'max_depth': [4, 10], 'learning_rate': [0.1, 0.33], 'subsample': [0.7, 1.0], 'colsample_bytree': [0.5, 1.0], 'min_child_weight': [1, 10], 'alpha': [0.0, 5.0], 'gamma': [0.0, 5.0], 'lambda': [0.0, 5.0]}}",breastcancer,xgb,hyperopt_kfold,f1,"{'alpha': 1.5362069887137089, 'colsample_bytree': 0.504859310559956, 'gamma': 1.4507730674848403, 'lambda': 3.019548664843605, 'learning_rate': 0.19199352781861176, 'max_bin': 75, 'max_depth': 4, 'min_child_weight': 4, 'n_estimators': 494, 'subsample': 0.8242914202753657, 'tree_method': 'hist', 'outer_params': {'hyperopt_evals': 50, 'validation_fraction': 0.15, 'early_stopping_rounds': 10, 'verbose': False}}",0.9707974690174627,0.009947545510745545,"{'recall': [0.9577464788732394, 0.971830985915493, 0.9861111111111112, 0.9722222222222222, 0.9859154929577465], 'precision': [1.0, 0.9324324324324325, 0.9594594594594594, 0.9859154929577465, 0.958904109589041], 'accuracy': [0.9736842105263158, 0.9385964912280702, 0.9649122807017544, 0.9736842105263158, 0.9646017699115044], 'f1': [0.9784172661870503, 0.9517241379310345, 0.9726027397260274, 0.979020979020979, 0.9722222222222222], 'roc_auc': [0.9983622666229938, 0.9834588928922371, 0.9834656084656085, 0.998181216931217, 0.9909456740442656], 'area_under_pr': [0.9990216795445428, 0.9901250616418977, 0.9875695975147962, 0.9988575123580992, 0.994147021537541], 'lift': [1.6056338028169013, 1.6056338028169013, 1.5833333333333335, 1.5833333333333335, 1.591549295774648]}",./output/modelsaves/breastcancer/xgb/202310-0205-2810-63fab0a5-f9c5-47b1-9a7b-2180802c619d//202310-0205-2810-63fab0a5-f9c5-47b1-9a7b-2180802c619d,788.1124703884125
202310-0205-4118-7d538b2c-b256-4e00-a451-0893e49a4864,"{'dataset': 'titanic', 'model': 'xgb', 'best_params': {}, 'param_grid': {'n_estimators': [100, 2000], 'max_bin': [256, 32], 'tree_method': ['auto', 'hist'], 'max_depth': [4, 10], 'learning_rate': [0.1, 0.33], 'subsample': [0.7, 1.0], 'colsample_bytree': [0.5, 1.0], 'min_child_weight': [1, 10], 'alpha': [0.0, 5.0], 'gamma': [0.0, 5.0], 'lambda': [0.0, 5.0]}}",titanic,xgb,hyperopt_kfold,roc_auc,"{'alpha': 0.7964253315853251, 'colsample_bytree': 0.7625091069709334, 'gamma': 1.199211350131553, 'lambda': 2.21423025775779, 'learning_rate': 0.13125920423718612, 'max_bin': 184, 'max_depth': 9, 'min_child_weight': 2, 'n_estimators': 902, 'subsample': 0.9609276619590482, 'tree_method': 'auto', 'outer_params': {'hyperopt_evals': 50, 'validation_fraction': 0.15, 'early_stopping_rounds': 10, 'verbose': False}}",0.8858012893666005,0.02747304361681533,"{'recall': [0.7536231884057971, 0.7205882352941176, 0.6176470588235294, 0.75, 0.7536231884057971], 'precision': [0.8813559322033898, 0.8166666666666667, 0.7777777777777778, 0.8095238095238095, 0.8666666666666667], 'accuracy': [0.8659217877094972, 0.8314606741573034, 0.7865168539325843, 0.8370786516853933, 0.8595505617977528], 'f1': [0.8124999999999999, 0.7656250000000001, 0.6885245901639345, 0.7786259541984734, 0.8062015503875969], 'roc_auc': [0.925098814229249, 0.8968582887700535, 0.8400401069518716, 0.8823529411764706, 0.8846562957053583], 'area_under_pr': [0.8901163314596531, 0.8832791884572412, 0.811105638152329, 0.8779052604328605, 0.8576297162415356], 'lift': [2.441602728047741, 2.6176470588235294, 2.309688581314879, 2.6176470588235294, 2.4279624893435634]}",./output/modelsaves/titanic/xgb/202310-0205-4118-7d538b2c-b256-4e00-a451-0893e49a4864//202310-0205-4118-7d538b2c-b256-4e00-a451-0893e49a4864,1051.967452764511
202310-0215-4132-80cf4027-ced1-4e01-a97c-5433b745ae09,"{'dataset': 'iris', 'model': 'xgb', 'best_params': {}, 'param_grid': {'n_estimators': [100, 2000], 'max_bin': [256, 32], 'tree_method': ['auto', 'hist'], 'max_depth': [4, 10], 'learning_rate': [0.1, 0.33], 'subsample': [0.7, 1.0], 'colsample_bytree': [0.5, 1.0], 'min_child_weight': [1, 10], 'alpha': [0.0, 5.0], 'gamma': [0.0, 5.0], 'lambda': [0.0, 5.0]}}",iris,xgb,hyperopt_kfold,accuracy,"{'alpha': 2.4157432235372833, 'colsample_bytree': 0.6723299691799234, 'gamma': 0.6798647393732932, 'lambda': 2.9031069313425997, 'learning_rate': 0.26649601502704195, 'max_bin': 143, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 1880, 'subsample': 0.8361375951301544, 'tree_method': 'auto', 'outer_params': {'hyperopt_evals': 50, 'validation_fraction': 0.15, 'early_stopping_rounds': 10, 'verbose': False}}",0.9600000000000002,0.038873012632301994,"{'accuracy': [1.0, 0.9666666666666667, 0.9333333333333333, 1.0, 0.9], 'f1': [1.0, 0.9665831244778613, 0.9326599326599326, 1.0, 0.8997493734335841]}",./output/modelsaves/iris/xgb/202310-0215-4132-80cf4027-ced1-4e01-a97c-5433b745ae09//202310-0215-4132-80cf4027-ced1-4e01-a97c-5433b745ae09,88.88271450996399
202310-0215-4138-d3d9ff3a-b423-4f53-ad40-4cd29c3360b3,"{'dataset': 'iris', 'model': 'node', 'best_params': {}, 'param_grid': {'batch_size': [32, 64, 128, 256], 'num_layers': [1, 2, 3], 'num_trees': [12, 128], 'additional_tree_output_dim': [2, 3, 4], 'depth': [5, 7], 'choice_function': ['entmax15', 'sparsemax'], 'bin_function': ['entmoid15', 'sparsemoid'], 'input_dropout': [0.0, 0.1], 'embedding_dropout': [0.0, 0.1], 'embed_categorical': [True, False], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",iris,node,hyperopt_kfold,accuracy,"{'AdamW_weight_decay': 3.9436585596661325e-05, 'Adam_weight_decay': 1.9544553613857148e-05, 'ExponentialLR_gamma': 0.9291768981774606, 'ReduceLROnPlateau_factor': 0.46205097332497386, 'ReduceLROnPlateau_patience': 4, 'additional_tree_output_dim': 3, 'batch_size': 34, 'bin_function': 'entmoid15', 'choice_function': 'entmax15', 'depth': 6, 'embed_categorical': True, 'embedding_dropout': 0.028748327272114373, 'input_dropout': 0.05270698035669344, 'num_layers': 2, 'num_trees': 60, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 5}}",0.9800000000000001,0.02666666666666666,"{'accuracy': [1.0, 1.0, 0.9333333333333333, 1.0, 0.9666666666666667], 'f1': [1.0, 1.0, 0.9333333333333333, 1.0, 0.9665831244778613]}",./output/modelsaves/iris/node/202310-0215-4138-d3d9ff3a-b423-4f53-ad40-4cd29c3360b3//202310-0215-4138-d3d9ff3a-b423-4f53-ad40-4cd29c3360b3,843.8321316242218
202310-0215-5542-9805adc2-e321-4572-bbfd-0469e4da9663,"{'dataset': 'titanic', 'model': 'node', 'best_params': {}, 'param_grid': {'batch_size': [32, 64, 128, 256], 'num_layers': [1, 2, 3], 'num_trees': [12, 128], 'additional_tree_output_dim': [2, 3, 4], 'depth': [5, 7], 'choice_function': ['entmax15', 'sparsemax'], 'bin_function': ['entmoid15', 'sparsemoid'], 'input_dropout': [0.0, 0.1], 'embedding_dropout': [0.0, 0.1], 'embed_categorical': [True, False], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",titanic,node,hyperopt_kfold,roc_auc,"{'AdamW_weight_decay': 1.3322253267102219e-05, 'Adam_weight_decay': 3.466501460547525e-05, 'ExponentialLR_gamma': 0.9753175304954133, 'ReduceLROnPlateau_factor': 0.3942623038432992, 'ReduceLROnPlateau_patience': 3, 'additional_tree_output_dim': 2, 'batch_size': 61, 'bin_function': 'sparsemoid', 'choice_function': 'sparsemax', 'depth': 7, 'embed_categorical': False, 'embedding_dropout': 0.011808212701250532, 'input_dropout': 0.005106959544555053, 'num_layers': 1, 'num_trees': 68, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 5}}",0.881706930043294,0.021915454823087124,"{'recall': [0.7971014492753623, 0.8235294117647058, 0.6911764705882353, 0.7941176470588235, 0.7971014492753623], 'precision': [0.7432432432432432, 0.717948717948718, 0.734375, 0.7714285714285715, 0.8461538461538461], 'accuracy': [0.8156424581005587, 0.8089887640449438, 0.7865168539325843, 0.8314606741573034, 0.8651685393258427], 'f1': [0.7692307692307693, 0.767123287671233, 0.7121212121212122, 0.782608695652174, 0.8208955223880597], 'roc_auc': [0.9113965744400527, 0.8866310160427808, 0.8436497326203207, 0.8788770053475936, 0.8879803217657226], 'area_under_pr': [0.8741943610847764, 0.8612807097317644, 0.8222031046879413, 0.8766054542721209, 0.8408977072901349], 'lift': [2.5942028985507246, 2.6176470588235294, 2.463667820069204, 2.6176470588235294, 2.4279624893435634]}",./output/modelsaves/titanic/node/202310-0215-5542-9805adc2-e321-4572-bbfd-0469e4da9663//202310-0215-5542-9805adc2-e321-4572-bbfd-0469e4da9663,1244.3247609138489
202310-0216-1627-2ca4d0b8-86eb-43fc-91e3-a41eb93a8158,"{'dataset': 'breastcancer', 'model': 'node', 'best_params': {}, 'param_grid': {'batch_size': [32, 64, 128, 256], 'num_layers': [1, 2, 3], 'num_trees': [12, 128], 'additional_tree_output_dim': [2, 3, 4], 'depth': [5, 7], 'choice_function': ['entmax15', 'sparsemax'], 'bin_function': ['entmoid15', 'sparsemoid'], 'input_dropout': [0.0, 0.1], 'embedding_dropout': [0.0, 0.1], 'embed_categorical': [True, False], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",breastcancer,node,hyperopt_kfold,f1,"{'AdamW_weight_decay': 4.664866465780465e-05, 'Adam_weight_decay': 1.754727032738925e-05, 'ExponentialLR_gamma': 0.9177432565481651, 'ReduceLROnPlateau_factor': 0.16566548937803902, 'ReduceLROnPlateau_patience': 5, 'additional_tree_output_dim': 4, 'batch_size': 112, 'bin_function': 'entmoid15', 'choice_function': 'entmax15', 'depth': 7, 'embed_categorical': True, 'embedding_dropout': 0.043825033415070686, 'input_dropout': 0.013330044282393365, 'num_layers': 3, 'num_trees': 39, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 5}}",0.988945567370225,0.009276992991966807,"{'recall': [1.0, 1.0, 0.9861111111111112, 0.9861111111111112, 1.0], 'precision': [1.0, 0.9726027397260274, 0.9594594594594594, 1.0, 0.9861111111111112], 'accuracy': [1.0, 0.9824561403508771, 0.9649122807017544, 0.9912280701754386, 0.9910714285714286], 'f1': [1.0, 0.9861111111111112, 0.9726027397260274, 0.993006993006993, 0.993006993006993], 'roc_auc': [1.0, 0.9918113331149689, 0.9831349206349206, 0.9993386243386243, 0.9972518035039505], 'area_under_pr': [1.0, 0.9945914278271166, 0.9867558972009745, 0.9996246246246245, 0.9983532500019233], 'lift': [1.6056338028169013, 1.6056338028169013, 1.5833333333333335, 1.5833333333333335, 1.5774647887323945]}",./output/modelsaves/breastcancer/node/202310-0216-1627-2ca4d0b8-86eb-43fc-91e3-a41eb93a8158//202310-0216-1627-2ca4d0b8-86eb-43fc-91e3-a41eb93a8158,981.5898666381836
202310-0215-4300-6fdfdc6a-10d3-4d5d-8315-461c871b27c8,"{'dataset': 'diabetes', 'model': 'xgb', 'best_params': {}, 'param_grid': {'n_estimators': [100, 1500], 'max_bin': [256, 32], 'tree_method': ['auto', 'hist'], 'max_depth': [4, 10], 'learning_rate': [0.1, 0.33], 'subsample': [0.7, 1.0], 'colsample_bytree': [0.5, 1.0], 'min_child_weight': [1, 10], 'alpha': [0.0, 5.0], 'gamma': [0.0, 5.0], 'lambda': [0.0, 5.0]}}",diabetes,xgb,hyperopt_kfold,lift,"{'alpha': 0.7542323746808111, 'colsample_bytree': 0.6965580923192364, 'gamma': 0.2165462366078169, 'lambda': 0.24173145551695363, 'learning_rate': 0.15349516995751222, 'max_bin': 52, 'max_depth': 6, 'min_child_weight': 5, 'n_estimators': 306, 'subsample': 0.7983111134333983, 'tree_method': 'hist', 'outer_params': {'hyperopt_evals': 50, 'validation_fraction': 0.15, 'early_stopping_rounds': 10, 'verbose': False}}",2.4957818863348704,0.08679156792934728,"{'recall': [0.025088028169014086, 0.019374724790841038, 0.010568031704095112, 0.013210039630118891, 0.01584507042253521], 'precision': [0.57, 0.5714285714285714, 0.5581395348837209, 0.5769230769230769, 0.5373134328358209], 'accuracy': [0.8890635747273263, 0.8889598584975188, 0.8886650616616715, 0.8888124600795951, 0.888615928855697], 'f1': [0.048060708263069137, 0.037478705281090284, 0.020743301642178046, 0.02582866982350409, 0.0307823856348867], 'roc_auc': [0.6789463171296332, 0.6920695587511678, 0.6780798623190766, 0.6826735205162293, 0.676844044327911], 'area_under_pr': [0.23044418067927447, 0.24872298143608987, 0.22827619433762347, 0.23699597795327165, 0.22621989078656435], 'lift': [2.3992391078658684, 2.651205402592457, 2.4662375838069366, 2.519085532031371, 2.4431418053777207]}",./output/modelsaves/diabetes/xgb/202310-0215-4300-6fdfdc6a-10d3-4d5d-8315-461c871b27c8//202310-0215-4300-6fdfdc6a-10d3-4d5d-8315-461c871b27c8,3686.675400495529
202310-0216-4427-088e5702-0e5d-4cc5-be10-140235026e43,"{'dataset': 'creditcard', 'model': 'xgb', 'best_params': {}, 'param_grid': {'n_estimators': [100, 1500], 'max_bin': [256, 32], 'tree_method': ['auto', 'hist'], 'max_depth': [4, 10], 'learning_rate': [0.1, 0.33], 'subsample': [0.7, 1.0], 'colsample_bytree': [0.5, 1.0], 'min_child_weight': [1, 10], 'alpha': [0.0, 5.0], 'gamma': [0.0, 5.0], 'lambda': [0.0, 5.0]}}",creditcard,xgb,hyperopt_kfold,lift,"{'alpha': 3.726681573346677, 'colsample_bytree': 0.6078442297724492, 'gamma': 0.3407720626123095, 'lambda': 0.9052108766258732, 'learning_rate': 0.15738950787288739, 'max_bin': 147, 'max_depth': 9, 'min_child_weight': 9, 'n_estimators': 533, 'subsample': 0.8356912207102457, 'tree_method': 'auto', 'outer_params': {'hyperopt_evals': 50, 'validation_fraction': 0.15, 'early_stopping_rounds': 10, 'verbose': False}}",9.654741464171641,0.21931586174797246,"{'recall': [0.7575757575757576, 0.8181818181818182, 0.8061224489795918, 0.7755102040816326, 0.7857142857142857], 'precision': [0.9375, 0.9878048780487805, 0.9404761904761905, 0.9382716049382716, 0.9058823529411765], 'accuracy': [0.9994908886626171, 0.9996664442961974, 0.9995786590825302, 0.9995259914678464, 0.999490879724724], 'f1': [0.8379888268156425, 0.8950276243093922, 0.8681318681318683, 0.8491620111731844, 0.8415300546448088], 'roc_auc': [0.9855120503169322, 0.980241452209164, 0.9954907732046269, 0.9700196892854182, 0.9827630821950503], 'area_under_pr': [0.8344785120938257, 0.895671941106917, 0.8705128406651571, 0.8408530314611666, 0.832524265661344], 'lift': [9.798323828169334, 9.495282885030075, 10.000175561797752, 9.387919915157074, 9.592005130703965]}",./output/modelsaves/creditcard/xgb/202310-0216-4427-088e5702-0e5d-4cc5-be10-140235026e43//202310-0216-4427-088e5702-0e5d-4cc5-be10-140235026e43,1457.8515331745148
202310-0217-0845-b5a53099-4376-4e88-9906-0fe55eb48372,"{'dataset': 'heloc', 'model': 'xgb', 'best_params': {}, 'param_grid': {'n_estimators': [100, 1500], 'max_bin': [256, 32], 'tree_method': ['auto', 'hist'], 'max_depth': [4, 10], 'learning_rate': [0.1, 0.33], 'subsample': [0.7, 1.0], 'colsample_bytree': [0.5, 1.0], 'min_child_weight': [1, 10], 'alpha': [0.0, 5.0], 'gamma': [0.0, 5.0], 'lambda': [0.0, 5.0]}}",heloc,xgb,hyperopt_kfold,lift,"{'alpha': 3.2776473039460963, 'colsample_bytree': 0.915199405541038, 'gamma': 2.405566646524979, 'lambda': 3.8098444767263437, 'learning_rate': 0.234992487251094, 'max_bin': 178, 'max_depth': 8, 'min_child_weight': 5, 'n_estimators': 1129, 'subsample': 0.7251171303335975, 'tree_method': 'hist', 'outer_params': {'hyperopt_evals': 50, 'validation_fraction': 0.15, 'early_stopping_rounds': 10, 'verbose': False}}",1.7197461036720043,0.050833514967808587,"{'recall': [0.7573260073260073, 0.7646520146520146, 0.7902930402930403, 0.7783882783882784, 0.7671860678276811], 'precision': [0.7129310344827586, 0.7185886402753873, 0.7050653594771242, 0.704225352112676, 0.7246753246753247], 'accuracy': [0.7141491395793499, 0.7208413001912046, 0.7179732313575525, 0.7136711281070746, 0.7264466762314682], 'f1': [0.7344582593250445, 0.7409050576752438, 0.7452504317789291, 0.7394519356241845, 0.7453250222617988], 'roc_auc': [0.79332326007326, 0.789103021978022, 0.7868891941391942, 0.7920430402930403, 0.803269019248396], 'area_under_pr': [0.7960098194702739, 0.7820623420406503, 0.7766150179671751, 0.7986188760153226, 0.7989678575686101], 'lift': [1.7507580139159085, 1.668261562998405, 1.649929018350071, 1.7782568308884097, 1.7515250922072285]}",./output/modelsaves/heloc/xgb/202310-0217-0845-b5a53099-4376-4e88-9906-0fe55eb48372//202310-0217-0845-b5a53099-4376-4e88-9906-0fe55eb48372,31.726662158966064
202310-0217-2810-13fe6a70-857a-4c81-ab07-46a72d2ccdd4,"{'dataset': 'ageconditions', 'model': 'node', 'best_params': {}, 'param_grid': {'batch_size': [32, 64, 128, 256], 'num_layers': [1, 2, 3], 'num_trees': [12, 128], 'additional_tree_output_dim': [2, 3, 4], 'depth': [5, 7], 'choice_function': ['entmax15', 'sparsemax'], 'bin_function': ['entmoid15', 'sparsemoid'], 'input_dropout': [0.0, 0.1], 'embedding_dropout': [0.0, 0.1], 'embed_categorical': [True, False], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",ageconditions,node,hyperopt_kfold,f1,"{'AdamW_weight_decay': 7.571029527428746e-05, 'Adam_weight_decay': 3.315799853711848e-05, 'ExponentialLR_gamma': 0.9220961598053498, 'ReduceLROnPlateau_factor': 0.4449473705421336, 'ReduceLROnPlateau_patience': 3, 'additional_tree_output_dim': 3, 'batch_size': 64, 'bin_function': 'sparsemoid', 'choice_function': 'entmax15', 'depth': 5, 'embed_categorical': False, 'embedding_dropout': 0.04638023542651057, 'input_dropout': 0.08720492260553112, 'num_layers': 1, 'num_trees': 122, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 5}}",0.7966835483357222,0.0933063259123575,"{'recall': [1.0, 0.9090909090909091, 0.8181818181818182, 0.7619047619047619, 0.9523809523809523], 'precision': [0.7333333333333333, 0.6666666666666666, 0.6428571428571429, 0.64, 0.9523809523809523], 'accuracy': [0.936, 0.904, 0.8870967741935484, 0.8870967741935484, 0.9838709677419355], 'f1': [0.846153846153846, 0.7692307692307692, 0.7200000000000001, 0.6956521739130435, 0.9523809523809523], 'roc_auc': [0.9748455428067079, 0.941747572815534, 0.9420677361853832, 0.9214054553860379, 0.9995376791493297], 'area_under_pr': [0.8758748849852203, 0.870384998779107, 0.7631822307271074, 0.7861756821946033, 0.997835497835498], 'lift': [5.208333333333333, 5.208333333333333, 4.696969696969697, 4.920634920634921, 5.904761904761905]}",./output/modelsaves/ageconditions/node/202310-0217-2810-13fe6a70-857a-4c81-ab07-46a72d2ccdd4//202310-0217-2810-13fe6a70-857a-4c81-ab07-46a72d2ccdd4,1102.7943742275238
202310-0219-2242-d0159178-dc3e-429d-9eac-c80a0f31e020,"{'dataset': 'titanic', 'model': 'autoint', 'best_params': {}, 'param_grid': {'batch_size': [32, 64, 128, 256], 'attn_embed_dim_multiplier': [2, 16], 'num_heads': [2, 8], 'num_attn_blocks': [2, 6], 'attn_dropouts': [0.0, 0.3], 'embedding_dim': [8, 32], 'embedding_initialization': ['kaiming_uniform', 'kaiming_normal'], 'embedding_bias': [True, False], 'share_embedding': [True, False], 'share_embedding_strategy': ['add', 'fraction'], 'shared_embedding_fraction': [0.25, 0.1, 0.5], 'deep_layers': [True, False], 'layers': ['128-64-32', '128-64-32-16', '256-128-64'], 'dropout': [0.0, 0.3], 'activation': ['ReLU', 'LeakyReLU'], 'initialization': ['kaiming', 'xavier'], 'attention_pooling': [True, False], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",titanic,autoint,hyperopt_kfold,roc_auc,"{'AdamW_weight_decay': 2.4443950301449195e-05, 'Adam_weight_decay': 8.37205239448477e-05, 'ExponentialLR_gamma': 0.9286181526711297, 'ReduceLROnPlateau_factor': 0.16395616097315774, 'ReduceLROnPlateau_patience': 3, 'activation': 'ReLU', 'attention_pooling': True, 'attn_dropouts': 0.22240027837880189, 'attn_embed_dim_multiplier': 9, 'batch_size': 132, 'deep_layers': False, 'dropout': 0.022829026620029925, 'embedding_bias': False, 'embedding_dim': 24, 'embedding_initialization': 'kaiming_normal', 'initialization': 'xavier', 'layers': '128-64-32', 'num_attn_blocks': 6, 'num_heads': 6, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'share_embedding': True, 'share_embedding_strategy': 'fraction', 'shared_embedding_fraction': 0.2632366301962227, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 16, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 5}}",0.867249140908131,0.019426577814893018,"{'recall': [0.782608695652174, 0.75, 0.7794117647058824, 0.7794117647058824, 0.8260869565217391], 'precision': [0.7297297297297297, 0.7611940298507462, 0.6883116883116883, 0.6883116883116883, 0.7125], 'accuracy': [0.8044692737430168, 0.8146067415730337, 0.7808988764044944, 0.7808988764044944, 0.8033707865168539], 'f1': [0.7552447552447553, 0.7555555555555554, 0.7310344827586206, 0.7310344827586206, 0.7651006711409397], 'roc_auc': [0.8861001317523056, 0.8776737967914437, 0.830548128342246, 0.866042780748663, 0.8758808669059964], 'area_under_pr': [0.86155782989211, 0.8466684329337787, 0.8010989322182832, 0.8638830182164704, 0.844734002095997], 'lift': [2.5942028985507246, 2.463667820069204, 2.6176470588235294, 2.6176470588235294, 2.4279624893435634]}",./output/modelsaves/titanic/autoint/202310-0219-2242-d0159178-dc3e-429d-9eac-c80a0f31e020//202310-0219-2242-d0159178-dc3e-429d-9eac-c80a0f31e020,1250.759554386139
202310-0217-4633-8bff7d61-90b7-4bf3-87f7-f3ea80cf3ea8,"{'dataset': 'adult', 'model': 'node', 'best_params': {}, 'param_grid': {'batch_size': [512, 1024], 'num_layers': [1, 2, 3], 'num_trees': [12, 128], 'additional_tree_output_dim': [2, 3, 4], 'depth': [5, 7], 'choice_function': ['entmax15', 'sparsemax'], 'bin_function': ['entmoid15', 'sparsemoid'], 'input_dropout': [0.0, 0.1], 'embedding_dropout': [0.0, 0.1], 'embed_categorical': [True, False], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",adult,node,hyperopt_kfold,roc_auc,"{'AdamW_weight_decay': 1.27949813443311e-05, 'Adam_weight_decay': 2.7063879965134595e-05, 'ExponentialLR_gamma': 0.9336709700436032, 'ReduceLROnPlateau_factor': 0.18096785081270378, 'ReduceLROnPlateau_patience': 3, 'additional_tree_output_dim': 2, 'batch_size': 859, 'bin_function': 'sparsemoid', 'choice_function': 'sparsemax', 'depth': 5, 'embed_categorical': True, 'embedding_dropout': 0.0720193989763807, 'input_dropout': 0.05264502798573829, 'num_layers': 3, 'num_trees': 60, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 5}}",0.915726879973643,0.001935032965512214,"{'recall': [0.8534098151688974, 0.8724489795918368, 0.8711734693877551, 0.8692602040816326, 0.8584183673469388], 'precision': [0.5799047206582937, 0.5733445096395641, 0.5812765957446808, 0.561598681499794, 0.581174438687392], 'accuracy': [0.8157531091662829, 0.812960687960688, 0.8178746928746928, 0.8051289926289926, 0.816953316953317], 'f1': [0.6905621454357916, 0.6919575113808801, 0.697294538029607, 0.6823529411764706, 0.6930998970133883], 'roc_auc': [0.9167747606848714, 0.9170247589326993, 0.9158622490258239, 0.9119522581484051, 0.9170203730764149], 'area_under_pr': [0.7989436636932374, 0.7859936243547884, 0.7869652564085591, 0.7847640863395224, 0.7988453251076907], 'lift': [3.704701988116532, 3.604423336154739, 3.6490799084610805, 3.6745979497789905, 3.751152073732719]}",./output/modelsaves/adult/node/202310-0217-4633-8bff7d61-90b7-4bf3-87f7-f3ea80cf3ea8//202310-0217-4633-8bff7d61-90b7-4bf3-87f7-f3ea80cf3ea8,7170.7167983055115
202310-0219-4333-b281db2b-3773-4039-9174-ec436c6b1ef9,"{'dataset': 'breastcancer', 'model': 'autoint', 'best_params': {}, 'param_grid': {'batch_size': [32, 64, 128, 256], 'attn_embed_dim_multiplier': [2, 16], 'num_heads': [2, 8], 'num_attn_blocks': [2, 6], 'attn_dropouts': [0.0, 0.3], 'embedding_dim': [8, 32], 'embedding_initialization': ['kaiming_uniform', 'kaiming_normal'], 'embedding_bias': [True, False], 'share_embedding': [True, False], 'share_embedding_strategy': ['add', 'fraction'], 'shared_embedding_fraction': [0.25, 0.1, 0.5], 'deep_layers': [True, False], 'layers': ['128-64-32', '128-64-32-16', '256-128-64'], 'dropout': [0.0, 0.3], 'activation': ['ReLU', 'LeakyReLU'], 'initialization': ['kaiming', 'xavier'], 'attention_pooling': [True, False], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",breastcancer,autoint,hyperopt_kfold,f1,"{'AdamW_weight_decay': 5.486693527282193e-05, 'Adam_weight_decay': 1.2460695957841637e-05, 'ExponentialLR_gamma': 0.9149241998344151, 'ReduceLROnPlateau_factor': 0.21793495386091802, 'ReduceLROnPlateau_patience': 4, 'activation': 'ReLU', 'attention_pooling': True, 'attn_dropouts': 0.18201398334209026, 'attn_embed_dim_multiplier': 12, 'batch_size': 102, 'deep_layers': False, 'dropout': 0.22216135597378683, 'embedding_bias': True, 'embedding_dim': 8, 'embedding_initialization': 'kaiming_uniform', 'initialization': 'xavier', 'layers': '256-128-64', 'num_attn_blocks': 4, 'num_heads': 2, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>, 'share_embedding': False, 'share_embedding_strategy': 'add', 'shared_embedding_fraction': 0.14263390291925862, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 16, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 5}}",0.9846338605542103,0.005162146241731895,"{'recall': [0.9859154929577465, 0.9859154929577465, 0.9861111111111112, 0.9722222222222222, 1.0], 'precision': [0.9722222222222222, 0.9859154929577465, 0.9726027397260274, 1.0, 0.9861111111111112], 'accuracy': [0.9736842105263158, 0.9824561403508771, 0.9736842105263158, 0.9824561403508771, 0.9911504424778761], 'f1': [0.979020979020979, 0.9859154929577465, 0.9793103448275863, 0.9859154929577464, 0.993006993006993], 'roc_auc': [0.9918113331149688, 0.9983622666229939, 0.9851190476190476, 0.9996693121693121, 0.9986586183769282], 'area_under_pr': [0.99449192816893, 0.9990504529524564, 0.9897246843325376, 0.9998097412480973, 0.9992006779740839], 'lift': [1.6056338028169013, 1.6056338028169013, 1.5833333333333335, 1.5833333333333335, 1.591549295774648]}",./output/modelsaves/breastcancer/autoint/202310-0219-4333-b281db2b-3773-4039-9174-ec436c6b1ef9//202310-0219-4333-b281db2b-3773-4039-9174-ec436c6b1ef9,999.7914414405823
202310-0219-2303-616a3a37-6b52-4c37-ae0c-4529ac83bcfa,"{'dataset': 'housing', 'model': 'categoryembedding', 'best_params': {}, 'param_grid': {'batch_size': [1024, 2048, 4096], 'layers': ['128-64-32', '128-64-32-16', '256-128-64'], 'activation': ['ReLU', 'LeakyReLU', 'Tanh'], 'initialization': ['kaiming', 'xavier'], 'dropout': [0.0, 0.3], 'embedding_dropout': [0.0, 0.3], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",housing,categoryembedding,hyperopt_kfold,r2_score,"{'AdamW_weight_decay': 9.267773189850353e-05, 'Adam_weight_decay': 4.101854042788317e-05, 'ExponentialLR_gamma': 0.9894511479894631, 'ReduceLROnPlateau_factor': 0.7986741176038994, 'ReduceLROnPlateau_patience': 5, 'activation': 'LeakyReLU', 'batch_size': 3328, 'dropout': 0.018818524494155442, 'embedding_dropout': 9.702881981838579e-05, 'initialization': 'kaiming', 'layers': '128-64-32', 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 16, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 5}}",0.6768259960495896,0.012900671198077272,"{'mse': [0.5237762638639207, 0.5289386104183407, 0.5177301130028883, 0.47872462136327115, 0.5342851242667137], 'rmse': [0.7237238864815232, 0.7272816582441363, 0.7195346503142765, 0.6918992855634923, 0.7309480995711759], 'r2_score': [0.6660165750966714, 0.6783061161034256, 0.6699462365608564, 0.7012768460149719, 0.6685842064720221]}",./output/modelsaves/housing/categoryembedding/202310-0219-2303-616a3a37-6b52-4c37-ae0c-4529ac83bcfa//202310-0219-2303-616a3a37-6b52-4c37-ae0c-4529ac83bcfa,5775.08614897728
202310-0219-4604-06f39b62-8c3d-4783-a9ed-cdb8622e2fa0,"{'dataset': 'housing', 'model': 'node', 'best_params': {}, 'param_grid': {'batch_size': [512, 1024], 'num_layers': [1, 2, 3], 'num_trees': [12, 128], 'additional_tree_output_dim': [2, 3, 4], 'depth': [5, 7], 'choice_function': ['entmax15', 'sparsemax'], 'bin_function': ['entmoid15', 'sparsemoid'], 'input_dropout': [0.0, 0.1], 'embedding_dropout': [0.0, 0.1], 'embed_categorical': [True, False], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",housing,node,hyperopt_kfold,r2_score,"{'AdamW_weight_decay': 5.186618528954418e-05, 'Adam_weight_decay': 1.907886579453724e-05, 'ExponentialLR_gamma': 0.9114313266624429, 'ReduceLROnPlateau_factor': 0.2039685372459998, 'ReduceLROnPlateau_patience': 3, 'additional_tree_output_dim': 4, 'batch_size': 792, 'bin_function': 'sparsemoid', 'choice_function': 'entmax15', 'depth': 7, 'embed_categorical': False, 'embedding_dropout': 0.002826630235855939, 'input_dropout': 0.056440961474163526, 'num_layers': 3, 'num_trees': 43, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 5}}",0.7655644193429781,0.014645777282761611,"{'mse': [0.29766848361477377, 0.3284346952024986, 0.3053202613979258, 0.2836530063766402, 0.3461019162072779], 'rmse': [0.5455900325471258, 0.5730922222491758, 0.5525579258303385, 0.5325908433090455, 0.5883042717907783], 'r2_score': [0.7728430676548281, 0.7595811972391702, 0.7653281539343865, 0.7872057609013869, 0.7428639169851188]}",./output/modelsaves/housing/node/202310-0219-4604-06f39b62-8c3d-4783-a9ed-cdb8622e2fa0//202310-0219-4604-06f39b62-8c3d-4783-a9ed-cdb8622e2fa0,7767.39023399353
202310-0220-5919-125a400d-d513-493e-8b65-7419cbb4003a,"{'dataset': 'heloc', 'model': 'categoryembedding', 'best_params': {}, 'param_grid': {'batch_size': [1024, 2048, 4096], 'layers': ['128-64-32', '128-64-32-16', '256-128-64'], 'activation': ['ReLU', 'LeakyReLU', 'Tanh'], 'initialization': ['kaiming', 'xavier'], 'dropout': [0.0, 0.3], 'embedding_dropout': [0.0, 0.3], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",heloc,categoryembedding,hyperopt_kfold,lift,"{'AdamW_weight_decay': 2.8600375073754828e-05, 'Adam_weight_decay': 5.18466552722249e-05, 'ExponentialLR_gamma': 0.9314269773258598, 'ReduceLROnPlateau_factor': 0.263302128968097, 'ReduceLROnPlateau_patience': 5, 'activation': 'LeakyReLU', 'batch_size': 3340, 'dropout': 0.1117978745920478, 'embedding_dropout': 0.04200572103617551, 'initialization': 'kaiming', 'layers': '256-128-64', 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 16, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 5}}",1.7124114793659875,0.023609101830857397,"{'recall': [0.7298534798534798, 0.7527472527472527, 0.6877289377289377, 0.6932234432234432, 0.6489459211732356], 'precision': [0.7225747960108794, 0.7300177619893428, 0.7341153470185728, 0.7363813229571985, 0.7612903225806451], 'accuracy': [0.7127151051625239, 0.7256214149139579, 0.7069789674952199, 0.7103250478011472, 0.7106647537063606], 'f1': [0.7261958997722096, 0.7412082957619476, 0.7101654846335698, 0.7141509433962265, 0.7006432459178624], 'roc_auc': [0.786430402930403, 0.7904606227106228, 0.7854606227106228, 0.783058608058608, 0.7954601283226398], 'area_under_pr': [0.7886856315016256, 0.7847599202413961, 0.7762639724383145, 0.790673769481528, 0.7916479417133514], 'lift': [1.7140929246192402, 1.7140929246192402, 1.668261562998405, 1.7324254692675742, 1.7331845153254772]}",./output/modelsaves/heloc/categoryembedding/202310-0220-5919-125a400d-d513-493e-8b65-7419cbb4003a//202310-0220-5919-125a400d-d513-493e-8b65-7419cbb4003a,3384.374784231186
202310-0221-5543-33de6074-526a-4b37-9123-622232f7f11e,"{'dataset': 'iris', 'model': 'categoryembedding', 'best_params': {}, 'param_grid': {'batch_size': [32, 64, 128, 256], 'layers': ['128-64-32', '128-64-32-16', '256-128-64'], 'activation': ['ReLU', 'LeakyReLU', 'Tanh'], 'initialization': ['kaiming', 'xavier'], 'dropout': [0.0, 0.3], 'embedding_dropout': [0.0, 0.3], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",iris,categoryembedding,hyperopt_kfold,accuracy,"{'AdamW_weight_decay': 2.0246689238073135e-05, 'Adam_weight_decay': 9.948983447892247e-05, 'ExponentialLR_gamma': 0.9200387567577661, 'ReduceLROnPlateau_factor': 0.13675996229292545, 'ReduceLROnPlateau_patience': 3, 'activation': 'Tanh', 'batch_size': 77, 'dropout': 0.16471739906539257, 'embedding_dropout': 0.0028456381146058918, 'initialization': 'xavier', 'layers': '256-128-64', 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 16, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 5}}",0.9733333333333334,0.02494438257849294,"{'accuracy': [1.0, 0.9666666666666667, 0.9333333333333333, 1.0, 0.9666666666666667], 'f1': [1.0, 0.9665831244778613, 0.9333333333333333, 1.0, 0.9665831244778613]}",./output/modelsaves/iris/categoryembedding/202310-0221-5543-33de6074-526a-4b37-9123-622232f7f11e//202310-0221-5543-33de6074-526a-4b37-9123-622232f7f11e,1200.0065491199493
202310-0222-1543-1e9a4998-b82b-48f0-91ca-3a9e6d2f2ae3,"{'dataset': 'breastcancer', 'model': 'categoryembedding', 'best_params': {}, 'param_grid': {'batch_size': [32, 64, 128, 256], 'layers': ['128-64-32', '128-64-32-16', '256-128-64'], 'activation': ['ReLU', 'LeakyReLU', 'Tanh'], 'initialization': ['kaiming', 'xavier'], 'dropout': [0.0, 0.3], 'embedding_dropout': [0.0, 0.3], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",breastcancer,categoryembedding,hyperopt_kfold,f1,"{'AdamW_weight_decay': 6.143575096803424e-05, 'Adam_weight_decay': 7.151591347942346e-05, 'ExponentialLR_gamma': 0.9557636066793738, 'ReduceLROnPlateau_factor': 0.8987718577363002, 'ReduceLROnPlateau_patience': 5, 'activation': 'Tanh', 'batch_size': 33, 'dropout': 0.047623411120878825, 'embedding_dropout': 0.16888113831912566, 'initialization': 'kaiming', 'layers': '128-64-32', 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 16, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 5}}",0.9888488272632836,0.005552154467889063,"{'recall': [0.9859154929577465, 0.9859154929577465, 1.0, 0.9861111111111112, 1.0], 'precision': [1.0, 0.9722222222222222, 0.972972972972973, 1.0, 0.9861111111111112], 'accuracy': [0.9912280701754386, 0.9736842105263158, 0.9824561403508771, 0.9912280701754386, 0.9911504424778761], 'f1': [0.9929078014184397, 0.979020979020979, 0.9863013698630138, 0.993006993006993, 0.993006993006993], 'roc_auc': [0.9993449066491975, 0.9963969865705863, 0.9897486772486772, 1.0, 0.9983232729711603], 'area_under_pr': [0.9996141230947329, 0.9978814604456268, 0.9927765179560343, 1.0, 0.9989935528705214], 'lift': [1.6056338028169013, 1.6056338028169013, 1.5833333333333335, 1.5833333333333335, 1.591549295774648]}",./output/modelsaves/breastcancer/categoryembedding/202310-0222-1543-1e9a4998-b82b-48f0-91ca-3a9e6d2f2ae3//202310-0222-1543-1e9a4998-b82b-48f0-91ca-3a9e6d2f2ae3,1066.2011215686798
202310-0222-3329-d83d7801-dc1f-4e96-bae7-204063c288d2,"{'dataset': 'titanic', 'model': 'categoryembedding', 'best_params': {}, 'param_grid': {'batch_size': [32, 64, 128, 256], 'layers': ['128-64-32', '128-64-32-16', '256-128-64'], 'activation': ['ReLU', 'LeakyReLU', 'Tanh'], 'initialization': ['kaiming', 'xavier'], 'dropout': [0.0, 0.3], 'embedding_dropout': [0.0, 0.3], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",titanic,categoryembedding,hyperopt_kfold,roc_auc,"{'AdamW_weight_decay': 6.984117601648357e-05, 'Adam_weight_decay': 2.841101080790893e-05, 'ExponentialLR_gamma': 0.9418848645492701, 'ReduceLROnPlateau_factor': 0.7114874278295789, 'ReduceLROnPlateau_patience': 3, 'activation': 'Tanh', 'batch_size': 58, 'dropout': 0.07604384843283163, 'embedding_dropout': 0.0467465519436529, 'initialization': 'kaiming', 'layers': '256-128-64', 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 16, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 5}}",0.8784135667901711,0.027037444707582913,"{'recall': [0.7681159420289855, 0.7352941176470589, 0.7205882352941176, 0.7647058823529411, 0.8405797101449275], 'precision': [0.7910447761194029, 0.746268656716418, 0.7101449275362319, 0.7536231884057971, 0.7435897435897436], 'accuracy': [0.8324022346368715, 0.8033707865168539, 0.7808988764044944, 0.8146067415730337, 0.8258426966292135], 'f1': [0.7794117647058824, 0.7407407407407408, 0.7153284671532847, 0.759124087591241, 0.7891156462585034], 'roc_auc': [0.9138998682476943, 0.8815508021390375, 0.8301470588235295, 0.8810160427807489, 0.8854540619598457], 'area_under_pr': [0.8734210179882217, 0.8670786871529547, 0.8134759052459998, 0.8737127398081815, 0.864155065181826], 'lift': [2.441602728047741, 2.6176470588235294, 2.6176470588235294, 2.6176470588235294, 2.579710144927536]}",./output/modelsaves/titanic/categoryembedding/202310-0222-3329-d83d7801-dc1f-4e96-bae7-204063c288d2//202310-0222-3329-d83d7801-dc1f-4e96-bae7-204063c288d2,1664.3516597747803
202310-0223-5410-f0489c68-6427-4c26-b370-18e6a3d6bf98,"{'dataset': 'ageconditions', 'model': 'categoryembedding', 'best_params': {}, 'param_grid': {'batch_size': [32, 64, 128, 256], 'layers': ['128-64-32', '128-64-32-16', '256-128-64'], 'activation': ['ReLU', 'LeakyReLU', 'Tanh'], 'initialization': ['kaiming', 'xavier'], 'dropout': [0.0, 0.3], 'embedding_dropout': [0.0, 0.3], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",ageconditions,categoryembedding,hyperopt_kfold,f1,"{'AdamW_weight_decay': 1.7981187137084847e-05, 'Adam_weight_decay': 8.157566866520748e-05, 'ExponentialLR_gamma': 0.9590657419134175, 'ReduceLROnPlateau_factor': 0.25566787927439555, 'ReduceLROnPlateau_patience': 3, 'activation': 'Tanh', 'batch_size': 121, 'dropout': 0.06672592034623645, 'embedding_dropout': 0.23762224361966366, 'initialization': 'kaiming', 'layers': '128-64-32', 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 16, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 5}}",0.7233581190602126,0.0603934543865453,"{'recall': [0.8181818181818182, 0.8181818181818182, 0.7272727272727273, 0.8095238095238095, 0.9047619047619048], 'precision': [0.6428571428571429, 0.5, 0.7619047619047619, 0.6538461538461539, 0.7307692307692307], 'accuracy': [0.888, 0.824, 0.9112903225806451, 0.8951612903225806, 0.9274193548387096], 'f1': [0.7200000000000001, 0.6206896551724137, 0.7441860465116279, 0.7234042553191489, 0.8085106382978723], 'roc_auc': [0.944395410414828, 0.8729037952338924, 0.9237967914438503, 0.8700878409616273, 0.975959315765141], 'area_under_pr': [0.7101954211553145, 0.6763698774627889, 0.6780947285482426, 0.7303138964033935, 0.9217789738041984], 'lift': [4.261363636363637, 3.787878787878788, 4.227272727272727, 4.920634920634921, 5.904761904761905]}",./output/modelsaves/ageconditions/categoryembedding/202310-0223-5410-f0489c68-6427-4c26-b370-18e6a3d6bf98//202310-0223-5410-f0489c68-6427-4c26-b370-18e6a3d6bf98,658.5808384418488
202310-0300-0508-c62e0048-56d8-4e0c-9fcd-ead46c79dbf6,"{'dataset': 'diabetes', 'model': 'categoryembedding', 'best_params': {}, 'param_grid': {'batch_size': [1024, 2048, 4096], 'layers': ['128-64-32', '128-64-32-16', '256-128-64'], 'activation': ['ReLU', 'LeakyReLU', 'Tanh'], 'initialization': ['kaiming', 'xavier'], 'dropout': [0.0, 0.3], 'embedding_dropout': [0.0, 0.3], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",diabetes,categoryembedding,hyperopt_kfold,lift,"{'AdamW_weight_decay': 2.499971717191055e-05, 'Adam_weight_decay': 8.55197246787361e-05, 'ExponentialLR_gamma': 0.9125645344689168, 'ReduceLROnPlateau_factor': 0.7513709206124669, 'ReduceLROnPlateau_patience': 3, 'activation': 'LeakyReLU', 'batch_size': 1379, 'dropout': 0.16206704145201048, 'embedding_dropout': 0.01456836751400122, 'initialization': 'xavier', 'layers': '256-128-64', 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 16, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 5}}",2.461435759772783,0.08163776387548663,"{'recall': [0.5999119718309859, 0.615147512109203, 0.5970937912813739, 0.647732276530163, 0.6205985915492958], 'precision': [0.17550862734998712, 0.17949376846974174, 0.18072770891643342, 0.17480689245395128, 0.17128279883381925], 'accuracy': [0.6407585732534146, 0.6432958286247727, 0.6530241242077335, 0.6195155505330909, 0.6224635188915639], 'f1': [0.2715680414425184, 0.2778993435448578, 0.27747084100675257, 0.27531349429159646, 0.2684691546077685], 'roc_auc': [0.6758218209962128, 0.6888026029081957, 0.6771315915835445, 0.680225014368956, 0.67228373872737], 'area_under_pr': [0.22811664849400243, 0.2401881755953904, 0.22174114860455846, 0.23139962665107158, 0.21586575441480754], 'lift': [2.3992391078658684, 2.607165445738761, 2.4221976269532415, 2.4926615579191536, 2.3859150603868917]}",./output/modelsaves/diabetes/categoryembedding/202310-0300-0508-c62e0048-56d8-4e0c-9fcd-ead46c79dbf6//202310-0300-0508-c62e0048-56d8-4e0c-9fcd-ead46c79dbf6,17815.721475839615
202310-0223-5323-65f9477d-27cb-408a-bc85-1835ccfbbc4d,"{'dataset': 'iris', 'model': 'gate', 'best_params': {}, 'param_grid': {'batch_size': [32, 64, 128, 256], 'tree_depth': [4, 7], 'num_trees': [4, 10], 'chain_trees': [False, True], 'gflu_stages': [3, 8], 'gflu_dropout': [0.0, 0.05], 'tree_dropout': [0.0, 0.05], 'tree_wise_attention_dropout': [0.0, 0.05], 'embedding_dropout': [0, 0.2], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",iris,gate,hyperopt_kfold,accuracy,"{'AdamW_weight_decay': 3.2968002746028435e-05, 'Adam_weight_decay': 1.966691046661326e-05, 'ExponentialLR_gamma': 0.9092726596465195, 'ReduceLROnPlateau_factor': 0.3982410911468566, 'ReduceLROnPlateau_patience': 3, 'batch_size': 61, 'chain_trees': True, 'embedding_dropout': 0, 'gflu_dropout': 0.03418410755502854, 'gflu_stages': 4, 'num_trees': 6, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'tree_depth': 5, 'tree_dropout': 0.03161397071527924, 'tree_wise_attention_dropout': 0.0451658763200941, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 5}}",0.9666666666666668,0.04216370213557838,"{'accuracy': [1.0, 1.0, 0.9333333333333333, 1.0, 0.9], 'f1': [1.0, 1.0, 0.9333333333333333, 1.0, 0.8997493734335841]}",./output/modelsaves/iris/gate/202310-0223-5323-65f9477d-27cb-408a-bc85-1835ccfbbc4d//202310-0223-5323-65f9477d-27cb-408a-bc85-1835ccfbbc4d,19163.96044611931
202310-0223-5357-4e0e8986-d45a-46df-8bd8-7a63836f2d3e,"{'dataset': 'diabetes', 'model': 'autoint', 'best_params': {}, 'param_grid': {'batch_size': [1024, 2048, 4096], 'attn_embed_dim_multiplier': [2, 16], 'num_heads': [2, 8], 'num_attn_blocks': [2, 6], 'attn_dropouts': [0.0, 0.3], 'embedding_dim': [8, 32], 'embedding_initialization': ['kaiming_uniform', 'kaiming_normal'], 'embedding_bias': [True, False], 'share_embedding': [True, False], 'share_embedding_strategy': ['add', 'fraction'], 'shared_embedding_fraction': [0.25, 0.1, 0.5], 'deep_layers': [True, False], 'layers': ['128-64-32', '128-64-32-16', '256-128-64'], 'dropout': [0.0, 0.3], 'activation': ['ReLU', 'LeakyReLU'], 'initialization': ['kaiming', 'xavier'], 'attention_pooling': [True, False], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",diabetes,autoint,hyperopt_kfold,lift,"{'AdamW_weight_decay': 7.488898991164218e-05, 'Adam_weight_decay': 9.532495629140001e-05, 'ExponentialLR_gamma': 0.9561703066841265, 'ReduceLROnPlateau_factor': 0.16898955618453693, 'ReduceLROnPlateau_patience': 5, 'activation': 'ReLU', 'attention_pooling': True, 'attn_dropouts': 0.09646786520238941, 'attn_embed_dim_multiplier': 10, 'batch_size': 3339, 'deep_layers': False, 'dropout': 0.2543627780032219, 'embedding_bias': False, 'embedding_dim': 29, 'embedding_initialization': 'kaiming_uniform', 'initialization': 'kaiming', 'layers': '128-64-32', 'num_attn_blocks': 6, 'num_heads': 5, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>, 'share_embedding': False, 'share_embedding_strategy': 'fraction', 'shared_embedding_fraction': 0.4033813001112184, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 16, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 5}}",2.3945131130645207,0.10321623299401805,"{'recall': [0.5704225352112676, 0.6243945398502863, 0.6142668428005285, 0.6340819022457067, 0.596830985915493], 'precision': [0.17407656145063802, 0.17951639448031395, 0.17640364188163885, 0.16840135656648345, 0.1752843846949328], 'accuracy': [0.6499459565687334, 0.6396600009826561, 0.6369576966540559, 0.6097872549501302, 0.641527047609689], 'f1': [0.2667489966038901, 0.27885939036381513, 0.27409372236958446, 0.2661245610792829, 0.27098321342925663], 'roc_auc': [0.6685209037935165, 0.687926426561789, 0.675831725242475, 0.6787115679435008, 0.6661469251046347], 'area_under_pr': [0.2070585913143494, 0.23520629111798647, 0.21257433356463667, 0.2277293065012294, 0.20587193735251413], 'lift': [2.3067913624251655, 2.519085532031371, 2.3781576700995455, 2.5058735449752625, 2.262657455791259]}",./output/modelsaves/diabetes/autoint/202310-0223-5357-4e0e8986-d45a-46df-8bd8-7a63836f2d3e//202310-0223-5357-4e0e8986-d45a-46df-8bd8-7a63836f2d3e,23064.881199359894
202310-0309-2839-643113dd-b54f-4f58-8a0c-5bc7c907d033,"{'dataset': 'iris', 'model': 'autoint', 'best_params': {}, 'param_grid': {'batch_size': [32, 64, 128, 256], 'attn_embed_dim_multiplier': [2, 16], 'num_heads': [2, 8], 'num_attn_blocks': [2, 6], 'attn_dropouts': [0.0, 0.3], 'embedding_dim': [8, 32], 'embedding_initialization': ['kaiming_uniform', 'kaiming_normal'], 'embedding_bias': [True, False], 'share_embedding': [True, False], 'share_embedding_strategy': ['add', 'fraction'], 'shared_embedding_fraction': [0.25, 0.1, 0.5], 'deep_layers': [True, False], 'layers': ['128-64-32', '128-64-32-16', '256-128-64'], 'dropout': [0.0, 0.3], 'activation': ['ReLU', 'LeakyReLU'], 'initialization': ['kaiming', 'xavier'], 'attention_pooling': [True, False], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",iris,autoint,hyperopt_kfold,accuracy,"{'AdamW_weight_decay': 3.384519911050485e-05, 'Adam_weight_decay': 1.4974033595997699e-05, 'ExponentialLR_gamma': 0.9894246271868206, 'ReduceLROnPlateau_factor': 0.10057436825325987, 'ReduceLROnPlateau_patience': 3, 'activation': 'LeakyReLU', 'attention_pooling': True, 'attn_dropouts': 0.06645147850346317, 'attn_embed_dim_multiplier': 15, 'batch_size': 156, 'deep_layers': False, 'dropout': 0.298754236239731, 'embedding_bias': True, 'embedding_dim': 29, 'embedding_initialization': 'kaiming_uniform', 'initialization': 'kaiming', 'layers': '128-64-32', 'num_attn_blocks': 2, 'num_heads': 3, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'share_embedding': False, 'share_embedding_strategy': 'fraction', 'shared_embedding_fraction': 0.1779356178255116, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 16, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 10}}",0.9866666666666667,0.016329931618554516,"{'accuracy': [1.0, 1.0, 0.9666666666666667, 1.0, 0.9666666666666667], 'f1': [1.0, 1.0, 0.9665831244778613, 1.0, 0.9665831244778613]}",./output/modelsaves/iris/autoint/202310-0309-2839-643113dd-b54f-4f58-8a0c-5bc7c907d033//202310-0309-2839-643113dd-b54f-4f58-8a0c-5bc7c907d033,798.458010673523
202310-0310-3443-4141fa35-3208-466e-b908-ee364e5c2eba,"{'dataset': 'iris', 'model': 'mlp', 'best_params': {}, 'param_grid': {'hidden_layer_sizes': [[64, 32, 16], [256, 128, 64, 32], [128, 64, 32, 16]], 'activation': ['relu', 'tanh', 'logistic'], 'solver': ['adam', 'lbfgs'], 'alpha': [0.0001, 0.001, 0.01], 'learning_rate_init': [0.0001, 0.01, 0.1], 'beta_1': [0.99, 0.8], 'beta_2': [0.999, 0.9], 'batch_size': [32, 64, 128, 256]}}",iris,mlp,hyperopt_kfold,accuracy,"{'activation': 'logistic', 'alpha': 0.000389485243183445, 'batch_size': 90, 'beta_1': 0.937898354378537, 'beta_2': 0.9172069184676471, 'hidden_layer_sizes': (128, 64, 32, 16), 'learning_rate_init': 0.007885663539250777, 'solver': 'lbfgs', 'outer_params': {'cv_iterations': 10, 'early_stopping': True, 'cv_size': 5, 'validation_fraction': 0.15, 'hyperopt_evals': 50, 'n_iter_no_change': 50, 'max_iter': 1000}}",0.9666666666666668,0.04216370213557838,"{'accuracy': [1.0, 1.0, 0.9333333333333333, 1.0, 0.9], 'f1': [1.0, 1.0, 0.9326599326599326, 1.0, 0.8997493734335841]}",./output/modelsaves/iris/mlp/202310-0310-3443-4141fa35-3208-466e-b908-ee364e5c2eba//202310-0310-3443-4141fa35-3208-466e-b908-ee364e5c2eba,607.7544503211975
202310-0310-3506-f6ce2aa0-5c7d-4dfd-bf71-a224dfe49ebd,"{'dataset': 'iris', 'model': 'tabtransformer', 'best_params': {}, 'param_grid': {'batch_size': [32, 64, 128, 256], 'embedding_bias': [True, False], 'embedding_initialization': ['kaiming_uniform', 'kaiming_normal'], 'shared_embedding_fraction': [0.125, 0.25, 0.5], 'num_attn_blocks': [4, 10], 'attn_dropout': [0.05, 0.3], 'add_norm_dropout': [0.05, 0.3], 'ff_dropout': [0.05, 0.3], 'ff_hidden_multiplier': [2, 6], 'transformer_activation': ['GEGLU', 'ReGLU', 'SwiGLU'], 'embedding_dropout': [0.05, 0.3], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",iris,tabtransformer,hyperopt_kfold,accuracy,"{'AdamW_weight_decay': 4.501295593182965e-05, 'Adam_weight_decay': 1.3537853615885958e-05, 'ExponentialLR_gamma': 0.9581919041275976, 'ReduceLROnPlateau_factor': 0.8933492167570437, 'ReduceLROnPlateau_patience': 5, 'add_norm_dropout': 0.09962503335511823, 'attn_dropout': 0.2997684118802012, 'batch_size': 79, 'embedding_bias': True, 'embedding_dropout': 0.06475383150617227, 'embedding_initialization': 'kaiming_normal', 'ff_dropout': 0.10021608395860351, 'ff_hidden_multiplier': 5, 'num_attn_blocks': 6, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'shared_embedding_fraction': 0.3724047047208797, 'transformer_activation': 'ReGLU', 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 16, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 10}}",0.9800000000000001,0.039999999999999994,"{'accuracy': [1.0, 1.0, 0.9, 1.0, 1.0], 'f1': [1.0, 1.0, 0.8997493734335841, 1.0, 1.0]}",./output/modelsaves/iris/tabtransformer/202310-0310-3506-f6ce2aa0-5c7d-4dfd-bf71-a224dfe49ebd//202310-0310-3506-f6ce2aa0-5c7d-4dfd-bf71-a224dfe49ebd,2143.196766614914
202310-0310-4450-cb39941c-66ee-4d48-bf25-d64e3261ac93,"{'dataset': 'titanic', 'model': 'mlp', 'best_params': {}, 'param_grid': {'hidden_layer_sizes': [[64, 32, 16], [256, 128, 64, 32], [128, 64, 32, 16]], 'activation': ['relu', 'tanh', 'logistic'], 'solver': ['adam', 'lbfgs'], 'alpha': [0.0001, 0.001, 0.01], 'learning_rate_init': [0.0001, 0.01, 0.1], 'beta_1': [0.99, 0.8], 'beta_2': [0.999, 0.9], 'batch_size': [32, 64, 128, 256]}}",titanic,mlp,hyperopt_kfold,roc_auc,"{'activation': 'relu', 'alpha': 0.0018455106400832948, 'batch_size': 178, 'beta_1': 0.8268211938633007, 'beta_2': 0.9772142825985788, 'hidden_layer_sizes': (256, 128, 64, 32), 'learning_rate_init': 0.014430586073715404, 'solver': 'adam', 'outer_params': {'cv_iterations': 10, 'early_stopping': True, 'cv_size': 5, 'validation_fraction': 0.15, 'hyperopt_evals': 50, 'n_iter_no_change': 50, 'max_iter': 1000}}",0.8590203739689297,0.004392224981033241,"{'recall': [0.7536231884057971, 0.6911764705882353, 0.6911764705882353, 0.7058823529411765, 0.6376811594202898], 'precision': [0.8253968253968254, 0.7704918032786885, 0.7230769230769231, 0.9056603773584906, 0.8979591836734694], 'accuracy': [0.8435754189944135, 0.8033707865168539, 0.7808988764044944, 0.8595505617977528, 0.8314606741573034], 'f1': [0.787878787878788, 0.7286821705426356, 0.7067669172932332, 0.7933884297520662, 0.7457627118644068], 'roc_auc': [0.8606719367588933, 0.8593582887700536, 0.851403743315508, 0.8586898395721925, 0.8649780614280016], 'area_under_pr': [0.8344926351127062, 0.8299462133652511, 0.8126987441690949, 0.8622806689824828, 0.8671321198748098], 'lift': [2.441602728047741, 2.463667820069204, 2.463667820069204, 2.6176470588235294, 2.579710144927536]}",./output/modelsaves/titanic/mlp/202310-0310-4450-cb39941c-66ee-4d48-bf25-d64e3261ac93//202310-0310-4450-cb39941c-66ee-4d48-bf25-d64e3261ac93,2926.2042891979218
202310-0311-3337-e5f9ede4-3f87-4cec-8b52-9e2abbd2c4f9,"{'dataset': 'breastcancer', 'model': 'mlp', 'best_params': {}, 'param_grid': {'hidden_layer_sizes': [[64, 32, 16], [256, 128, 64, 32], [128, 64, 32, 16]], 'activation': ['relu', 'tanh', 'logistic'], 'solver': ['adam', 'lbfgs'], 'alpha': [0.0001, 0.001, 0.01], 'learning_rate_init': [0.0001, 0.01, 0.1], 'beta_1': [0.99, 0.8], 'beta_2': [0.999, 0.9], 'batch_size': [32, 64, 128, 256]}}",breastcancer,mlp,hyperopt_kfold,f1,"{'activation': 'tanh', 'alpha': 0.0007672874280294561, 'batch_size': 206, 'beta_1': 0.848283211273961, 'beta_2': 0.989039761781936, 'hidden_layer_sizes': (64, 32, 16), 'learning_rate_init': 0.029570110933299608, 'solver': 'adam', 'outer_params': {'cv_iterations': 10, 'early_stopping': True, 'cv_size': 5, 'validation_fraction': 0.15, 'hyperopt_evals': 50, 'n_iter_no_change': 50, 'max_iter': 1000}}",0.9847096732407138,0.009166628650812088,"{'recall': [0.971830985915493, 1.0, 0.9861111111111112, 1.0, 1.0], 'precision': [0.9857142857142858, 0.9726027397260274, 0.9594594594594594, 1.0, 0.9726027397260274], 'accuracy': [0.9736842105263158, 0.9824561403508771, 0.9649122807017544, 1.0, 0.9823008849557522], 'f1': [0.9787234042553192, 0.9861111111111112, 0.9726027397260274, 1.0, 0.9861111111111112], 'roc_auc': [0.9990173599737963, 0.9977071732721913, 0.9874338624338624, 1.0, 0.9986586183769282], 'area_under_pr': [0.9994048012645513, 0.9985930775955999, 0.9913970928140821, 1.0, 0.9992006779740839], 'lift': [1.6056338028169013, 1.6056338028169013, 1.5833333333333335, 1.5833333333333335, 1.591549295774648]}",./output/modelsaves/breastcancer/mlp/202310-0311-3337-e5f9ede4-3f87-4cec-8b52-9e2abbd2c4f9//202310-0311-3337-e5f9ede4-3f87-4cec-8b52-9e2abbd2c4f9,585.4486622810364
202310-0311-4322-ff2a1a0c-31e0-48a0-8737-65e163cc5c6d,"{'dataset': 'ageconditions', 'model': 'mlp', 'best_params': {}, 'param_grid': {'hidden_layer_sizes': [[64, 32, 16], [256, 128, 64, 32], [128, 64, 32, 16]], 'activation': ['relu', 'tanh', 'logistic'], 'solver': ['adam', 'lbfgs'], 'alpha': [0.0001, 0.001, 0.01], 'learning_rate_init': [0.0001, 0.01, 0.1], 'beta_1': [0.99, 0.8], 'beta_2': [0.999, 0.9], 'batch_size': [32, 64, 128, 256]}}",ageconditions,mlp,hyperopt_kfold,f1,"{'activation': 'relu', 'alpha': 0.008849613009500636, 'batch_size': 102, 'beta_1': 0.8216644291014927, 'beta_2': 0.9981832607828609, 'hidden_layer_sizes': (256, 128, 64, 32), 'learning_rate_init': 0.0014959558488456285, 'solver': 'lbfgs', 'outer_params': {'cv_iterations': 10, 'early_stopping': True, 'cv_size': 5, 'validation_fraction': 0.15, 'hyperopt_evals': 50, 'n_iter_no_change': 50, 'max_iter': 1000}}",0.7269037195866463,0.08297132982277314,"{'recall': [0.7727272727272727, 0.6363636363636364, 0.5, 0.6666666666666666, 0.8095238095238095], 'precision': [0.85, 0.8235294117647058, 0.7857142857142857, 0.6666666666666666, 0.85], 'accuracy': [0.936, 0.912, 0.8870967741935484, 0.8870967741935484, 0.9435483870967742], 'f1': [0.8095238095238095, 0.717948717948718, 0.6111111111111112, 0.6666666666666666, 0.8292682926829269], 'roc_auc': [0.9417475728155341, 0.9024713150926743, 0.9099821746880571, 0.9251040221914009, 0.9389736477115118], 'area_under_pr': [0.8854978939220826, 0.7872614108452312, 0.7340773327978283, 0.7128059258497605, 0.9002287464693481], 'lift': [5.6818181818181825, 5.208333333333333, 4.227272727272727, 4.428571428571429, 5.904761904761905]}",./output/modelsaves/ageconditions/mlp/202310-0311-4322-ff2a1a0c-31e0-48a0-8737-65e163cc5c6d//202310-0311-4322-ff2a1a0c-31e0-48a0-8737-65e163cc5c6d,636.4119343757629
202310-0311-5359-173fb7e9-62c4-4bb8-82b8-f95a566cb4f6,"{'dataset': 'iris', 'model': 'tabnet', 'best_params': {}, 'param_grid': {'virtual_batch_size_ratio': [0.125, 0.25, 0.5, 1.0], 'batch_size': [32, 64, 128, 256], 'weights': [0, 1], 'mask_type': ['sparsemax', 'entmax'], 'n_d': [6, 32], 'n_steps': [1, 6], 'gamma': [1.0, 2.0], 'n_independent': [1, 3], 'n_shared': [1, 3], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",iris,tabnet,hyperopt_kfold,accuracy,"{'AdamW_weight_decay': 5.156738931047346e-05, 'Adam_weight_decay': 2.43561878417932e-05, 'ExponentialLR_gamma': 0.9366847077963721, 'ReduceLROnPlateau_factor': 0.6919985644348331, 'ReduceLROnPlateau_patience': 4, 'batch_size': 37, 'gamma': 1.9360362856903945, 'mask_type': 'sparsemax', 'n_d': 20, 'n_independent': 1, 'n_shared': 3, 'n_steps': 4, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>, 'virtual_batch_size_ratio': 0.25, 'weights': 0, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 16, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 10}}",0.9733333333333334,0.03265986323710903,"{'accuracy': [1.0, 1.0, 0.9333333333333333, 1.0, 0.9333333333333333], 'f1': [1.0, 1.0, 0.9333333333333333, 1.0, 0.9326599326599326]}",./output/modelsaves/iris/tabnet/202310-0311-5359-173fb7e9-62c4-4bb8-82b8-f95a566cb4f6//202310-0311-5359-173fb7e9-62c4-4bb8-82b8-f95a566cb4f6,3812.544846534729
202310-0311-1050-9b5dfdeb-3cf2-49e3-aecc-616412b18282,"{'dataset': 'titanic', 'model': 'tabtransformer', 'best_params': {}, 'param_grid': {'batch_size': [32, 64, 128, 256], 'embedding_bias': [True, False], 'embedding_initialization': ['kaiming_uniform', 'kaiming_normal'], 'shared_embedding_fraction': [0.125, 0.25, 0.5], 'num_attn_blocks': [4, 10], 'attn_dropout': [0.05, 0.3], 'add_norm_dropout': [0.05, 0.3], 'ff_dropout': [0.05, 0.3], 'ff_hidden_multiplier': [2, 6], 'transformer_activation': ['GEGLU', 'ReGLU', 'SwiGLU'], 'embedding_dropout': [0.05, 0.3], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",titanic,tabtransformer,hyperopt_kfold,roc_auc,"{'AdamW_weight_decay': 1.0281135416111879e-05, 'Adam_weight_decay': 1.2289218851195555e-05, 'ExponentialLR_gamma': 0.9483345950379792, 'ReduceLROnPlateau_factor': 0.24308397638652002, 'ReduceLROnPlateau_patience': 4, 'add_norm_dropout': 0.08608177924350335, 'attn_dropout': 0.10353529201125497, 'batch_size': 162, 'embedding_bias': True, 'embedding_dropout': 0.14718073364490872, 'embedding_initialization': 'kaiming_uniform', 'ff_dropout': 0.1068111369597474, 'ff_hidden_multiplier': 6, 'num_attn_blocks': 7, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>, 'shared_embedding_fraction': 0.24178469855688012, 'transformer_activation': 'GEGLU', 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 16, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 10}}",0.8556348143202597,0.015616554341066636,"{'recall': [0.7101449275362319, 0.7058823529411765, 0.6176470588235294, 0.6617647058823529, 0.8115942028985508], 'precision': [0.7101449275362319, 0.7058823529411765, 0.7241379310344828, 0.8035714285714286, 0.7368421052631579], 'accuracy': [0.776536312849162, 0.7752808988764045, 0.7640449438202247, 0.8089887640449438, 0.8146067415730337], 'f1': [0.7101449275362319, 0.7058823529411765, 0.6666666666666667, 0.7258064516129031, 0.7724137931034482], 'roc_auc': [0.8643610013175229, 0.8429812834224599, 0.8424465240641711, 0.8459893048128341, 0.8823959579843107], 'area_under_pr': [0.8203841518485278, 0.8159583054849707, 0.8120803723287817, 0.8444825137423904, 0.8413720379157963], 'lift': [2.289002557544757, 2.6176470588235294, 2.6176470588235294, 2.6176470588235294, 2.4279624893435634]}",./output/modelsaves/titanic/tabtransformer/202310-0311-1050-9b5dfdeb-3cf2-49e3-aecc-616412b18282//202310-0311-1050-9b5dfdeb-3cf2-49e3-aecc-616412b18282,6553.09139418602
202310-0313-0003-5828de04-bef6-459a-8597-6502b05b4188,"{'dataset': 'breastcancer', 'model': 'tabtransformer', 'best_params': {}, 'param_grid': {'batch_size': [32, 64, 128, 256], 'embedding_bias': [True, False], 'embedding_initialization': ['kaiming_uniform', 'kaiming_normal'], 'shared_embedding_fraction': [0.125, 0.25, 0.5], 'num_attn_blocks': [4, 10], 'attn_dropout': [0.05, 0.3], 'add_norm_dropout': [0.05, 0.3], 'ff_dropout': [0.05, 0.3], 'ff_hidden_multiplier': [2, 6], 'transformer_activation': ['GEGLU', 'ReGLU', 'SwiGLU'], 'embedding_dropout': [0.05, 0.3], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",breastcancer,tabtransformer,hyperopt_kfold,f1,"{'AdamW_weight_decay': 1.4983299066774802e-05, 'Adam_weight_decay': 3.3050480558396946e-05, 'ExponentialLR_gamma': 0.9771603545076043, 'ReduceLROnPlateau_factor': 0.1241198877593532, 'ReduceLROnPlateau_patience': 5, 'add_norm_dropout': 0.1900878635483734, 'attn_dropout': 0.0828385433406772, 'batch_size': 47, 'embedding_bias': True, 'embedding_dropout': 0.0987593348393527, 'embedding_initialization': 'kaiming_uniform', 'ff_dropout': 0.12593431858971033, 'ff_hidden_multiplier': 5, 'num_attn_blocks': 10, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>, 'shared_embedding_fraction': 0.2488767287123551, 'transformer_activation': 'GEGLU', 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 16, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 10}}",0.9875066527866085,0.005084992716339378,"{'recall': [1.0, 0.9859154929577465, 1.0, 1.0, 0.9859154929577465], 'precision': [0.9861111111111112, 0.9859154929577465, 0.96, 0.9863013698630136, 0.9859154929577465], 'accuracy': [0.9912280701754386, 0.9824561403508771, 0.9736842105263158, 0.9912280701754386, 0.9823008849557522], 'f1': [0.993006993006993, 0.9859154929577465, 0.9795918367346939, 0.993103448275862, 0.9859154929577465], 'roc_auc': [0.9996724533245988, 0.9977071732721913, 0.9871031746031745, 1.0, 0.9989939637826961], 'area_under_pr': [0.9998043818466351, 0.9987041326061361, 0.9907106454015269, 0.9999999999999999, 0.9994048012645511], 'lift': [1.6056338028169013, 1.6056338028169013, 1.5833333333333335, 1.5833333333333335, 1.591549295774648]}",./output/modelsaves/breastcancer/tabtransformer/202310-0313-0003-5828de04-bef6-459a-8597-6502b05b4188//202310-0313-0003-5828de04-bef6-459a-8597-6502b05b4188,1078.7344937324524
202310-0305-0204-8f377987-a5ba-4184-9f01-5a9c1b251400,"{'dataset': 'creditcard', 'model': 'categoryembedding', 'best_params': {}, 'param_grid': {'batch_size': [1024, 2048, 4096], 'layers': ['128-64-32', '128-64-32-16', '256-128-64'], 'activation': ['ReLU', 'LeakyReLU', 'Tanh'], 'initialization': ['kaiming', 'xavier'], 'dropout': [0.0, 0.3], 'embedding_dropout': [0.0, 0.3], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",creditcard,categoryembedding,hyperopt_kfold,lift,"{'AdamW_weight_decay': 4.9936400141347456e-05, 'Adam_weight_decay': 7.582175026820124e-05, 'ExponentialLR_gamma': 0.9398703877606966, 'ReduceLROnPlateau_factor': 0.5363256403016615, 'ReduceLROnPlateau_patience': 3, 'activation': 'Tanh', 'batch_size': 3792, 'dropout': 0.14107735794557316, 'embedding_dropout': 0.00938199862390901, 'initialization': 'xavier', 'layers': '256-128-64', 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 16, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 5}}",9.695352715268946,0.12876059108985044,"{'recall': [0.9292929292929293, 0.9494949494949495, 0.9387755102040817, 0.8979591836734694, 0.8877551020408163], 'precision': [0.04081632653061224, 0.06988847583643122, 0.03173508106243532, 0.0641399416909621, 0.05451127819548872], 'accuracy': [0.961921983076437, 0.9779502124223166, 0.9506153332982216, 0.9772827021997507, 0.9733150752269096], 'f1': [0.07819804504887376, 0.13019390581717452, 0.061394728061394725, 0.11972789115646257, 0.10271546635182999], 'roc_auc': [0.988680750845955, 0.9881429528388008, 0.9923117216568142, 0.9744254629907113, 0.9871530642751447], 'area_under_pr': [0.6888051261304006, 0.7579370717786131, 0.7878337204184875, 0.7659037945754635, 0.6804893165480125], 'lift': [9.798323828169334, 9.59629653274316, 9.898132954024305, 9.592005130703965, 9.592005130703965]}",./output/modelsaves/creditcard/categoryembedding/202310-0305-0204-8f377987-a5ba-4184-9f01-5a9c1b251400//202310-0305-0204-8f377987-a5ba-4184-9f01-5a9c1b251400,30081.84154844284
202310-0313-1801-24f485a6-b4e9-45a7-99c1-739ff4de9798,"{'dataset': 'ageconditions', 'model': 'tabtransformer', 'best_params': {}, 'param_grid': {'batch_size': [32, 64, 128, 256], 'embedding_bias': [True, False], 'embedding_initialization': ['kaiming_uniform', 'kaiming_normal'], 'shared_embedding_fraction': [0.125, 0.25, 0.5], 'num_attn_blocks': [4, 10], 'attn_dropout': [0.05, 0.3], 'add_norm_dropout': [0.05, 0.3], 'ff_dropout': [0.05, 0.3], 'ff_hidden_multiplier': [2, 6], 'transformer_activation': ['GEGLU', 'ReGLU', 'SwiGLU'], 'embedding_dropout': [0.05, 0.3], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",ageconditions,tabtransformer,hyperopt_kfold,f1,"{'AdamW_weight_decay': 1.3073155121555143e-05, 'Adam_weight_decay': 1.6725307544615988e-05, 'ExponentialLR_gamma': 0.9479394240314398, 'ReduceLROnPlateau_factor': 0.5137725183487856, 'ReduceLROnPlateau_patience': 5, 'add_norm_dropout': 0.17221736861798337, 'attn_dropout': 0.13103215365271959, 'batch_size': 112, 'embedding_bias': True, 'embedding_dropout': 0.0716893799077964, 'embedding_initialization': 'kaiming_uniform', 'ff_dropout': 0.2839619185700368, 'ff_hidden_multiplier': 4, 'num_attn_blocks': 9, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'shared_embedding_fraction': 0.3985703567693482, 'transformer_activation': 'ReGLU', 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 16, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 10}}",0.7009416782678238,0.025987440000207033,"{'recall': [0.8636363636363636, 0.8181818181818182, 0.7727272727272727, 0.8095238095238095, 0.8571428571428571], 'precision': [0.6333333333333333, 0.5806451612903226, 0.6071428571428571, 0.5862068965517241, 0.6428571428571429], 'accuracy': [0.888, 0.864, 0.8709677419354839, 0.8709677419354839, 0.8951612903225806], 'f1': [0.7307692307692307, 0.679245283018868, 0.68, 0.68, 0.7346938775510204], 'roc_auc': [0.9126213592233009, 0.8473080317740511, 0.8792335115864528, 0.9195561719833564, 0.9167822468793343], 'area_under_pr': [0.8022691976199818, 0.6496889759724752, 0.5713564539904035, 0.7364351014500041, 0.7388418222705733], 'lift': [4.734848484848485, 4.261363636363637, 3.7575757575757573, 3.9365079365079367, 4.920634920634921]}",./output/modelsaves/ageconditions/tabtransformer/202310-0313-1801-24f485a6-b4e9-45a7-99c1-739ff4de9798//202310-0313-1801-24f485a6-b4e9-45a7-99c1-739ff4de9798,1133.3688652515411
202310-0313-3655-c49845db-41ef-4186-bf09-841aa0561f32,"{'dataset': 'iris', 'model': 'gandalf', 'best_params': {}, 'param_grid': {'batch_size': [32, 64, 128, 256], 'gflu_stages': [4, 10], 'gflu_dropout': [0.0, 0.3], 'embedding_dropout': [0.0, 0.3], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",iris,gandalf,hyperopt_kfold,accuracy,"{'AdamW_weight_decay': 4.270355543394315e-05, 'Adam_weight_decay': 2.3603143415207604e-05, 'ExponentialLR_gamma': 0.9250312316270729, 'ReduceLROnPlateau_factor': 0.8893683097454737, 'ReduceLROnPlateau_patience': 4, 'batch_size': 122, 'embedding_dropout': 0.04349797219708555, 'gflu_dropout': 0.29881310115435095, 'gflu_stages': 4, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 16, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 10}}",0.9800000000000001,0.02666666666666666,"{'accuracy': [1.0, 1.0, 0.9333333333333333, 1.0, 0.9666666666666667], 'f1': [1.0, 1.0, 0.9333333333333333, 1.0, 0.9665831244778613]}",./output/modelsaves/iris/gandalf/202310-0313-3655-c49845db-41ef-4186-bf09-841aa0561f32//202310-0313-3655-c49845db-41ef-4186-bf09-841aa0561f32,1863.4715213775635
202310-0312-5731-f7f6386b-0aa2-437d-bc49-4e091538efaf,"{'dataset': 'titanic', 'model': 'tabnet', 'best_params': {}, 'param_grid': {'virtual_batch_size_ratio': [0.125, 0.25, 0.5, 1.0], 'batch_size': [32, 64, 128, 256], 'weights': [0, 1], 'mask_type': ['sparsemax', 'entmax'], 'n_d': [6, 32], 'n_steps': [1, 6], 'gamma': [1.0, 2.0], 'n_independent': [1, 3], 'n_shared': [1, 3], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",titanic,tabnet,hyperopt_kfold,roc_auc,"{'AdamW_weight_decay': 3.0518114945089195e-05, 'Adam_weight_decay': 5.558444026857581e-05, 'ExponentialLR_gamma': 0.9126770808754974, 'ReduceLROnPlateau_factor': 0.24798386878757261, 'ReduceLROnPlateau_patience': 3, 'batch_size': 58, 'gamma': 1.3534686010334578, 'mask_type': 'entmax', 'n_d': 10, 'n_independent': 1, 'n_shared': 1, 'n_steps': 1, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>, 'virtual_batch_size_ratio': 0.5, 'weights': 0, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 16, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 10}}",0.8687105391890231,0.02226928645106577,"{'recall': [0.6231884057971014, 0.7352941176470589, 0.6764705882352942, 0.7647058823529411, 0.8695652173913043], 'precision': [0.86, 0.7142857142857143, 0.71875, 0.7428571428571429, 0.6593406593406593], 'accuracy': [0.8156424581005587, 0.7865168539325843, 0.7752808988764045, 0.8089887640449438, 0.7752808988764045], 'f1': [0.7226890756302521, 0.7246376811594202, 0.696969696969697, 0.7536231884057971, 0.75], 'roc_auc': [0.9061923583662713, 0.8506684491978609, 0.8439171122994653, 0.8636363636363636, 0.8791384124451538], 'area_under_pr': [0.8388479966331724, 0.84604905485849, 0.8201073792097111, 0.8582018978622832, 0.8310131302089075], 'lift': [2.441602728047741, 2.6176470588235294, 2.6176470588235294, 2.6176470588235294, 2.4279624893435634]}",./output/modelsaves/titanic/tabnet/202310-0312-5731-f7f6386b-0aa2-437d-bc49-4e091538efaf//202310-0312-5731-f7f6386b-0aa2-437d-bc49-4e091538efaf,4589.36514043808
202310-0305-1247-18ecab32-c2bb-480a-a9ac-95d76642de74,"{'dataset': 'titanic', 'model': 'gate', 'best_params': {}, 'param_grid': {'batch_size': [32, 64, 128, 256], 'tree_depth': [4, 7], 'num_trees': [4, 10], 'chain_trees': [False, True], 'gflu_stages': [3, 8], 'gflu_dropout': [0.0, 0.05], 'tree_dropout': [0.0, 0.05], 'tree_wise_attention_dropout': [0.0, 0.05], 'embedding_dropout': [0, 0.2], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",titanic,gate,hyperopt_kfold,roc_auc,"{'AdamW_weight_decay': 5.493747562277505e-05, 'Adam_weight_decay': 3.961895563756546e-05, 'ExponentialLR_gamma': 0.9001406622075305, 'ReduceLROnPlateau_factor': 0.1660899475602357, 'ReduceLROnPlateau_patience': 4, 'batch_size': 105, 'chain_trees': True, 'embedding_dropout': 0, 'gflu_dropout': 0.038667476874155664, 'gflu_stages': 4, 'num_trees': 7, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'tree_depth': 4, 'tree_dropout': 0.010685858807269799, 'tree_wise_attention_dropout': 0.0070355743292431884, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 5}}",0.8681734690104783,0.027653304180783402,"{'recall': [0.8115942028985508, 0.7647058823529411, 0.6911764705882353, 0.7352941176470589, 0.8115942028985508], 'precision': [0.7567567567567568, 0.7536231884057971, 0.7230769230769231, 0.7352941176470589, 0.7777777777777778], 'accuracy': [0.8268156424581006, 0.8146067415730337, 0.7808988764044944, 0.797752808988764, 0.8370786516853933], 'f1': [0.7832167832167832, 0.759124087591241, 0.7067669172932332, 0.735294117647059, 0.7943262411347518], 'roc_auc': [0.905862977602108, 0.8605614973262031, 0.8218582887700535, 0.8704545454545454, 0.8821300358994814], 'area_under_pr': [0.8670475532031534, 0.8301096358220079, 0.7847691553084514, 0.8625516756897609, 0.8553674984992917], 'lift': [2.441602728047741, 2.463667820069204, 2.463667820069204, 2.6176470588235294, 2.4279624893435634]}",./output/modelsaves/titanic/gate/202310-0305-1247-18ecab32-c2bb-480a-a9ac-95d76642de74//202310-0305-1247-18ecab32-c2bb-480a-a9ac-95d76642de74,32523.661009788513
202310-0310-3459-aaff1b40-d67b-4673-a227-830b9fff0004,"{'dataset': 'iris', 'model': 's1dcnn', 'best_params': {}, 'param_grid': {'batch_size': [32, 64, 128, 256], 'hidden_size': [1024, 2048, 4096], 'optimizer_fn': {'Adam': {'weight_decay': [1e-05, 0.001], 'learning_rate': [0.0001, 0.01]}, 'AdamW': {'weight_decay': [1e-05, 0.001], 'learning_rate': [0.0001, 0.01]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",iris,s1dcnn,hyperopt_kfold,accuracy,"{'AdamW_learning_rate': 0.007533305910346311, 'AdamW_weight_decay': 2.0120874983312022e-05, 'Adam_learning_rate': 0.00017769505373181943, 'Adam_weight_decay': 0.0007683558237875469, 'ExponentialLR_gamma': 0.9388434108641118, 'ReduceLROnPlateau_factor': 0.38345702967617984, 'ReduceLROnPlateau_patience': 4, 'batch_size': 35, 'hidden_size': 1024, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'outer_params': {'hyperopt_evals': 50, 'max_epochs': 1000, 'early_stopping': True, 'shuffle': True, 'validation_fraction': 0.15, 'early_stopping_patience': 10}}",0.9733333333333333,0.038873012632301994,"{'accuracy': [1.0, 1.0, 0.9, 1.0, 0.9666666666666667], 'f1': [1.0, 1.0, 0.8997493734335841, 1.0, 0.9665831244778613]}",./output/modelsaves/iris/s1dcnn/202310-0310-3459-aaff1b40-d67b-4673-a227-830b9fff0004//202310-0310-3459-aaff1b40-d67b-4673-a227-830b9fff0004,14533.763449907303
202310-0314-0758-137645c1-9941-455a-bc0b-edd418f9d122,"{'dataset': 'titanic', 'model': 'gandalf', 'best_params': {}, 'param_grid': {'batch_size': [32, 64, 128, 256], 'gflu_stages': [4, 10], 'gflu_dropout': [0.0, 0.3], 'embedding_dropout': [0.0, 0.3], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",titanic,gandalf,hyperopt_kfold,roc_auc,"{'AdamW_weight_decay': 1.8741932207211996e-05, 'Adam_weight_decay': 3.816736745734649e-05, 'ExponentialLR_gamma': 0.9172107426966293, 'ReduceLROnPlateau_factor': 0.219770658565823, 'ReduceLROnPlateau_patience': 5, 'batch_size': 180, 'embedding_dropout': 0.24100919859776435, 'gflu_dropout': 0.22337411430571577, 'gflu_stages': 10, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 16, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 10}}",0.8769247692912607,0.022437328635668663,"{'recall': [0.8115942028985508, 0.7794117647058824, 0.6911764705882353, 0.7352941176470589, 0.8115942028985508], 'precision': [0.7777777777777778, 0.726027397260274, 0.6911764705882353, 0.7692307692307693, 0.7567567567567568], 'accuracy': [0.8379888268156425, 0.8033707865168539, 0.7640449438202247, 0.8146067415730337, 0.8258426966292135], 'f1': [0.7943262411347518, 0.75177304964539, 0.6911764705882353, 0.7518796992481205, 0.7832167832167832], 'roc_auc': [0.9113965744400526, 0.8768716577540108, 0.8419117647058824, 0.8700534759358288, 0.8843903736205292], 'area_under_pr': [0.8730089351368684, 0.8482416802259845, 0.8052469911031512, 0.8650575938897049, 0.8515756397662229], 'lift': [2.441602728047741, 2.463667820069204, 2.463667820069204, 2.6176470588235294, 2.2762148337595907]}",./output/modelsaves/titanic/gandalf/202310-0314-0758-137645c1-9941-455a-bc0b-edd418f9d122//202310-0314-0758-137645c1-9941-455a-bc0b-edd418f9d122,3065.438502073288
202310-0314-5904-9ef02555-5ed8-455b-93f1-8a3e854eebc6,"{'dataset': 'breastcancer', 'model': 'gandalf', 'best_params': {}, 'param_grid': {'batch_size': [32, 64, 128, 256], 'gflu_stages': [4, 10], 'gflu_dropout': [0.0, 0.3], 'embedding_dropout': [0.0, 0.3], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",breastcancer,gandalf,hyperopt_kfold,f1,"{'AdamW_weight_decay': 2.3837890787467192e-05, 'Adam_weight_decay': 1.2096910102738744e-05, 'ExponentialLR_gamma': 0.9631502656727748, 'ReduceLROnPlateau_factor': 0.19692898274849846, 'ReduceLROnPlateau_patience': 4, 'batch_size': 84, 'embedding_dropout': 0.26838306804022954, 'gflu_dropout': 0.04748079310604984, 'gflu_stages': 9, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 16, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 10}}",0.9889067004246052,0.005449979738766625,"{'recall': [0.9859154929577465, 1.0, 1.0, 0.9861111111111112, 1.0], 'precision': [1.0, 0.9594594594594594, 0.972972972972973, 1.0, 0.9861111111111112], 'accuracy': [0.9912280701754386, 0.9736842105263158, 0.9824561403508771, 0.9912280701754386, 0.9911504424778761], 'f1': [0.9929078014184397, 0.9793103448275862, 0.9863013698630138, 0.993006993006993, 0.993006993006993], 'roc_auc': [0.9993449066491975, 0.9970520799213888, 0.9837962962962963, 1.0, 0.9989939637826961], 'area_under_pr': [0.9996141230947329, 0.9981629912500206, 0.9881721458121433, 1.0, 0.9994048012645513], 'lift': [1.6056338028169013, 1.6056338028169013, 1.5833333333333335, 1.5833333333333335, 1.591549295774648]}",./output/modelsaves/breastcancer/gandalf/202310-0314-5904-9ef02555-5ed8-455b-93f1-8a3e854eebc6//202310-0314-5904-9ef02555-5ed8-455b-93f1-8a3e854eebc6,2042.5990598201752
202310-0315-3306-75c4e3c8-84da-45c7-bae8-cdc143d29da6,"{'dataset': 'ageconditions', 'model': 'gandalf', 'best_params': {}, 'param_grid': {'batch_size': [32, 64, 128, 256], 'gflu_stages': [4, 10], 'gflu_dropout': [0.0, 0.3], 'embedding_dropout': [0.0, 0.3], 'optimizer_fn': {'Adam': {'weight_decay': [0.0001, 1e-05]}, 'AdamW': {'weight_decay': [0.0001, 1e-05]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.9], 'patience': [3, 5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}",ageconditions,gandalf,hyperopt_kfold,f1,"{'AdamW_weight_decay': 5.9615011507161995e-05, 'Adam_weight_decay': 5.7147491844042206e-05, 'ExponentialLR_gamma': 0.9308439521263807, 'ReduceLROnPlateau_factor': 0.15291156992064192, 'ReduceLROnPlateau_patience': 5, 'batch_size': 49, 'embedding_dropout': 0.18834271745030104, 'gflu_dropout': 0.22168983770251444, 'gflu_stages': 10, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'outer_params': {'hyperopt_evals': 50, 'auto_lr_find': True, 'precision': 16, 'max_epochs': 1000, 'val_size': 0.15, 'early_stopping_patience': 10}}",0.7706217370669197,0.06276270226024905,"{'recall': [0.8636363636363636, 0.8181818181818182, 0.8181818181818182, 0.8095238095238095, 0.9047619047619048], 'precision': [0.7307692307692307, 0.6666666666666666, 0.6666666666666666, 0.6296296296296297, 0.8636363636363636], 'accuracy': [0.92, 0.896, 0.8951612903225806, 0.8870967741935484, 0.9596774193548387], 'f1': [0.7916666666666666, 0.7346938775510203, 0.7346938775510203, 0.7083333333333334, 0.8837209302325582], 'roc_auc': [0.9580759046778464, 0.9258605472197705, 0.927807486631016, 0.927877947295423, 0.9699491447064262], 'area_under_pr': [0.8217036734116604, 0.8226023644085843, 0.7215795281625214, 0.7745255199964474, 0.931047020697618], 'lift': [5.208333333333333, 5.208333333333333, 4.227272727272727, 4.920634920634921, 5.904761904761905]}",./output/modelsaves/ageconditions/gandalf/202310-0315-3306-75c4e3c8-84da-45c7-bae8-cdc143d29da6//202310-0315-3306-75c4e3c8-84da-45c7-bae8-cdc143d29da6,1866.302979707718
