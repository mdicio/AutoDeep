- dataset: titanic
  model: s1dcnn
  best_params: {}
  param_grid:
    outer_params: &id001
      hyperopt_evals: 50
      max_epochs: 1000
      early_stopping: true
      shuffle: true
      validation_fraction: 0.15
      early_stopping_patience: 10
    batch_size: &id002
    - 32
    - 64
    - 128
    - 256
    hidden_size: &id003
    - 1024
    - 2048
    - 4096
    optimizer_fn: &id004
      Adam:
        weight_decay:
        - 1.0e-05
        - 0.001
        learning_rate:
        - 0.0001
        - 0.01
      AdamW:
        weight_decay:
        - 1.0e-05
        - 0.001
        learning_rate:
        - 0.0001
        - 0.01
    scheduler_fn: &id005
      ReduceLROnPlateau:
        factor:
        - 0.1
        - 0.9
        patience:
        - 3
        - 5
      ExponentialLR:
        gamma:
        - 0.9
        - 0.99
- dataset: breastcancer
  model: s1dcnn
  best_params: {}
  param_grid:
    outer_params: *id001
    batch_size: *id002
    hidden_size: *id003
    optimizer_fn: *id004
    scheduler_fn: *id005
- dataset: ageconditions
  model: s1dcnn
  best_params: {}
  param_grid:
    outer_params: *id001
    batch_size: *id002
    hidden_size: *id003
    optimizer_fn: *id004
    scheduler_fn: *id005
- dataset: breastcancer
  model: tabnet
  best_params: {}
  param_grid:
    outer_params: &id006
      hyperopt_evals: 50
      auto_lr_find: true
      precision: 16
      max_epochs: 1000
      val_size: 0.15
      early_stopping_patience: 10
    virtual_batch_size_ratio: &id007
    - 0.125
    - 0.25
    - 0.5
    - 1.0
    batch_size: &id008
    - 32
    - 64
    - 128
    - 256
    weights: &id009
    - 0
    - 1
    mask_type: &id010
    - sparsemax
    - entmax
    n_d: &id011
    - 6
    - 32
    n_steps: &id012
    - 1
    - 6
    gamma: &id013
    - 1.0
    - 2.0
    n_independent: &id014
    - 1
    - 3
    n_shared: &id015
    - 1
    - 3
    optimizer_fn: &id016
      Adam:
        weight_decay:
        - 0.0001
        - 1.0e-05
      AdamW:
        weight_decay:
        - 0.0001
        - 1.0e-05
    scheduler_fn: &id017
      ReduceLROnPlateau:
        factor:
        - 0.1
        - 0.9
        patience:
        - 3
        - 5
      ExponentialLR:
        gamma:
        - 0.9
        - 0.99
- dataset: ageconditions
  model: tabnet
  best_params: {}
  param_grid:
    outer_params: *id006
    virtual_batch_size_ratio: *id007
    batch_size: *id008
    weights: *id009
    mask_type: *id010
    n_d: *id011
    n_steps: *id012
    gamma: *id013
    n_independent: *id014
    n_shared: *id015
    optimizer_fn: *id016
    scheduler_fn: *id017
- dataset: iris
  model: resnet
  best_params: {}
  param_grid:
    outer_params: &id018
      hyperopt_evals: 50
      max_epochs: 1000
      early_stopping: true
      early_stopping_patience: 10
      validation_fraction: 0.15
    batch_size: &id019
    - 32
    - 64
    - 128
    - 256
    resnet_depth: &id020
    - resnet18
    - resnet34
    - resnet50
    optimizer_fn: &id021
      Adam:
        weight_decay:
        - 1.0e-05
        - 0.001
        learning_rate:
        - 0.0001
        - 0.001
      AdamW:
        weight_decay:
        - 1.0e-05
        - 0.001
        learning_rate:
        - 0.0001
        - 0.001
    scheduler_fn: &id022
      ReduceLROnPlateau:
        factor:
        - 0.1
        - 0.9
        patience:
        - 3
        - 5
      ExponentialLR:
        gamma:
        - 0.9
        - 0.99
- dataset: titanic
  model: resnet
  best_params: {}
  param_grid:
    outer_params: *id018
    batch_size: *id019
    resnet_depth: *id020
    optimizer_fn: *id021
    scheduler_fn: *id022
- dataset: breastcancer
  model: resnet
  best_params: {}
  param_grid:
    outer_params: *id018
    batch_size: *id019
    resnet_depth: *id020
    optimizer_fn: *id021
    scheduler_fn: *id022
- dataset: ageconditions
  model: resnet
  best_params: {}
  param_grid:
    outer_params: *id018
    batch_size: *id019
    resnet_depth: *id020
    optimizer_fn: *id021
    scheduler_fn: *id022
- dataset: iris
  model: tabtransformer
  best_params: {}
  param_grid:
    outer_params: &id023
      hyperopt_evals: 50
      auto_lr_find: true
      precision: 16
      max_epochs: 1000
      val_size: 0.15
      early_stopping_patience: 10
    batch_size: &id024
    - 32
    - 64
    - 128
    - 256
    embedding_bias: &id025
    - true
    - false
    embedding_initialization: &id026
    - kaiming_uniform
    - kaiming_normal
    shared_embedding_fraction: &id027
    - 0.125
    - 0.25
    - 0.5
    num_attn_blocks: &id028
    - 4
    - 10
    attn_dropout: &id029
    - 0.05
    - 0.3
    add_norm_dropout: &id030
    - 0.05
    - 0.3
    ff_dropout: &id031
    - 0.05
    - 0.3
    ff_hidden_multiplier: &id032
    - 2
    - 6
    transformer_activation: &id033
    - GEGLU
    - ReGLU
    - SwiGLU
    embedding_dropout: &id034
    - 0.05
    - 0.3
    optimizer_fn: &id035
      Adam:
        weight_decay:
        - 0.0001
        - 1.0e-05
      AdamW:
        weight_decay:
        - 0.0001
        - 1.0e-05
    scheduler_fn: &id036
      ReduceLROnPlateau:
        factor:
        - 0.1
        - 0.9
        patience:
        - 3
        - 5
      ExponentialLR:
        gamma:
        - 0.9
        - 0.99
- dataset: titanic
  model: tabtransformer
  best_params: {}
  param_grid:
    outer_params: *id023
    batch_size: *id024
    embedding_bias: *id025
    embedding_initialization: *id026
    shared_embedding_fraction: *id027
    num_attn_blocks: *id028
    attn_dropout: *id029
    add_norm_dropout: *id030
    ff_dropout: *id031
    ff_hidden_multiplier: *id032
    transformer_activation: *id033
    embedding_dropout: *id034
    optimizer_fn: *id035
    scheduler_fn: *id036
- dataset: breastcancer
  model: tabtransformer
  best_params: {}
  param_grid:
    outer_params: *id023
    batch_size: *id024
    embedding_bias: *id025
    embedding_initialization: *id026
    shared_embedding_fraction: *id027
    num_attn_blocks: *id028
    attn_dropout: *id029
    add_norm_dropout: *id030
    ff_dropout: *id031
    ff_hidden_multiplier: *id032
    transformer_activation: *id033
    embedding_dropout: *id034
    optimizer_fn: *id035
    scheduler_fn: *id036
- dataset: ageconditions
  model: tabtransformer
  best_params: {}
  param_grid:
    outer_params: *id023
    batch_size: *id024
    embedding_bias: *id025
    embedding_initialization: *id026
    shared_embedding_fraction: *id027
    num_attn_blocks: *id028
    attn_dropout: *id029
    add_norm_dropout: *id030
    ff_dropout: *id031
    ff_hidden_multiplier: *id032
    transformer_activation: *id033
    embedding_dropout: *id034
    optimizer_fn: *id035
    scheduler_fn: *id036
