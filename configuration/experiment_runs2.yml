- dataset: creditcard
  model: categoryembedding
  best_params: {}
  param_grid:
    outer_params: &id001
      hyperopt_evals: 50
      auto_lr_find: true
      precision: 16
      max_epochs: 1000
      val_size: 0.15
      early_stopping_patience: 8
    batch_size: &id002
    - 1024
    - 2048
    - 4096
    layers: &id003
    - 128-64-32
    - 128-64-32-16
    - 256-128-64
    activation: &id004
    - ReLU
    - LeakyReLU
    - Tanh
    initialization: &id005
    - kaiming
    - xavier
    dropout: &id006
    - 0.0
    - 0.3
    embedding_dropout: &id007
    - 0.0
    - 0.3
    optimizer_fn: &id008
      Adam:
        weight_decay:
        - 0.0001
        - 1.0e-05
      AdamW:
        weight_decay:
        - 0.0001
        - 1.0e-05
    scheduler_fn: &id009
      ReduceLROnPlateau:
        factor:
        - 0.1
        - 0.9
        patience:
        - 3
        - 5
      ExponentialLR:
        gamma:
        - 0.9
        - 0.99
- dataset: adult
  model: categoryembedding
  best_params: {}
  param_grid:
    outer_params: *id001
    batch_size: *id002
    layers: *id003
    activation: *id004
    initialization: *id005
    dropout: *id006
    embedding_dropout: *id007
    optimizer_fn: *id008
    scheduler_fn: *id009
- dataset: covertype
  model: categoryembedding
  best_params: {}
  param_grid:
    outer_params: *id001
    batch_size: *id002
    layers: *id003
    activation: *id004
    initialization: *id005
    dropout: *id006
    embedding_dropout: *id007
    optimizer_fn: *id008
    scheduler_fn: *id009
- dataset: ageconditions
  model: categoryembedding
  best_params: {}
  param_grid:
    outer_params:
      hyperopt_evals: 50
      auto_lr_find: true
      precision: 16
      max_epochs: 1000
      val_size: 0.15
      early_stopping_patience: 10
    batch_size:
    - 32
    - 64
    - 128
    - 256
    layers:
    - 128-64-32
    - 128-64-32-16
    - 256-128-64
    activation:
    - ReLU
    - LeakyReLU
    - Tanh
    initialization:
    - kaiming
    - xavier
    dropout:
    - 0.0
    - 0.3
    embedding_dropout:
    - 0.0
    - 0.3
    optimizer_fn:
      Adam:
        weight_decay:
        - 0.0001
        - 1.0e-05
      AdamW:
        weight_decay:
        - 0.0001
        - 1.0e-05
    scheduler_fn:
      ReduceLROnPlateau:
        factor:
        - 0.1
        - 0.9
        patience:
        - 3
        - 5
      ExponentialLR:
        gamma:
        - 0.9
        - 0.99
- dataset: diabetes
  model: categoryembedding
  best_params: {}
  param_grid:
    outer_params: *id001
    batch_size: *id002
    layers: *id003
    activation: *id004
    initialization: *id005
    dropout: *id006
    embedding_dropout: *id007
    optimizer_fn: *id008
    scheduler_fn: *id009
