- dataset: titanic
  model: xgb
  best_params: {}
  param_grid:
    outer_params: &id001
      hyperopt_evals: 10
    n_estimators: &id002
    - 100
    - 300
    validation_fraction: &id003
    - 0.2
    max_bin: &id004
    - 128
    - 512
    tree_method: &id005
    - auto
    max_depth: &id006
    - 4
    - 12
    learning_rate: &id007
    - 0.01
    - 0.31
    subsample: &id008
    - 0.7
    - 1.0
    colsample_bytree: &id009
    - 0.7
    - 1.0
    min_child_weight: &id010
    - 1
    - 10
    alpha: &id011
    - 0.0
    - 5.0
    gamma: &id012
    - 0.0
    - 5.0
    lambda: &id013
    - 0.0
    - 5.0
- dataset: titanic
  model: mlp
  best_params: {}
  param_grid:
    outer_params: &id014
      cv_iterations: 32
      early_stopping: true
      cv_size: 5
    hidden_layer_sizes: &id015
    - - 16
      - 16
    - - 16
      - 8
    - - 32
      - 16
    - - 45
      - 20
    activation: &id016
    - relu
    - tanh
    - logistic
    solver: &id017
    - adam
    - lbfgs
    alpha: &id018
    - 0.0001
    - 0.001
    - 0.01
    learning_rate_init: &id019
    - 0.001
    - 0.01
    - 0.1
    beta_1: &id020
    - 0.9
    - 0.99
    - 0.8
    beta_2: &id021
    - 0.999
    - 0.9
    n_iter_no_change: &id022
    - 10
    - 20
    validation_fraction: &id023
    - 0.1
    - 0.15
    - 0.2
    max_iter: &id024
    - 100
    - 500
    batch_size: &id025
    - 32
    - 64
    - 128
    - 512
    - 1024
- dataset: titanic
  model: resnet
  best_params: {}
  param_grid:
    outer_params: &id026
      hyperopt_evals: 64
      num_epochs: 100
      early_stopping: true
    learning_rate: &id027
    - 0.0001
    - 0.001
    patience: &id028
    - 5
    - 21
    batch_size: &id029
    - 32
    - 64
    - 128
    - 256
    validation_fraction: &id030
    - 0.1
    - 0.3
    early_stopping_patience: &id031
    - 5
    - 25
    scheduler_factor: &id032
    - 0.1
    - 0.9
    scheduler_patience: &id033
    - 3
    - 5
- dataset: titanic
  model: s1dcnn
  best_params: {}
  param_grid:
    outer_params: &id034
      hyperopt_evals: 32
      num_epochs: 100
      early_stopping: true
      shuffle: true
    batch_size: &id035
    - 256
    - 2048
    validation_fraction: &id036
    - 0.1
    - 0.3
    early_stopping_patience: &id037
    - 3
    - 7
    learning_rate: &id038
    - 0.01
    - 0.001
    hidden_size: &id039
    - 2048
    - 4096
    scheduler_factor: &id040
    - 0.1
    - 0.9
    scheduler_patience: &id041
    - 3
    - 5
- dataset: titanic
  model: tabnet
  best_params: {}
  param_grid:
    outer_params: &id042
      max_epochs: 1000
      early_stopping_tolerance: 1.0e-06
      hyperopt_evals: 10
      val_size: 0.2
      auto_lr_find: false
    early_stopping_patience: &id043
    - 3
    - 5
    virtual_batch_size_ratio: &id044
    - 0.125
    - 0.25
    - 0.5
    batch_size: &id045
    - 128
    - 256
    - 512
    - 1024
    weights: &id046
    - 0
    - 1
    mask_type: &id047
    - sparsemax
    - entmax
    n_d: &id048
    - 8
    - 16
    n_steps: &id049
    - 3
    - 10
    gamma: &id050
    - 1.0
    - 2.0
    cat_emb_dim: &id051
    - 1
    - 3
    n_independent: &id052
    - 1
    - 5
    n_shared: &id053
    - 1
    - 5
    lambda_sparse: &id054
    - 0.001
    - 0.01
    momentum: &id055
    - 0.001
    - 0.4
    clip_value: &id056
    - 1
    - 2
    optimizer_fn: &id057
      Adam:
        lr:
        - 0.001
        weight_decay:
        - 0.0001
    scheduler_fn: &id058
      ReduceLROnPlateau:
        factor:
        - 0.1
        - 0.9
        patience:
        - 3
        - 5
- dataset: titanic
  model: gate
  best_params: {}
  param_grid:
    outer_params: &id059
      hyperopt_evals: 10
      auto_lr_find: false
      max_epochs: 300
      val_size: 0.2
    early_stopping_patience: &id060
    - 3
    - 5
    batch_size: &id061
    - 128
    - 256
    - 512
    - 1024
    tree_depth: &id062
    - 4
    - 12
    num_trees: &id063
    - 6
    - 16
    chain_trees: &id064
    - true
    - false
    gflu_stages: &id065
    - 2
    - 4
    optimizer_fn: &id066
      Adam:
        lr:
        - 0.001
        weight_decay:
        - 0.0001
    scheduler_fn: &id067
      ReduceLROnPlateau:
        factor:
        - 0.1
        - 0.9
        patience:
        - 3
        - 5
- dataset: titanic
  model: categoryembedding
  best_params: {}
  param_grid:
    outer_params: &id068
      max_epochs: 300
      early_stopping_tolerance: 1.0e-06
      hyperopt_evals: 10
      val_size: 0.2
      auto_lr_find: false
    early_stopping_patience: &id069
    - 3
    - 5
    batch_size: &id070
    - 128
    - 256
    - 512
    - 1024
    learning_rate: &id071
    - 0.001
    - 0.0001
    optimizer_fn: &id072
      Adam:
        lr:
        - 0.001
        - 0.0001
        weight_decay:
        - 0.0001
        - 0.3
    scheduler_fn: &id073
      ReduceLROnPlateau:
        factor:
        - 0.1
        - 0.9
        patience:
        - 4
        - 9
- dataset: titanic
  model: fttransformer
  best_params: {}
  param_grid:
    outer_params: &id074
      max_epochs: 300
      early_stopping_tolerance: 1.0e-06
      hyperopt_evals: 10
      val_size: 0.2
      auto_lr_find: false
    early_stopping_patience: &id075
    - 3
    - 5
    batch_size: &id076
    - 128
    - 256
    - 512
    - 1024
    input_embed_dim: &id077
    - 16
    - 32
    - 64
    embedding_initialization: &id078
    - kaiming_uniform
    - kaiming_normal
    embedding_bias: &id079
    - true
    - false
    share_embedding: &id080
    - true
    - false
    share_embedding_strategy: &id081
    - add
    - fraction
    - add
    shared_embedding_fraction: &id082
    - 0.1
    - 0.25
    - 0.5
    attn_feature_importance: &id083
    - true
    - false
    num_heads: &id084
    - 6
    - 8
    - 10
    num_attn_blocks: &id085
    - 4
    - 6
    - 8
    transformer_head_dim: &id086
    - 64
    - 128
    attn_dropout: &id087
    - 0.05
    - 0.1
    - 0.15
    add_norm_dropout: &id088
    - 0.05
    - 0.1
    - 0.15
    ff_dropout: &id089
    - 0.05
    - 0.1
    - 0.15
    ff_hidden_multiplier: &id090
    - 3
    - 4
    - 5
    transformer_activation: &id091
    - ReLU
    - GEGLU
    - SwiGLU
    embedding_dropout: &id092
    - 0.05
    - 0.1
    - 0.15
    batch_norm_continuous_input: &id093
    - false
    - true
    learning_rate: &id094
    - 0.0005
    - 0.001
    - 0.002
    optimizer_fn: &id095
      Adam:
        lr:
        - 0.001
        - 0.0001
        weight_decay:
        - 0.0001
        - 0.3
    scheduler_fn: &id096
      ReduceLROnPlateau:
        factor:
        - 0.1
        - 0.9
        patience:
        - 4
        - 9
- dataset: titanic
  model: gandalf
  best_params: {}
  param_grid:
    outer_params: &id097
      max_epochs: 300
      early_stopping_tolerance: 1.0e-06
      hyperopt_evals: 10
      val_size: 0.2
      auto_lr_find: false
    early_stopping_patience: &id098
    - 3
    - 5
    batch_size: &id099
    - 128
    - 256
    - 512
    - 1024
    optimizer_fn: &id100
      Adam:
        lr:
        - 0.001
        - 0.0001
        weight_decay:
        - 0.0001
        - 0.3
    scheduler_fn: &id101
      ReduceLROnPlateau:
        factor:
        - 0.1
        - 0.9
        patience:
        - 4
        - 9
- dataset: titanic
  model: node
  best_params: {}
  param_grid:
    outer_params: &id102
      max_epochs: 300
      early_stopping_tolerance: 1.0e-06
      hyperopt_evals: 10
      val_size: 0.2
      auto_lr_find: false
    early_stopping_patience: &id103
    - 3
    - 5
    batch_size: &id104
    - 128
    - 256
    - 512
    - 1024
    optimizer_fn: &id105
      Adam:
        lr:
        - 0.001
        - 0.0001
        weight_decay:
        - 0.0001
        - 0.3
    scheduler_fn: &id106
      ReduceLROnPlateau:
        factor:
        - 0.1
        - 0.9
        patience:
        - 4
        - 9
- dataset: housing
  model: xgb
  best_params: {}
  param_grid:
    outer_params: *id001
    n_estimators: *id002
    validation_fraction: *id003
    max_bin: *id004
    tree_method: *id005
    max_depth: *id006
    learning_rate: *id007
    subsample: *id008
    colsample_bytree: *id009
    min_child_weight: *id010
    alpha: *id011
    gamma: *id012
    lambda: *id013
- dataset: housing
  model: mlp
  best_params: {}
  param_grid:
    outer_params: *id014
    hidden_layer_sizes: *id015
    activation: *id016
    solver: *id017
    alpha: *id018
    learning_rate_init: *id019
    beta_1: *id020
    beta_2: *id021
    n_iter_no_change: *id022
    validation_fraction: *id023
    max_iter: *id024
    batch_size: *id025
- dataset: housing
  model: resnet
  best_params: {}
  param_grid:
    outer_params: *id026
    learning_rate: *id027
    patience: *id028
    batch_size: *id029
    validation_fraction: *id030
    early_stopping_patience: *id031
    scheduler_factor: *id032
    scheduler_patience: *id033
- dataset: housing
  model: s1dcnn
  best_params: {}
  param_grid:
    outer_params: *id034
    batch_size: *id035
    validation_fraction: *id036
    early_stopping_patience: *id037
    learning_rate: *id038
    hidden_size: *id039
    scheduler_factor: *id040
    scheduler_patience: *id041
- dataset: housing
  model: tabnet
  best_params: {}
  param_grid:
    outer_params: *id042
    early_stopping_patience: *id043
    virtual_batch_size_ratio: *id044
    batch_size: *id045
    weights: *id046
    mask_type: *id047
    n_d: *id048
    n_steps: *id049
    gamma: *id050
    cat_emb_dim: *id051
    n_independent: *id052
    n_shared: *id053
    lambda_sparse: *id054
    momentum: *id055
    clip_value: *id056
    optimizer_fn: *id057
    scheduler_fn: *id058
- dataset: housing
  model: gate
  best_params: {}
  param_grid:
    outer_params: *id059
    early_stopping_patience: *id060
    batch_size: *id061
    tree_depth: *id062
    num_trees: *id063
    chain_trees: *id064
    gflu_stages: *id065
    optimizer_fn: *id066
    scheduler_fn: *id067
- dataset: housing
  model: categoryembedding
  best_params: {}
  param_grid:
    outer_params: *id068
    early_stopping_patience: *id069
    batch_size: *id070
    learning_rate: *id071
    optimizer_fn: *id072
    scheduler_fn: *id073
- dataset: housing
  model: fttransformer
  best_params: {}
  param_grid:
    outer_params: *id074
    early_stopping_patience: *id075
    batch_size: *id076
    input_embed_dim: *id077
    embedding_initialization: *id078
    embedding_bias: *id079
    share_embedding: *id080
    share_embedding_strategy: *id081
    shared_embedding_fraction: *id082
    attn_feature_importance: *id083
    num_heads: *id084
    num_attn_blocks: *id085
    transformer_head_dim: *id086
    attn_dropout: *id087
    add_norm_dropout: *id088
    ff_dropout: *id089
    ff_hidden_multiplier: *id090
    transformer_activation: *id091
    embedding_dropout: *id092
    batch_norm_continuous_input: *id093
    learning_rate: *id094
    optimizer_fn: *id095
    scheduler_fn: *id096
- dataset: housing
  model: gandalf
  best_params: {}
  param_grid:
    outer_params: *id097
    early_stopping_patience: *id098
    batch_size: *id099
    optimizer_fn: *id100
    scheduler_fn: *id101
- dataset: housing
  model: node
  best_params: {}
  param_grid:
    outer_params: *id102
    early_stopping_patience: *id103
    batch_size: *id104
    optimizer_fn: *id105
    scheduler_fn: *id106
- dataset: adult
  model: xgb
  best_params: {}
  param_grid:
    outer_params: *id001
    n_estimators: *id002
    validation_fraction: *id003
    max_bin: *id004
    tree_method: *id005
    max_depth: *id006
    learning_rate: *id007
    subsample: *id008
    colsample_bytree: *id009
    min_child_weight: *id010
    alpha: *id011
    gamma: *id012
    lambda: *id013
- dataset: adult
  model: mlp
  best_params: {}
  param_grid:
    outer_params: *id014
    hidden_layer_sizes: *id015
    activation: *id016
    solver: *id017
    alpha: *id018
    learning_rate_init: *id019
    beta_1: *id020
    beta_2: *id021
    n_iter_no_change: *id022
    validation_fraction: *id023
    max_iter: *id024
    batch_size: *id025
- dataset: adult
  model: resnet
  best_params: {}
  param_grid:
    outer_params: *id026
    learning_rate: *id027
    patience: *id028
    batch_size: *id029
    validation_fraction: *id030
    early_stopping_patience: *id031
    scheduler_factor: *id032
    scheduler_patience: *id033
- dataset: adult
  model: s1dcnn
  best_params: {}
  param_grid:
    outer_params: *id034
    batch_size: *id035
    validation_fraction: *id036
    early_stopping_patience: *id037
    learning_rate: *id038
    hidden_size: *id039
    scheduler_factor: *id040
    scheduler_patience: *id041
- dataset: adult
  model: tabnet
  best_params: {}
  param_grid:
    outer_params: *id042
    early_stopping_patience: *id043
    virtual_batch_size_ratio: *id044
    batch_size: *id045
    weights: *id046
    mask_type: *id047
    n_d: *id048
    n_steps: *id049
    gamma: *id050
    cat_emb_dim: *id051
    n_independent: *id052
    n_shared: *id053
    lambda_sparse: *id054
    momentum: *id055
    clip_value: *id056
    optimizer_fn: *id057
    scheduler_fn: *id058
- dataset: adult
  model: gate
  best_params: {}
  param_grid:
    outer_params: *id059
    early_stopping_patience: *id060
    batch_size: *id061
    tree_depth: *id062
    num_trees: *id063
    chain_trees: *id064
    gflu_stages: *id065
    optimizer_fn: *id066
    scheduler_fn: *id067
- dataset: adult
  model: categoryembedding
  best_params: {}
  param_grid:
    outer_params: *id068
    early_stopping_patience: *id069
    batch_size: *id070
    learning_rate: *id071
    optimizer_fn: *id072
    scheduler_fn: *id073
- dataset: adult
  model: fttransformer
  best_params: {}
  param_grid:
    outer_params: *id074
    early_stopping_patience: *id075
    batch_size: *id076
    input_embed_dim: *id077
    embedding_initialization: *id078
    embedding_bias: *id079
    share_embedding: *id080
    share_embedding_strategy: *id081
    shared_embedding_fraction: *id082
    attn_feature_importance: *id083
    num_heads: *id084
    num_attn_blocks: *id085
    transformer_head_dim: *id086
    attn_dropout: *id087
    add_norm_dropout: *id088
    ff_dropout: *id089
    ff_hidden_multiplier: *id090
    transformer_activation: *id091
    embedding_dropout: *id092
    batch_norm_continuous_input: *id093
    learning_rate: *id094
    optimizer_fn: *id095
    scheduler_fn: *id096
- dataset: adult
  model: gandalf
  best_params: {}
  param_grid:
    outer_params: *id097
    early_stopping_patience: *id098
    batch_size: *id099
    optimizer_fn: *id100
    scheduler_fn: *id101
- dataset: adult
  model: node
  best_params: {}
  param_grid:
    outer_params: *id102
    early_stopping_patience: *id103
    batch_size: *id104
    optimizer_fn: *id105
    scheduler_fn: *id106
- dataset: heloc
  model: xgb
  best_params: {}
  param_grid:
    outer_params: *id001
    n_estimators: *id002
    validation_fraction: *id003
    max_bin: *id004
    tree_method: *id005
    max_depth: *id006
    learning_rate: *id007
    subsample: *id008
    colsample_bytree: *id009
    min_child_weight: *id010
    alpha: *id011
    gamma: *id012
    lambda: *id013
- dataset: heloc
  model: mlp
  best_params: {}
  param_grid:
    outer_params: *id014
    hidden_layer_sizes: *id015
    activation: *id016
    solver: *id017
    alpha: *id018
    learning_rate_init: *id019
    beta_1: *id020
    beta_2: *id021
    n_iter_no_change: *id022
    validation_fraction: *id023
    max_iter: *id024
    batch_size: *id025
- dataset: heloc
  model: resnet
  best_params: {}
  param_grid:
    outer_params: *id026
    learning_rate: *id027
    patience: *id028
    batch_size: *id029
    validation_fraction: *id030
    early_stopping_patience: *id031
    scheduler_factor: *id032
    scheduler_patience: *id033
- dataset: heloc
  model: s1dcnn
  best_params: {}
  param_grid:
    outer_params: *id034
    batch_size: *id035
    validation_fraction: *id036
    early_stopping_patience: *id037
    learning_rate: *id038
    hidden_size: *id039
    scheduler_factor: *id040
    scheduler_patience: *id041
- dataset: heloc
  model: tabnet
  best_params: {}
  param_grid:
    outer_params: *id042
    early_stopping_patience: *id043
    virtual_batch_size_ratio: *id044
    batch_size: *id045
    weights: *id046
    mask_type: *id047
    n_d: *id048
    n_steps: *id049
    gamma: *id050
    cat_emb_dim: *id051
    n_independent: *id052
    n_shared: *id053
    lambda_sparse: *id054
    momentum: *id055
    clip_value: *id056
    optimizer_fn: *id057
    scheduler_fn: *id058
- dataset: heloc
  model: gate
  best_params: {}
  param_grid:
    outer_params: *id059
    early_stopping_patience: *id060
    batch_size: *id061
    tree_depth: *id062
    num_trees: *id063
    chain_trees: *id064
    gflu_stages: *id065
    optimizer_fn: *id066
    scheduler_fn: *id067
- dataset: heloc
  model: categoryembedding
  best_params: {}
  param_grid:
    outer_params: *id068
    early_stopping_patience: *id069
    batch_size: *id070
    learning_rate: *id071
    optimizer_fn: *id072
    scheduler_fn: *id073
- dataset: heloc
  model: fttransformer
  best_params: {}
  param_grid:
    outer_params: *id074
    early_stopping_patience: *id075
    batch_size: *id076
    input_embed_dim: *id077
    embedding_initialization: *id078
    embedding_bias: *id079
    share_embedding: *id080
    share_embedding_strategy: *id081
    shared_embedding_fraction: *id082
    attn_feature_importance: *id083
    num_heads: *id084
    num_attn_blocks: *id085
    transformer_head_dim: *id086
    attn_dropout: *id087
    add_norm_dropout: *id088
    ff_dropout: *id089
    ff_hidden_multiplier: *id090
    transformer_activation: *id091
    embedding_dropout: *id092
    batch_norm_continuous_input: *id093
    learning_rate: *id094
    optimizer_fn: *id095
    scheduler_fn: *id096
- dataset: heloc
  model: gandalf
  best_params: {}
  param_grid:
    outer_params: *id097
    early_stopping_patience: *id098
    batch_size: *id099
    optimizer_fn: *id100
    scheduler_fn: *id101
- dataset: heloc
  model: node
  best_params: {}
  param_grid:
    outer_params: *id102
    early_stopping_patience: *id103
    batch_size: *id104
    optimizer_fn: *id105
    scheduler_fn: *id106
- dataset: iris
  model: xgb
  best_params: {}
  param_grid:
    outer_params: *id001
    n_estimators: *id002
    validation_fraction: *id003
    max_bin: *id004
    tree_method: *id005
    max_depth: *id006
    learning_rate: *id007
    subsample: *id008
    colsample_bytree: *id009
    min_child_weight: *id010
    alpha: *id011
    gamma: *id012
    lambda: *id013
- dataset: iris
  model: mlp
  best_params: {}
  param_grid:
    outer_params: *id014
    hidden_layer_sizes: *id015
    activation: *id016
    solver: *id017
    alpha: *id018
    learning_rate_init: *id019
    beta_1: *id020
    beta_2: *id021
    n_iter_no_change: *id022
    validation_fraction: *id023
    max_iter: *id024
    batch_size: *id025
- dataset: iris
  model: tabnet
  best_params: {}
  param_grid:
    outer_params: *id042
    early_stopping_patience: *id043
    virtual_batch_size_ratio: *id044
    batch_size: *id045
    weights: *id046
    mask_type: *id047
    n_d: *id048
    n_steps: *id049
    gamma: *id050
    cat_emb_dim: *id051
    n_independent: *id052
    n_shared: *id053
    lambda_sparse: *id054
    momentum: *id055
    clip_value: *id056
    optimizer_fn: *id057
    scheduler_fn: *id058
- dataset: iris
  model: resnet
  best_params: {}
  param_grid:
    outer_params: *id026
    learning_rate: *id027
    patience: *id028
    batch_size: *id029
    validation_fraction: *id030
    early_stopping_patience: *id031
    scheduler_factor: *id032
    scheduler_patience: *id033
- dataset: iris
  model: s1dcnn
  best_params: {}
  param_grid:
    outer_params: *id034
    batch_size: *id035
    validation_fraction: *id036
    early_stopping_patience: *id037
    learning_rate: *id038
    hidden_size: *id039
    scheduler_factor: *id040
    scheduler_patience: *id041
- dataset: iris
  model: gate
  best_params: {}
  param_grid:
    outer_params: *id059
    early_stopping_patience: *id060
    batch_size: *id061
    tree_depth: *id062
    num_trees: *id063
    chain_trees: *id064
    gflu_stages: *id065
    optimizer_fn: *id066
    scheduler_fn: *id067
- dataset: iris
  model: categoryembedding
  best_params: {}
  param_grid:
    outer_params: *id068
    early_stopping_patience: *id069
    batch_size: *id070
    learning_rate: *id071
    optimizer_fn: *id072
    scheduler_fn: *id073
- dataset: iris
  model: fttransformer
  best_params: {}
  param_grid:
    outer_params: *id074
    early_stopping_patience: *id075
    batch_size: *id076
    input_embed_dim: *id077
    embedding_initialization: *id078
    embedding_bias: *id079
    share_embedding: *id080
    share_embedding_strategy: *id081
    shared_embedding_fraction: *id082
    attn_feature_importance: *id083
    num_heads: *id084
    num_attn_blocks: *id085
    transformer_head_dim: *id086
    attn_dropout: *id087
    add_norm_dropout: *id088
    ff_dropout: *id089
    ff_hidden_multiplier: *id090
    transformer_activation: *id091
    embedding_dropout: *id092
    batch_norm_continuous_input: *id093
    learning_rate: *id094
    optimizer_fn: *id095
    scheduler_fn: *id096
- dataset: iris
  model: gandalf
  best_params: {}
  param_grid:
    outer_params: *id097
    early_stopping_patience: *id098
    batch_size: *id099
    optimizer_fn: *id100
    scheduler_fn: *id101
- dataset: iris
  model: node
  best_params: {}
  param_grid:
    outer_params: *id102
    early_stopping_patience: *id103
    batch_size: *id104
    optimizer_fn: *id105
    scheduler_fn: *id106
- dataset: iris
  model: autoint
  best_params: {}
  param_grid:
    outer_params:
      max_epochs: 300
      early_stopping_tolerance: 1.0e-06
      hyperopt_evals: 10
      val_size: 0.2
      auto_lr_find: false
    early_stopping_patience:
    - 3
    - 5
    batch_size:
    - 128
    - 256
    - 512
    - 1024
    optimizer_fn:
      Adam:
        lr:
        - 0.001
        - 0.0001
        weight_decay:
        - 0.0001
        - 0.3
    scheduler_fn:
      ReduceLROnPlateau:
        factor:
        - 0.1
        - 0.9
        patience:
        - 4
        - 9
    attn_embed_dim:
    - 32
    - 16
    - 64
    num_heads:
    - 2
    - 1
    - 8
    num_attn_blocks:
    - 3
    - 1
    - 5
    attn_dropouts:
    - 0.01
    - 0.3
    has_residuals:
    - true
    - true
    - false
    embedding_dim:
    - 16
    - 8
    - 32
    embedding_initialization:
    - kaiming_uniform
    - kaiming_normal
    embedding_bias:
    - true
    - false
    share_embedding:
    - false
    - true
    share_embedding_strategy:
    - fraction
    - add
    shared_embedding_fraction:
    - 0.25
    - 0.1
    - 0.5
    deep_layers:
    - false
    - true
    layers:
    - 128-64-32
    - 64-32
    - 256-128-64-32
    activation:
    - ReLU
    - Tanh
    - LeakyReLU
    use_batch_norm:
    - false
    - true
    initialization:
    - kaiming
    - xavier
    - random
    dropout:
    - 0.01
    - 0.2
    - 0.3
    attention_pooling:
    - false
    - true
    head:
    - LinearHead
    - MixtureDensityHead
    embedding_dropout:
    - 0.1
    - 0.01
    - 0.5
    batch_norm_continuous_input:
    - true
    - false
    learning_rate:
    - 0.001
    - 0.0001
    - 0.01
- dataset: breastcancer
  model: xgb
  best_params: {}
  param_grid:
    outer_params: *id001
    n_estimators: *id002
    validation_fraction: *id003
    max_bin: *id004
    tree_method: *id005
    max_depth: *id006
    learning_rate: *id007
    subsample: *id008
    colsample_bytree: *id009
    min_child_weight: *id010
    alpha: *id011
    gamma: *id012
    lambda: *id013
- dataset: breastcancer
  model: fttransformer
  best_params: {}
  param_grid:
    outer_params: *id074
    early_stopping_patience: *id075
    batch_size: *id076
    input_embed_dim: *id077
    embedding_initialization: *id078
    embedding_bias: *id079
    share_embedding: *id080
    share_embedding_strategy: *id081
    shared_embedding_fraction: *id082
    attn_feature_importance: *id083
    num_heads: *id084
    num_attn_blocks: *id085
    transformer_head_dim: *id086
    attn_dropout: *id087
    add_norm_dropout: *id088
    ff_dropout: *id089
    ff_hidden_multiplier: *id090
    transformer_activation: *id091
    embedding_dropout: *id092
    batch_norm_continuous_input: *id093
    learning_rate: *id094
    optimizer_fn: *id095
    scheduler_fn: *id096
- dataset: breastcancer
  model: mlp
  best_params: {}
  param_grid:
    outer_params: *id014
    hidden_layer_sizes: *id015
    activation: *id016
    solver: *id017
    alpha: *id018
    learning_rate_init: *id019
    beta_1: *id020
    beta_2: *id021
    n_iter_no_change: *id022
    validation_fraction: *id023
    max_iter: *id024
    batch_size: *id025
- dataset: breastcancer
  model: tabnet
  best_params: {}
  param_grid:
    outer_params: *id042
    early_stopping_patience: *id043
    virtual_batch_size_ratio: *id044
    batch_size: *id045
    weights: *id046
    mask_type: *id047
    n_d: *id048
    n_steps: *id049
    gamma: *id050
    cat_emb_dim: *id051
    n_independent: *id052
    n_shared: *id053
    lambda_sparse: *id054
    momentum: *id055
    clip_value: *id056
    optimizer_fn: *id057
    scheduler_fn: *id058
- dataset: breastcancer
  model: resnet
  best_params: {}
  param_grid:
    outer_params: *id026
    learning_rate: *id027
    patience: *id028
    batch_size: *id029
    validation_fraction: *id030
    early_stopping_patience: *id031
    scheduler_factor: *id032
    scheduler_patience: *id033
- dataset: breastcancer
  model: s1dcnn
  best_params: {}
  param_grid:
    outer_params: *id034
    batch_size: *id035
    validation_fraction: *id036
    early_stopping_patience: *id037
    learning_rate: *id038
    hidden_size: *id039
    scheduler_factor: *id040
    scheduler_patience: *id041
- dataset: breastcancer
  model: gate
  best_params: {}
  param_grid:
    outer_params: *id059
    early_stopping_patience: *id060
    batch_size: *id061
    tree_depth: *id062
    num_trees: *id063
    chain_trees: *id064
    gflu_stages: *id065
    optimizer_fn: *id066
    scheduler_fn: *id067
- dataset: breastcancer
  model: categoryembedding
  best_params: {}
  param_grid:
    outer_params: *id068
    early_stopping_patience: *id069
    batch_size: *id070
    learning_rate: *id071
    optimizer_fn: *id072
    scheduler_fn: *id073
- dataset: breastcancer
  model: gandalf
  best_params: {}
  param_grid:
    outer_params: *id097
    early_stopping_patience: *id098
    batch_size: *id099
    optimizer_fn: *id100
    scheduler_fn: *id101
- dataset: breastcancer
  model: node
  best_params: {}
  param_grid:
    outer_params: *id102
    early_stopping_patience: *id103
    batch_size: *id104
    optimizer_fn: *id105
    scheduler_fn: *id106
