- dataset: titanic
  model: fttransformer
  best_params: {}
  param_grid:
    outer_params:
      hyperopt_evals: 1
      auto_lr_find: true
      max_epochs: 1000
      val_size: 0.15
      early_stopping_patience: 10
    batch_size:
    - 1024
    optimizer_fn:
      Adam:
        weight_decay:
        - 0.0
        learning_rate:
        - 0.001
    scheduler_fn:
      ReduceLROnPlateau:
        factor:
        - 0.1
        patience:
        - 5
- dataset: titanic
  model: categoryembedding
  best_params: {}
  param_grid:
    outer_params:
      hyperopt_evals: 1
      auto_lr_find: true
      max_epochs: 1000
      val_size: 0.15
      early_stopping_patience: 10
    batch_size:
    - 1024
    optimizer_fn:
      Adam:
        weight_decay:
        - 0.0
        learning_rate:
        - 0.001
    scheduler_fn:
      ReduceLROnPlateau:
        factor:
        - 0.1
        patience:
        - 5
- dataset: titanic
  model: gandalf
  best_params: {}
  param_grid:
    outer_params:
      hyperopt_evals: 1
      auto_lr_find: true
      max_epochs: 1000
      val_size: 0.15
      early_stopping_patience: 10
    batch_size:
    - 1024
    optimizer_fn:
      Adam:
        weight_decay:
        - 0.0
        learning_rate:
        - 0.001
    scheduler_fn:
      ReduceLROnPlateau:
        factor:
        - 0.1
        patience:
        - 5
- dataset: titanic
  model: node
  best_params: {}
  param_grid:
    outer_params:
      hyperopt_evals: 1
      auto_lr_find: true
      max_epochs: 1000
      val_size: 0.15
      early_stopping_patience: 10
    batch_size:
    - 1024
    optimizer_fn:
      Adam:
        weight_decay:
        - 0.0
        learning_rate:
        - 0.001
    scheduler_fn:
      ReduceLROnPlateau:
        factor:
        - 0.1
        patience:
        - 5
- dataset: titanic
  model: autoint
  best_params: {}
  param_grid:
    outer_params:
      hyperopt_evals: 1
      auto_lr_find: true
      max_epochs: 1000
      val_size: 0.15
      early_stopping_patience: 10
    batch_size:
    - 1024
    optimizer_fn:
      Adam:
        weight_decay:
        - 0.0
        learning_rate:
        - 0.001
    scheduler_fn:
      ReduceLROnPlateau:
        factor:
        - 0.1
        patience:
        - 5
- dataset: titanic
  model: tabtransformer
  best_params: {}
  param_grid:
    outer_params:
      hyperopt_evals: 1
      auto_lr_find: true
      max_epochs: 1000
      val_size: 0.15
      early_stopping_patience: 10
    batch_size:
    - 1024
    optimizer_fn:
      Adam:
        weight_decay:
        - 0.0
        learning_rate:
        - 0.001
    scheduler_fn:
      ReduceLROnPlateau:
        factor:
        - 0.1
        patience:
        - 5
