{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abd838c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from tabulate import tabulate\n",
    "import json\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import dataframe_image as dfi\n",
    "\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0405c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"REALRUN\"  ## insert the name of the file used in the runner.py\n",
    "df = pd.read_csv(rf\"../output/{filename}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9161df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of metric names\n",
    "metric_names = [\n",
    "    \"lift\",\n",
    "    \"f1\",\n",
    "    \"mse\",\n",
    "    \"accuracy\",\n",
    "    \"recall\",\n",
    "    \"precision\",\n",
    "    \"roc_auc\",\n",
    "    \"area_under_pr\",\n",
    "    \"r2_score\",\n",
    "    \"rmse\",\n",
    "]\n",
    "dataset = df.copy()\n",
    "# Create columns based on metric names\n",
    "# Convert string representations to dictionaries\n",
    "dataset[\"output_metrics\"] = dataset[\"output_metrics\"].apply(ast.literal_eval)\n",
    "dataset[\"run_time\"] = dataset[\"run_time\"].apply(lambda x: np.round(x / 60, 2))\n",
    "# Create columns based on metric names\n",
    "for metric in metric_names:\n",
    "    dataset[metric] = dataset[\"output_metrics\"].apply(\n",
    "        lambda x: x.get(metric) if isinstance(x, dict) else np.nan\n",
    "    )\n",
    "    dataset[f\"{metric}_std\"] = dataset[metric].apply(\n",
    "        lambda x: np.std(x) if isinstance(x, list) else np.nan\n",
    "    )\n",
    "    dataset[metric] = dataset[metric].apply(\n",
    "        lambda x: np.average(x) if isinstance(x, list) else np.nan\n",
    "    )\n",
    "\n",
    "base_cols = [\n",
    "    \"dataset\",\n",
    "    \"model\",\n",
    "    \"run_time\",\n",
    "    \"eval_metric\",\n",
    "    \"best_score\",\n",
    "    \"score_std\",\n",
    "    \"output_metrics\",\n",
    "]\n",
    "\n",
    "base_cols += [i for i in metric_names]\n",
    "base_cols += [i + \"_std\" for i in metric_names]\n",
    "\n",
    "dataset = dataset[base_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354f4366-4e14-468b-bf93-a0e849a3e3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.loc[dataset[\"model\"] == \"xgb\"].sort_values(\"dataset\").head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4f9922",
   "metadata": {},
   "outputs": [],
   "source": [
    "tomax = {\n",
    "    \"mse\": False,\n",
    "    \"rmse\": False,\n",
    "    \"accuracy\": True,\n",
    "    \"recall\": True,\n",
    "    \"precision\": True,\n",
    "    \"roc_auc\": True,\n",
    "    \"area_under_pr\": True,\n",
    "    \"lift\": True,\n",
    "    \"f1\": True,\n",
    "    \"r2_score\": True,\n",
    "}\n",
    "\n",
    "\n",
    "# Define a function to select the first row based on whether to maximize or minimize the \"best_score\"\n",
    "def select_first_row(group):\n",
    "    metric = group[\"eval_metric\"].iloc[0]\n",
    "    ascending = not tomax.get(\n",
    "        metric, True\n",
    "    )  # If metric not in tomax, assume True (maximize)\n",
    "    return group.sort_values(by=\"best_score\", ascending=ascending).iloc[0]\n",
    "\n",
    "\n",
    "# Apply the function to each group\n",
    "filtered_df = dataset.groupby([\"dataset\", \"model\", \"eval_metric\"]).apply(\n",
    "    select_first_row\n",
    ")\n",
    "# Reset the index to get a new DataFrame\n",
    "filtered_df = filtered_df.reset_index(drop=True)\n",
    "# Find the rows that maximize the specified metric for each dataset\n",
    "\n",
    "\n",
    "# Sort the DataFrame based on whether the metric is to be maximized or not\n",
    "filtered_df[\"ascending\"] = filtered_df[\"eval_metric\"].map(\n",
    "    {k: not v for k, v in tomax.items()}\n",
    ")  # Create a new column for ascending order\n",
    "dfmax = filtered_df.loc[filtered_df[\"ascending\"] == False].sort_values(\n",
    "    by=[\"dataset\", \"eval_metric\", \"best_score\"], ascending=[False, False, False]\n",
    ")\n",
    "dfmin = filtered_df.loc[filtered_df[\"ascending\"] == True].sort_values(\n",
    "    by=[\"dataset\", \"eval_metric\", \"best_score\"], ascending=[False, False, True]\n",
    ")\n",
    "\n",
    "best_df = pd.concat([dfmax, dfmin])\n",
    "best_df.drop(columns=[\"ascending\"], inplace=True)\n",
    "\n",
    "best_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab629ae0-b755-45a9-aa4b-4ca6a7771585",
   "metadata": {},
   "source": [
    "# Check State of Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85401fd-f8e2-4848-953c-957b93775b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../configuration/experiment_config.yml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Extract the necessary information from the configuration file\n",
    "included_models = [i.lower() for i in config[\"include_models\"]]\n",
    "included_datasets = [i.lower() for i in config[\"include_datasets\"]]\n",
    "\n",
    "# Get all combinations of items from the two lists\n",
    "combinations_possible = list(itertools.product(included_datasets, included_models))\n",
    "\n",
    "\n",
    "# Get unique combinations based on 'Column1' and 'Column2'\n",
    "existing_combinations = df[[\"dataset\", \"model\"]].drop_duplicates()\n",
    "# Convert the DataFrame to a list of tuples\n",
    "existing_combinations = [tuple(row) for row in existing_combinations.values]\n",
    "\n",
    "missing_combos = [i for i in combinations_possible if i not in existing_combinations]\n",
    "for i in missing_combos:\n",
    "    print(f\"Missing Combination {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f989d6-2edb-42c9-96dd-e77ce0ab21b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in missing_combos if \"xgb\" in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a4e401-9162-4475-a72f-6cafa66d01f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in missing_combos if \"node\" in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4a86f0-c411-4aa3-8665-68e92970167e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_df[\"dataset\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673c7520-2735-447d-9d84-848762d4ec03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"model\"] == \"gate\"][\"best_params\"].iloc[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8ddbb6-f466-4a8d-b41a-74912386a29a",
   "metadata": {},
   "source": [
    "# Execution Time Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4f9914-418f-47e0-b8e5-d86f1211a596",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_df.sort_values(\"run_time\", ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1476bf84-82fa-4453-8f2a-f7dec5849680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by the \"dataset\" column and aggregate \"run_time\" using the sum function\n",
    "hyperopt_evals = 1\n",
    "num_parallel = 2\n",
    "efficiency_estimate = 0.8\n",
    "aggregated_df = best_df.groupby(\"model\")[\"run_time\"].sum().reset_index()\n",
    "# Rename the aggregated column for clarity\n",
    "aggregated_df = aggregated_df.rename(columns={\"run_time\": \"sum_run_time\"})\n",
    "aggregated_df[\"total_search_hours_estimate\"] = (\n",
    "    aggregated_df[\"sum_run_time\"] * hyperopt_evals / 60 / num_parallel * 0.8\n",
    ")\n",
    "aggregated_df.sort_values(\"total_search_hours_estimate\", ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f044ec74-82b9-4f45-9062-eb456eaa2058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame to ASCII table\n",
    "class Format:\n",
    "    end = \"\\033[0m\"\n",
    "    underline = \"\\033[4m\"\n",
    "\n",
    "\n",
    "def make_results_table(\n",
    "    df, dataset_name, display_cols, metric_cols, image_name=\"\", dpi=1200, image_path=\"/home/boom/sdev/WTabRun/notebooks/tables/\",\n",
    "    image_folder = \"\"\n",
    "):\n",
    "    result_df = df.loc[df[\"dataset\"] == dataset_name].reset_index(drop=True).copy()\n",
    "\n",
    "    # Create a dictionary to store the indices of the rows with the highest values for each metric column\n",
    "    max_indices = {}\n",
    "    for metric in metric_cols:\n",
    "        max_indices[metric] = result_df[metric].idxmax()\n",
    "\n",
    "    # Modify all columns with std to include relative std\n",
    "    result_df[\"best_score\"] = result_df.apply(\n",
    "        lambda row: f\"{row['best_score']:.4f} ± ({row['score_std']:.4f})\", axis=1\n",
    "    )\n",
    "    for metric in metric_cols:\n",
    "        result_df[metric] = result_df.apply(\n",
    "            lambda row: f\"{row[metric]:.4f} ± ({row[metric+'_std']:.4f})\", axis=1\n",
    "        )\n",
    "        # Drop the corresponding std column\n",
    "        result_df.drop(columns=[metric + \"_std\"], inplace=True)\n",
    "\n",
    "    result_df[display_cols].to_csv(rf\"{image_path}/{image_folder}/{image_name}.csv\")\n",
    "\n",
    "    return result_df[display_cols]\n",
    "\n",
    "\n",
    "# Define a custom styling function\n",
    "def highlight_max_row(s):\n",
    "    is_max = s == s.max()\n",
    "    return [\"background-color: green\" if v else \"\" for v in is_max]\n",
    "\n",
    "\n",
    "def highlight_min_row(s):\n",
    "    is_max = s == s.min()\n",
    "    return [\"background-color: green\" if v else \"\" for v in is_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae68b406-40cd-4ce4-8842-ab07b74de369",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"hyperopt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bd0e43-eb38-4fa7-88f8-0d93c649c71b",
   "metadata": {},
   "source": [
    "# Titanic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98874279-dafa-4c75-805a-4f9304328c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_cols = [\n",
    "    \"model\",\n",
    "    \"accuracy\",\n",
    "    \"roc_auc\",\n",
    "    \"lift\",\n",
    "    \"f1\",\n",
    "    \"recall\",\n",
    "    \"precision\",\n",
    "    \"area_under_pr\",\n",
    "]\n",
    "metric_cols = [\n",
    "    \"accuracy\",\n",
    "    \"roc_auc\",\n",
    "    \"lift\",\n",
    "    \"f1\",\n",
    "    \"recall\",\n",
    "    \"precision\",\n",
    "    \"area_under_pr\",\n",
    "]\n",
    "dataset_name = \"titanic\"\n",
    "df = make_results_table(\n",
    "    best_df, dataset_name, display_cols, metric_cols, image_name=dataset_name, image_folder = folder, dpi=1200\n",
    ")\n",
    "# Apply the styling function to the specified columns\n",
    "styled_df = df.style.apply(highlight_max_row, subset=metric_cols, axis=0)\n",
    "dfi.export(styled_df, f\"./tables/{folder}/df_styled_{dataset_name}.png\" , dpi=400)\n",
    "styled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74742db3-2b1e-4e24-9a42-ff0d0d67a604",
   "metadata": {},
   "source": [
    "# Housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ad2335-3ebb-4fab-a97d-2dd1f3a8af29",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_cols = [\"model\", \"mse\", \"r2_score\", \"rmse\"]\n",
    "metric_cols = [\"mse\", \"r2_score\", \"rmse\"]\n",
    "dataset_name = \"housing\"\n",
    "df = make_results_table(\n",
    "    best_df, dataset_name, display_cols, metric_cols, image_name=dataset_name, image_folder = folder, dpi=1200\n",
    ")\n",
    "# Apply the styling function to the specified columns\n",
    "styled_df = df.style.apply(highlight_max_row, subset=[\"r2_score\"], axis=0).apply(\n",
    "    highlight_min_row, subset=[\"mse\", \"rmse\"], axis=0\n",
    ")\n",
    "dfi.export(styled_df, f\"./tables/{folder}/df_styled_{dataset_name}.png\", dpi=400)\n",
    "styled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce1e2a0-2a64-4073-9fcb-b2c8a4847b7d",
   "metadata": {},
   "source": [
    "# Heloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e20057-73df-452e-bff3-1df8b628d6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_cols = [\n",
    "    \"model\",\n",
    "    \"accuracy\",\n",
    "    \"roc_auc\",\n",
    "    \"lift\",\n",
    "    \"f1\",\n",
    "    \"recall\",\n",
    "    \"precision\",\n",
    "    \"area_under_pr\",\n",
    "]\n",
    "metric_cols = [\n",
    "    \"accuracy\",\n",
    "    \"roc_auc\",\n",
    "    \"lift\",\n",
    "    \"f1\",\n",
    "    \"recall\",\n",
    "    \"precision\",\n",
    "    \"area_under_pr\",\n",
    "]\n",
    "dataset_name = \"heloc\"\n",
    "df = make_results_table(\n",
    "    best_df, dataset_name, display_cols, metric_cols, image_name=dataset_name, image_folder = folder, dpi=1200\n",
    ")\n",
    "# Apply the styling function to the specified columns\n",
    "styled_df = df.style.apply(highlight_max_row, subset=metric_cols, axis=0)\n",
    "dfi.export(styled_df, f\"./tables/{folder}/df_styled_{dataset_name}.png\", dpi=400)\n",
    "styled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28adbbc3-5a6a-4fad-8f20-fad13efc6313",
   "metadata": {},
   "source": [
    "# Diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47f4763-3dc6-4096-b2f3-9deebce2ce33",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_cols = [\n",
    "    \"model\",\n",
    "    \"accuracy\",\n",
    "    \"roc_auc\",\n",
    "    \"lift\",\n",
    "    \"f1\",\n",
    "    \"recall\",\n",
    "    \"precision\",\n",
    "    \"area_under_pr\",\n",
    "]\n",
    "metric_cols = [\n",
    "    \"accuracy\",\n",
    "    \"roc_auc\",\n",
    "    \"lift\",\n",
    "    \"f1\",\n",
    "    \"recall\",\n",
    "    \"precision\",\n",
    "    \"area_under_pr\",\n",
    "]\n",
    "dataset_name = \"diabetes\"\n",
    "df = make_results_table(\n",
    "    best_df, dataset_name, display_cols, metric_cols, image_name=dataset_name, image_folder = folder, dpi=1200\n",
    ")\n",
    "# Apply the styling function to the specified columns\n",
    "styled_df = df.style.apply(highlight_max_row, subset=metric_cols, axis=0)\n",
    "dfi.export(styled_df, f\"./tables/{folder}/df_styled_{dataset_name}.png\", dpi=400)\n",
    "styled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4455dbdb-1373-4e6e-ad03-50238d3e01d1",
   "metadata": {},
   "source": [
    "# Creditcard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafc0687-3235-4ef6-8909-499aa3cbede3",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_cols = [\n",
    "    \"model\",\n",
    "    \"accuracy\",\n",
    "    \"roc_auc\",\n",
    "    \"lift\",\n",
    "    \"f1\",\n",
    "    \"recall\",\n",
    "    \"precision\",\n",
    "    \"area_under_pr\",\n",
    "]\n",
    "metric_cols = [\n",
    "    \"accuracy\",\n",
    "    \"roc_auc\",\n",
    "    \"lift\",\n",
    "    \"f1\",\n",
    "    \"recall\",\n",
    "    \"precision\",\n",
    "    \"area_under_pr\",\n",
    "]\n",
    "dataset_name = \"creditcard\"\n",
    "df = make_results_table(\n",
    "    best_df, dataset_name, display_cols, metric_cols, image_name=dataset_name, image_folder = folder, dpi=1200\n",
    ")\n",
    "# Apply the styling function to the specified columns\n",
    "styled_df = df.style.apply(highlight_max_row, subset=metric_cols, axis=0)\n",
    "dfi.export(styled_df, f\"./tables/{folder}/df_styled_{dataset_name}.png\", dpi=400)\n",
    "styled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b8016b-e9f4-41e3-9be1-fed232e3227e",
   "metadata": {},
   "source": [
    "# Adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626d2b74-fcc9-44d0-ad83-e305540fe9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_cols = [\n",
    "    \"model\",\n",
    "    \"accuracy\",\n",
    "    \"roc_auc\",\n",
    "    \"f1\",\n",
    "    \"recall\",\n",
    "    \"precision\",\n",
    "    \"area_under_pr\",\n",
    "]\n",
    "metric_cols = [\"accuracy\", \"roc_auc\", \"f1\", \"recall\", \"precision\", \"area_under_pr\"]\n",
    "dataset_name = \"adult\"\n",
    "df = make_results_table(\n",
    "    best_df, dataset_name, display_cols, metric_cols, image_name=dataset_name, image_folder = folder, dpi=1200\n",
    ")\n",
    "# Apply the styling function to the specified columns\n",
    "styled_df = df.style.apply(highlight_max_row, subset=metric_cols, axis=0)\n",
    "dfi.export(styled_df, f\"./tables/{folder}/df_styled_{dataset_name}.png\", dpi=400)\n",
    "styled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56195994-7980-4887-8d7e-f980541ab212",
   "metadata": {},
   "source": [
    "# Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c35a056-fd57-4aff-9740-b255d76cf86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_cols = [\"model\", \"accuracy\", \"f1\"]\n",
    "metric_cols = [\n",
    "    \"accuracy\",\n",
    "    \"f1\",\n",
    "]\n",
    "dataset_name = \"iris\"\n",
    "df = make_results_table(\n",
    "    best_df, dataset_name, display_cols, metric_cols, image_name=dataset_name, image_folder = folder, dpi=1200\n",
    ")\n",
    "# Apply the styling function to the specified columns\n",
    "styled_df = df.style.apply(highlight_max_row, subset=metric_cols, axis=0)\n",
    "dfi.export(styled_df, f\"./tables/{folder}/df_styled_{dataset_name}.png\", dpi=400)\n",
    "styled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4102d9-d6e4-417e-8714-d2596b549b6f",
   "metadata": {},
   "source": [
    "# Covertype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b84c0c-4daf-4df1-95f2-a05222b9d2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_cols = [\"model\", \"accuracy\", \"f1\"]\n",
    "metric_cols = [\"accuracy\", \"f1\"]\n",
    "dataset_name = \"covertype\"\n",
    "df = make_results_table(\n",
    "    best_df, dataset_name, display_cols, metric_cols, image_name=dataset_name, image_folder = folder, dpi=1200\n",
    ")\n",
    "# Apply the styling function to the specified columns\n",
    "styled_df = df.style.apply(highlight_max_row, subset=metric_cols, axis=0)\n",
    "dfi.export(styled_df, f\"./tables/{folder}/df_styled_{dataset_name}.png\", dpi=400)\n",
    "styled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffbcdb3-d017-44df-a93e-2821adc10e0f",
   "metadata": {},
   "source": [
    "# Breastcancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e64408-48a1-4d78-91e2-544656868691",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_cols = [\n",
    "    \"model\",\n",
    "    \"accuracy\",\n",
    "    \"roc_auc\",\n",
    "    \"lift\",\n",
    "    \"f1\",\n",
    "    \"recall\",\n",
    "    \"precision\",\n",
    "    \"area_under_pr\",\n",
    "]\n",
    "metric_cols = [\n",
    "    \"accuracy\",\n",
    "    \"roc_auc\",\n",
    "    \"lift\",\n",
    "    \"f1\",\n",
    "    \"recall\",\n",
    "    \"precision\",\n",
    "    \"area_under_pr\",\n",
    "]\n",
    "dataset_name = \"breastcancer\"\n",
    "df = make_results_table(\n",
    "    best_df, dataset_name, display_cols, metric_cols, image_name=dataset_name, image_folder = folder, dpi=1200\n",
    ")\n",
    "# Apply the styling function to the specified columns\n",
    "styled_df = df.sort_values(\"f1\", ascending=False).style.apply(\n",
    "    highlight_max_row, subset=metric_cols, axis=0\n",
    ")\n",
    "dfi.export(styled_df, f\"./tables/{folder}/df_styled_{dataset_name}.png\", dpi=400)\n",
    "styled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d0b1c1-3b58-46e6-b7bb-65b1d1da937f",
   "metadata": {},
   "source": [
    "# Ageconditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e0b79e-e985-43bc-a0f3-81fc91d013ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_cols = [\n",
    "    \"model\",\n",
    "    \"accuracy\",\n",
    "    \"roc_auc\",\n",
    "    \"lift\",\n",
    "    \"f1\",\n",
    "    \"recall\",\n",
    "    \"precision\",\n",
    "    \"area_under_pr\",\n",
    "]\n",
    "metric_cols = [\n",
    "    \"accuracy\",\n",
    "    \"roc_auc\",\n",
    "    \"lift\",\n",
    "    \"f1\",\n",
    "    \"recall\",\n",
    "    \"precision\",\n",
    "    \"area_under_pr\",\n",
    "]\n",
    "dataset_name = \"ageconditions\"\n",
    "df = make_results_table(\n",
    "    best_df, dataset_name, display_cols, metric_cols, image_name=dataset_name, image_folder = folder, dpi=1200\n",
    ")\n",
    "# Apply the styling function to the specified columns\n",
    "styled_df = df.sort_values(\"f1\", ascending=False).style.apply(\n",
    "    highlight_max_row, subset=metric_cols, axis=0\n",
    ")\n",
    "dfi.export(styled_df, f\"./tables/{folder}/df_styled_{dataset_name}.png\", dpi=400)\n",
    "styled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3838fefd-5b83-4947-9624-8aa9215a7cc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a2c3b3-0ccf-4023-a951-32c4a1ad2ea0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd623e6-a08d-41c6-9b06-209606c2fd9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
