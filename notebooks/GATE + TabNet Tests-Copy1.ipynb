{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "385dfcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install seaborn\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from pytorch_tabular import TabularModel\n",
    "from pytorch_tabular.models import GatedAdditiveTreeEnsembleConfig\n",
    "from pytorch_tabular.config import (\n",
    "    DataConfig,\n",
    "    OptimizerConfig,\n",
    "    TrainerConfig,\n",
    "    #ExperimentConfig,\n",
    ")\n",
    "from pytorch_tabular.utils import get_class_weighted_cross_entropy\n",
    "#pip install pytorch_tabular[extra]\n",
    "from evaluation.generalevaluator import *\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris, fetch_california_housing, load_breast_cancer\n",
    "from factory import create_data_loader\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ed13b73-1a7f-41c9-a0ca-baf82e8bb599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mdicio/Documents/GitHub/WTabRun/notebooks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22eff7d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/covertype/covtype.data.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m data_loader \u001b[38;5;241m=\u001b[39m create_data_loader(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcovertype\u001b[39m\u001b[38;5;124m'\u001b[39m, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, normalize_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean_std\u001b[39m\u001b[38;5;124m\"\u001b[39m, return_extra_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 2\u001b[0m X_train, X_val, y_train, y_val, extra_info \u001b[38;5;241m=\u001b[39m \u001b[43mdata_loader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/WTabRun/dataloaders/dataloader.py:786\u001b[0m, in \u001b[0;36mCoverTypeDataLoader.load_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;66;03m# Load the Adult dataset from UCI Machine Learning Repository\u001b[39;00m\n\u001b[0;32m--> 786\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./data/covertype/covtype.data.gz\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    788\u001b[0m     df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m5\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_column})\n\u001b[1;32m    789\u001b[0m     df[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_column] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_column] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/envs/clean/lib/python3.10/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/envs/clean/lib/python3.10/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/envs/clean/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/envs/clean/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1670\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/envs/clean/lib/python3.10/site-packages/pandas/io/common.py:753\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    749\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgzip\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    750\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    751\u001b[0m         \u001b[38;5;66;03m# error: Incompatible types in assignment (expression has type\u001b[39;00m\n\u001b[1;32m    752\u001b[0m         \u001b[38;5;66;03m# \"GzipFile\", variable has type \"Union[str, BaseBuffer]\")\u001b[39;00m\n\u001b[0;32m--> 753\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[43mgzip\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGzipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[assignment]\u001b[39;49;00m\n\u001b[1;32m    754\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    755\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    756\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcompression_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    757\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    759\u001b[0m         handle \u001b[38;5;241m=\u001b[39m gzip\u001b[38;5;241m.\u001b[39mGzipFile(\n\u001b[1;32m    760\u001b[0m             \u001b[38;5;66;03m# No overload variant of \"GzipFile\" matches argument types\u001b[39;00m\n\u001b[1;32m    761\u001b[0m             \u001b[38;5;66;03m# \"Union[str, BaseBuffer]\", \"str\", \"Dict[str, Any]\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcompression_args,\n\u001b[1;32m    765\u001b[0m         )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/gzip.py:174\u001b[0m, in \u001b[0;36mGzipFile.__init__\u001b[0;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[1;32m    172\u001b[0m     mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fileobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 174\u001b[0m     fileobj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmyfileobj \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(fileobj, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/covertype/covtype.data.gz'"
     ]
    }
   ],
   "source": [
    "data_loader = create_data_loader('covertype', test_size=0.2, normalize_features = \"mean_std\", return_extra_info = True)\n",
    "X_train, X_val, y_train, y_val, extra_info = data_loader.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e72a140",
   "metadata": {},
   "source": [
    "# GATE Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de94b527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.6229508196721312, 2.6052631578947367]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_count = 891\n",
    "class_count = [549, 342]\n",
    "class_weights = [total_count / count for count in class_count]\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e70556b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu = 0.6229508196721312\n"
     ]
    }
   ],
   "source": [
    "mu = class_weights[0] / class_weights[1] # 0.620\n",
    "weighted_loss = get_class_weighted_cross_entropy(y_train.values.ravel(), mu=mu)\n",
    "print(f\"mu = {mu}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbfec264",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-27 00:47:48,921 - {pytorch_tabular.tabular_model:105} - INFO - Experiment Tracking is turned off\n"
     ]
    }
   ],
   "source": [
    "# Define the data configuration\n",
    "\n",
    "from torchmetrics.regression import MeanSquaredError\n",
    "\n",
    "\n",
    "data_config = DataConfig(\n",
    "    target=['target'],\n",
    "    continuous_cols= [i for i in extra_info[\"num_col_names\"] if i != \"target\"],\n",
    "    categorical_cols=extra_info[\"cat_col_names\"],\n",
    ")\n",
    "trainer_config = TrainerConfig(\n",
    "    auto_lr_find = False,  # Runs the LRFinder to automatically derive a learning rate\n",
    "    batch_size   = 512,\n",
    "    max_epochs   = 2,\n",
    ")\n",
    "\n",
    "optimizer_config = OptimizerConfig()\n",
    "\n",
    "from torchmetrics.functional.regression import mean_squared_error\n",
    "model_config = GatedAdditiveTreeEnsembleConfig(\n",
    "    task=\"classification\",\n",
    "    tree_depth  =  4,\n",
    "    num_trees   = 12,\n",
    "    chain_trees = True, # akin to bagging, True is akin to boosting\n",
    "    gflu_stages =  2\n",
    ")\n",
    "\n",
    "tabular_model = TabularModel(\n",
    "    data_config=data_config,\n",
    "    model_config=model_config,\n",
    "    optimizer_config=optimizer_config,\n",
    "    trainer_config=trainer_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a6caefa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class TrainerConfig in module pytorch_tabular.config.config:\n",
      "\n",
      "class TrainerConfig(builtins.object)\n",
      " |  TrainerConfig(batch_size: int = 64, data_aware_init_batch_size: int = 2000, fast_dev_run: bool = False, max_epochs: int = 10, min_epochs: Optional[int] = 1, max_time: Optional[int] = None, gpus: Optional[int] = None, accelerator: Optional[str] = 'auto', devices: Optional[int] = None, devices_list: Optional[List[int]] = None, accumulate_grad_batches: int = 1, auto_lr_find: bool = False, auto_select_gpus: bool = True, check_val_every_n_epoch: int = 1, gradient_clip_val: float = 0.0, overfit_batches: float = 0.0, deterministic: bool = False, profiler: Optional[str] = None, early_stopping: Optional[str] = 'valid_loss', early_stopping_min_delta: float = 0.001, early_stopping_mode: str = 'min', early_stopping_patience: int = 3, early_stopping_kwargs: Optional[Dict[str, Any]] = <factory>, checkpoints: Optional[str] = 'valid_loss', checkpoints_path: str = 'saved_models', checkpoints_every_n_epochs: int = 1, checkpoints_name: Optional[str] = None, checkpoints_mode: str = 'min', checkpoints_save_top_k: int = 1, checkpoints_kwargs: Optional[Dict[str, Any]] = <factory>, load_best: bool = True, track_grad_norm: int = -1, progress_bar: str = 'rich', precision: int = 32, seed: int = 42, trainer_kwargs: Dict[str, Any] = <factory>) -> None\n",
      " |  \n",
      " |  Trainer configuration\n",
      " |  Args:\n",
      " |      batch_size (int): Number of samples in each batch of training\n",
      " |  \n",
      " |      data_aware_init_batch_size (int): Number of samples in each batch of training for the data-aware initialization,\n",
      " |          when applicable. Defaults to 2000\n",
      " |  \n",
      " |      fast_dev_run (bool): runs n if set to ``n`` (int) else 1 if set to ``True`` batch(es) of train, val\n",
      " |              and test to find any bugs (ie: a sort of unit test).\n",
      " |  \n",
      " |      max_epochs (int): Maximum number of epochs to be run\n",
      " |  \n",
      " |      min_epochs (Optional[int]): Force training for at least these many epochs. 1 by default\n",
      " |  \n",
      " |      max_time (Optional[int]): Stop training after this amount of time has passed. Disabled by default\n",
      " |              (None)\n",
      " |  \n",
      " |      gpus (Optional[int]): DEPRECATED: Number of gpus to train on (int). -1 uses all available GPUs. By\n",
      " |              default uses CPU (None)\n",
      " |  \n",
      " |      accelerator (Optional[str]): The accelerator to use for training. Can be one of\n",
      " |              'cpu','gpu','tpu','ipu', 'mps', 'auto'. Defaults to 'auto'.\n",
      " |              Choices are: [`cpu`,`gpu`,`tpu`,`ipu`,'mps',`auto`].\n",
      " |  \n",
      " |      devices (Optional[int]): Number of devices to train on (int). -1 uses all available devices. By\n",
      " |              default uses all available devices (-1)\n",
      " |  \n",
      " |      devices_list (Optional[List[int]]): List of devices to train on (list). If specified, takes\n",
      " |              precedence over `devices` argument. Defaults to None\n",
      " |  \n",
      " |      accumulate_grad_batches (int): Accumulates grads every k batches or as set up in the dict. Trainer\n",
      " |              also calls optimizer.step() for the last indivisible step number.\n",
      " |  \n",
      " |      auto_lr_find (bool): Runs a learning rate finder algorithm (see this paper) when calling\n",
      " |              trainer.tune(), to find optimal initial learning rate.\n",
      " |  \n",
      " |      auto_select_gpus (bool): If enabled and `devices` is an integer, pick available gpus automatically.\n",
      " |              This is especially useful when GPUs are configured to be in 'exclusive mode', such that only one\n",
      " |              process at a time can access them.\n",
      " |  \n",
      " |      check_val_every_n_epoch (int): Check val every n train epochs.\n",
      " |  \n",
      " |      gradient_clip_val (float): Gradient clipping value\n",
      " |  \n",
      " |      overfit_batches (float): Uses this much data of the training set. If nonzero, will use the same\n",
      " |              training set for validation and testing. If the training dataloaders have shuffle=True, Lightning\n",
      " |              will automatically disable it. Useful for quickly debugging or trying to overfit on purpose.\n",
      " |  \n",
      " |      deterministic (bool): If true enables cudnn.deterministic. Might make your system slower, but\n",
      " |              ensures reproducibility.\n",
      " |  \n",
      " |      profiler (Optional[str]): To profile individual steps during training and assist in identifying\n",
      " |              bottlenecks. None, simple or advanced, pytorch. Choices are:\n",
      " |              [`None`,`simple`,`advanced`,`pytorch`].\n",
      " |  \n",
      " |      early_stopping (Optional[str]): The loss/metric that needed to be monitored for early stopping. If\n",
      " |              None, there will be no early stopping\n",
      " |  \n",
      " |      early_stopping_min_delta (float): The minimum delta in the loss/metric which qualifies as an\n",
      " |              improvement in early stopping\n",
      " |  \n",
      " |      early_stopping_mode (str): The direction in which the loss/metric should be optimized. Choices are:\n",
      " |              [`max`,`min`].\n",
      " |  \n",
      " |      early_stopping_patience (int): The number of epochs to wait until there is no further improvements\n",
      " |              in loss/metric\n",
      " |  \n",
      " |      early_stopping_kwargs (Optional[Dict]): Additional keyword arguments for the early stopping callback.\n",
      " |              See the documentation for the PyTorch Lightning EarlyStopping callback for more details.\n",
      " |  \n",
      " |      checkpoints (Optional[str]): The loss/metric that needed to be monitored for checkpoints. If None,\n",
      " |              there will be no checkpoints\n",
      " |  \n",
      " |      checkpoints_path (str): The path where the saved models will be\n",
      " |  \n",
      " |      checkpoints_every_n_epochs (int): Number of training steps between checkpoints\n",
      " |  \n",
      " |      checkpoints_name (Optional[str]): The name under which the models will be saved. If left blank,\n",
      " |              first it will look for `run_name` in experiment_config and if that is also None then it will use a\n",
      " |              generic name like task_version.\n",
      " |  \n",
      " |      checkpoints_mode (str): The direction in which the loss/metric should be optimized\n",
      " |  \n",
      " |      checkpoints_save_top_k (int): The number of best models to save\n",
      " |  \n",
      " |      checkpoints_kwargs (Optional[Dict]): Additional keyword arguments for the checkpoints callback.\n",
      " |              See the documentation for the PyTorch Lightning ModelCheckpoint callback for more details.\n",
      " |  \n",
      " |      load_best (bool): Flag to load the best model saved during training\n",
      " |  \n",
      " |      track_grad_norm (int): Track and Log Gradient Norms in the logger. -1 by default means no tracking.\n",
      " |              1 for the L1 norm, 2 for L2 norm, etc.\n",
      " |  \n",
      " |      progress_bar (str): Progress bar type. Can be one of: `none`, `simple`, `rich`. Defaults to `rich`.\n",
      " |  \n",
      " |      precision (int): Precision of the model. Can be one of: `32`, `16`, `64`. Defaults to `32`..\n",
      " |              Choices are: [`32`,`16`,`64`].\n",
      " |  \n",
      " |      seed (int): Seed for random number generators. Defaults to 42\n",
      " |  \n",
      " |      trainer_kwargs (Dict[str, Any]): Additional kwargs to be passed to PyTorch Lightning Trainer. See\n",
      " |              https://pytorch-lightning.readthedocs.io/en/latest/api/pytorch_lightning.trainer.html#pytorch_lightning.trainer.Trainer\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __eq__(self, other)\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __init__(self, batch_size: int = 64, data_aware_init_batch_size: int = 2000, fast_dev_run: bool = False, max_epochs: int = 10, min_epochs: Optional[int] = 1, max_time: Optional[int] = None, gpus: Optional[int] = None, accelerator: Optional[str] = 'auto', devices: Optional[int] = None, devices_list: Optional[List[int]] = None, accumulate_grad_batches: int = 1, auto_lr_find: bool = False, auto_select_gpus: bool = True, check_val_every_n_epoch: int = 1, gradient_clip_val: float = 0.0, overfit_batches: float = 0.0, deterministic: bool = False, profiler: Optional[str] = None, early_stopping: Optional[str] = 'valid_loss', early_stopping_min_delta: float = 0.001, early_stopping_mode: str = 'min', early_stopping_patience: int = 3, early_stopping_kwargs: Optional[Dict[str, Any]] = <factory>, checkpoints: Optional[str] = 'valid_loss', checkpoints_path: str = 'saved_models', checkpoints_every_n_epochs: int = 1, checkpoints_name: Optional[str] = None, checkpoints_mode: str = 'min', checkpoints_save_top_k: int = 1, checkpoints_kwargs: Optional[Dict[str, Any]] = <factory>, load_best: bool = True, track_grad_norm: int = -1, progress_bar: str = 'rich', precision: int = 32, seed: int = 42, trainer_kwargs: Dict[str, Any] = <factory>) -> None\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __post_init__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __annotations__ = {'accelerator': typing.Optional[str], 'accumulate_gr...\n",
      " |  \n",
      " |  __dataclass_fields__ = {'accelerator': Field(name='accelerator',type=t...\n",
      " |  \n",
      " |  __dataclass_params__ = _DataclassParams(init=True,repr=True,eq=True,or...\n",
      " |  \n",
      " |  __hash__ = None\n",
      " |  \n",
      " |  __match_args__ = ('batch_size', 'data_aware_init_batch_size', 'fast_de...\n",
      " |  \n",
      " |  accelerator = 'auto'\n",
      " |  \n",
      " |  accumulate_grad_batches = 1\n",
      " |  \n",
      " |  auto_lr_find = False\n",
      " |  \n",
      " |  auto_select_gpus = True\n",
      " |  \n",
      " |  batch_size = 64\n",
      " |  \n",
      " |  check_val_every_n_epoch = 1\n",
      " |  \n",
      " |  checkpoints = 'valid_loss'\n",
      " |  \n",
      " |  checkpoints_every_n_epochs = 1\n",
      " |  \n",
      " |  checkpoints_mode = 'min'\n",
      " |  \n",
      " |  checkpoints_name = None\n",
      " |  \n",
      " |  checkpoints_path = 'saved_models'\n",
      " |  \n",
      " |  checkpoints_save_top_k = 1\n",
      " |  \n",
      " |  data_aware_init_batch_size = 2000\n",
      " |  \n",
      " |  deterministic = False\n",
      " |  \n",
      " |  devices = None\n",
      " |  \n",
      " |  devices_list = None\n",
      " |  \n",
      " |  early_stopping = 'valid_loss'\n",
      " |  \n",
      " |  early_stopping_min_delta = 0.001\n",
      " |  \n",
      " |  early_stopping_mode = 'min'\n",
      " |  \n",
      " |  early_stopping_patience = 3\n",
      " |  \n",
      " |  fast_dev_run = False\n",
      " |  \n",
      " |  gpus = None\n",
      " |  \n",
      " |  gradient_clip_val = 0.0\n",
      " |  \n",
      " |  load_best = True\n",
      " |  \n",
      " |  max_epochs = 10\n",
      " |  \n",
      " |  max_time = None\n",
      " |  \n",
      " |  min_epochs = 1\n",
      " |  \n",
      " |  overfit_batches = 0.0\n",
      " |  \n",
      " |  precision = 32\n",
      " |  \n",
      " |  profiler = None\n",
      " |  \n",
      " |  progress_bar = 'rich'\n",
      " |  \n",
      " |  seed = 42\n",
      " |  \n",
      " |  track_grad_norm = -1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(TrainerConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e3c352a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert X_train.isnull().sum().sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5ba72e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "33eed7f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "      <th>family_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>0.829568</td>\n",
       "      <td>male</td>\n",
       "      <td>-1.373384</td>\n",
       "      <td>-0.465084</td>\n",
       "      <td>-0.466183</td>\n",
       "      <td>0.513812</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NA</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0.800346</td>\n",
       "      <td>-0.556339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>-0.370945</td>\n",
       "      <td>male</td>\n",
       "      <td>-1.373384</td>\n",
       "      <td>-0.465084</td>\n",
       "      <td>-0.466183</td>\n",
       "      <td>-0.662563</td>\n",
       "      <td>S</td>\n",
       "      <td>Second</td>\n",
       "      <td>NA</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0.800346</td>\n",
       "      <td>-0.556339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>-1.571457</td>\n",
       "      <td>male</td>\n",
       "      <td>-1.373384</td>\n",
       "      <td>-0.465084</td>\n",
       "      <td>-0.466183</td>\n",
       "      <td>3.955399</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0.800346</td>\n",
       "      <td>-0.556339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>0.829568</td>\n",
       "      <td>female</td>\n",
       "      <td>-0.346436</td>\n",
       "      <td>-0.465084</td>\n",
       "      <td>0.727782</td>\n",
       "      <td>-0.467874</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NA</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>-1.249460</td>\n",
       "      <td>0.073412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>-0.370945</td>\n",
       "      <td>female</td>\n",
       "      <td>0.395248</td>\n",
       "      <td>0.478335</td>\n",
       "      <td>0.727782</td>\n",
       "      <td>-0.115977</td>\n",
       "      <td>S</td>\n",
       "      <td>Second</td>\n",
       "      <td>NA</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>-1.249460</td>\n",
       "      <td>0.703162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>0.829568</td>\n",
       "      <td>female</td>\n",
       "      <td>-1.373384</td>\n",
       "      <td>-0.465084</td>\n",
       "      <td>-0.466183</td>\n",
       "      <td>-0.498500</td>\n",
       "      <td>Q</td>\n",
       "      <td>Third</td>\n",
       "      <td>NA</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>0.800346</td>\n",
       "      <td>-0.556339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>-1.571457</td>\n",
       "      <td>female</td>\n",
       "      <td>0.623459</td>\n",
       "      <td>-0.465084</td>\n",
       "      <td>-0.466183</td>\n",
       "      <td>10.005329</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>NA</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0.800346</td>\n",
       "      <td>-0.556339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>0.829568</td>\n",
       "      <td>female</td>\n",
       "      <td>1.365143</td>\n",
       "      <td>0.478335</td>\n",
       "      <td>3.115713</td>\n",
       "      <td>0.053205</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NA</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>-1.249460</td>\n",
       "      <td>1.962663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>-1.571457</td>\n",
       "      <td>male</td>\n",
       "      <td>1.308091</td>\n",
       "      <td>-0.465084</td>\n",
       "      <td>-0.466183</td>\n",
       "      <td>0.139097</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>E</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0.800346</td>\n",
       "      <td>-0.556339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>-1.571457</td>\n",
       "      <td>male</td>\n",
       "      <td>-1.373384</td>\n",
       "      <td>-0.465084</td>\n",
       "      <td>-0.466183</td>\n",
       "      <td>-0.109730</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>NA</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0.800346</td>\n",
       "      <td>-0.556339</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>712 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pclass     sex       age     sibsp     parch       fare embarked  \\\n",
       "692  0.829568    male -1.373384 -0.465084 -0.466183   0.513812        S   \n",
       "481 -0.370945    male -1.373384 -0.465084 -0.466183  -0.662563        S   \n",
       "527 -1.571457    male -1.373384 -0.465084 -0.466183   3.955399        S   \n",
       "855  0.829568  female -0.346436 -0.465084  0.727782  -0.467874        S   \n",
       "801 -0.370945  female  0.395248  0.478335  0.727782  -0.115977        S   \n",
       "..        ...     ...       ...       ...       ...        ...      ...   \n",
       "359  0.829568  female -1.373384 -0.465084 -0.466183  -0.498500        Q   \n",
       "258 -1.571457  female  0.623459 -0.465084 -0.466183  10.005329        C   \n",
       "736  0.829568  female  1.365143  0.478335  3.115713   0.053205        S   \n",
       "462 -1.571457    male  1.308091 -0.465084 -0.466183   0.139097        S   \n",
       "507 -1.571457    male -1.373384 -0.465084 -0.466183  -0.109730        S   \n",
       "\n",
       "      class deck  embark_town     alone  family_size  \n",
       "692   Third   NA  Southampton  0.800346    -0.556339  \n",
       "481  Second   NA  Southampton  0.800346    -0.556339  \n",
       "527   First    C  Southampton  0.800346    -0.556339  \n",
       "855   Third   NA  Southampton -1.249460     0.073412  \n",
       "801  Second   NA  Southampton -1.249460     0.703162  \n",
       "..      ...  ...          ...       ...          ...  \n",
       "359   Third   NA   Queenstown  0.800346    -0.556339  \n",
       "258   First   NA    Cherbourg  0.800346    -0.556339  \n",
       "736   Third   NA  Southampton -1.249460     1.962663  \n",
       "462   First    E  Southampton  0.800346    -0.556339  \n",
       "507   First   NA  Southampton  0.800346    -0.556339  \n",
       "\n",
       "[712 rows x 12 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c143882a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "      <th>family_size</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>0.829568</td>\n",
       "      <td>male</td>\n",
       "      <td>-0.004120</td>\n",
       "      <td>1.421753</td>\n",
       "      <td>-0.466183</td>\n",
       "      <td>-0.159704</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NA</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>-1.249460</td>\n",
       "      <td>0.703162</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0.829568</td>\n",
       "      <td>male</td>\n",
       "      <td>1.136933</td>\n",
       "      <td>-0.465084</td>\n",
       "      <td>0.727782</td>\n",
       "      <td>-0.327324</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NA</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>-1.249460</td>\n",
       "      <td>0.073412</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>0.829568</td>\n",
       "      <td>male</td>\n",
       "      <td>-0.118226</td>\n",
       "      <td>-0.465084</td>\n",
       "      <td>-0.466183</td>\n",
       "      <td>-0.512122</td>\n",
       "      <td>C</td>\n",
       "      <td>Third</td>\n",
       "      <td>NA</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0.800346</td>\n",
       "      <td>-0.556339</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>0.829568</td>\n",
       "      <td>male</td>\n",
       "      <td>0.965775</td>\n",
       "      <td>1.421753</td>\n",
       "      <td>-0.466183</td>\n",
       "      <td>-0.368795</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NA</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>-1.249460</td>\n",
       "      <td>0.703162</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>0.829568</td>\n",
       "      <td>female</td>\n",
       "      <td>-1.373384</td>\n",
       "      <td>0.478335</td>\n",
       "      <td>-0.466183</td>\n",
       "      <td>-0.339817</td>\n",
       "      <td>Q</td>\n",
       "      <td>Third</td>\n",
       "      <td>NA</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>-1.249460</td>\n",
       "      <td>0.073412</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>-0.370945</td>\n",
       "      <td>female</td>\n",
       "      <td>0.052932</td>\n",
       "      <td>-0.465084</td>\n",
       "      <td>0.727782</td>\n",
       "      <td>-0.121182</td>\n",
       "      <td>S</td>\n",
       "      <td>Second</td>\n",
       "      <td>NA</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>-1.249460</td>\n",
       "      <td>0.073412</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.829568</td>\n",
       "      <td>male</td>\n",
       "      <td>-0.232331</td>\n",
       "      <td>-0.465084</td>\n",
       "      <td>-0.466183</td>\n",
       "      <td>-0.499020</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NA</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0.800346</td>\n",
       "      <td>-0.556339</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>-0.370945</td>\n",
       "      <td>male</td>\n",
       "      <td>0.224090</td>\n",
       "      <td>-0.465084</td>\n",
       "      <td>-0.466183</td>\n",
       "      <td>-0.443929</td>\n",
       "      <td>S</td>\n",
       "      <td>Second</td>\n",
       "      <td>NA</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0.800346</td>\n",
       "      <td>-0.556339</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>-0.370945</td>\n",
       "      <td>female</td>\n",
       "      <td>-0.061173</td>\n",
       "      <td>-0.465084</td>\n",
       "      <td>-0.466183</td>\n",
       "      <td>-0.375388</td>\n",
       "      <td>C</td>\n",
       "      <td>Second</td>\n",
       "      <td>D</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0.800346</td>\n",
       "      <td>-0.556339</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>-0.370945</td>\n",
       "      <td>male</td>\n",
       "      <td>0.395248</td>\n",
       "      <td>0.478335</td>\n",
       "      <td>0.727782</td>\n",
       "      <td>-0.115977</td>\n",
       "      <td>S</td>\n",
       "      <td>Second</td>\n",
       "      <td>NA</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>-1.249460</td>\n",
       "      <td>0.703162</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>179 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pclass     sex       age     sibsp     parch      fare embarked  \\\n",
       "565  0.829568    male -0.004120  1.421753 -0.466183 -0.159704        S   \n",
       "160  0.829568    male  1.136933 -0.465084  0.727782 -0.327324        S   \n",
       "553  0.829568    male -0.118226 -0.465084 -0.466183 -0.512122        C   \n",
       "860  0.829568    male  0.965775  1.421753 -0.466183 -0.368795        S   \n",
       "241  0.829568  female -1.373384  0.478335 -0.466183 -0.339817        Q   \n",
       "..        ...     ...       ...       ...       ...       ...      ...   \n",
       "880 -0.370945  female  0.052932 -0.465084  0.727782 -0.121182        S   \n",
       "91   0.829568    male -0.232331 -0.465084 -0.466183 -0.499020        S   \n",
       "883 -0.370945    male  0.224090 -0.465084 -0.466183 -0.443929        S   \n",
       "473 -0.370945  female -0.061173 -0.465084 -0.466183 -0.375388        C   \n",
       "637 -0.370945    male  0.395248  0.478335  0.727782 -0.115977        S   \n",
       "\n",
       "      class deck  embark_town     alone  family_size  target  \n",
       "565   Third   NA  Southampton -1.249460     0.703162       0  \n",
       "160   Third   NA  Southampton -1.249460     0.073412       0  \n",
       "553   Third   NA    Cherbourg  0.800346    -0.556339       1  \n",
       "860   Third   NA  Southampton -1.249460     0.703162       0  \n",
       "241   Third   NA   Queenstown -1.249460     0.073412       1  \n",
       "..      ...  ...          ...       ...          ...     ...  \n",
       "880  Second   NA  Southampton -1.249460     0.073412       1  \n",
       "91    Third   NA  Southampton  0.800346    -0.556339       0  \n",
       "883  Second   NA  Southampton  0.800346    -0.556339       0  \n",
       "473  Second    D    Cherbourg  0.800346    -0.556339       1  \n",
       "637  Second   NA  Southampton -1.249460     0.703162       0  \n",
       "\n",
       "[179 rows x 13 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7488c259",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-27 00:48:04,738 - {pytorch_tabular.tabular_model:105} - INFO - Experiment Tracking is turned off\n",
      "Global seed set to 42\n",
      "2023-07-27 00:48:04,776 - {pytorch_tabular.tabular_model:473} - INFO - Preparing the DataLoaders\n",
      "2023-07-27 00:48:04,778 - {pytorch_tabular.tabular_datamodule:290} - INFO - Setting up the datamodule for classification task\n",
      "2023-07-27 00:48:04,836 - {pytorch_tabular.tabular_model:521} - INFO - Preparing the Model: GatedAdditiveTreeEnsembleModel\n",
      "2023-07-27 00:48:04,987 - {pytorch_tabular.tabular_model:268} - INFO - Preparing the Trainer\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "2023-07-27 00:48:05,078 - {pytorch_tabular.tabular_model:582} - INFO - Training Started\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                       </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ custom_loss      │ CrossEntropyLoss           │      0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _backbone        │ GatedAdditiveTreesBackbone │  111 K │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _embedding_layer │ Embedding1dLayer           │    103 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ _head            │ CustomHead                 │     46 │\n",
       "└───┴──────────────────┴────────────────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType                      \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ custom_loss      │ CrossEntropyLoss           │      0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ GatedAdditiveTreesBackbone │  111 K │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer           │    103 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ _head            │ CustomHead                 │     46 │\n",
       "└───┴──────────────────┴────────────────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 111 K                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 111 K                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 111 K                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 111 K                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0348fe61a064c388a730cefe7fdb840",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-27 00:48:07,666 - {pytorch_tabular.tabular_model:584} - INFO - Training the model completed\n",
      "2023-07-27 00:48:07,668 - {pytorch_tabular.tabular_model:1258} - INFO - Loading the best model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pytorch_lightning.trainer.trainer.Trainer at 0x14a2cfbb0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabular_model = TabularModel(\n",
    "    data_config=data_config,\n",
    "    model_config=model_config,\n",
    "    optimizer_config=optimizer_config,\n",
    "    trainer_config=trainer_config,\n",
    ")\n",
    "\n",
    "# Merge X_train and y_train  \n",
    "train = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "# Merge X_val and y_val\n",
    "validation = pd.concat([X_val, y_val], axis=1)\n",
    "\n",
    "tabular_model.fit(\n",
    "    train=train, \n",
    "    validation=validation,\n",
    "    loss=weighted_loss\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7cf29766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06abd6c4789d4a36acce94302b1ebd92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_df = tabular_model.predict(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "65b70634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "      <th>family_size</th>\n",
       "      <th>target</th>\n",
       "      <th>0_probability</th>\n",
       "      <th>1_probability</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>0.829568</td>\n",
       "      <td>male</td>\n",
       "      <td>-0.004120</td>\n",
       "      <td>1.421753</td>\n",
       "      <td>-0.466183</td>\n",
       "      <td>-0.159704</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NA</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>-1.249460</td>\n",
       "      <td>0.703162</td>\n",
       "      <td>0</td>\n",
       "      <td>0.581861</td>\n",
       "      <td>0.418139</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0.829568</td>\n",
       "      <td>male</td>\n",
       "      <td>1.136933</td>\n",
       "      <td>-0.465084</td>\n",
       "      <td>0.727782</td>\n",
       "      <td>-0.327324</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NA</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>-1.249460</td>\n",
       "      <td>0.073412</td>\n",
       "      <td>0</td>\n",
       "      <td>0.576033</td>\n",
       "      <td>0.423967</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>0.829568</td>\n",
       "      <td>male</td>\n",
       "      <td>-0.118226</td>\n",
       "      <td>-0.465084</td>\n",
       "      <td>-0.466183</td>\n",
       "      <td>-0.512122</td>\n",
       "      <td>C</td>\n",
       "      <td>Third</td>\n",
       "      <td>NA</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0.800346</td>\n",
       "      <td>-0.556339</td>\n",
       "      <td>1</td>\n",
       "      <td>0.583989</td>\n",
       "      <td>0.416011</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>0.829568</td>\n",
       "      <td>male</td>\n",
       "      <td>0.965775</td>\n",
       "      <td>1.421753</td>\n",
       "      <td>-0.466183</td>\n",
       "      <td>-0.368795</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NA</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>-1.249460</td>\n",
       "      <td>0.703162</td>\n",
       "      <td>0</td>\n",
       "      <td>0.580584</td>\n",
       "      <td>0.419416</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>0.829568</td>\n",
       "      <td>female</td>\n",
       "      <td>-1.373384</td>\n",
       "      <td>0.478335</td>\n",
       "      <td>-0.466183</td>\n",
       "      <td>-0.339817</td>\n",
       "      <td>Q</td>\n",
       "      <td>Third</td>\n",
       "      <td>NA</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>-1.249460</td>\n",
       "      <td>0.073412</td>\n",
       "      <td>1</td>\n",
       "      <td>0.583330</td>\n",
       "      <td>0.416670</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>-0.370945</td>\n",
       "      <td>female</td>\n",
       "      <td>0.052932</td>\n",
       "      <td>-0.465084</td>\n",
       "      <td>0.727782</td>\n",
       "      <td>-0.121182</td>\n",
       "      <td>S</td>\n",
       "      <td>Second</td>\n",
       "      <td>NA</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>-1.249460</td>\n",
       "      <td>0.073412</td>\n",
       "      <td>1</td>\n",
       "      <td>0.580422</td>\n",
       "      <td>0.419578</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.829568</td>\n",
       "      <td>male</td>\n",
       "      <td>-0.232331</td>\n",
       "      <td>-0.465084</td>\n",
       "      <td>-0.466183</td>\n",
       "      <td>-0.499020</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NA</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0.800346</td>\n",
       "      <td>-0.556339</td>\n",
       "      <td>0</td>\n",
       "      <td>0.583955</td>\n",
       "      <td>0.416045</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>-0.370945</td>\n",
       "      <td>male</td>\n",
       "      <td>0.224090</td>\n",
       "      <td>-0.465084</td>\n",
       "      <td>-0.466183</td>\n",
       "      <td>-0.443929</td>\n",
       "      <td>S</td>\n",
       "      <td>Second</td>\n",
       "      <td>NA</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0.800346</td>\n",
       "      <td>-0.556339</td>\n",
       "      <td>0</td>\n",
       "      <td>0.585967</td>\n",
       "      <td>0.414033</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>-0.370945</td>\n",
       "      <td>female</td>\n",
       "      <td>-0.061173</td>\n",
       "      <td>-0.465084</td>\n",
       "      <td>-0.466183</td>\n",
       "      <td>-0.375388</td>\n",
       "      <td>C</td>\n",
       "      <td>Second</td>\n",
       "      <td>D</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0.800346</td>\n",
       "      <td>-0.556339</td>\n",
       "      <td>1</td>\n",
       "      <td>0.588488</td>\n",
       "      <td>0.411512</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>-0.370945</td>\n",
       "      <td>male</td>\n",
       "      <td>0.395248</td>\n",
       "      <td>0.478335</td>\n",
       "      <td>0.727782</td>\n",
       "      <td>-0.115977</td>\n",
       "      <td>S</td>\n",
       "      <td>Second</td>\n",
       "      <td>NA</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>-1.249460</td>\n",
       "      <td>0.703162</td>\n",
       "      <td>0</td>\n",
       "      <td>0.581362</td>\n",
       "      <td>0.418638</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>179 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pclass     sex       age     sibsp     parch      fare embarked  \\\n",
       "565  0.829568    male -0.004120  1.421753 -0.466183 -0.159704        S   \n",
       "160  0.829568    male  1.136933 -0.465084  0.727782 -0.327324        S   \n",
       "553  0.829568    male -0.118226 -0.465084 -0.466183 -0.512122        C   \n",
       "860  0.829568    male  0.965775  1.421753 -0.466183 -0.368795        S   \n",
       "241  0.829568  female -1.373384  0.478335 -0.466183 -0.339817        Q   \n",
       "..        ...     ...       ...       ...       ...       ...      ...   \n",
       "880 -0.370945  female  0.052932 -0.465084  0.727782 -0.121182        S   \n",
       "91   0.829568    male -0.232331 -0.465084 -0.466183 -0.499020        S   \n",
       "883 -0.370945    male  0.224090 -0.465084 -0.466183 -0.443929        S   \n",
       "473 -0.370945  female -0.061173 -0.465084 -0.466183 -0.375388        C   \n",
       "637 -0.370945    male  0.395248  0.478335  0.727782 -0.115977        S   \n",
       "\n",
       "      class deck  embark_town     alone  family_size  target  0_probability  \\\n",
       "565   Third   NA  Southampton -1.249460     0.703162       0       0.581861   \n",
       "160   Third   NA  Southampton -1.249460     0.073412       0       0.576033   \n",
       "553   Third   NA    Cherbourg  0.800346    -0.556339       1       0.583989   \n",
       "860   Third   NA  Southampton -1.249460     0.703162       0       0.580584   \n",
       "241   Third   NA   Queenstown -1.249460     0.073412       1       0.583330   \n",
       "..      ...  ...          ...       ...          ...     ...            ...   \n",
       "880  Second   NA  Southampton -1.249460     0.073412       1       0.580422   \n",
       "91    Third   NA  Southampton  0.800346    -0.556339       0       0.583955   \n",
       "883  Second   NA  Southampton  0.800346    -0.556339       0       0.585967   \n",
       "473  Second    D    Cherbourg  0.800346    -0.556339       1       0.588488   \n",
       "637  Second   NA  Southampton -1.249460     0.703162       0       0.581362   \n",
       "\n",
       "     1_probability  prediction  \n",
       "565       0.418139           0  \n",
       "160       0.423967           0  \n",
       "553       0.416011           0  \n",
       "860       0.419416           0  \n",
       "241       0.416670           0  \n",
       "..             ...         ...  \n",
       "880       0.419578           0  \n",
       "91        0.416045           0  \n",
       "883       0.414033           0  \n",
       "473       0.411512           0  \n",
       "637       0.418638           0  \n",
       "\n",
       "[179 rows x 16 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "acfdb679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0252803ab8b49b9b4407dbba9b0d919",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'df_val_id' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m pred_df\u001b[38;5;241m.\u001b[39mhead()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Add PassengerId information to the predictions\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m pred_df_with_ids \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([\u001b[43mdf_val_id\u001b[49m\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), pred_df\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      6\u001b[0m pred_df_with_ids \u001b[38;5;241m=\u001b[39m pred_df_with_ids\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSurvived\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Display the predictions with PassengerId information\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_val_id' is not defined"
     ]
    }
   ],
   "source": [
    "pred_df = tabular_model.predict(validation)\n",
    "pred_df.head()\n",
    "# Add PassengerId information to the predictions\n",
    "pred_df_with_ids = pd.concat([df_val_id.reset_index(drop=True), pred_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "pred_df_with_ids = pred_df_with_ids.rename(columns={'prediction': 'Survived'})\n",
    "# Display the predictions with PassengerId information\n",
    "pred_df_with_ids[[\"PassengerId\", \"Survived\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee916b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df_with_ids[\"Survived\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b38fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df_with_ids[[\"PassengerId\", \"Survived\"]].to_csv(\"/Users/mdicio/Desktop/doidownloads/kaggle_datasets/test_submission_boom.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f46e051",
   "metadata": {},
   "source": [
    "# TabTransformer Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549c0914",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tab-transformer-pytorch\n",
    "import torch\n",
    "from tab_transformer_pytorch import FTTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db3e44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = FTTransformer(\n",
    "    categories = (5, 5, 5, 5, 5),      # tuple containing the number of unique values within each category\n",
    "    num_continuous = 10,                # number of continuous values\n",
    "    dim = 32,                           # dimension, paper set at 32\n",
    "    dim_out = 1,                        # binary prediction, but could be anything\n",
    "    depth = 6,                          # depth, paper recommended 6\n",
    "    heads = 8,                          # heads, paper recommends 8\n",
    "    attn_dropout = 0.1,                 # post-attention dropout\n",
    "    ff_dropout = 0.1                    # feed forward dropout\n",
    ")\n",
    "\n",
    "x_categ = torch.randint(0, 5, (1, 5))     # category values, from 0 - max number of categories, in the order as passed into the constructor above\n",
    "x_numer = torch.randn(1, 10)              # numerical value\n",
    "\n",
    "pred = model(x_categ, x_numer) # (1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ac956f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_categ.shape, x_numer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34999a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_categ = torch.randint(0, 5, (1, 5))  \n",
    "x_categ, x_numer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8064d1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23d426e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebdc7be",
   "metadata": {},
   "source": [
    "# Tabnet Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb30a010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the train data into training and validation sets\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from pytorch_tabnet.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f096715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class TabNetClassifier in module pytorch_tabnet.tab_model:\n",
      "\n",
      "class TabNetClassifier(pytorch_tabnet.abstract_model.TabModel)\n",
      " |  TabNetClassifier(n_d: int = 8, n_a: int = 8, n_steps: int = 3, gamma: float = 1.3, cat_idxs: List[int] = <factory>, cat_dims: List[int] = <factory>, cat_emb_dim: int = 1, n_independent: int = 2, n_shared: int = 2, epsilon: float = 1e-15, momentum: float = 0.02, lambda_sparse: float = 0.001, seed: int = 0, clip_value: int = 1, verbose: int = 1, optimizer_fn: Any = <class 'torch.optim.adam.Adam'>, optimizer_params: Dict = <factory>, scheduler_fn: Any = None, scheduler_params: Dict = <factory>, mask_type: str = 'sparsemax', input_dim: int = None, output_dim: int = None, device_name: str = 'auto', n_shared_decoder: int = 1, n_indep_decoder: int = 1) -> None\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      TabNetClassifier\n",
      " |      pytorch_tabnet.abstract_model.TabModel\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __post_init__(self)\n",
      " |  \n",
      " |  compute_loss(self, y_pred, y_true)\n",
      " |      Compute the loss.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      y_score : a :tensor: `torch.Tensor`\n",
      " |          Score matrix\n",
      " |      y_true : a :tensor: `torch.Tensor`\n",
      " |          Target matrix\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      float\n",
      " |          Loss value\n",
      " |  \n",
      " |  predict_func(self, outputs)\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Make predictions for classification on a batch (valid)\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : a :tensor: `torch.Tensor`\n",
      " |          Input data\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      res : np.ndarray\n",
      " |  \n",
      " |  prepare_target(self, y)\n",
      " |      Prepare target before training.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      y : a :tensor: `torch.Tensor`\n",
      " |          Target matrix.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      `torch.Tensor`\n",
      " |          Converted target matrix.\n",
      " |  \n",
      " |  stack_batches(self, list_y_true, list_y_score)\n",
      " |  \n",
      " |  update_fit_params(self, X_train, y_train, eval_set, weights)\n",
      " |      Set attributes relative to fit function.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X_train : np.ndarray\n",
      " |          Train set\n",
      " |      y_train : np.array\n",
      " |          Train targets\n",
      " |      eval_set : list of tuple\n",
      " |          List of eval tuple set (X, y).\n",
      " |      weights : bool or dictionnary\n",
      " |          0 for no balancing\n",
      " |          1 for automated balancing\n",
      " |  \n",
      " |  weight_updater(self, weights)\n",
      " |      Updates weights dictionary according to target_mapper.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      weights : bool or dict\n",
      " |          Given weights for balancing training.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      bool or dict\n",
      " |          Same bool if weights are bool, updated dict otherwise.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __annotations__ = {}\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pytorch_tabnet.abstract_model.TabModel:\n",
      " |  \n",
      " |  __eq__(self, other)\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __init__(self, n_d: int = 8, n_a: int = 8, n_steps: int = 3, gamma: float = 1.3, cat_idxs: List[int] = <factory>, cat_dims: List[int] = <factory>, cat_emb_dim: int = 1, n_independent: int = 2, n_shared: int = 2, epsilon: float = 1e-15, momentum: float = 0.02, lambda_sparse: float = 0.001, seed: int = 0, clip_value: int = 1, verbose: int = 1, optimizer_fn: Any = <class 'torch.optim.adam.Adam'>, optimizer_params: Dict = <factory>, scheduler_fn: Any = None, scheduler_params: Dict = <factory>, mask_type: str = 'sparsemax', input_dim: int = None, output_dim: int = None, device_name: str = 'auto', n_shared_decoder: int = 1, n_indep_decoder: int = 1) -> None\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __update__(self, **kwargs)\n",
      " |      Updates parameters.\n",
      " |      If does not already exists, creates it.\n",
      " |      Otherwise overwrite with warnings.\n",
      " |  \n",
      " |  explain(self, X, normalize=False)\n",
      " |      Return local explanation\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : tensor: `torch.Tensor`\n",
      " |          Input data\n",
      " |      normalize : bool (default False)\n",
      " |          Wheter to normalize so that sum of features are equal to 1\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      M_explain : matrix\n",
      " |          Importance per sample, per columns.\n",
      " |      masks : matrix\n",
      " |          Sparse matrix showing attention masks used by network.\n",
      " |  \n",
      " |  fit(self, X_train, y_train, eval_set=None, eval_name=None, eval_metric=None, loss_fn=None, weights=0, max_epochs=100, patience=10, batch_size=1024, virtual_batch_size=128, num_workers=0, drop_last=True, callbacks=None, pin_memory=True, from_unsupervised=None, warm_start=False, augmentations=None)\n",
      " |      Train a neural network stored in self.network\n",
      " |      Using train_dataloader for training data and\n",
      " |      valid_dataloader for validation.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X_train : np.ndarray\n",
      " |          Train set\n",
      " |      y_train : np.array\n",
      " |          Train targets\n",
      " |      eval_set : list of tuple\n",
      " |          List of eval tuple set (X, y).\n",
      " |          The last one is used for early stopping\n",
      " |      eval_name : list of str\n",
      " |          List of eval set names.\n",
      " |      eval_metric : list of str\n",
      " |          List of evaluation metrics.\n",
      " |          The last metric is used for early stopping.\n",
      " |      loss_fn : callable or None\n",
      " |          a PyTorch loss function\n",
      " |      weights : bool or dictionnary\n",
      " |          0 for no balancing\n",
      " |          1 for automated balancing\n",
      " |          dict for custom weights per class\n",
      " |      max_epochs : int\n",
      " |          Maximum number of epochs during training\n",
      " |      patience : int\n",
      " |          Number of consecutive non improving epoch before early stopping\n",
      " |      batch_size : int\n",
      " |          Training batch size\n",
      " |      virtual_batch_size : int\n",
      " |          Batch size for Ghost Batch Normalization (virtual_batch_size < batch_size)\n",
      " |      num_workers : int\n",
      " |          Number of workers used in torch.utils.data.DataLoader\n",
      " |      drop_last : bool\n",
      " |          Whether to drop last batch during training\n",
      " |      callbacks : list of callback function\n",
      " |          List of custom callbacks\n",
      " |      pin_memory: bool\n",
      " |          Whether to set pin_memory to True or False during training\n",
      " |      from_unsupervised: unsupervised trained model\n",
      " |          Use a previously self supervised model as starting weights\n",
      " |      warm_start: bool\n",
      " |          If True, current model parameters are used to start training\n",
      " |  \n",
      " |  load_class_attrs(self, class_attrs)\n",
      " |  \n",
      " |  load_model(self, filepath)\n",
      " |      Load TabNet model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      filepath : str\n",
      " |          Path of the model.\n",
      " |  \n",
      " |  load_weights_from_unsupervised(self, unsupervised_model)\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Make predictions on a batch (valid)\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : a :tensor: `torch.Tensor`\n",
      " |          Input data\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      predictions : np.array\n",
      " |          Predictions of the regression problem\n",
      " |  \n",
      " |  save_model(self, path)\n",
      " |      Saving TabNet model in two distinct files.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path : str\n",
      " |          Path of the model.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      str\n",
      " |          input filepath with \".zip\" appended\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from pytorch_tabnet.abstract_model.TabModel:\n",
      " |  \n",
      " |  __dataclass_fields__ = {'cat_dims': Field(name='cat_dims',type=typing....\n",
      " |  \n",
      " |  __dataclass_params__ = _DataclassParams(init=True,repr=True,eq=True,or...\n",
      " |  \n",
      " |  __hash__ = None\n",
      " |  \n",
      " |  __match_args__ = ('n_d', 'n_a', 'n_steps', 'gamma', 'cat_idxs', 'cat_d...\n",
      " |  \n",
      " |  cat_emb_dim = 1\n",
      " |  \n",
      " |  clip_value = 1\n",
      " |  \n",
      " |  device_name = 'auto'\n",
      " |  \n",
      " |  epsilon = 1e-15\n",
      " |  \n",
      " |  gamma = 1.3\n",
      " |  \n",
      " |  input_dim = None\n",
      " |  \n",
      " |  lambda_sparse = 0.001\n",
      " |  \n",
      " |  mask_type = 'sparsemax'\n",
      " |  \n",
      " |  momentum = 0.02\n",
      " |  \n",
      " |  n_a = 8\n",
      " |  \n",
      " |  n_d = 8\n",
      " |  \n",
      " |  n_indep_decoder = 1\n",
      " |  \n",
      " |  n_independent = 2\n",
      " |  \n",
      " |  n_shared = 2\n",
      " |  \n",
      " |  n_shared_decoder = 1\n",
      " |  \n",
      " |  n_steps = 3\n",
      " |  \n",
      " |  optimizer_fn = <class 'torch.optim.adam.Adam'>\n",
      " |      Implements Adam algorithm.\n",
      " |      \n",
      " |      .. math::\n",
      " |         \\begin{aligned}\n",
      " |              &\\rule{110mm}{0.4pt}                                                                 \\\\\n",
      " |              &\\textbf{input}      : \\gamma \\text{ (lr)}, \\beta_1, \\beta_2\n",
      " |                  \\text{ (betas)},\\theta_0 \\text{ (params)},f(\\theta) \\text{ (objective)}          \\\\\n",
      " |              &\\hspace{13mm}      \\lambda \\text{ (weight decay)},  \\: \\textit{amsgrad},\n",
      " |                  \\:\\textit{maximize}                                                              \\\\\n",
      " |              &\\textbf{initialize} :  m_0 \\leftarrow 0 \\text{ ( first moment)},\n",
      " |                  v_0\\leftarrow 0 \\text{ (second moment)},\\: \\widehat{v_0}^{max}\\leftarrow 0\\\\[-1.ex]\n",
      " |              &\\rule{110mm}{0.4pt}                                                                 \\\\\n",
      " |              &\\textbf{for} \\: t=1 \\: \\textbf{to} \\: \\ldots \\: \\textbf{do}                         \\\\\n",
      " |      \n",
      " |              &\\hspace{5mm}\\textbf{if} \\: \\textit{maximize}:                                       \\\\\n",
      " |              &\\hspace{10mm}g_t           \\leftarrow   -\\nabla_{\\theta} f_t (\\theta_{t-1})         \\\\\n",
      " |              &\\hspace{5mm}\\textbf{else}                                                           \\\\\n",
      " |              &\\hspace{10mm}g_t           \\leftarrow   \\nabla_{\\theta} f_t (\\theta_{t-1})          \\\\\n",
      " |              &\\hspace{5mm}\\textbf{if} \\: \\lambda \\neq 0                                           \\\\\n",
      " |              &\\hspace{10mm} g_t \\leftarrow g_t + \\lambda  \\theta_{t-1}                            \\\\\n",
      " |              &\\hspace{5mm}m_t           \\leftarrow   \\beta_1 m_{t-1} + (1 - \\beta_1) g_t          \\\\\n",
      " |              &\\hspace{5mm}v_t           \\leftarrow   \\beta_2 v_{t-1} + (1-\\beta_2) g^2_t          \\\\\n",
      " |              &\\hspace{5mm}\\widehat{m_t} \\leftarrow   m_t/\\big(1-\\beta_1^t \\big)                   \\\\\n",
      " |              &\\hspace{5mm}\\widehat{v_t} \\leftarrow   v_t/\\big(1-\\beta_2^t \\big)                   \\\\\n",
      " |              &\\hspace{5mm}\\textbf{if} \\: amsgrad                                                  \\\\\n",
      " |              &\\hspace{10mm}\\widehat{v_t}^{max} \\leftarrow \\mathrm{max}(\\widehat{v_t}^{max},\n",
      " |                  \\widehat{v_t})                                                                   \\\\\n",
      " |              &\\hspace{10mm}\\theta_t \\leftarrow \\theta_{t-1} - \\gamma \\widehat{m_t}/\n",
      " |                  \\big(\\sqrt{\\widehat{v_t}^{max}} + \\epsilon \\big)                                 \\\\\n",
      " |              &\\hspace{5mm}\\textbf{else}                                                           \\\\\n",
      " |              &\\hspace{10mm}\\theta_t \\leftarrow \\theta_{t-1} - \\gamma \\widehat{m_t}/\n",
      " |                  \\big(\\sqrt{\\widehat{v_t}} + \\epsilon \\big)                                       \\\\\n",
      " |              &\\rule{110mm}{0.4pt}                                                          \\\\[-1.ex]\n",
      " |              &\\bf{return} \\:  \\theta_t                                                     \\\\[-1.ex]\n",
      " |              &\\rule{110mm}{0.4pt}                                                          \\\\[-1.ex]\n",
      " |         \\end{aligned}\n",
      " |      \n",
      " |      For further details regarding the algorithm we refer to `Adam: A Method for Stochastic Optimization`_.\n",
      " |      \n",
      " |      Args:\n",
      " |          params (iterable): iterable of parameters to optimize or dicts defining\n",
      " |              parameter groups\n",
      " |          lr (float, optional): learning rate (default: 1e-3)\n",
      " |          betas (Tuple[float, float], optional): coefficients used for computing\n",
      " |              running averages of gradient and its square (default: (0.9, 0.999))\n",
      " |          eps (float, optional): term added to the denominator to improve\n",
      " |              numerical stability (default: 1e-8)\n",
      " |          weight_decay (float, optional): weight decay (L2 penalty) (default: 0)\n",
      " |          amsgrad (bool, optional): whether to use the AMSGrad variant of this\n",
      " |              algorithm from the paper `On the Convergence of Adam and Beyond`_\n",
      " |              (default: False)\n",
      " |          foreach (bool, optional): whether foreach implementation of optimizer\n",
      " |              is used (default: None)\n",
      " |          maximize (bool, optional): maximize the params based on the objective, instead of\n",
      " |              minimizing (default: False)\n",
      " |          capturable (bool, optional): whether this instance is safe to capture in a CUDA graph.\n",
      " |              Passing True can impair ungraphed performance, so if you don't intend to\n",
      " |              graph capture this instance, leave it False (default: False)\n",
      " |          fused (bool, optional): whether fused implementation of optimizer is used.\n",
      " |              Currently, `torch.float64`, `torch.float32`, `torch.float16`, and `torch.bfloat16`\n",
      " |              are supported. (default: False)\n",
      " |      \n",
      " |      .. _Adam\\: A Method for Stochastic Optimization:\n",
      " |          https://arxiv.org/abs/1412.6980\n",
      " |      .. _On the Convergence of Adam and Beyond:\n",
      " |          https://openreview.net/forum?id=ryQu7f-RZ\n",
      " |  \n",
      " |  \n",
      " |  output_dim = None\n",
      " |  \n",
      " |  scheduler_fn = None\n",
      " |  \n",
      " |  seed = 0\n",
      " |  \n",
      " |  verbose = 1\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(TabNetClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99175122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['self', 'n_d', 'n_a', 'n_steps', 'gamma', 'cat_idxs', 'cat_dims', 'cat_emb_dim', 'n_independent', 'n_shared', 'epsilon', 'momentum', 'lambda_sparse', 'seed', 'clip_value', 'verbose', 'optimizer_fn', 'optimizer_params', 'scheduler_fn', 'scheduler_params', 'mask_type', 'input_dim', 'output_dim', 'device_name', 'n_shared_decoder', 'n_indep_decoder']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6a09b30",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Pandas DataFrame are not supported: apply X.values when calling fit",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m TabNetClassifier()\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Train the model with early stopping\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlogloss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43mpatience\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m            \n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/envs/WTab/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:200\u001b[0m, in \u001b[0;36mTabModel.fit\u001b[0;34m(self, X_train, y_train, eval_set, eval_name, eval_metric, loss_fn, weights, max_epochs, patience, batch_size, virtual_batch_size, num_workers, drop_last, callbacks, pin_memory, from_unsupervised, warm_start, augmentations)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_fn \u001b[38;5;241m=\u001b[39m loss_fn\n\u001b[0;32m--> 200\u001b[0m \u001b[43mcheck_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m check_warm_start(warm_start, from_unsupervised)\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_fit_params(\n\u001b[1;32m    204\u001b[0m     X_train,\n\u001b[1;32m    205\u001b[0m     y_train,\n\u001b[1;32m    206\u001b[0m     eval_set,\n\u001b[1;32m    207\u001b[0m     weights,\n\u001b[1;32m    208\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/envs/WTab/lib/python3.10/site-packages/pytorch_tabnet/utils.py:351\u001b[0m, in \u001b[0;36mcheck_input\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(X, (pd\u001b[38;5;241m.\u001b[39mDataFrame, pd\u001b[38;5;241m.\u001b[39mSeries)):\n\u001b[1;32m    350\u001b[0m     err_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPandas DataFrame are not supported: apply X.values when calling fit\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 351\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(err_message)\n\u001b[1;32m    352\u001b[0m check_array(X)\n",
      "\u001b[0;31mTypeError\u001b[0m: Pandas DataFrame are not supported: apply X.values when calling fit"
     ]
    }
   ],
   "source": [
    "# Define the early stopping callback\n",
    "early_stopping = EarlyStopping(early_stopping_metric = 'val_loss',\n",
    "is_maximize = False,\n",
    "patience = 32\n",
    ")\n",
    "\n",
    "model = TabNetClassifier()\n",
    "\n",
    "# Train the model with early stopping\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    eval_name=['valid'],\n",
    "    eval_metric=['logloss'],\n",
    "    max_epochs=2,\n",
    "    batch_size = 16,\n",
    "    callbacks=[early_stopping],\n",
    "patience = 32)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7f7a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e23bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the labels of the validation data\n",
    "y_pred = model.predict(X_test)\n",
    "# Calculate the score using the specified metric\n",
    "evaluator = Evaluator(problem_type = \"multiclass_classification\")\n",
    "evaluator.y_true = y_val\n",
    "evaluator.y_pred = y_pred\n",
    "score = evaluator.evaluate_metric(metric_name = \"f1\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
