{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abd838c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f0405c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"../output/default_pytorch_tabular_benchmark.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9161df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of metric names\n",
    "metric_names = [\"f1\",\"mse\",\"accuracy\",\"recall\",\"precision\", \"auc\",\"area_under_pr\", \"r2_score\", \"rmse\"]\n",
    "dataset = df.copy()\n",
    "# Create columns based on metric names\n",
    "# Convert string representations to dictionaries\n",
    "dataset['output_metrics'] = dataset['output_metrics'].apply(ast.literal_eval)\n",
    "# Create columns based on metric names\n",
    "for metric in metric_names:\n",
    "    dataset[metric] = dataset['output_metrics'].apply(lambda x: x.get(metric) if isinstance(x, dict) else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e4f9922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>run_time</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>best_params</th>\n",
       "      <th>output_metrics</th>\n",
       "      <th>debug_ytrue</th>\n",
       "      <th>f1</th>\n",
       "      <th>mse</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>auc</th>\n",
       "      <th>area_under_pr</th>\n",
       "      <th>r2_score</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [dataset, model, run_time, eval_metric, best_params, output_metrics, debug_ytrue, f1, mse, accuracy, recall, precision, auc, area_under_pr, r2_score, rmse]\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify the metric you want to maximize\n",
    "metric_to_maximize = 'mse'\n",
    "tomax = {\"f1\": True,\n",
    "         \"mse\": False,\n",
    "         \"accuracy\": True,\n",
    "         \"recall\": True,\n",
    "         \"precision\": True,\n",
    "         \"auc\": True,\n",
    "         \"area_under_pr\": True,\n",
    "        \"rmse\": False,\n",
    "        \"r2_score\": True}\n",
    "\n",
    "\n",
    "# Filter out rows with NaN values in the specified metric column\n",
    "filtered_df = dataset.dropna(subset=[metric_to_maximize]).loc[dataset[metric_to_maximize] != \"nan\"]\n",
    "\n",
    "# Find the rows that maximize the specified metric for each dataset\n",
    "if  tomax[metric_to_maximize]:\n",
    "    max_rows = filtered_df.sort_values([\"dataset\",metric_to_maximize])\n",
    "else:\n",
    "    max_rows = filtered_df.sort_values(metric_to_maximize)\n",
    "    \n",
    "sel_cols = ['dataset', 'model', 'run_time',\n",
    "       'eval_metric', 'best_params', 'output_metrics',\n",
    " 'debug_ytrue', 'f1', 'mse', 'accuracy',\n",
    "       'recall', 'precision', 'auc', 'area_under_pr', 'r2_score', 'rmse']\n",
    "\n",
    "max_rows[sel_cols].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "deb16109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>run_config</th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>execution_mode</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>best_params</th>\n",
       "      <th>output_metrics</th>\n",
       "      <th>saved_model_path</th>\n",
       "      <th>run_time</th>\n",
       "      <th>...</th>\n",
       "      <th>debug_ytrue</th>\n",
       "      <th>f1</th>\n",
       "      <th>mse</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>auc</th>\n",
       "      <th>area_under_pr</th>\n",
       "      <th>r2_score</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202308-0918-0955-9db8ad13-8c88-4b45-8a33-58435...</td>\n",
       "      <td>{'dataset': 'titanic', 'model': 'tabnet', 'bes...</td>\n",
       "      <td>titanic</td>\n",
       "      <td>tabnet</td>\n",
       "      <td>hyperopt</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>{'Adam_weight_decay': 0.0008344870704054452, '...</td>\n",
       "      <td>{'recall': 0.7558139534883721, 'precision': 0....</td>\n",
       "      <td>./output/modelsaves/titanic/tabnet/202308-0918...</td>\n",
       "      <td>96.496373</td>\n",
       "      <td>...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
       "      <td>0.613208</td>\n",
       "      <td>None</td>\n",
       "      <td>0.632287</td>\n",
       "      <td>0.755814</td>\n",
       "      <td>0.515873</td>\n",
       "      <td>0.702682</td>\n",
       "      <td>0.484074</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              run_id  \\\n",
       "0  202308-0918-0955-9db8ad13-8c88-4b45-8a33-58435...   \n",
       "\n",
       "                                          run_config  dataset   model  \\\n",
       "0  {'dataset': 'titanic', 'model': 'tabnet', 'bes...  titanic  tabnet   \n",
       "\n",
       "  execution_mode eval_metric  \\\n",
       "0       hyperopt    accuracy   \n",
       "\n",
       "                                         best_params  \\\n",
       "0  {'Adam_weight_decay': 0.0008344870704054452, '...   \n",
       "\n",
       "                                      output_metrics  \\\n",
       "0  {'recall': 0.7558139534883721, 'precision': 0....   \n",
       "\n",
       "                                    saved_model_path   run_time  ...  \\\n",
       "0  ./output/modelsaves/titanic/tabnet/202308-0918...  96.496373  ...   \n",
       "\n",
       "                      debug_ytrue        f1   mse  accuracy    recall  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]  0.613208  None  0.632287  0.755814   \n",
       "\n",
       "   precision       auc  area_under_pr  r2_score  rmse  \n",
       "0   0.515873  0.702682       0.484074      None  None  \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify the metric you want to maximize\n",
    "metric_to_maximize = 'f1'\n",
    "tomax = {\"f1\": True,\n",
    "         \"mse\": False,\n",
    "         \"accuracy\": True,\n",
    "         \"recall\": True,\n",
    "         \"precision\": True,\n",
    "         \"auc\": True,\n",
    "         \"area_under_pr\": True,\n",
    "        \"rmse\": False,\n",
    "        \"r2_score\": True}\n",
    "\n",
    "\n",
    "\n",
    "# Filter out rows with NaN values in the specified metric column\n",
    "filtered_df = dataset.dropna(subset=[metric_to_maximize]).loc[dataset[metric_to_maximize] != \"nan\"]\n",
    "\n",
    "# Find the rows that maximize the specified metric for each dataset\n",
    "if  tomax[metric_to_maximize]:\n",
    "    max_rows = filtered_df.groupby('dataset')[metric_to_maximize].idxmax()\n",
    "else:\n",
    "    max_rows = filtered_df.groupby('dataset')[metric_to_maximize].idxmin()\n",
    "    \n",
    "# Retrieve the rows that maximize the metric\n",
    "maximized_rows = filtered_df.loc[max_rows]\n",
    "\n",
    "maximized_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4148ed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'Adam_weight_decay': 0.0008344870704054452, 'ReduceLROnPlateau_factor': 0.39054754693784877, 'ReduceLROnPlateau_patience': 9, 'batch_size': 64, 'cat_emb_dim': 3, 'clip_value': 2, 'early_stopping_patience': 5, 'gamma': 1.1112005798198572, 'lambda_sparse': 0.0018702554034918367, 'learning_rate': 0.00023539065760010136, 'mask_type': 'entmax', 'momentum': 0.002024407113236184, 'n_d': 11, 'n_independent': 2, 'n_shared': 3, 'n_steps': 6, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'scheduler_fn': 'ReduceLROnPlateau', 'virtual_batch_size_ratio': 0.5, 'weights': 1, 'outer_params': {'max_epochs': 1000, 'early_stopping_tolerance': 1e-06, 'hyperopt_evals': 10, 'val_size': 0.2, 'auto_lr_find': False}, 'virtual_batch_size': 32, 'optimizer_params': {'weight_decay': 0.0008344870704054452}, 'scheduler_params': {'factor': 0.39054754693784877, 'patience': 9, 'min_lr': 1e-07, 'verbose': True, 'mode': 'min'}, 'n_a': 11}\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maximized_rows[\"best_params\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78a1539c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'alpha': 1, 'colsample_bytree': 0.7701468147287692, 'gamma': 4, 'lambda': 5, 'learning_rate': 0.019628488779340834, 'max_bin': 156, 'max_depth': 8, 'min_child_weight': 8, 'n_estimators': 255, 'subsample': 0.9280869759290384, 'tree_method': 'auto'}\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maximized_rows[\"best_params\"].iloc[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
