{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "385dfcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install seaborn\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from evaluation.generalevaluator import *\n",
    "from factory import create_data_loader\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d3704da",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = create_data_loader('housing', test_size=0.2, normalize_features = \"mean_std\", return_extra_info = True, encode_categorical = True)\n",
    "X_train, X_test, y_train, y_test, extra_info = data_loader.load_data()\n",
    "\n",
    "# Assume that X_train is a pandas DataFrame containing your features\n",
    "numeric_features = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72015d3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14196    1.03000\n",
       "8267     3.82100\n",
       "17445    1.72600\n",
       "14265    0.93400\n",
       "2271     0.96500\n",
       "17848    2.64800\n",
       "6252     1.57300\n",
       "9389     5.00001\n",
       "6113     1.39800\n",
       "6061     3.15600\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "761e7dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelsdefinition.ResNetModel import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f45373e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ResNetTrainer.__init__() missing 2 required positional arguments: 'img_rows' and 'img_columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mResNetTrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: ResNetTrainer.__init__() missing 2 required positional arguments: 'img_rows' and 'img_columns'"
     ]
    }
   ],
   "source": [
    "model = ResNetTrainer().load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80796a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'> <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_test), type(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aea90e09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16512, 8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e2ebcd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d370eef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([0,1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4492757b",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43ma\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "a[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c87db17f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14196</th>\n",
       "      <td>-0.326196</td>\n",
       "      <td>0.348490</td>\n",
       "      <td>-0.174916</td>\n",
       "      <td>-0.208365</td>\n",
       "      <td>0.768276</td>\n",
       "      <td>0.051376</td>\n",
       "      <td>-1.372811</td>\n",
       "      <td>1.272587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8267</th>\n",
       "      <td>-0.035843</td>\n",
       "      <td>1.618118</td>\n",
       "      <td>-0.402835</td>\n",
       "      <td>-0.128530</td>\n",
       "      <td>-0.098901</td>\n",
       "      <td>-0.117362</td>\n",
       "      <td>-0.876696</td>\n",
       "      <td>0.709162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17445</th>\n",
       "      <td>0.144701</td>\n",
       "      <td>-1.952710</td>\n",
       "      <td>0.088216</td>\n",
       "      <td>-0.257538</td>\n",
       "      <td>-0.449818</td>\n",
       "      <td>-0.032280</td>\n",
       "      <td>-0.460146</td>\n",
       "      <td>-0.447603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14265</th>\n",
       "      <td>-1.017864</td>\n",
       "      <td>0.586545</td>\n",
       "      <td>-0.600015</td>\n",
       "      <td>-0.145156</td>\n",
       "      <td>-0.007434</td>\n",
       "      <td>0.077507</td>\n",
       "      <td>-1.382172</td>\n",
       "      <td>1.232698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2271</th>\n",
       "      <td>-0.171488</td>\n",
       "      <td>1.142008</td>\n",
       "      <td>0.349007</td>\n",
       "      <td>0.086624</td>\n",
       "      <td>-0.485877</td>\n",
       "      <td>-0.068832</td>\n",
       "      <td>0.532084</td>\n",
       "      <td>-0.108551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11284</th>\n",
       "      <td>1.307215</td>\n",
       "      <td>0.507194</td>\n",
       "      <td>0.290620</td>\n",
       "      <td>-0.393391</td>\n",
       "      <td>-0.675847</td>\n",
       "      <td>-0.005588</td>\n",
       "      <td>-0.872016</td>\n",
       "      <td>0.808883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11964</th>\n",
       "      <td>-0.436266</td>\n",
       "      <td>0.348490</td>\n",
       "      <td>0.600411</td>\n",
       "      <td>0.398898</td>\n",
       "      <td>0.287195</td>\n",
       "      <td>0.069722</td>\n",
       "      <td>-0.759688</td>\n",
       "      <td>1.073144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>-0.496973</td>\n",
       "      <td>0.586545</td>\n",
       "      <td>-0.606759</td>\n",
       "      <td>-0.039216</td>\n",
       "      <td>0.289833</td>\n",
       "      <td>0.020306</td>\n",
       "      <td>-0.755007</td>\n",
       "      <td>0.599469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>0.965450</td>\n",
       "      <td>-1.079841</td>\n",
       "      <td>0.402175</td>\n",
       "      <td>-0.066265</td>\n",
       "      <td>0.308303</td>\n",
       "      <td>0.007076</td>\n",
       "      <td>0.906510</td>\n",
       "      <td>-1.185540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>-0.685448</td>\n",
       "      <td>1.856173</td>\n",
       "      <td>-0.851446</td>\n",
       "      <td>-0.087508</td>\n",
       "      <td>1.048834</td>\n",
       "      <td>-0.085354</td>\n",
       "      <td>0.995437</td>\n",
       "      <td>-1.414898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16512 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  \\\n",
       "14196 -0.326196  0.348490 -0.174916  -0.208365    0.768276  0.051376   \n",
       "8267  -0.035843  1.618118 -0.402835  -0.128530   -0.098901 -0.117362   \n",
       "17445  0.144701 -1.952710  0.088216  -0.257538   -0.449818 -0.032280   \n",
       "14265 -1.017864  0.586545 -0.600015  -0.145156   -0.007434  0.077507   \n",
       "2271  -0.171488  1.142008  0.349007   0.086624   -0.485877 -0.068832   \n",
       "...         ...       ...       ...        ...         ...       ...   \n",
       "11284  1.307215  0.507194  0.290620  -0.393391   -0.675847 -0.005588   \n",
       "11964 -0.436266  0.348490  0.600411   0.398898    0.287195  0.069722   \n",
       "5390  -0.496973  0.586545 -0.606759  -0.039216    0.289833  0.020306   \n",
       "860    0.965450 -1.079841  0.402175  -0.066265    0.308303  0.007076   \n",
       "15795 -0.685448  1.856173 -0.851446  -0.087508    1.048834 -0.085354   \n",
       "\n",
       "       Latitude  Longitude  \n",
       "14196 -1.372811   1.272587  \n",
       "8267  -0.876696   0.709162  \n",
       "17445 -0.460146  -0.447603  \n",
       "14265 -1.382172   1.232698  \n",
       "2271   0.532084  -0.108551  \n",
       "...         ...        ...  \n",
       "11284 -0.872016   0.808883  \n",
       "11964 -0.759688   1.073144  \n",
       "5390  -0.755007   0.599469  \n",
       "860    0.906510  -1.185540  \n",
       "15795  0.995437  -1.414898  \n",
       "\n",
       "[16512 rows x 8 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41a34fd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked', 'class',\n",
       "       'deck', 'embark_town', 'alone'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "80d4265b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(AB    -1.288129e-16\n",
       " AF     1.441263e-17\n",
       " AH     3.603158e-18\n",
       " AM    -5.765053e-17\n",
       " AR    -1.873642e-16\n",
       " AX     8.287263e-17\n",
       " AY     2.630305e-16\n",
       " AZ    -3.639189e-16\n",
       " BC    -4.323789e-17\n",
       " BD    -1.585389e-16\n",
       " BN    -1.621421e-16\n",
       " BP     8.647579e-17\n",
       " BQ     7.206316e-18\n",
       " BR     6.485684e-17\n",
       " BZ    -3.603158e-17\n",
       " CB     0.000000e+00\n",
       " CC     5.404737e-18\n",
       " CD     3.963474e-17\n",
       " CF     3.603158e-18\n",
       " CH     1.549358e-16\n",
       " CL     1.621421e-17\n",
       " CR    -6.125368e-17\n",
       " CS    -3.062684e-17\n",
       " CU     5.404737e-18\n",
       " CW    -7.206316e-17\n",
       " DA    -1.008884e-16\n",
       " DE    -2.089832e-16\n",
       " DF    -6.846000e-17\n",
       " DH     3.639189e-16\n",
       " DI     1.585389e-16\n",
       " DL    -1.657453e-16\n",
       " DN     2.269989e-16\n",
       " DU     3.963474e-17\n",
       " DV     1.098963e-16\n",
       " DY     9.188053e-17\n",
       " EB     5.404737e-18\n",
       " EE     3.242842e-17\n",
       " EG    -5.224579e-17\n",
       " EH    -3.603158e-18\n",
       " EJ    -8.107105e-17\n",
       " EL    -2.161895e-17\n",
       " EP     2.306021e-16\n",
       " EU    -2.972605e-17\n",
       " FC     5.404737e-17\n",
       " FD    -2.522211e-17\n",
       " FE     6.665842e-17\n",
       " FI    -7.926947e-17\n",
       " FL    -5.404737e-18\n",
       " FR     3.242842e-17\n",
       " FS    -2.882526e-17\n",
       " GB    -3.125739e-16\n",
       " GE    -6.846000e-17\n",
       " GF    -8.107105e-17\n",
       " GH    -1.116979e-16\n",
       " GI    -6.125368e-17\n",
       " GL    -7.206316e-17\n",
       " dtype: float64,\n",
       " AB     1.001016\n",
       " AF     1.001016\n",
       " AH     1.001016\n",
       " AM     1.001016\n",
       " AR     1.001016\n",
       " AX     1.001016\n",
       " AY     1.001016\n",
       " AZ     1.001016\n",
       " BC     1.001016\n",
       " BD     1.001016\n",
       " BN     1.001016\n",
       " BP     1.001016\n",
       " BQ     1.001016\n",
       " BR     1.001016\n",
       " BZ     1.001016\n",
       " CB     1.001016\n",
       " CC     1.001016\n",
       " CD     1.001016\n",
       " CF     1.001016\n",
       " CH     1.001016\n",
       " CL     1.001016\n",
       " CR     1.001016\n",
       " CS     1.001016\n",
       " CU     1.001016\n",
       " CW     1.001016\n",
       " DA     1.001016\n",
       " DE     1.001016\n",
       " DF     1.001016\n",
       " DH     1.001016\n",
       " DI     1.001016\n",
       " DL     1.001016\n",
       " DN     1.001016\n",
       " DU     1.001016\n",
       " DV     1.001016\n",
       " DY     1.001016\n",
       " EB     1.001016\n",
       " EE     1.001016\n",
       " EG     1.001016\n",
       " EH     1.001016\n",
       " EJ     1.001016\n",
       " EL     1.001016\n",
       " EP     1.001016\n",
       " EU     1.001016\n",
       " FC     1.001016\n",
       " FD     1.001016\n",
       " FE     1.001016\n",
       " FI     1.001016\n",
       " FL     1.001016\n",
       " FR     1.001016\n",
       " FS     1.001016\n",
       " GB     1.001016\n",
       " GE     1.001016\n",
       " GF     1.001016\n",
       " GH     1.001016\n",
       " GI     1.001016\n",
       " GL     1.001016\n",
       " dtype: float64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# precompute mean and standard deviation of the training data\n",
    "train_mean = X_train.mean(axis=0)\n",
    "train_std = X_train.std(axis=0)\n",
    "train_mean,train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84b4ad22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((493, 56),\n",
       " (493,),\n",
       " target\n",
       " 0    408\n",
       " 1     85\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3291cf21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory './data/temp/' already exists.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# specify the directory path\n",
    "path = \"./data/temp/\"\n",
    "# check if the directory already exists\n",
    "if not os.path.exists(path):\n",
    "    # create the directory if it does not exist\n",
    "    os.makedirs(path)\n",
    "    print(f\"Directory '{path}' created successfully.\")\n",
    "else:\n",
    "    print(f\"Directory '{path}' already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "afe95e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv(f\"{path}/xtrain.csv\", index = False)\n",
    "X_test.to_csv(f\"{path}/xtest.csv\", index = False)\n",
    "y_train.to_csv(f\"{path}/ytrain.csv\", index = False)\n",
    "y_test.to_csv(f\"{path}/ytest.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5998e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(493, 56)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = pd.read_csv(f\"{path}/xtrain.csv\")\n",
    "X_test = pd.read_csv(f\"{path}/xtest.csv\")\n",
    "y_train = pd.read_csv(f\"{path}/ytrain.csv\")\n",
    "y_test = pd.read_csv(f\"{path}/ytest.csv\")\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8ddfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22eff7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only numeric features from X_train and X_val\n",
    "X_train = X_train[numeric_features]\n",
    "X_test = X_test[numeric_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c027df20",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651f2d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet18, resnet34, resnet50\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import os\n",
    "\n",
    "\n",
    "class ResNetModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        problem_type=\"binary_classification\",\n",
    "        num_classes=1,\n",
    "        depth=\"resnet50\",\n",
    "        pretrained=True,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super(ResNetModel, self).__init__()\n",
    "\n",
    "        self.pretrained = pretrained\n",
    "        self.problem_type = problem_type\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        if depth == \"resnet18\":\n",
    "            self.resnet = resnet18(pretrained=self.pretrained)\n",
    "        elif depth == \"resnet34\":\n",
    "            self.resnet = resnet34(pretrained=self.pretrained)\n",
    "        elif depth == \"resnet50\":\n",
    "            self.resnet = resnet50(pretrained=self.pretrained)\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Invalid depth. Supported options: resnet18, resnet34, resnet50.\"\n",
    "            )\n",
    "\n",
    "        self.num_features = self.resnet.fc.in_features\n",
    "\n",
    "        if self.problem_type == \"binary_classification\":\n",
    "            self.classifier = nn.Linear(self.num_features, 1)\n",
    "        elif self.problem_type == \"multiclass_classification\":\n",
    "            self.classifier = nn.Linear(self.num_features, self.num_classes)\n",
    "        elif self.problem_type == \"regression\":\n",
    "            self.classifier = nn.Linear(self.num_features, 1)\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Invalid problem_type. Supported options: binary_classification, multiclass_classification, regression.\"\n",
    "            )\n",
    "\n",
    "        self.resnet.fc = nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.resnet(x)\n",
    "        x = self.classifier(features)\n",
    "        x = self.output_activation(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResNetTrainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        img_rows=224,\n",
    "        img_columns=224,\n",
    "        num_classes=1,\n",
    "        depth=\"resnet50\",\n",
    "        pretrained=True,\n",
    "        batch_size=64,\n",
    "        learning_rate=0.001,\n",
    "        problem_type=\"binary_classification\",\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.num_classes = num_classes\n",
    "        self.img_rows = img_rows\n",
    "        self.img_columns = img_columns\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.depth = depth\n",
    "        self.pretrained = pretrained\n",
    "        self.problem_type = problem_type\n",
    "        self.save_path = None\n",
    "\n",
    "        self.model = ResNetModel(\n",
    "            self.problem_type, self.num_classes, self.depth, self.pretrained\n",
    "        )\n",
    "\n",
    "        if self.problem_type == \"binary_classification\":\n",
    "            self.loss_fn = nn.BCEWithLogitsLoss()\n",
    "        elif self.problem_type == \"multiclass_classification\":\n",
    "            self.loss_fn = nn.CrossEntropyLoss()\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Invalid problem_type. Supported options: binary_classification, multiclass_classification\"\n",
    "            )\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "        self.scheduler = ReduceLROnPlateau(\n",
    "            self.optimizer, mode=\"min\", factor=0.1, patience=5, verbose=True\n",
    "        )\n",
    "\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    def load_model(self, model_path):\n",
    "        \"\"\"Load a trained model from a given path\"\"\"\n",
    "        if not os.path.isfile(model_path):\n",
    "            raise FileNotFoundError(f\"Model file not found at {model_path}\")\n",
    "\n",
    "        self.model.load_state_dict(torch.load(model_path, map_location=self.device))\n",
    "        self.model.eval()\n",
    "        print(f\"Model loaded successfully from {model_path}\")\n",
    "\n",
    "    def save_model(self, model_dir, model_name):\n",
    "        \"\"\"Save the trained model to a given directory with the specified name\"\"\"\n",
    "        save_path = os.path.join(model_dir, model_name)\n",
    "        torch.save(self.model.state_dict(), save_path)\n",
    "        print(f\"Model saved successfully at {save_path}\")\n",
    "\n",
    "    def train(self, X_train, y_train, params={}, extra_info=None):\n",
    "        # IGTD_ORDERING\n",
    "        index_ordering = extra_info[\"column_ordering\"]\n",
    "        self.img_rows = extra_info[\"img_rows\"]\n",
    "        self.img_columns = extra_info[\"img_columns\"]\n",
    "\n",
    "        # Assuming you have a DataFrame named 'df' with the original column order\n",
    "        original_columns = X_train.columns\n",
    "        # Reindex the DataFrame with the new column order\n",
    "        self.new_column_ordering = [original_columns[i] for i in index_ordering]\n",
    "        X_train = X_train.reindex(columns=self.new_column_ordering)\n",
    "\n",
    "        validation_fraction = params.get(\"validation_fraction\", 0.2)\n",
    "        early_stopping = params.get(\"early_stopping\", False)\n",
    "        patience = params.get(\"patience\", 3)\n",
    "        num_epochs = params.get(\"num_epochs\", 10)\n",
    "\n",
    "        self.transformation = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        print(type(X_train), type(y_train))\n",
    "\n",
    "        train_dataset = CustomDataset(\n",
    "            X_train,\n",
    "            pd.DataFrame(y_train),\n",
    "            self.img_rows,\n",
    "            self.img_columns,\n",
    "            transform=self.transformation,\n",
    "        )\n",
    "\n",
    "        train_size = int((1 - validation_fraction) * len(train_dataset))\n",
    "        val_size = len(train_dataset) - train_size\n",
    "        train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "            train_dataset, [train_size, val_size]\n",
    "        )\n",
    "\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset, batch_size=self.batch_size, shuffle=True\n",
    "        )\n",
    "        val_loader = DataLoader(val_dataset, batch_size=self.batch_size, shuffle=False)\n",
    "\n",
    "        self.model.to(self.device)\n",
    "        self.model.train()\n",
    "\n",
    "        best_val_loss = float(\"inf\")\n",
    "        best_epoch = 0\n",
    "        current_patience = 0\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            running_loss = 0.0\n",
    "            for i, (inputs, labels) in enumerate(train_loader):\n",
    "                inputs = inputs.to(self.device)\n",
    "\n",
    "                if self.problem_type == \"binary_classification\":\n",
    "                    labels = labels.squeeze().float().to(self.device)\n",
    "                elif self.problem_type == \"multiclass_classification\":\n",
    "                    labels = labels.long().to(self.device)\n",
    "                else:\n",
    "                    raise ValueError(\n",
    "                        \"Invalid problem_type. Supported options: binary_classification, multiclass_classification\"\n",
    "                    )\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.loss_fn(outputs.squeeze(), labels.float())\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "\n",
    "            epoch_loss = running_loss / len(train_loader)\n",
    "\n",
    "            if early_stopping and validation_fraction > 0:\n",
    "                self.model.eval()\n",
    "\n",
    "                val_loss = 0.0\n",
    "                with torch.no_grad():\n",
    "                    for inputs, labels in val_loader:\n",
    "                        inputs = inputs.to(self.device)\n",
    "\n",
    "                        if self.problem_type == \"binary_classification\":\n",
    "                            labels = labels.squeeze().float().to(self.device)\n",
    "                        elif self.problem_type == \"multiclass_classification\":\n",
    "                            labels = labels.long().to(self.device)\n",
    "                        else:\n",
    "                            raise ValueError(\n",
    "                                \"Invalid problem_type. Supported options: binary_classification, multiclass_classification\"\n",
    "                            )\n",
    "\n",
    "                        outputs = self.model(inputs)\n",
    "                        loss = self.loss_fn(outputs.squeeze(), labels.float())\n",
    "                        val_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "                val_loss /= len(val_dataset)\n",
    "\n",
    "                self.scheduler.step(val_loss)\n",
    "\n",
    "                if val_loss < best_val_loss:\n",
    "                    best_val_loss = val_loss\n",
    "                    best_epoch = epoch\n",
    "                    current_patience = 0\n",
    "\n",
    "                    if self.save_path is not None:\n",
    "                        torch.save(self.model.state_dict(), self.save_path + \"_checkpt\")\n",
    "                else:\n",
    "                    current_patience += 1\n",
    "\n",
    "                print(\n",
    "                    f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {epoch_loss:.4f}, Val Loss: {val_loss:.4f}\"\n",
    "                )\n",
    "\n",
    "                if current_patience >= patience:\n",
    "                    print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "                    break\n",
    "\n",
    "        if self.save_path is not None:\n",
    "            print(f\"Best model weights saved at epoch {best_epoch+1}\")\n",
    "            self.model.load_state_dict(torch.load(self.save_path + \"_checkpt\"))\n",
    "\n",
    "    def predict(self, X_test, predict_proba = False):\n",
    "        X_test = X_test.reindex(columns=self.new_column_ordering)\n",
    "\n",
    "        test_dataset = CustomDataset(\n",
    "            X_test,\n",
    "            labels=None,\n",
    "            img_rows=self.img_rows,\n",
    "            img_columns=self.img_columns,\n",
    "            transform=self.transformation,\n",
    "        )\n",
    "\n",
    "        test_loader = DataLoader(\n",
    "            test_dataset, batch_size=self.batch_size, shuffle=False\n",
    "        )\n",
    "\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "\n",
    "        predictions = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs in test_loader:\n",
    "                inputs = inputs.to(self.device)\n",
    "                outputs = self.model(inputs.to(self.device))\n",
    "\n",
    "                if self.problem_type == \"binary_classification\":\n",
    "                    preds = (\n",
    "                        (torch.sigmoid(outputs) >= 0.5)\n",
    "                        .squeeze()\n",
    "                        .int()\n",
    "                        .to(\"cpu\")\n",
    "                        .numpy()\n",
    "                    )\n",
    "                elif self.problem_type == \"multiclass_classification\":\n",
    "                    _, preds = torch.max(outputs, 1).item()\n",
    "                elif self.problem_type == \"regression\":\n",
    "                    preds = outputs.to(\"cpu\").tolist()\n",
    "                else:\n",
    "                    raise ValueError(\n",
    "                        \"Invalid problem_type. Supported options: binary_classification, multiclass_classification, regression.\"\n",
    "                    )\n",
    "\n",
    "                predictions.extend(preds)\n",
    "\n",
    "        return np.array(predictions)\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(\n",
    "        self, data, labels=None, img_rows=224, img_columns=224, transform=None\n",
    "    ):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.img_rows = img_rows\n",
    "        self.img_columns = img_columns\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.labels is not None:\n",
    "            x = self.data.iloc[index].values.reshape(self.img_rows, self.img_columns)\n",
    "            x = np.stack([x] * 3, axis=-1).astype(np.float32)  # Convert to float32\n",
    "            x = self.transform(x)\n",
    "            # self.labels = pd.DataFrame(self.labels)\n",
    "            y = self.labels.iloc[index].values\n",
    "            return x, y\n",
    "        else:\n",
    "            x = self.data.iloc[index].values.reshape(self.img_rows, self.img_columns)\n",
    "            x = np.stack([x] * 3, axis=-1).astype(np.float32)  # Convert to float32\n",
    "            x = self.transform(x)\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60b53c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Instantiate the CustomDataset with your data\n",
    "dataset = CustomDataset(X_train, img_rows=5, img_columns=6, transform=transforms.ToTensor())\n",
    "\n",
    "# Select a sample from the dataset\n",
    "sample_index = 0\n",
    "sample = dataset[sample_index]  # Accessing the sample\n",
    "\n",
    "# Convert the sample to an image\n",
    "image = transforms.ToPILImage()(sample)\n",
    "\n",
    "# Get the feature names from the original DataFrame\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Display the image with feature names as labels\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "\n",
    "# Add feature names as labels to the x-axis\n",
    "plt.xticks(range(len(feature_names)), feature_names, rotation='vertical')\n",
    "\n",
    "# Add a label to the y-axis\n",
    "plt.ylabel('Rows')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d451c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "\n",
    "img_rows = 5\n",
    "img_columns = 6\n",
    "depth = \"resnet18\"\n",
    "pretrained = True\n",
    "batch_size = 2048\n",
    "num_classes = 1\n",
    "\n",
    "# Instantiate the ResNetTrainer\n",
    "trainer = ResNetTrainer(num_classes, img_rows, img_columns)\n",
    "\n",
    "# Set the desired parameters\n",
    "params = {\n",
    "    'num_epochs': 10,\n",
    "    'validation_fraction': 0.2,\n",
    "    'early_stopping': True,\n",
    "    'patience': 5,\n",
    "    'save_path': 'creditcard_resnet_model_weights.pth'\n",
    "}\n",
    "\n",
    "# Train the model\n",
    "trainer.train(X_train[:4096], y_train[:4096], params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1646dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test data\n",
    "trainer.batch_size = 2048\n",
    "y_pred = trainer.predict(X_test)\n",
    "# 'predictions' will be a NumPy array of shape (num_test_samples, num_classes) containing the predicted probabilities for each class\n",
    "# You can further process the predictions as per your requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4d89aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531d793f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_true, y_pred)\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_true, y_pred)\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "print(\"F1 score:\", f1)\n",
    "\n",
    "# Calculate ROC AUC score\n",
    "roc_auc = roc_auc_score(y_true, y_pred)\n",
    "print(\"ROC AUC score:\", roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dedbea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6e355f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c779629",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cead9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8325e098",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da03c81f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e72a140",
   "metadata": {},
   "source": [
    "# GATE Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de94b527",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_count = 891\n",
    "class_count = [549, 342]\n",
    "class_weights = [total_count / count for count in class_count]\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70556b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = class_weights[0] / class_weights[1] # 0.620\n",
    "weighted_loss = get_class_weighted_cross_entropy(y_train.values.ravel(), mu=mu)\n",
    "print(f\"mu = {mu}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfec264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data configuration\n",
    "data_config = DataConfig(\n",
    "    target=['target'],\n",
    "    continuous_cols= [i for i in extra_info[\"num_col_names\"] if i != \"target\"],\n",
    "    categorical_cols=extra_info[\"cat_col_names\"],\n",
    ")\n",
    "trainer_config = TrainerConfig(\n",
    "    auto_lr_find = True,  # Runs the LRFinder to automatically derive a learning rate\n",
    "    batch_size   = 32,\n",
    "    max_epochs   = 1000,\n",
    ")\n",
    "\n",
    "optimizer_config = OptimizerConfig()\n",
    "\n",
    "model_config = GatedAdditiveTreeEnsembleConfig(\n",
    "    task=\"classification\",\n",
    "    tree_depth  =  6,\n",
    "    num_trees   = 16,\n",
    "    chain_trees = True, # akin to bagging, True is akin to boosting\n",
    "    gflu_stages =  2,\n",
    "    metrics=['accuracy'],\n",
    "    metrics_params=[dict(task=\"multiclass\", num_classes=2)]\n",
    ")\n",
    "\n",
    "tabular_model = TabularModel(\n",
    "    data_config=data_config,\n",
    "    model_config=model_config,\n",
    "    optimizer_config=optimizer_config,\n",
    "    trainer_config=trainer_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6caefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(TrainerConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661b2152",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(GatedAdditiveTreeEnsembleConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3c352a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert X_train.isnull().sum().sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7488c259",
   "metadata": {},
   "outputs": [],
   "source": [
    "tabular_model = TabularModel(\n",
    "    data_config=data_config,\n",
    "    model_config=model_config,\n",
    "    optimizer_config=optimizer_config,\n",
    "    trainer_config=trainer_config,\n",
    ")\n",
    "\n",
    "# Merge X_train and y_train  \n",
    "train = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "# Merge X_val and y_val\n",
    "validation = pd.concat([X_val, y_val], axis=1)\n",
    "\n",
    "tabular_model.fit(\n",
    "    train=train, \n",
    "    validation=validation,\n",
    "    loss=weighted_loss\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a43950e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a98fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "result  = tabular_model.evaluate(df_val)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e477bf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfdb679",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = tabular_model.predict(df_val)\n",
    "pred_df.head()\n",
    "# Add PassengerId information to the predictions\n",
    "pred_df_with_ids = pd.concat([df_val_id.reset_index(drop=True), pred_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "pred_df_with_ids = pred_df_with_ids.rename(columns={'prediction': 'Survived'})\n",
    "# Display the predictions with PassengerId information\n",
    "pred_df_with_ids[[\"PassengerId\", \"Survived\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee916b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df_with_ids[\"Survived\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b38fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df_with_ids[[\"PassengerId\", \"Survived\"]].to_csv(\"/Users/mdicio/Desktop/doidownloads/kaggle_datasets/test_submission_boom.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f46e051",
   "metadata": {},
   "source": [
    "# TabTransformer Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549c0914",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tab-transformer-pytorch\n",
    "import torch\n",
    "from tab_transformer_pytorch import FTTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db3e44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = FTTransformer(\n",
    "    categories = (5, 5, 5, 5, 5),      # tuple containing the number of unique values within each category\n",
    "    num_continuous = 10,                # number of continuous values\n",
    "    dim = 32,                           # dimension, paper set at 32\n",
    "    dim_out = 1,                        # binary prediction, but could be anything\n",
    "    depth = 6,                          # depth, paper recommended 6\n",
    "    heads = 8,                          # heads, paper recommends 8\n",
    "    attn_dropout = 0.1,                 # post-attention dropout\n",
    "    ff_dropout = 0.1                    # feed forward dropout\n",
    ")\n",
    "\n",
    "x_categ = torch.randint(0, 5, (1, 5))     # category values, from 0 - max number of categories, in the order as passed into the constructor above\n",
    "x_numer = torch.randn(1, 10)              # numerical value\n",
    "\n",
    "pred = model(x_categ, x_numer) # (1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ac956f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_categ.shape, x_numer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34999a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_categ = torch.randint(0, 5, (1, 5))  \n",
    "x_categ, x_numer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8064d1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23d426e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebdc7be",
   "metadata": {},
   "source": [
    "# Tabnet Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb30a010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the train data into training and validation sets\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from pytorch_tabnet.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f096715",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(TabNetClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99175122",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a09b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the early stopping callback\n",
    "early_stopping = EarlyStopping(early_stopping_metric = 'val_loss',\n",
    "is_maximize = False,\n",
    "patience = 32\n",
    ")\n",
    "\n",
    "model = TabNetClassifier()\n",
    "\n",
    "# Train the model with early stopping\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    eval_name=['valid'],\n",
    "    eval_metric=['logloss'],\n",
    "    max_epochs=2,\n",
    "    batch_size = 16,\n",
    "    callbacks=[early_stopping],\n",
    "patience = 32)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7f7a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e23bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the labels of the validation data\n",
    "y_pred = model.predict(X_test)\n",
    "# Calculate the score using the specified metric\n",
    "evaluator = Evaluator(problem_type = \"multiclass_classification\")\n",
    "evaluator.y_true = y_val\n",
    "evaluator.y_pred = y_pred\n",
    "score = evaluator.evaluate_metric(metric_name = \"f1\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
