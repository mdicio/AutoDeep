{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test AutoML Functionality in a Separate Notebook\n",
    "from autodeep.automl import AutoRunner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-31 15:12:19,346 - INFO - CommonStructure.py - Device cuda is available\n",
      "2025-01-31 15:12:19,346 - INFO - CommonStructure.py - Starting hyperopt search 2 evals maximizing roc_auc metric on dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running node on dataset1...\n",
      "{'random_state': 4200, 'retrain': True, 'include_models': ['XGB', 'CatBoost', 'MLP', 'TabNet', 'GATE', 'resnet', 'S1DCNN', 'CategoryEmbedding', 'FTTransformer', 'TabTransformer', 'GANDALF', 'AutoInt', 'Node'], 'model_configs': {'catboost': {'data_params': {'normalize_features': 'mean_std', 'encode_categorical': False, 'return_extra_info': True}, 'default_params': {'retrain': False, 'validation_fraction': 0.15, 'early_stopping_rounds': 100, 'verbose': False, 'iterations': 500}, 'param_grid': {'early_stopping_rounds': [100, 50], 'iterations': [100, 500]}}, 'categoryembedding': {'data_params': {'normalize_features': 'mean_std', 'encode_categorical': False, 'return_extra_info': True}, 'default_params': {'early_stopping_rounds': 10, 'verbose': False, 'iterations': 20, 'retrain': False, 'auto_lr_find': False, 'max_epochs': 10, 'val_size': 0.15, 'early_stopping_patience': 20}, 'param_grid': {'batch_size': [128, 1024], 'layers': ['128-64-32', '256-128', '256-128-64-32', '32-16', '64-32-16', '64-32'], 'activation': ['ReLU', 'LeakyReLU'], 'use_batch_norm': [True, False], 'initialization': ['kaiming', 'xavier', 'random'], 'dropout': [0.0, 0.3], 'embedding_dropout': [0.0, 0.2], 'optimizer_fn': {'Adam': {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}, 'SGD': {'weight_decay': [0.0, 1e-07], 'momentum': [0.0, 0.9], 'learning_rate': [0.001, 1e-05]}, 'AdamW': {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.01], 'patience': [5, 10]}, 'StepLR': {'step_size': [10, 30], 'gamma': [0.1, 0.5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}, 'gandalf': {'data_params': {'normalize_features': 'mean_std', 'encode_categorical': False, 'return_extra_info': True}, 'default_params': {'early_stopping_rounds': 10, 'verbose': False, 'iterations': 20, 'retrain': False, 'auto_lr_find': False, 'max_epochs': 10, 'val_size': 0.15, 'early_stopping_patience': 20}, 'param_grid': {'batch_size': [128, 1024], 'layers': ['128-64-32', '256-128', '256-128-64-32', '32-16', '64-32-16', '64-32'], 'activation': ['ReLU', 'LeakyReLU'], 'gflu_stages': [2, 8], 'gflu_dropout': [0.0, 0.1], 'embedding_dropout': [0.0, 0.1], 'optimizer_fn': {'Adam': {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}, 'SGD': {'weight_decay': [0.0, 1e-07], 'momentum': [0.0, 0.9], 'learning_rate': [0.001, 1e-05]}, 'AdamW': {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.01], 'patience': [5, 10]}, 'StepLR': {'step_size': [10, 30], 'gamma': [0.1, 0.5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}, 'autoint': {'data_params': {'normalize_features': 'mean_std', 'encode_categorical': False, 'return_extra_info': True}, 'default_params': {'early_stopping_rounds': 10, 'verbose': False, 'iterations': 20, 'retrain': False, 'auto_lr_find': False, 'max_epochs': 10, 'val_size': 0.15, 'early_stopping_patience': 20}, 'param_grid': {'batch_size': [64, 1024], 'attn_embed_dim': [16, 64], 'num_heads': [1, 4], 'num_attn_blocks': [1, 3], 'attn_dropouts': [0.0, 0.2], 'embedding_dim': [8, 32], 'shared_embedding_fraction': [0.1, 0.4], 'layers': ['64-32', '128-64-32', '256-128-64-32'], 'activation': ['ReLU', 'LeakyReLU', 'TanH'], 'dropout': [0.0, 0.2], 'attention_pooling': [True, False], 'embedding_initialization': ['kaiming_uniform', 'kaiming_normal'], 'share_embedding_strategy': ['add', 'fraction'], 'embedding_dropout': [0.05, 0.2], 'batch_norm_continuous_input': [True, False], 'initialization': ['kaiming', 'xavier', 'random'], 'optimizer_fn': {'Adam': {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}, 'SGD': {'weight_decay': [0.0, 1e-07], 'momentum': [0.0, 0.9], 'learning_rate': [0.001, 1e-05]}, 'AdamW': {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.01], 'patience': [5, 10]}, 'StepLR': {'step_size': [10, 30], 'gamma': [0.1, 0.5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}, 'fttransformer': {'data_params': {'normalize_features': 'mean_std', 'encode_categorical': False, 'return_extra_info': True}, 'default_params': {'early_stopping_rounds': 10, 'verbose': False, 'iterations': 20, 'retrain': False, 'auto_lr_find': False, 'max_epochs': 10, 'val_size': 0.15, 'early_stopping_patience': 20}, 'param_grid': {'batch_size': [64, 1024], 'input_embed_dim': [16, 64], 'num_heads': [4, 16], 'num_attn_blocks': [3, 8], 'attn_dropout': [0.0, 0.2], 'add_norm_dropout': [0.0, 0.2], 'ff_dropout': [0.0, 0.2], 'ff_hidden_multiplier': [2, 6], 'shared_embedding_fraction': [0.1, 0.4], 'learning_rate': [0.0005, 0.005], 'transformer_activation': ['GEGLU', 'ReGLU', 'SwiGLU', 'ReLU'], 'embedding_initialization': ['kaiming_uniform', 'kaiming_normal'], 'share_embedding_strategy': ['add', 'fraction'], 'embedding_dropout': [0.05, 0.2], 'batch_norm_continuous_input': [True, False], 'attention_pooling': [True, False], 'optimizer_fn': {'Adam': {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}, 'SGD': {'weight_decay': [0.0, 1e-07], 'momentum': [0.0, 0.9], 'learning_rate': [0.001, 1e-05]}, 'AdamW': {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.01], 'patience': [5, 10]}, 'StepLR': {'step_size': [10, 30], 'gamma': [0.1, 0.5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}, 'gate': {'data_params': {'normalize_features': 'mean_std', 'encode_categorical': False, 'return_extra_info': True}, 'default_params': {'early_stopping_rounds': 10, 'verbose': False, 'iterations': 20, 'retrain': False, 'auto_lr_find': False, 'max_epochs': 10, 'val_size': 0.15, 'early_stopping_patience': 20}, 'param_grid': {'batch_size': [64, 1024], 'gflu_stages': [4, 8], 'gflu_dropout': [0.0, 0.2], 'tree_depth': [3, 6], 'num_trees': [5, 20], 'binning_activation': ['sparsemoid', 'entmoid'], 'feature_mask_function': ['sparsemax', 'entmax'], 'tree_dropout': [0.0, 0.2], 'tree_wise_attention': [True, False], 'tree_wise_attention_dropout': [0.0, 0.2], 'share_head_weights': [True, False], 'learning_rate': [0.0005, 0.005], 'embedding_dropout': [0.05, 0.2], 'batch_norm_continuous_input': [True, False], 'optimizer_fn': {'Adam': {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}, 'SGD': {'weight_decay': [0.0, 1e-07], 'momentum': [0.0, 0.9], 'learning_rate': [0.001, 1e-05]}, 'AdamW': {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.01], 'patience': [5, 10]}, 'StepLR': {'step_size': [10, 30], 'gamma': [0.1, 0.5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}, 'node': {'data_params': {'normalize_features': 'mean_std', 'encode_categorical': False, 'return_extra_info': True}, 'default_params': {'early_stopping_rounds': 10, 'verbose': False, 'iterations': 20, 'retrain': False, 'auto_lr_find': False, 'max_epochs': 10, 'val_size': 0.15, 'early_stopping_patience': 20}, 'param_grid': {'batch_size': [64, 512], 'num_layers': [1, 2], 'num_trees': [512, 1024], 'additional_tree_output_dim': [2, 4], 'depth': [4, 6], 'choice_function': ['entmax15', 'sparsemax'], 'bin_function': ['entmoid15', 'sparsemoid'], 'input_dropout': [0.0, 0.2], 'initialize_response': ['normal', 'uniform'], 'initialize_selection_logits': ['normal', 'uniform'], 'threshold_init_beta': [0.5, 1.0, 1.5], 'threshold_init_cutoff': [0.5, 1.0, 1.5], 'embedding_dropout': [0.0, 0.2], 'batch_norm_continuous_input': [True, False], 'optimizer_fn': {'Adam': {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}, 'SGD': {'weight_decay': [0.0, 1e-07], 'momentum': [0.0, 0.9], 'learning_rate': [0.001, 1e-05]}, 'AdamW': {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.01], 'patience': [5, 10]}, 'StepLR': {'step_size': [10, 30], 'gamma': [0.1, 0.5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}, 'tabnet': {'data_params': {'normalize_features': 'mean_std', 'encode_categorical': False, 'return_extra_info': True}, 'default_params': {'early_stopping_rounds': 10, 'verbose': False, 'iterations': 20, 'retrain': False, 'auto_lr_find': False, 'max_epochs': 10, 'val_size': 0.15, 'early_stopping_patience': 20}, 'param_grid': {'batch_size': [64, 512, 1024], 'n_d': [8, 16, 32, 64], 'n_a': [8, 16, 32, 64], 'n_steps': [3, 4, 5, 6], 'gamma': [1.1, 1.3, 1.5], 'n_independent': [1, 2, 3], 'n_shared': [1, 2, 3], 'virtual_batch_size': [32, 64, 128], 'mask_type': ['sparsemax', 'entmax'], 'learning_rate': [0.0005, 0.001, 0.005], 'embedding_dropout': [0.0, 0.1, 0.2], 'batch_norm_continuous_input': [True, False], 'head': ['LinearHead', 'MixtureDensityHead'], 'optimizer_fn': {'Adam': {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}, 'SGD': {'weight_decay': [0.0, 1e-07], 'momentum': [0.0, 0.9], 'learning_rate': [0.001, 1e-05]}, 'AdamW': {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.01], 'patience': [5, 10]}, 'StepLR': {'step_size': [10, 30], 'gamma': [0.1, 0.5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}, 'tabtransformer': {'data_params': {'normalize_features': 'mean_std', 'encode_categorical': False, 'return_extra_info': True}, 'default_params': {'early_stopping_rounds': 10, 'verbose': False, 'iterations': 20, 'retrain': False, 'auto_lr_find': False, 'max_epochs': 10, 'val_size': 0.15, 'early_stopping_patience': 20}, 'param_grid': {'batch_size': [64, 512, 1024], 'input_embed_dim': [32, 64, 128], 'embedding_initialization': ['kaiming_uniform', 'kaiming_normal'], 'embedding_bias': [True, False], 'share_embedding': [True, False], 'share_embedding_strategy': ['add', 'fraction'], 'shared_embedding_fraction': [0.25, 0.5, 0.75], 'num_heads': [4, 8, 16], 'num_attn_blocks': [4, 6, 8], 'transformer_head_dim': [32, 64, 128], 'attn_dropout': [0.1, 0.2, 0.3], 'add_norm_dropout': [0.1, 0.2], 'ff_dropout': [0.1, 0.2], 'ff_hidden_multiplier': [2, 4, 8], 'transformer_activation': ['GEGLU', 'ReLU', 'SwiGLU'], 'out_ff_layers': ['128-64-32', '256-128-64'], 'out_ff_activation': ['ReLU', 'LeakyReLU'], 'out_ff_dropout': [0.0, 0.1, 0.2], 'out_ff_initialization': ['kaiming', 'xavier', 'random'], 'learning_rate': [0.0005, 0.001, 0.005], 'embedding_dropout': [0.0, 0.1, 0.2], 'batch_norm_continuous_input': [True, False], 'head': ['LinearHead', 'MixtureDensityHead'], 'optimizer_fn': {'Adam': {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}, 'SGD': {'weight_decay': [0.0, 1e-07], 'momentum': [0.0, 0.9], 'learning_rate': [0.001, 1e-05]}, 'AdamW': {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.01], 'patience': [5, 10]}, 'StepLR': {'step_size': [10, 30], 'gamma': [0.1, 0.5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}, 'resnet': {'data_params': {'normalize_features': 'mean_std', 'encode_categorical': True, 'return_extra_info': True}, 'default_params': {'early_stopping_rounds': 10, 'verbose': False, 'iterations': 20, 'retrain': False, 'auto_lr_find': False, 'max_epochs': 1000, 'val_size': 0.2, 'early_stopping_patience': 6}, 'param_grid': {'resnet_depth': ['resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152'], 'batch_size': [1024, 512, 256], 'optimizer_fn': {'Adam': {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}, 'SGD': {'weight_decay': [0.0, 1e-07], 'momentum': [0.0, 0.9], 'learning_rate': [0.001, 1e-05]}, 'AdamW': {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.01], 'patience': [5, 10]}, 'StepLR': {'step_size': [10, 30], 'gamma': [0.1, 0.5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}, 's1dcnn': {'data_params': {'normalize_features': 'mean_std', 'encode_categorical': False, 'return_extra_info': True}, 'default_params': {'early_stopping_rounds': 10, 'verbose': False, 'iterations': 20, 'retrain': False, 'auto_lr_find': False, 'max_epochs': 1, 'val_size': 0.15, 'early_stopping_patience': 5}, 'param_grid': {'batch_size': [1024, 512, 256], 'hidden_size': [4096, 2048, 1024], 'optimizer_fn': {'Adam': {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}, 'SGD': {'weight_decay': [0.0, 1e-07], 'momentum': [0.0, 0.9], 'learning_rate': [0.001, 1e-05]}, 'AdamW': {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.01], 'patience': [5, 10]}, 'StepLR': {'step_size': [10, 30], 'gamma': [0.1, 0.5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}, 'xgb': {'data_params': {'normalize_features': False, 'encode_categorical': True, 'return_extra_info': False}, 'default_params': {'retrain': True, 'early_stopping_rounds': 30, 'verbose': False, 'learning_rate': 0.3, 'max_depth': 6, 'n_estimators': 100, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 0.0}, 'param_grid': {'early_stopping_rounds': [30, 50], 'learning_rate': [0.3, 0.01], 'max_depth': [4, 6, 8], 'n_estimators': [50, 100, 200], 'min_child_weight': [1, 5, 10], 'subsample': [0.6, 0.8, 1.0], 'colsample_bytree': [0.6, 0.8, 1.0], 'gamma': [0.0, 0.1, 0.2]}}, 'mlp': {'data_params': {'normalize_features': 'mean_std', 'encode_categorical': True, 'return_extra_info': False}, 'default_params': {'early_stopping': True, 'n_iter_no_change': 10, 'max_iter': 1000, 'hidden_layer_sizes': [32], 'activation': 'relu', 'solver': 'adam', 'batch_size': 1024}, 'param_grid': {'n_iter_no_change': [10, 15], 'max_iter': [1000, 2000], 'hidden_layer_sizes': [[64, 32], [128, 64, 32]], 'activation': ['relu', 'tanh'], 'solver': ['adam', 'sgd'], 'batch_size': [1024, 2048]}}}}\n",
      "{'data_params': {'normalize_features': 'mean_std', 'encode_categorical': False, 'return_extra_info': True}, 'default_params': {'early_stopping_rounds': 10, 'verbose': False, 'iterations': 20, 'retrain': False, 'auto_lr_find': False, 'max_epochs': 10, 'val_size': 0.15, 'early_stopping_patience': 20}, 'param_grid': {'batch_size': [64, 512], 'num_layers': [1, 2], 'num_trees': [512, 1024], 'additional_tree_output_dim': [2, 4], 'depth': [4, 6], 'choice_function': ['entmax15', 'sparsemax'], 'bin_function': ['entmoid15', 'sparsemoid'], 'input_dropout': [0.0, 0.2], 'initialize_response': ['normal', 'uniform'], 'initialize_selection_logits': ['normal', 'uniform'], 'threshold_init_beta': [0.5, 1.0, 1.5], 'threshold_init_cutoff': [0.5, 1.0, 1.5], 'embedding_dropout': [0.0, 0.2], 'batch_norm_continuous_input': [True, False], 'optimizer_fn': {'Adam': {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}, 'SGD': {'weight_decay': [0.0, 1e-07], 'momentum': [0.0, 0.9], 'learning_rate': [0.001, 1e-05]}, 'AdamW': {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.01], 'patience': [5, 10]}, 'StepLR': {'step_size': [10, 30], 'gamma': [0.1, 0.5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}\n",
      "Using dynamic loader for dataset: /home/boom/sdev/repos/AutoDeep/autodeep/examples/testautodata/adult.csv\n",
      "SPACE ######################################################\n",
      "{'batch_size': <hyperopt.pyll.base.Apply object at 0x7743005ffc10>, 'num_layers': <hyperopt.pyll.base.Apply object at 0x7743005ffbb0>, 'num_trees': <hyperopt.pyll.base.Apply object at 0x77443ef9c910>, 'additional_tree_output_dim': <hyperopt.pyll.base.Apply object at 0x77443ef9c7c0>, 'depth': <hyperopt.pyll.base.Apply object at 0x77443ef9c670>, 'choice_function': <hyperopt.pyll.base.Apply object at 0x77443ef9c0d0>, 'bin_function': <hyperopt.pyll.base.Apply object at 0x77443ef9c3a0>, 'input_dropout': <hyperopt.pyll.base.Apply object at 0x77443ef9c3d0>, 'initialize_response': <hyperopt.pyll.base.Apply object at 0x77443ef9ca00>, 'initialize_selection_logits': <hyperopt.pyll.base.Apply object at 0x77443ef9cb50>, 'threshold_init_beta': <hyperopt.pyll.base.Apply object at 0x77443ef9cd00>, 'threshold_init_cutoff': <hyperopt.pyll.base.Apply object at 0x77443ef9ce50>, 'embedding_dropout': <hyperopt.pyll.base.Apply object at 0x77443ef9cfa0>, 'batch_norm_continuous_input': <hyperopt.pyll.base.Apply object at 0x77443ef9d090>, 'optimizer_fn': <hyperopt.pyll.base.Apply object at 0x77443ef9d9c0>, 'scheduler_fn': <hyperopt.pyll.base.Apply object at 0x77443ef9e230>}\n",
      "  0%|          | 0/2 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-31 15:12:19,401 - INFO - CommonStructure.py - Training with hyperparameters: {'additional_tree_output_dim': 4, 'batch_norm_continuous_input': True, 'batch_size': 416, 'bin_function': 'entmoid15', 'choice_function': 'sparsemax', 'depth': 5, 'embedding_dropout': 0.07435784443450048, 'initialize_response': 'uniform', 'initialize_selection_logits': 'uniform', 'input_dropout': 0.023542720433600173, 'num_layers': 1, 'num_trees': 626, 'optimizer_fn': {'SGD_learning_rate': 0.0008141368009300764, 'SGD_momentum': 0.4934848523501228, 'SGD_weight_decay': 3.0713987069389626e-08, 'optimizer_fn': <class 'torch.optim.sgd.SGD'>}, 'scheduler_fn': {'StepLR_gamma': 0.34801825886274895, 'StepLR_step_size': 21, 'scheduler_fn': <class 'torch.optim.lr_scheduler.StepLR'>}, 'threshold_init_beta': 0.826726207188516, 'threshold_init_cutoff': 0.9402437257075205}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tabular model params                                 \n",
      "{'additional_tree_output_dim': 4, 'batch_norm_continuous_input': True, 'batch_size': 416, 'bin_function': 'entmoid15', 'choice_function': 'sparsemax', 'depth': 5, 'embedding_dropout': 0.07435784443450048, 'initialize_response': 'uniform', 'initialize_selection_logits': 'uniform', 'input_dropout': 0.023542720433600173, 'num_layers': 1, 'num_trees': 626, 'optimizer_fn': {'SGD_learning_rate': 0.0008141368009300764, 'SGD_momentum': 0.4934848523501228, 'SGD_weight_decay': 3.0713987069389626e-08, 'optimizer_fn': <class 'torch.optim.sgd.SGD'>}, 'scheduler_fn': {'StepLR_gamma': 0.34801825886274895, 'StepLR_step_size': 21, 'scheduler_fn': <class 'torch.optim.lr_scheduler.StepLR'>}, 'threshold_init_beta': 0.826726207188516, 'threshold_init_cutoff': 0.9402437257075205}\n",
      "tabular model outer params                           \n",
      "{'early_stopping_rounds': 10, 'verbose': False, 'iterations': 20, 'retrain': False, 'auto_lr_find': False, 'max_epochs': 10, 'val_size': 0.15, 'early_stopping_patience': 20}\n",
      "  0%|          | 0/2 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-31 15:12:19,415 - WARNING - CommonStructure.py - You are passing some invalid parameters to the model {'batch_size': 416, 'optimizer_fn': {'SGD_learning_rate': 0.0008141368009300764, 'SGD_momentum': 0.4934848523501228, 'SGD_weight_decay': 3.0713987069389626e-08, 'optimizer_fn': <class 'torch.optim.sgd.SGD'>}, 'scheduler_fn': {'StepLR_gamma': 0.34801825886274895, 'StepLR_step_size': 21, 'scheduler_fn': <class 'torch.optim.lr_scheduler.StepLR'>}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataConfig(target=['target'], continuous_cols=['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week'], categorical_cols=['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country'], date_columns=[], encode_date_columns=True, validation_split=0.2, continuous_feature_transform=None, normalize_continuous_features=True, quantile_noise=0, num_workers=4, pin_memory=True, handle_unknown_categories=True, handle_missing_values=True, dataloader_kwargs={})\n",
      "NodeConfig(task='classification', head='LinearHead', head_config={'layers': ''}, embedding_dims=None, embedding_dropout=0.07435784443450048, batch_norm_continuous_input=True, learning_rate=0.0008141368009300764, loss='CrossEntropyLoss', metrics=['accuracy'], metrics_prob_input=[False], metrics_params=[{}], target_range=None, virtual_batch_size=None, seed=42, _module_src='models.node', _model_name='NODEModel', _backbone_name='NODEBackbone', _config_name='NodeConfig', num_layers=1, num_trees=626, additional_tree_output_dim=4, depth=5, choice_function='sparsemax', bin_function='entmoid15', max_features=None, input_dropout=0.023542720433600173, initialize_response='uniform', initialize_selection_logits='uniform', threshold_init_beta=0.826726207188516, threshold_init_cutoff=0.9402437257075205)\n",
      "OptimizerConfig(optimizer='SGD', optimizer_params={'weight_decay': 3.0713987069389626e-08, 'momentum': 0.4934848523501228}, lr_scheduler='StepLR', lr_scheduler_params={'step_size': 21, 'gamma': 0.34801825886274895}, lr_scheduler_monitor_metric='valid_loss')\n",
      "TrainerConfig(batch_size=416, data_aware_init_batch_size=2000, fast_dev_run=False, max_epochs=10, min_epochs=1, max_time=None, accelerator='auto', devices=-1, devices_list=None, accumulate_grad_batches=1, auto_lr_find=False, auto_select_gpus=True, check_val_every_n_epoch=1, gradient_clip_val=0.0, overfit_batches=0.0, deterministic=False, profiler=None, early_stopping='valid_loss', early_stopping_min_delta=0.0, early_stopping_mode='min', early_stopping_patience=20, early_stopping_kwargs={}, checkpoints='valid_loss', checkpoints_path='ptabular_checkpoints', checkpoints_every_n_epochs=10, checkpoints_name=None, checkpoints_mode='min', checkpoints_save_top_k=1, checkpoints_kwargs={}, load_best=True, track_grad_norm=-1, progress_bar='rich', precision=32, seed=42, trainer_kwargs={})\n",
      "  0%|          | 0/2 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:12:19</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">449</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">146</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m15:12:19\u001b[0m,\u001b[1;36m449\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m146\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:12:19</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">476</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m15:12:19\u001b[0m,\u001b[1;36m476\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:12:19</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">502</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m15:12:19\u001b[0m,\u001b[1;36m502\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:12:19</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">583</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: NODEModel              \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m15:12:19\u001b[0m,\u001b[1;36m583\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: NODEModel              \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:12:19</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">643</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.models.node.node_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">74</span><span style=\"font-weight: bold\">}</span> - INFO - Data Aware Initialization of NODE   \n",
       "using a forward pass with <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2000</span> batch size<span style=\"color: #808000; text-decoration-color: #808000\">...</span>.                                                                      \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m15:12:19\u001b[0m,\u001b[1;36m643\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.models.node.node_model:\u001b[1;36m74\u001b[0m\u001b[1m}\u001b[0m - INFO - Data Aware Initialization of NODE   \n",
       "using a forward pass with \u001b[1;36m2000\u001b[0m batch size\u001b[33m...\u001b[0m.                                                                      \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:12:20</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">917</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m15:12:20\u001b[0m,\u001b[1;36m917\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:12:20</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">931</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m15:12:20\u001b[0m,\u001b[1;36m931\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ custom_loss      │ CrossEntropyLoss │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _backbone        │ NODEBackbone     │  323 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _embedding_layer │ Embedding1dLayer │  1.4 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ _head            │ Lambda           │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ custom_loss      │ CrossEntropyLoss │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ NODEBackbone     │  323 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer │  1.4 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ _head            │ Lambda           │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 325 K                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 321                                                                                          \n",
       "<span style=\"font-weight: bold\">Total params</span>: 325 K                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 1                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 18                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 325 K                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 321                                                                                          \n",
       "\u001b[1mTotal params\u001b[0m: 325 K                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 1                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 18                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b9671270ce14c1e950595a63bac7e24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:12:43</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">420</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m15:12:43\u001b[0m,\u001b[1;36m420\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:12:43</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">424</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m15:12:43\u001b[0m,\u001b[1;36m424\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n",
      "\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n",
      "\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n",
      "\tWeightsUnpickler error: Unsupported global: GLOBAL omegaconf.dictconfig.DictConfig was not an allowed global by default. Please use `torch.serialization.add_safe_globals([DictConfig])` or the `torch.serialization.safe_globals([DictConfig])` context manager to allowlist this global if you trust this class/function.\n",
      "\n",
      "Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:24<?, ?trial/s, best loss=?]\n"
     ]
    },
    {
     "ename": "UnpicklingError",
     "evalue": "Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL omegaconf.dictconfig.DictConfig was not an allowed global by default. Please use `torch.serialization.add_safe_globals([DictConfig])` or the `torch.serialization.safe_globals([DictConfig])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 66\u001b[0m\n\u001b[1;32m     54\u001b[0m runner \u001b[38;5;241m=\u001b[39m AutoRunner(\n\u001b[1;32m     55\u001b[0m     data_config\u001b[38;5;241m=\u001b[39mDATA_CONFIG,\n\u001b[1;32m     56\u001b[0m     output_folder\u001b[38;5;241m=\u001b[39mOUTPUT_FOLDER,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     62\u001b[0m     output_file_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{dataset}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{model}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{timestamp}\u001b[39;00m\u001b[38;5;124m.yml\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     63\u001b[0m )\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# Run the AutoML process\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# Print results\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# Assuming results are saved correctly in the `runner.results` list (adapt as necessary)\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mresults:\n",
      "File \u001b[0;32m~/sdev/repos/AutoDeep/autodeep/automl.py:148\u001b[0m, in \u001b[0;36mAutoRunner.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;66;03m# Handle new execution modes\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m execution_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhyperopt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    144\u001b[0m     (\n\u001b[1;32m    145\u001b[0m         best_params,\n\u001b[1;32m    146\u001b[0m         best_score,\n\u001b[1;32m    147\u001b[0m         full_metrics,\n\u001b[0;32m--> 148\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhyperopt_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m        \u001b[49m\u001b[43mval_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_config\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdefault_params\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mval_size\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_config\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetric\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_config\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meval_metrics\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproblem_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_config\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mproblem_type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    160\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain(X_train, y_train)\n",
      "File \u001b[0;32m~/sdev/repos/AutoDeep/autodeep/modelsdefinition/CommonStructure.py:342\u001b[0m, in \u001b[0;36mPytorchTabularTrainer.hyperopt_search\u001b[0;34m(self, X, y, model_config, metric, eval_metrics, val_size, max_evals, problem_type, extra_info)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluator \u001b[38;5;241m=\u001b[39m Evaluator(problem_type\u001b[38;5;241m=\u001b[39mproblem_type)\n\u001b[1;32m    340\u001b[0m threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluator\u001b[38;5;241m.\u001b[39mmaximize[metric][\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m--> 342\u001b[0m best \u001b[38;5;241m=\u001b[39m \u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtpe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuggest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault_rng\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stop_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop_on_perfect_lossCondition\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    352\u001b[0m best_params \u001b[38;5;241m=\u001b[39m space_eval(space, best)\n\u001b[1;32m    353\u001b[0m best_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault_params\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_params\n",
      "File \u001b[0;32m~/.pyenv/versions/thesis/lib/python3.10/site-packages/hyperopt/fmin.py:540\u001b[0m, in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    537\u001b[0m     fn \u001b[38;5;241m=\u001b[39m __objective_fmin_wrapper(fn)\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m allow_trials_fmin \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(trials, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfmin\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 540\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrials\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    542\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[43m        \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malgo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    547\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_queue_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    548\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_argmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_argmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progressbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progressbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[43m        \u001b[49m\u001b[43mearly_stop_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stop_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrials_save_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrials_save_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trials \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    559\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(trials_save_file):\n",
      "File \u001b[0;32m~/.pyenv/versions/thesis/lib/python3.10/site-packages/hyperopt/base.py:671\u001b[0m, in \u001b[0;36mTrials.fmin\u001b[0;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;66;03m# -- Stop-gap implementation!\u001b[39;00m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;66;03m#    fmin should have been a Trials method in the first place\u001b[39;00m\n\u001b[1;32m    668\u001b[0m \u001b[38;5;66;03m#    but for now it's still sitting in another file.\u001b[39;00m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfmin\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m fmin\n\u001b[0;32m--> 671\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malgo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_trials_fmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# -- prevent recursion\u001b[39;49;00m\n\u001b[1;32m    683\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_argmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_argmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progressbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progressbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stop_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stop_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrials_save_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrials_save_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/thesis/lib/python3.10/site-packages/hyperopt/fmin.py:586\u001b[0m, in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    583\u001b[0m rval\u001b[38;5;241m.\u001b[39mcatch_eval_exceptions \u001b[38;5;241m=\u001b[39m catch_eval_exceptions\n\u001b[1;32m    585\u001b[0m \u001b[38;5;66;03m# next line is where the fmin is actually executed\u001b[39;00m\n\u001b[0;32m--> 586\u001b[0m \u001b[43mrval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexhaust\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_argmin:\n\u001b[1;32m    589\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(trials\u001b[38;5;241m.\u001b[39mtrials) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/.pyenv/versions/thesis/lib/python3.10/site-packages/hyperopt/fmin.py:364\u001b[0m, in \u001b[0;36mFMinIter.exhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mexhaust\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    363\u001b[0m     n_done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials)\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_done\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock_until_done\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masynchronous\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[1;32m    366\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/thesis/lib/python3.10/site-packages/hyperopt/fmin.py:300\u001b[0m, in \u001b[0;36mFMinIter.run\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    297\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpoll_interval_secs)\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;66;03m# -- loop over trials and do the jobs directly\u001b[39;00m\n\u001b[0;32m--> 300\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserial_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials_save_file \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.pyenv/versions/thesis/lib/python3.10/site-packages/hyperopt/fmin.py:178\u001b[0m, in \u001b[0;36mFMinIter.serial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    176\u001b[0m ctrl \u001b[38;5;241m=\u001b[39m base\u001b[38;5;241m.\u001b[39mCtrl(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials, current_trial\u001b[38;5;241m=\u001b[39mtrial)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 178\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdomain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctrl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    180\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjob exception: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mstr\u001b[39m(e))\n",
      "File \u001b[0;32m~/.pyenv/versions/thesis/lib/python3.10/site-packages/hyperopt/base.py:892\u001b[0m, in \u001b[0;36mDomain.evaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    884\u001b[0m     \u001b[38;5;66;03m# -- the \"work\" of evaluating `config` can be written\u001b[39;00m\n\u001b[1;32m    885\u001b[0m     \u001b[38;5;66;03m#    either into the pyll part (self.expr)\u001b[39;00m\n\u001b[1;32m    886\u001b[0m     \u001b[38;5;66;03m#    or the normal Python part (self.fn)\u001b[39;00m\n\u001b[1;32m    887\u001b[0m     pyll_rval \u001b[38;5;241m=\u001b[39m pyll\u001b[38;5;241m.\u001b[39mrec_eval(\n\u001b[1;32m    888\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpr,\n\u001b[1;32m    889\u001b[0m         memo\u001b[38;5;241m=\u001b[39mmemo,\n\u001b[1;32m    890\u001b[0m         print_node_on_error\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrec_eval_print_node_on_error,\n\u001b[1;32m    891\u001b[0m     )\n\u001b[0;32m--> 892\u001b[0m     rval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpyll_rval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rval, (\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mint\u001b[39m, np\u001b[38;5;241m.\u001b[39mnumber)):\n\u001b[1;32m    895\u001b[0m     dict_rval \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(rval), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m\"\u001b[39m: STATUS_OK}\n",
      "File \u001b[0;32m~/sdev/repos/AutoDeep/autodeep/modelsdefinition/CommonStructure.py:311\u001b[0m, in \u001b[0;36mPytorchTabularTrainer.hyperopt_search.<locals>.objective\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_range \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    302\u001b[0m         (\n\u001b[1;32m    303\u001b[0m             \u001b[38;5;28mfloat\u001b[39m(np\u001b[38;5;241m.\u001b[39mmin(train_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.8\u001b[39m),\n\u001b[1;32m    304\u001b[0m             \u001b[38;5;28mfloat\u001b[39m(np\u001b[38;5;241m.\u001b[39mmax(train_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1.2\u001b[39m),\n\u001b[1;32m    305\u001b[0m         )\n\u001b[1;32m    306\u001b[0m     ]\n\u001b[1;32m    308\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_tabular_model(\n\u001b[1;32m    309\u001b[0m     params, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_params, default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault\n\u001b[1;32m    310\u001b[0m )\n\u001b[0;32m--> 311\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    313\u001b[0m pred_df \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(test_data)\n\u001b[1;32m    314\u001b[0m predictions \u001b[38;5;241m=\u001b[39m pred_df[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_col]\u001b[38;5;241m.\u001b[39mvalues\n",
      "File \u001b[0;32m~/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/tabular_model.py:806\u001b[0m, in \u001b[0;36mTabularModel.fit\u001b[0;34m(self, train, validation, loss, metrics, metrics_prob_inputs, optimizer, optimizer_params, train_sampler, target_transform, max_epochs, min_epochs, seed, callbacks, datamodule, cache_data, handle_oom)\u001b[0m\n\u001b[1;32m    792\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    793\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain data and datamodule is provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    794\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Ignoring the train data and using the datamodule.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    795\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Set either one of them to None to avoid this warning.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    796\u001b[0m         )\n\u001b[1;32m    797\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_model(\n\u001b[1;32m    798\u001b[0m     datamodule,\n\u001b[1;32m    799\u001b[0m     loss,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    803\u001b[0m     optimizer_params \u001b[38;5;129;01mor\u001b[39;00m {},\n\u001b[1;32m    804\u001b[0m )\n\u001b[0;32m--> 806\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhandle_oom\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/tabular_model.py:691\u001b[0m, in \u001b[0;36mTabularModel.train\u001b[0;34m(self, model, datamodule, callbacks, max_epochs, min_epochs, handle_oom)\u001b[0m\n\u001b[1;32m    689\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining the model completed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mload_best:\n\u001b[0;32m--> 691\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_best_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\n",
      "File \u001b[0;32m~/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/tabular_model.py:1534\u001b[0m, in \u001b[0;36mTabularModel.load_best_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1532\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n\u001b[1;32m   1533\u001b[0m         logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel Checkpoint: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mckpt_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1534\u001b[0m     ckpt \u001b[38;5;241m=\u001b[39m \u001b[43mpl_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloc\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1535\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mload_state_dict(ckpt[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/utils/python_utils.py:85\u001b[0m, in \u001b[0;36mpl_load\u001b[0;34m(path_or_url, map_location)\u001b[0m\n\u001b[1;32m     83\u001b[0m fs \u001b[38;5;241m=\u001b[39m get_filesystem(path_or_url)\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m fs\u001b[38;5;241m.\u001b[39mopen(path_or_url, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 85\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmap_location\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/serialization.py:1470\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1462\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m _load(\n\u001b[1;32m   1463\u001b[0m                     opened_zipfile,\n\u001b[1;32m   1464\u001b[0m                     map_location,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1467\u001b[0m                     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args,\n\u001b[1;32m   1468\u001b[0m                 )\n\u001b[1;32m   1469\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1470\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1471\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _load(\n\u001b[1;32m   1472\u001b[0m             opened_zipfile,\n\u001b[1;32m   1473\u001b[0m             map_location,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1476\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args,\n\u001b[1;32m   1477\u001b[0m         )\n\u001b[1;32m   1478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n",
      "\u001b[0;31mUnpicklingError\u001b[0m: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL omegaconf.dictconfig.DictConfig was not an allowed global by default. Please use `torch.serialization.add_safe_globals([DictConfig])` or the `torch.serialization.safe_globals([DictConfig])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html."
     ]
    }
   ],
   "source": [
    "# Define paths to configuration files and data\n",
    "DATA_FOLDER = r\"/home/boom/sdev/repos/AutoDeep/autodeep/examples/testautodata\"\n",
    "OUTPUT_FOLDER = r\"/home/boom/sdev/repos/AutoDeep/autodeep/examples/output\"\n",
    "\n",
    "DEFAULT_MODELS = [\"node\"]\n",
    "# Add any new models here\n",
    "# WORKING ONES (BARELY WORKING [xgb\", \"catboost\", \"mlp\", ])\n",
    "# Define the configuration dictionary for datasets\n",
    "DATA_CONFIG = {\n",
    "    \"dataset1\": {\n",
    "        \"dataset_path\": f\"{DATA_FOLDER}/adult.csv\",\n",
    "        \"target_col\": \"target\",\n",
    "        \"problem_type\": \"binary_classification\",\n",
    "        \"test_size\": 0.25,\n",
    "        \"num_targets\": 1,\n",
    "        \"metric\": \"roc_auc\",\n",
    "        \"eval_metrics\": [\"accuracy\", \"roc_auc\", \"lift5\"],\n",
    "    },\n",
    "    \"dataset2\": {\n",
    "        \"dataset_path\": f\"{DATA_FOLDER}/adult_2.csv\",\n",
    "        \"target_col\": \"target\",\n",
    "        \"problem_type\": \"binary_classification\",\n",
    "        \"test_size\": 0.2,\n",
    "        \"num_targets\": 1,\n",
    "        \"metric\": \"roc_auc\",\n",
    "        \"eval_metrics\": [\"accuracy\", \"roc_auc\", \"lift1\"],\n",
    "    },\n",
    "    \"dataset3\": {\n",
    "        \"dataset_path\": f\"{DATA_FOLDER}/adult.csv\",\n",
    "        \"target_col\": \"target\",\n",
    "        \"problem_type\": \"binary_classification\",\n",
    "        \"split_col\": \"split\",\n",
    "        \"num_targets\": 1,\n",
    "        \"metric\": \"roc_auc\",\n",
    "        \"eval_metrics\": [\"accuracy\", \"roc_auc\", \"lift5\"],\n",
    "    },\n",
    "    # Add more datasets as needed\n",
    "}\n",
    "\n",
    "DATA_CONFIG = {\n",
    "    \"dataset1\": {\n",
    "        \"dataset_path\": f\"{DATA_FOLDER}/adult.csv\",\n",
    "        \"target_col\": \"target\",\n",
    "        \"problem_type\": \"binary_classification\",\n",
    "        \"test_size\": 0.2,\n",
    "        \"num_targets\": 1,\n",
    "        \"metric\": \"roc_auc\",\n",
    "        \"eval_metrics\": [\"accuracy\", \"roc_auc\", \"lift5\"],\n",
    "    },\n",
    "    # Add more datasets as needed\n",
    "}\n",
    "\n",
    "# Initialize AutoRunner instance with the configuration\n",
    "runner = AutoRunner(\n",
    "    data_config=DATA_CONFIG,\n",
    "    output_folder=OUTPUT_FOLDER,\n",
    "    default_models=DEFAULT_MODELS,\n",
    "    random_state=42,\n",
    "    execution_mode=\"hyperopt\",  # You can change this to other modes like \"cv\" or \"new_mode\"\n",
    "    eval_metrics=[\"accuracy\", \"f1\", \"roc_auc\"],  # Evaluation metrics as needed\n",
    "    max_evals=2,\n",
    "    output_file_format=\"{dataset}_{model}_{timestamp}.yml\",\n",
    ")\n",
    "\n",
    "# Run the AutoML process\n",
    "runner.run()\n",
    "\n",
    "# Print results\n",
    "# Assuming results are saved correctly in the `runner.results` list (adapt as necessary)\n",
    "for result in runner.results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --force-reinstall torch==2.5.1 torchvision==0.20.0 torchaudio==2.5.0 --index-url https://download.pytorch.org/whl/cu124\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class NodeConfig in module pytorch_tabular.models.node.config:\n",
      "\n",
      "class NodeConfig(pytorch_tabular.config.config.ModelConfig)\n",
      " |  NodeConfig(task: str, head: Optional[str] = 'LinearHead', head_config: Optional[Dict] = <factory>, embedding_dims: Optional[List] = None, embedding_dropout: float = 0.0, batch_norm_continuous_input: bool = True, learning_rate: float = 0.001, loss: Optional[str] = None, metrics: Optional[List[str]] = None, metrics_prob_input: Optional[List[bool]] = None, metrics_params: Optional[List] = None, target_range: Optional[List] = None, seed: int = 42, _module_src: str = 'models.node', _model_name: str = 'NODEModel', _backbone_name: str = 'NODEBackbone', _config_name: str = 'NodeConfig', num_layers: int = 1, num_trees: int = 2048, additional_tree_output_dim: int = 3, depth: int = 6, choice_function: str = 'entmax15', bin_function: str = 'entmoid15', max_features: Optional[int] = None, input_dropout: float = 0.0, initialize_response: str = 'normal', initialize_selection_logits: str = 'uniform', threshold_init_beta: float = 1.0, threshold_init_cutoff: float = 1.0, cat_embedding_dropout: float = 0.0, embed_categorical: bool = False) -> None\n",
      " |  \n",
      " |  Model configuration\n",
      " |  Args:\n",
      " |      num_layers (int): Number of Oblivious Decision Tree Layers in the Dense Architecture\n",
      " |  \n",
      " |      num_trees (int): Number of Oblivious Decision Trees in each layer\n",
      " |  \n",
      " |      additional_tree_output_dim (int): The additional output dimensions which is only used to pass\n",
      " |              through different layers of the architectures. Only the first output_dim outputs will be used for\n",
      " |              prediction\n",
      " |  \n",
      " |      depth (int): The depth of the individual Oblivious Decision Trees\n",
      " |  \n",
      " |      choice_function (str): Generates a sparse probability distribution to be used as feature\n",
      " |              weights(aka, soft feature selection). Choices are: [`entmax15`,`sparsemax`].\n",
      " |  \n",
      " |      bin_function (str): Generates a sparse probability distribution to be used as tree leaf weights.\n",
      " |              Choices are: [`entmoid15`,`sparsemoid`].\n",
      " |  \n",
      " |      max_features (Optional[int]): If not None, sets a max limit on the number of features to be carried\n",
      " |              forward from layer to layer in the Dense Architecture\n",
      " |  \n",
      " |      input_dropout (float): Dropout to be applied to the inputs between layers of the Dense Architecture\n",
      " |  \n",
      " |      initialize_response (str): Initializing the response variable in the Oblivious Decision Trees. By\n",
      " |              default, it is a standard normal distribution. Choices are: [`normal`,`uniform`].\n",
      " |  \n",
      " |      initialize_selection_logits (str): Initializing the feature selector. By default is a uniform\n",
      " |              distribution across the features. Choices are: [`uniform`,`normal`].\n",
      " |  \n",
      " |      threshold_init_beta (float):                  Used in the Data-aware initialization of thresholds\n",
      " |              where the threshold is initialized randomly                 (with a beta distribution) to feature\n",
      " |              values in the first batch.                 It initializes threshold to a q-th quantile of data\n",
      " |              points.                 where q ~ Beta(:threshold_init_beta:, :threshold_init_beta:)\n",
      " |              If this param is set to 1, initial thresholds will have the same distribution as data points\n",
      " |              If greater than 1 (e.g. 10), thresholds will be closer to median data value                 If\n",
      " |              less than 1 (e.g. 0.1), thresholds will approach min/max data values.\n",
      " |  \n",
      " |      threshold_init_cutoff (float):                  Used in the Data-aware initialization of\n",
      " |              scales(used in the scaling ODTs).                 It is initialized in such a way that all the\n",
      " |              samples in the first batch belong to the linear                 region of the\n",
      " |              entmoid/sparsemoid(bin-selectors) and thereby have non-zero gradients                 Threshold\n",
      " |              log-temperatures initializer, in (0, inf)                 By default(1.0), log-temperatures are\n",
      " |              initialized in such a way that all bin selectors                 end up in the linear region of\n",
      " |              sparse-sigmoid. The temperatures are then scaled by this parameter.                 Setting this\n",
      " |              value > 1.0 will result in some margin between data points and sparse-sigmoid cutoff value\n",
      " |              Setting this value < 1.0 will cause (1 - value) part of data points to end up in flat sparse-\n",
      " |              sigmoid region                 For instance, threshold_init_cutoff = 0.9 will set 10% points equal\n",
      " |              to 0.0 or 1.0                 Setting this value > 1.0 will result in a margin between data points\n",
      " |              and sparse-sigmoid cutoff value                 All points will be between (0.5 - 0.5 /\n",
      " |              threshold_init_cutoff) and (0.5 + 0.5 / threshold_init_cutoff)\n",
      " |  \n",
      " |      cat_embedding_dropout (float): DEPRECATED: Please use `embedding_dropout` instead. probability of\n",
      " |              an embedding element to be zeroed.\n",
      " |  \n",
      " |      embed_categorical (bool): Flag to embed categorical columns using an Embedding Layer. If turned\n",
      " |              off, the categorical columns are encoded using LeaveOneOutEncoder. This is DEPRECATED and will\n",
      " |              always be `True` from next release.\n",
      " |  \n",
      " |  \n",
      " |      task (str): Specify whether the problem is regression or classification. `backbone` is a task which\n",
      " |              considers the model as a backbone to generate features. Mostly used internally for SSL and related\n",
      " |              tasks.. Choices are: [`regression`,`classification`,`backbone`].\n",
      " |  \n",
      " |      head (Optional[str]): The head to be used for the model. Should be one of the heads defined in\n",
      " |              `pytorch_tabular.models.common.heads`. Defaults to  LinearHead. Choices are:\n",
      " |              [`None`,`LinearHead`,`MixtureDensityHead`].\n",
      " |  \n",
      " |      head_config (Optional[Dict]): The config as a dict which defines the head. If left empty, will be\n",
      " |              initialized as default linear head.\n",
      " |  \n",
      " |      embedding_dims (Optional[List]): The dimensions of the embedding for each categorical column as a\n",
      " |              list of tuples (cardinality, embedding_dim). If left empty, will infer using the cardinality of\n",
      " |              the categorical column using the rule min(50, (x + 1) // 2)\n",
      " |  \n",
      " |      embedding_dropout (float): Dropout to be applied to the Categorical Embedding. Defaults to 0.1\n",
      " |  \n",
      " |      batch_norm_continuous_input (bool): If True, we will normalize the continuous layer by passing it\n",
      " |              through a BatchNorm layer.\n",
      " |  \n",
      " |      learning_rate (float): The learning rate of the model. Defaults to 1e-3.\n",
      " |  \n",
      " |      loss (Optional[str]): The loss function to be applied. By Default it is MSELoss for regression and\n",
      " |              CrossEntropyLoss for classification. Unless you are sure what you are doing, leave it at MSELoss\n",
      " |              or L1Loss for regression and CrossEntropyLoss for classification\n",
      " |  \n",
      " |      metrics (Optional[List[str]]): the list of metrics you need to track during training. The metrics\n",
      " |              should be one of the functional metrics implemented in ``torchmetrics``. By default, it is\n",
      " |              accuracy if classification and mean_squared_error for regression\n",
      " |  \n",
      " |      metrics_params (Optional[List]): The parameters to be passed to the metrics function. `task` is forced to\n",
      " |              be `multiclass` because the multiclass version can handle binary as well and for simplicity we are\n",
      " |              only using `multiclass`.\n",
      " |  \n",
      " |      metrics_prob_input (Optional[List]): Is a mandatory parameter for classification metrics defined in the config.\n",
      " |          This defines whether the input to the metric function is the probability or the class. Length should be\n",
      " |          same as the number of metrics. Defaults to None.\n",
      " |  \n",
      " |      target_range (Optional[List]): The range in which we should limit the output variable. Currently\n",
      " |              ignored for multi-target regression. Typically used for Regression problems. If left empty, will\n",
      " |              not apply any restrictions\n",
      " |  \n",
      " |      seed (int): The seed for reproducibility. Defaults to 42\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      NodeConfig\n",
      " |      pytorch_tabular.config.config.ModelConfig\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __eq__(self, other)\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __init__(self, task: str, head: Optional[str] = 'LinearHead', head_config: Optional[Dict] = <factory>, embedding_dims: Optional[List] = None, embedding_dropout: float = 0.0, batch_norm_continuous_input: bool = True, learning_rate: float = 0.001, loss: Optional[str] = None, metrics: Optional[List[str]] = None, metrics_prob_input: Optional[List[bool]] = None, metrics_params: Optional[List] = None, target_range: Optional[List] = None, seed: int = 42, _module_src: str = 'models.node', _model_name: str = 'NODEModel', _backbone_name: str = 'NODEBackbone', _config_name: str = 'NodeConfig', num_layers: int = 1, num_trees: int = 2048, additional_tree_output_dim: int = 3, depth: int = 6, choice_function: str = 'entmax15', bin_function: str = 'entmoid15', max_features: Optional[int] = None, input_dropout: float = 0.0, initialize_response: str = 'normal', initialize_selection_logits: str = 'uniform', threshold_init_beta: float = 1.0, threshold_init_cutoff: float = 1.0, cat_embedding_dropout: float = 0.0, embed_categorical: bool = False) -> None\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __post_init__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __annotations__ = {'_backbone_name': <class 'str'>, '_config_name': <c...\n",
      " |  \n",
      " |  __dataclass_fields__ = {'_backbone_name': Field(name='_backbone_name',...\n",
      " |  \n",
      " |  __dataclass_params__ = _DataclassParams(init=True,repr=True,eq=True,or...\n",
      " |  \n",
      " |  __hash__ = None\n",
      " |  \n",
      " |  __match_args__ = ('task', 'head', 'head_config', 'embedding_dims', 'em...\n",
      " |  \n",
      " |  additional_tree_output_dim = 3\n",
      " |  \n",
      " |  bin_function = 'entmoid15'\n",
      " |  \n",
      " |  cat_embedding_dropout = 0.0\n",
      " |  \n",
      " |  choice_function = 'entmax15'\n",
      " |  \n",
      " |  depth = 6\n",
      " |  \n",
      " |  embed_categorical = False\n",
      " |  \n",
      " |  initialize_response = 'normal'\n",
      " |  \n",
      " |  initialize_selection_logits = 'uniform'\n",
      " |  \n",
      " |  input_dropout = 0.0\n",
      " |  \n",
      " |  max_features = None\n",
      " |  \n",
      " |  num_layers = 1\n",
      " |  \n",
      " |  num_trees = 2048\n",
      " |  \n",
      " |  threshold_init_beta = 1.0\n",
      " |  \n",
      " |  threshold_init_cutoff = 1.0\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pytorch_tabular.config.config.ModelConfig:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from pytorch_tabular.config.config.ModelConfig:\n",
      " |  \n",
      " |  batch_norm_continuous_input = True\n",
      " |  \n",
      " |  embedding_dims = None\n",
      " |  \n",
      " |  embedding_dropout = 0.0\n",
      " |  \n",
      " |  head = 'LinearHead'\n",
      " |  \n",
      " |  learning_rate = 0.001\n",
      " |  \n",
      " |  loss = None\n",
      " |  \n",
      " |  metrics = None\n",
      " |  \n",
      " |  metrics_params = None\n",
      " |  \n",
      " |  metrics_prob_input = None\n",
      " |  \n",
      " |  seed = 42\n",
      " |  \n",
      " |  target_range = None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "from pytorch_tabular.models import NodeConfig\n",
    "\n",
    "help(NodeConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dok1 = {\n",
    "    \"additional_tree_output_dim\": 3,\n",
    "    \"batch_norm_continuous_input\": True,\n",
    "    \"bin_function\": \"entmoid15\",\n",
    "    \"choice_function\": \"entmax15\",\n",
    "    \"depth\": 5,\n",
    "    \"embed_categorical\": True,\n",
    "    \"embedding_dropout\": 0.06089480159646259,\n",
    "    \"initialize_response\": \"normal\",\n",
    "    \"initialize_selection_logits\": \"normal\",\n",
    "    \"input_dropout\": 0.15466990749662266,\n",
    "    \"max_features\": 32,\n",
    "    \"num_layers\": 1,\n",
    "    \"num_trees\": 736,\n",
    "    \"threshold_init_beta\": 0.6724199121113691,\n",
    "    \"threshold_init_cutoff\": 0.6076965359243615,\n",
    "}\n",
    "dko2 = {\n",
    "    \"additional_tree_output_dim\": 3,\n",
    "    \"batch_norm_continuous_input\": False,\n",
    "    \"bin_function\": \"entmoid15\",\n",
    "    \"choice_function\": \"entmax15\",\n",
    "    \"depth\": 6,\n",
    "    \"embedding_dropout\": 0.05438018363383848,\n",
    "    \"initialize_response\": \"normal\",\n",
    "    \"initialize_selection_logits\": \"normal\",\n",
    "    \"input_dropout\": 0.17230551619837015,\n",
    "    \"max_features\": 21,\n",
    "    \"num_layers\": 1,\n",
    "    \"num_trees\": 626,\n",
    "    \"threshold_init_beta\": 0.9430824174145327,\n",
    "    \"threshold_init_cutoff\": 1.1093300211337618,\n",
    "}\n",
    "\n",
    "dko3 = {\n",
    "    \"additional_tree_output_dim\": 3,\n",
    "    \"batch_norm_continuous_input\": False,\n",
    "    \"bin_function\": \"sparsemoid\",\n",
    "    \"choice_function\": \"entmax15\",\n",
    "    \"depth\": 4,\n",
    "    \"embedding_dropout\": 0.05438018363383848,\n",
    "    \"initialize_response\": \"normal\",\n",
    "    \"initialize_selection_logits\": \"normal\",\n",
    "    \"input_dropout\": 0.17230551619837015,\n",
    "    \"max_features\": 21,\n",
    "    \"num_layers\": 1,\n",
    "    \"num_trees\": 626,\n",
    "    \"threshold_init_beta\": 0.826726207188516,\n",
    "    \"threshold_init_cutoff\": 0.9402437257075205,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_norm_continuous_input': False,\n",
       " 'depth': 6,\n",
       " 'embedding_dropout': 0.05438018363383848,\n",
       " 'input_dropout': 0.17230551619837015,\n",
       " 'max_features': 21,\n",
       " 'num_trees': 626,\n",
       " 'threshold_init_beta': 0.9430824174145327,\n",
       " 'threshold_init_cutoff': 1.1093300211337618}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddiff = {k: v for k, v in dko2.items() if dko2[k] != dok1[k]}\n",
    "ddiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_norm_continuous_input': False,\n",
       " 'bin_function': 'sparsemoid',\n",
       " 'depth': 4,\n",
       " 'embedding_dropout': 0.05438018363383848,\n",
       " 'input_dropout': 0.17230551619837015,\n",
       " 'max_features': 21,\n",
       " 'num_trees': 626,\n",
       " 'threshold_init_beta': 0.826726207188516,\n",
       " 'threshold_init_cutoff': 0.9402437257075205}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddiff = {k: v for k, v in dko3.items() if dko3[k] != dok1[k]}\n",
    "ddiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Define the folder to format and lint\n",
    "folder_to_check = \"autodeep\"\n",
    "\n",
    "# Define output files\n",
    "output_files = {\n",
    "    \"isort\": \"isort_output.txt\",\n",
    "    \"black\": \"black_output.txt\",\n",
    "    \"pylint\": \"pylint_output.txt\",\n",
    "    \"flake8\": \"flake8_output.txt\",\n",
    "}\n",
    "\n",
    "# Ensure the output folder exists\n",
    "os.makedirs(\"linting_outputs\", exist_ok=True)\n",
    "\n",
    "# Run isort\n",
    "with open(os.path.join(\"linting_outputs\", output_files[\"isort\"]), \"w\") as f:\n",
    "    subprocess.run([\"isort\", folder_to_check], stdout=f, stderr=f)\n",
    "\n",
    "# Run black\n",
    "with open(os.path.join(\"linting_outputs\", output_files[\"black\"]), \"w\") as f:\n",
    "    subprocess.run([\"black\", folder_to_check], stdout=f, stderr=f)\n",
    "\n",
    "# Run pylint\n",
    "with open(os.path.join(\"linting_outputs\", output_files[\"pylint\"]), \"w\") as f:\n",
    "    subprocess.run([\"pylint\", folder_to_check], stdout=f, stderr=f)\n",
    "\n",
    "# Run flake8\n",
    "with open(os.path.join(\"linting_outputs\", output_files[\"flake8\"]), \"w\") as f:\n",
    "    subprocess.run([\"flake8\", folder_to_check], stdout=f, stderr=f)\n",
    "\n",
    "print(\n",
    "    \"Linting and formatting completed. Outputs are saved in the 'linting_outputs' folder.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install isort black pylint flake8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Define the path to the folder to format and lint (one level up from the current directory)\n",
    "folder_to_check = \"../../autodeep\"\n",
    "\n",
    "# Define the output folder and ensure it exists\n",
    "output_folder = \"linting_outputs\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Define the output files\n",
    "output_files = {\n",
    "    \"isort\": \"isort_output.txt\",\n",
    "    \"black\": \"black_output.txt\",\n",
    "    \"pylint\": \"pylint_output.txt\",\n",
    "    \"flake8\": \"flake8_output.txt\",\n",
    "}\n",
    "\n",
    "# Run isort\n",
    "isort_output_path = os.path.join(output_folder, output_files[\"isort\"])\n",
    "with open(isort_output_path, \"w\") as f:\n",
    "    subprocess.run([\"isort\", folder_to_check], stdout=f, stderr=f)\n",
    "\n",
    "# Run black\n",
    "black_output_path = os.path.join(output_folder, output_files[\"black\"])\n",
    "with open(black_output_path, \"w\") as f:\n",
    "    subprocess.run([\"black\", folder_to_check], stdout=f, stderr=f)\n",
    "\n",
    "# Run pylint\n",
    "pylint_output_path = os.path.join(output_folder, output_files[\"pylint\"])\n",
    "with open(pylint_output_path, \"w\") as f:\n",
    "    subprocess.run([\"pylint\", folder_to_check], stdout=f, stderr=f)\n",
    "\n",
    "# Run flake8\n",
    "flake8_output_path = os.path.join(output_folder, output_files[\"flake8\"])\n",
    "with open(flake8_output_path, \"w\") as f:\n",
    "    subprocess.run([\"flake8\", folder_to_check], stdout=f, stderr=f)\n",
    "\n",
    "print(\n",
    "    f\"Linting and formatting completed. Outputs are saved in the '{output_folder}' folder.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
