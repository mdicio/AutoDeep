{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test AutoML Functionality in a Separate Notebook\n",
    "from autodeep.automl import AutoRunner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = [\n",
    "    # \"XGB\",  # Extreme Gradient Boosting\n",
    "    # \"CatBoost\",\n",
    "    \"MLP\",  # Multi,Layer Perceptron\n",
    "    \"TabNet\",  # TabNet Classifier\n",
    "    \"GATE\",\n",
    "    # \"resnet\",\n",
    "    # \"S1DCNN\",\n",
    "    \"CategoryEmbedding\",\n",
    "    \"FTTransformer\",\n",
    "    \"TabTransformer\",\n",
    "    \"GANDALF\",\n",
    "    \"AutoInt\",\n",
    "    \"Node\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"../examples/testautodata/adult.csv\")\n",
    "df[\"s\"] = \"s\"\n",
    "df[\"a\"] = \"s\"\n",
    "df[\"f\"] = \"s\"\n",
    "df[\"y\"] = \"s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def _auto_determine_img_size(X):\n",
    "    num_features = len(X.columns)\n",
    "\n",
    "    # Find valid (row, col) pairs where row * col = num_features\n",
    "    factors = [\n",
    "        (r, num_features // r)\n",
    "        for r in range(1, int(np.sqrt(num_features)) + 1)\n",
    "        if num_features % r == 0\n",
    "    ]\n",
    "    print(factors)\n",
    "    # Pick the most square-like option (largest row)\n",
    "    num_row, num_col = factors[-1]\n",
    "\n",
    "    # Check if num_features is prime (only divisible by 1 and itself)\n",
    "    if len(factors) == 1:  # Only (1, num_features) exists\n",
    "        print(\n",
    "            f\"Warning: The number of features ({num_features}) is prime. \"\n",
    "            \"For better IGTD performance, consider adding or removing columns to allow a more standard grid size.\"\n",
    "        )\n",
    "\n",
    "    return num_row, num_col\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32561, 19)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 19)]\n",
      "Warning: The number of features (19) is prime. For better IGTD performance, consider adding or removing columns to allow a more standard grid size.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 19)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_auto_determine_img_size(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#tested with 100 hyperopt iterations did not break on adult dataset:\n",
    "\n",
    "\"autoint\",\n",
    "\"node\",\n",
    "\"mlp\",\n",
    "\"tabnet\",\n",
    "\"categoryembedding\",\n",
    "\"fttransformer\",\n",
    "\"tabtransformer\",\n",
    "\"gandalf\",\n",
    "\"mlp\"\n",
    "\n",
    "\n",
    "# very slow, had to decrease parameters for memory consumption also:\n",
    "\"gate\",\n",
    "\n",
    "# Not tested hyperopt search yet:\n",
    "\n",
    "#catboost\n",
    "#xgb\n",
    "#resnet\n",
    "#s1dcnn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running categoryembedding on dataset1...\n",
      "Using dynamic loader for dataset: /home/boom/sdev/repos/AutoDeep/autodeep/examples/testautodata/adult.csv\n",
      "2025-01-31 22:23:01,116 - INFO - CommonStructure.py - CategoryEmbeddingTrainer - Initialized CategoryEmbeddingTrainer with problem type binary_classification\n",
      "2025-01-31 22:23:01,117 - INFO - CommonStructure.py - CategoryEmbeddingTrainer - Device cuda is available\n",
      "2025-01-31 22:23:01,118 - INFO - CommonStructure.py - CategoryEmbeddingTrainer - Trainer initialized\n",
      "2025-01-31 22:23:01,118 - INFO - CommonStructure.py - CategoryEmbeddingTrainer - Starting hyperopt search 30 evals maximizing roc_auc metric on dataset\n",
      "SPACE ######################################################\n",
      "{'batch_size': <hyperopt.pyll.base.Apply object at 0x710ed53133d0>, 'layers': <hyperopt.pyll.base.Apply object at 0x710ed4eba0e0>, 'activation': <hyperopt.pyll.base.Apply object at 0x710ed4ebb790>, 'use_batch_norm': <hyperopt.pyll.base.Apply object at 0x710ed4ca36d0>, 'initialization': <hyperopt.pyll.base.Apply object at 0x710ed4ca3880>, 'dropout': <hyperopt.pyll.base.Apply object at 0x710ed483cf70>, 'embedding_dropout': <hyperopt.pyll.base.Apply object at 0x710ed483e3b0>, 'optimizer_fn': <hyperopt.pyll.base.Apply object at 0x710ec925ee30>, 'scheduler_fn': <hyperopt.pyll.base.Apply object at 0x710ed53b01c0>}\n",
      "2025-01-31 22:23:01,141 - DEBUG - CommonStructure.py - CategoryEmbeddingTrainer - Full dataset shape : (24420, 15)\n",
      "2025-01-31 22:23:01,151 - DEBUG - CommonStructure.py - CategoryEmbeddingTrainer - Train set shape: (20757, 15), Test set shape: (3663, 15)\n",
      "  0%|          | 0/30 [00:00<?, ?trial/s, best loss=?]2025-01-31 22:23:01,175 - INFO - CommonStructure.py - CategoryEmbeddingTrainer - Training with hyperparameters: {'activation': 'ReLU', 'batch_size': 352, 'dropout': 0.07180182756042691, 'embedding_dropout': 0.04456699223511802, 'initialization': 'xavier', 'layers': '256-128-64-32', 'optimizer_fn': {'AdamW_learning_rate': 0.0002369073315019895, 'AdamW_weight_decay': 2.7190091816919235e-08, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>}, 'scheduler_fn': {'StepLR_gamma': 0.24871568886900097, 'StepLR_step_size': 27, 'scheduler_fn': <class 'torch.optim.lr_scheduler.StepLR'>}, 'use_batch_norm': False}\n",
      "tabular model params                                  \n",
      "{'activation': 'ReLU', 'batch_size': 352, 'dropout': 0.07180182756042691, 'embedding_dropout': 0.04456699223511802, 'initialization': 'xavier', 'layers': '256-128-64-32', 'optimizer_fn': {'AdamW_learning_rate': 0.0002369073315019895, 'AdamW_weight_decay': 2.7190091816919235e-08, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>}, 'scheduler_fn': {'StepLR_gamma': 0.24871568886900097, 'StepLR_step_size': 27, 'scheduler_fn': <class 'torch.optim.lr_scheduler.StepLR'>}, 'use_batch_norm': False}\n",
      "tabular model outer params                            \n",
      "{'early_stopping_rounds': 10, 'verbose': False, 'iterations': 20, 'retrain': False, 'auto_lr_find': False, 'max_epochs': 3, 'val_size': 0.15, 'early_stopping_patience': 20}\n",
      "  0%|          | 0/30 [00:00<?, ?trial/s, best loss=?]2025-01-31 22:23:01,190 - WARNING - CommonStructure.py - CategoryEmbeddingTrainer - You are passing some invalid parameters to the model {'batch_size': 352, 'optimizer_fn': {'AdamW_learning_rate': 0.0002369073315019895, 'AdamW_weight_decay': 2.7190091816919235e-08, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>}, 'scheduler_fn': {'StepLR_gamma': 0.24871568886900097, 'StepLR_step_size': 27, 'scheduler_fn': <class 'torch.optim.lr_scheduler.StepLR'>}}\n",
      "2025-01-31 22:23:01,191 - DEBUG - CommonStructure.py - CategoryEmbeddingTrainer - compatible parameters: {'activation': 'ReLU', 'dropout': 0.07180182756042691, 'embedding_dropout': 0.04456699223511802, 'initialization': 'xavier', 'layers': '256-128-64-32', 'use_batch_norm': False}\n",
      "DataConfig(target=['target'], continuous_cols=['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week'], categorical_cols=['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country'], date_columns=[], encode_date_columns=True, validation_split=0.2, continuous_feature_transform=None, normalize_continuous_features=True, quantile_noise=0, num_workers=4, pin_memory=True, handle_unknown_categories=True, handle_missing_values=True, dataloader_kwargs={})\n",
      "CategoryEmbeddingModelConfig(task='classification', head='LinearHead', head_config={'layers': ''}, embedding_dims=None, embedding_dropout=0.0, batch_norm_continuous_input=True, learning_rate=0.0002369073315019895, loss='CrossEntropyLoss', metrics=['accuracy'], metrics_prob_input=[False], metrics_params=[{}], target_range=None, virtual_batch_size=None, seed=42, _module_src='models.category_embedding', _model_name='CategoryEmbeddingModel', _backbone_name='CategoryEmbeddingBackbone', _config_name='CategoryEmbeddingModelConfig', layers='256-128-64-32', activation='ReLU', use_batch_norm=False, initialization='kaiming', dropout=0.0)\n",
      "OptimizerConfig(optimizer='AdamW', optimizer_params={'weight_decay': 2.7190091816919235e-08}, lr_scheduler='StepLR', lr_scheduler_params={'step_size': 27, 'gamma': 0.24871568886900097}, lr_scheduler_monitor_metric='valid_loss')\n",
      "TrainerConfig(batch_size=352, data_aware_init_batch_size=2000, fast_dev_run=False, max_epochs=3, min_epochs=1, max_time=None, accelerator='auto', devices=-1, devices_list=None, accumulate_grad_batches=1, auto_lr_find=False, auto_select_gpus=True, check_val_every_n_epoch=1, gradient_clip_val=0.0, overfit_batches=0.0, deterministic=False, profiler=None, early_stopping='valid_loss', early_stopping_min_delta=0.0, early_stopping_mode='min', early_stopping_patience=20, early_stopping_kwargs={}, checkpoints='valid_loss', checkpoints_path='ptabular_checkpoints', checkpoints_every_n_epochs=10, checkpoints_name=None, checkpoints_mode='min', checkpoints_save_top_k=1, checkpoints_kwargs={}, load_best=True, track_grad_norm=-1, progress_bar='rich', precision=32, seed=42, trainer_kwargs={})\n",
      "  0%|          | 0/30 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:01</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">221</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">146</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:01\u001b[0m,\u001b[1;36m221\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m146\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:01</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">249</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:01\u001b[0m,\u001b[1;36m249\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:01</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">282</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:01\u001b[0m,\u001b[1;36m282\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:01</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">370</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: CategoryEmbeddingModel \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:01\u001b[0m,\u001b[1;36m370\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: CategoryEmbeddingModel \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:01</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">430</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:01\u001b[0m,\u001b[1;36m430\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:01</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">441</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:01\u001b[0m,\u001b[1;36m441\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                      </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ custom_loss      │ CrossEntropyLoss          │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _backbone        │ CategoryEmbeddingBackbone │ 59.6 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _embedding_layer │ Embedding1dLayer          │  1.4 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ head             │ LinearHead                │     66 │ train │\n",
       "└───┴──────────────────┴───────────────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType                     \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ custom_loss      │ CrossEntropyLoss          │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ CategoryEmbeddingBackbone │ 59.6 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer          │  1.4 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ head             │ LinearHead                │     66 │ train │\n",
       "└───┴──────────────────┴───────────────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 61.1 K                                                                                           \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 61.1 K                                                                                               \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 26                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 61.1 K                                                                                           \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 61.1 K                                                                                               \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 26                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2758d52e149048f88953a8e6b426c4e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:08</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">439</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:08\u001b[0m,\u001b[1;36m439\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:08</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">442</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:08\u001b[0m,\u001b[1;36m442\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:08</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">443</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1537</span><span style=\"font-weight: bold\">}</span> - WARNING - No best model available to load. Did you\n",
       "run it more than <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> epoch?<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                                                                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:08\u001b[0m,\u001b[1;36m443\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1537\u001b[0m\u001b[1m}\u001b[0m - WARNING - No best model available to load. Did you\n",
       "run it more than \u001b[1;36m1\u001b[0m epoch?\u001b[33m...\u001b[0m                                                                                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       target_0_probability  target_1_probability  target_prediction\n",
      "20196              0.958937              0.041063                  0\n",
      "2308               0.153516              0.846484                  1\n",
      "9498               0.211828              0.788172                  1\n",
      "18596              0.048162              0.951838                  1\n",
      "20834              0.548964              0.451036                  0\n",
      "...                     ...                   ...                ...\n",
      "19265              0.884769              0.115231                  0\n",
      "7304               0.000032              0.999968                  1\n",
      "9758               0.859634              0.140366                  0\n",
      "8840               0.583212              0.416788                  0\n",
      "5028               0.981848              0.018152                  0\n",
      "\n",
      "[3663 rows x 3 columns]\n",
      "  0%|          | 0/30 [00:08<?, ?trial/s, best loss=?]2025-01-31 22:23:09,227 - INFO - CommonStructure.py - CategoryEmbeddingTrainer - Validation metrics: {'accuracy': 0.7818727818727819, 'roc_auc': 0.9002557033840745}\n",
      "  3%|▎         | 1/30 [00:08<03:53,  8.06s/trial, best loss: -0.9002557033840745]2025-01-31 22:23:09,501 - INFO - CommonStructure.py - CategoryEmbeddingTrainer - Training with hyperparameters: {'activation': 'ReLU', 'batch_size': 608, 'dropout': 0.13793074406282088, 'embedding_dropout': 0.08748838326419968, 'initialization': 'random', 'layers': '256-128', 'optimizer_fn': {'Adam_learning_rate': 0.0003929327884259557, 'Adam_weight_decay': 3.044740079823129e-08, 'optimizer_fn': <class 'torch.optim.adam.Adam'>}, 'scheduler_fn': {'ReduceLROnPlateau_factor': 0.054041101815896615, 'ReduceLROnPlateau_patience': 9, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>}, 'use_batch_norm': True}\n",
      "tabular model params                                                             \n",
      "{'activation': 'ReLU', 'batch_size': 608, 'dropout': 0.13793074406282088, 'embedding_dropout': 0.08748838326419968, 'initialization': 'random', 'layers': '256-128', 'optimizer_fn': {'Adam_learning_rate': 0.0003929327884259557, 'Adam_weight_decay': 3.044740079823129e-08, 'optimizer_fn': <class 'torch.optim.adam.Adam'>}, 'scheduler_fn': {'ReduceLROnPlateau_factor': 0.054041101815896615, 'ReduceLROnPlateau_patience': 9, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>}, 'use_batch_norm': True}\n",
      "tabular model outer params                                                       \n",
      "{'early_stopping_rounds': 10, 'verbose': False, 'iterations': 20, 'retrain': False, 'auto_lr_find': False, 'max_epochs': 3, 'val_size': 0.15, 'early_stopping_patience': 20}\n",
      "  3%|▎         | 1/30 [00:08<03:53,  8.06s/trial, best loss: -0.9002557033840745]2025-01-31 22:23:09,510 - WARNING - CommonStructure.py - CategoryEmbeddingTrainer - You are passing some invalid parameters to the model {'batch_size': 608, 'optimizer_fn': {'Adam_learning_rate': 0.0003929327884259557, 'Adam_weight_decay': 3.044740079823129e-08, 'optimizer_fn': <class 'torch.optim.adam.Adam'>}, 'scheduler_fn': {'ReduceLROnPlateau_factor': 0.054041101815896615, 'ReduceLROnPlateau_patience': 9, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>}}\n",
      "2025-01-31 22:23:09,511 - DEBUG - CommonStructure.py - CategoryEmbeddingTrainer - compatible parameters: {'activation': 'ReLU', 'dropout': 0.13793074406282088, 'embedding_dropout': 0.08748838326419968, 'initialization': 'random', 'layers': '256-128', 'use_batch_norm': True}\n",
      "DataConfig(target=['target'], continuous_cols=['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week'], categorical_cols=['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country'], date_columns=[], encode_date_columns=True, validation_split=0.2, continuous_feature_transform=None, normalize_continuous_features=True, quantile_noise=0, num_workers=4, pin_memory=True, handle_unknown_categories=True, handle_missing_values=True, dataloader_kwargs={})\n",
      "CategoryEmbeddingModelConfig(task='classification', head='LinearHead', head_config={'layers': ''}, embedding_dims=None, embedding_dropout=0.0, batch_norm_continuous_input=True, learning_rate=0.0003929327884259557, loss='CrossEntropyLoss', metrics=['accuracy'], metrics_prob_input=[False], metrics_params=[{}], target_range=None, virtual_batch_size=None, seed=42, _module_src='models.category_embedding', _model_name='CategoryEmbeddingModel', _backbone_name='CategoryEmbeddingBackbone', _config_name='CategoryEmbeddingModelConfig', layers='256-128', activation='ReLU', use_batch_norm=False, initialization='kaiming', dropout=0.0)\n",
      "OptimizerConfig(optimizer='Adam', optimizer_params={'weight_decay': 3.044740079823129e-08}, lr_scheduler='ReduceLROnPlateau', lr_scheduler_params={'factor': 0.054041101815896615, 'patience': 9, 'min_lr': 1e-08, 'verbose': True, 'mode': 'min'}, lr_scheduler_monitor_metric='valid_loss')\n",
      "TrainerConfig(batch_size=608, data_aware_init_batch_size=2000, fast_dev_run=False, max_epochs=3, min_epochs=1, max_time=None, accelerator='auto', devices=-1, devices_list=None, accumulate_grad_batches=1, auto_lr_find=False, auto_select_gpus=True, check_val_every_n_epoch=1, gradient_clip_val=0.0, overfit_batches=0.0, deterministic=False, profiler=None, early_stopping='valid_loss', early_stopping_min_delta=0.0, early_stopping_mode='min', early_stopping_patience=20, early_stopping_kwargs={}, checkpoints='valid_loss', checkpoints_path='ptabular_checkpoints', checkpoints_every_n_epochs=10, checkpoints_name=None, checkpoints_mode='min', checkpoints_save_top_k=1, checkpoints_kwargs={}, load_best=True, track_grad_norm=-1, progress_bar='rich', precision=32, seed=42, trainer_kwargs={})\n",
      "  3%|▎         | 1/30 [00:08<03:53,  8.06s/trial, best loss: -0.9002557033840745]"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:09</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">534</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">146</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:09\u001b[0m,\u001b[1;36m534\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m146\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:09</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">557</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:09\u001b[0m,\u001b[1;36m557\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:09</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">579</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:09\u001b[0m,\u001b[1;36m579\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:09</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">658</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: CategoryEmbeddingModel \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:09\u001b[0m,\u001b[1;36m658\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: CategoryEmbeddingModel \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:09</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">724</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:09\u001b[0m,\u001b[1;36m724\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:09</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">740</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:09\u001b[0m,\u001b[1;36m740\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                      </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ custom_loss      │ CrossEntropyLoss          │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _backbone        │ CategoryEmbeddingBackbone │ 49.3 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _embedding_layer │ Embedding1dLayer          │  1.4 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ head             │ LinearHead                │    258 │ train │\n",
       "└───┴──────────────────┴───────────────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType                     \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ custom_loss      │ CrossEntropyLoss          │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ CategoryEmbeddingBackbone │ 49.3 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer          │  1.4 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ head             │ LinearHead                │    258 │ train │\n",
       "└───┴──────────────────┴───────────────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 50.9 K                                                                                           \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 50.9 K                                                                                               \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 22                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 50.9 K                                                                                           \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 50.9 K                                                                                               \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 22                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7dd645206a34f2bafd18a8b1ccf63fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:13</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">781</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:13\u001b[0m,\u001b[1;36m781\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:13</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">783</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:13\u001b[0m,\u001b[1;36m783\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:13</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">785</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1537</span><span style=\"font-weight: bold\">}</span> - WARNING - No best model available to load. Did you\n",
       "run it more than <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> epoch?<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                                                                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:13\u001b[0m,\u001b[1;36m785\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1537\u001b[0m\u001b[1m}\u001b[0m - WARNING - No best model available to load. Did you\n",
       "run it more than \u001b[1;36m1\u001b[0m epoch?\u001b[33m...\u001b[0m                                                                                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       target_0_probability  target_1_probability  target_prediction             \n",
      "20196              0.779250              0.220750                  0\n",
      "2308               0.188005              0.811995                  1\n",
      "9498               0.260712              0.739288                  1\n",
      "18596              0.088753              0.911247                  1\n",
      "20834              0.729220              0.270780                  0\n",
      "...                     ...                   ...                ...\n",
      "19265              0.902716              0.097284                  0\n",
      "7304               0.000041              0.999959                  1\n",
      "9758               0.912081              0.087919                  0\n",
      "8840               0.619270              0.380730                  0\n",
      "5028               0.944602              0.055398                  0\n",
      "\n",
      "[3663 rows x 3 columns]\n",
      "  3%|▎         | 1/30 [00:12<03:53,  8.06s/trial, best loss: -0.9002557033840745]2025-01-31 22:23:14,152 - INFO - CommonStructure.py - CategoryEmbeddingTrainer - Validation metrics: {'accuracy': 0.7856947856947857, 'roc_auc': 0.8946736071870914}\n",
      "  7%|▋         | 2/30 [00:12<02:54,  6.22s/trial, best loss: -0.9002557033840745]2025-01-31 22:23:14,170 - INFO - CommonStructure.py - CategoryEmbeddingTrainer - Training with hyperparameters: {'activation': 'LeakyReLU', 'batch_size': 1888, 'dropout': 0.29111456801897106, 'embedding_dropout': 0.19331901528810344, 'initialization': 'kaiming', 'layers': '32-16', 'optimizer_fn': {'AdamW_learning_rate': 0.0005937305631605383, 'AdamW_weight_decay': 4.8713045781524146e-08, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>}, 'scheduler_fn': {'ReduceLROnPlateau_factor': 0.0717979001699833, 'ReduceLROnPlateau_patience': 8, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>}, 'use_batch_norm': True}\n",
      "tabular model params                                                             \n",
      "{'activation': 'LeakyReLU', 'batch_size': 1888, 'dropout': 0.29111456801897106, 'embedding_dropout': 0.19331901528810344, 'initialization': 'kaiming', 'layers': '32-16', 'optimizer_fn': {'AdamW_learning_rate': 0.0005937305631605383, 'AdamW_weight_decay': 4.8713045781524146e-08, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>}, 'scheduler_fn': {'ReduceLROnPlateau_factor': 0.0717979001699833, 'ReduceLROnPlateau_patience': 8, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>}, 'use_batch_norm': True}\n",
      "tabular model outer params                                                       \n",
      "{'early_stopping_rounds': 10, 'verbose': False, 'iterations': 20, 'retrain': False, 'auto_lr_find': False, 'max_epochs': 3, 'val_size': 0.15, 'early_stopping_patience': 20}\n",
      "  7%|▋         | 2/30 [00:13<02:54,  6.22s/trial, best loss: -0.9002557033840745]2025-01-31 22:23:14,182 - WARNING - CommonStructure.py - CategoryEmbeddingTrainer - You are passing some invalid parameters to the model {'batch_size': 1888, 'optimizer_fn': {'AdamW_learning_rate': 0.0005937305631605383, 'AdamW_weight_decay': 4.8713045781524146e-08, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>}, 'scheduler_fn': {'ReduceLROnPlateau_factor': 0.0717979001699833, 'ReduceLROnPlateau_patience': 8, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>}}\n",
      "2025-01-31 22:23:14,183 - DEBUG - CommonStructure.py - CategoryEmbeddingTrainer - compatible parameters: {'activation': 'LeakyReLU', 'dropout': 0.29111456801897106, 'embedding_dropout': 0.19331901528810344, 'initialization': 'kaiming', 'layers': '32-16', 'use_batch_norm': True}\n",
      "DataConfig(target=['target'], continuous_cols=['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week'], categorical_cols=['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country'], date_columns=[], encode_date_columns=True, validation_split=0.2, continuous_feature_transform=None, normalize_continuous_features=True, quantile_noise=0, num_workers=4, pin_memory=True, handle_unknown_categories=True, handle_missing_values=True, dataloader_kwargs={})\n",
      "CategoryEmbeddingModelConfig(task='classification', head='LinearHead', head_config={'layers': ''}, embedding_dims=None, embedding_dropout=0.0, batch_norm_continuous_input=True, learning_rate=0.0005937305631605383, loss='CrossEntropyLoss', metrics=['accuracy'], metrics_prob_input=[False], metrics_params=[{}], target_range=None, virtual_batch_size=None, seed=42, _module_src='models.category_embedding', _model_name='CategoryEmbeddingModel', _backbone_name='CategoryEmbeddingBackbone', _config_name='CategoryEmbeddingModelConfig', layers='32-16', activation='LeakyReLU', use_batch_norm=False, initialization='kaiming', dropout=0.0)\n",
      "OptimizerConfig(optimizer='AdamW', optimizer_params={'weight_decay': 4.8713045781524146e-08}, lr_scheduler='ReduceLROnPlateau', lr_scheduler_params={'factor': 0.0717979001699833, 'patience': 8, 'min_lr': 1e-08, 'verbose': True, 'mode': 'min'}, lr_scheduler_monitor_metric='valid_loss')\n",
      "TrainerConfig(batch_size=1888, data_aware_init_batch_size=2000, fast_dev_run=False, max_epochs=3, min_epochs=1, max_time=None, accelerator='auto', devices=-1, devices_list=None, accumulate_grad_batches=1, auto_lr_find=False, auto_select_gpus=True, check_val_every_n_epoch=1, gradient_clip_val=0.0, overfit_batches=0.0, deterministic=False, profiler=None, early_stopping='valid_loss', early_stopping_min_delta=0.0, early_stopping_mode='min', early_stopping_patience=20, early_stopping_kwargs={}, checkpoints='valid_loss', checkpoints_path='ptabular_checkpoints', checkpoints_every_n_epochs=10, checkpoints_name=None, checkpoints_mode='min', checkpoints_save_top_k=1, checkpoints_kwargs={}, load_best=True, track_grad_norm=-1, progress_bar='rich', precision=32, seed=42, trainer_kwargs={})\n",
      "  7%|▋         | 2/30 [00:13<02:54,  6.22s/trial, best loss: -0.9002557033840745]"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:14</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">213</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">146</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:14\u001b[0m,\u001b[1;36m213\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m146\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:14</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">237</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:14\u001b[0m,\u001b[1;36m237\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:14</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">261</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:14\u001b[0m,\u001b[1;36m261\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:14</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">347</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: CategoryEmbeddingModel \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:14\u001b[0m,\u001b[1;36m347\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: CategoryEmbeddingModel \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:14</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">428</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:14\u001b[0m,\u001b[1;36m428\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:14</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">438</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:14\u001b[0m,\u001b[1;36m438\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                      </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ custom_loss      │ CrossEntropyLoss          │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _backbone        │ CategoryEmbeddingBackbone │  2.6 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _embedding_layer │ Embedding1dLayer          │  1.4 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ head             │ LinearHead                │     34 │ train │\n",
       "└───┴──────────────────┴───────────────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType                     \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ custom_loss      │ CrossEntropyLoss          │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ CategoryEmbeddingBackbone │  2.6 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer          │  1.4 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ head             │ LinearHead                │     34 │ train │\n",
       "└───┴──────────────────┴───────────────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 4.0 K                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 4.0 K                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 22                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 4.0 K                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 4.0 K                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 22                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47ab9af29cfb40d3a941cc3f631d2735",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:17</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">288</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:17\u001b[0m,\u001b[1;36m288\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:17</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">292</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:17\u001b[0m,\u001b[1;36m292\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:17</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">294</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1537</span><span style=\"font-weight: bold\">}</span> - WARNING - No best model available to load. Did you\n",
       "run it more than <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> epoch?<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                                                                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:17\u001b[0m,\u001b[1;36m294\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1537\u001b[0m\u001b[1m}\u001b[0m - WARNING - No best model available to load. Did you\n",
       "run it more than \u001b[1;36m1\u001b[0m epoch?\u001b[33m...\u001b[0m                                                                                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       target_0_probability  target_1_probability  target_prediction             \n",
      "20196              0.745597              0.254403                  0\n",
      "2308               0.320624              0.679376                  1\n",
      "9498               0.268394              0.731606                  1\n",
      "18596              0.283714              0.716286                  1\n",
      "20834              0.569735              0.430265                  0\n",
      "...                     ...                   ...                ...\n",
      "19265              0.751676              0.248324                  0\n",
      "7304               0.204575              0.795425                  1\n",
      "9758               0.472943              0.527057                  1\n",
      "8840               0.861246              0.138754                  0\n",
      "5028               0.710687              0.289313                  0\n",
      "\n",
      "[3663 rows x 3 columns]\n",
      "  7%|▋         | 2/30 [00:16<02:54,  6.22s/trial, best loss: -0.9002557033840745]2025-01-31 22:23:17,666 - INFO - CommonStructure.py - CategoryEmbeddingTrainer - Validation metrics: {'accuracy': 0.7406497406497407, 'roc_auc': 0.833853138522579}\n",
      " 10%|█         | 3/30 [00:16<02:14,  4.98s/trial, best loss: -0.9002557033840745]2025-01-31 22:23:17,688 - INFO - CommonStructure.py - CategoryEmbeddingTrainer - Training with hyperparameters: {'activation': 'LeakyReLU', 'batch_size': 1376, 'dropout': 0.19449045900525083, 'embedding_dropout': 0.08720530524828946, 'initialization': 'kaiming', 'layers': '128-64-32', 'optimizer_fn': {'Adam_learning_rate': 0.0008849422181265142, 'Adam_weight_decay': 4.811133293049958e-08, 'optimizer_fn': <class 'torch.optim.adam.Adam'>}, 'scheduler_fn': {'ReduceLROnPlateau_factor': 0.07857720058107419, 'ReduceLROnPlateau_patience': 9, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>}, 'use_batch_norm': False}\n",
      "tabular model params                                                             \n",
      "{'activation': 'LeakyReLU', 'batch_size': 1376, 'dropout': 0.19449045900525083, 'embedding_dropout': 0.08720530524828946, 'initialization': 'kaiming', 'layers': '128-64-32', 'optimizer_fn': {'Adam_learning_rate': 0.0008849422181265142, 'Adam_weight_decay': 4.811133293049958e-08, 'optimizer_fn': <class 'torch.optim.adam.Adam'>}, 'scheduler_fn': {'ReduceLROnPlateau_factor': 0.07857720058107419, 'ReduceLROnPlateau_patience': 9, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>}, 'use_batch_norm': False}\n",
      "tabular model outer params                                                       \n",
      "{'early_stopping_rounds': 10, 'verbose': False, 'iterations': 20, 'retrain': False, 'auto_lr_find': False, 'max_epochs': 3, 'val_size': 0.15, 'early_stopping_patience': 20}\n",
      " 10%|█         | 3/30 [00:16<02:14,  4.98s/trial, best loss: -0.9002557033840745]2025-01-31 22:23:17,704 - WARNING - CommonStructure.py - CategoryEmbeddingTrainer - You are passing some invalid parameters to the model {'batch_size': 1376, 'optimizer_fn': {'Adam_learning_rate': 0.0008849422181265142, 'Adam_weight_decay': 4.811133293049958e-08, 'optimizer_fn': <class 'torch.optim.adam.Adam'>}, 'scheduler_fn': {'ReduceLROnPlateau_factor': 0.07857720058107419, 'ReduceLROnPlateau_patience': 9, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>}}\n",
      "2025-01-31 22:23:17,705 - DEBUG - CommonStructure.py - CategoryEmbeddingTrainer - compatible parameters: {'activation': 'LeakyReLU', 'dropout': 0.19449045900525083, 'embedding_dropout': 0.08720530524828946, 'initialization': 'kaiming', 'layers': '128-64-32', 'use_batch_norm': False}\n",
      "DataConfig(target=['target'], continuous_cols=['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week'], categorical_cols=['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country'], date_columns=[], encode_date_columns=True, validation_split=0.2, continuous_feature_transform=None, normalize_continuous_features=True, quantile_noise=0, num_workers=4, pin_memory=True, handle_unknown_categories=True, handle_missing_values=True, dataloader_kwargs={})\n",
      "CategoryEmbeddingModelConfig(task='classification', head='LinearHead', head_config={'layers': ''}, embedding_dims=None, embedding_dropout=0.0, batch_norm_continuous_input=True, learning_rate=0.0008849422181265142, loss='CrossEntropyLoss', metrics=['accuracy'], metrics_prob_input=[False], metrics_params=[{}], target_range=None, virtual_batch_size=None, seed=42, _module_src='models.category_embedding', _model_name='CategoryEmbeddingModel', _backbone_name='CategoryEmbeddingBackbone', _config_name='CategoryEmbeddingModelConfig', layers='128-64-32', activation='LeakyReLU', use_batch_norm=False, initialization='kaiming', dropout=0.0)\n",
      "OptimizerConfig(optimizer='Adam', optimizer_params={'weight_decay': 4.811133293049958e-08}, lr_scheduler='ReduceLROnPlateau', lr_scheduler_params={'factor': 0.07857720058107419, 'patience': 9, 'min_lr': 1e-08, 'verbose': True, 'mode': 'min'}, lr_scheduler_monitor_metric='valid_loss')\n",
      "TrainerConfig(batch_size=1376, data_aware_init_batch_size=2000, fast_dev_run=False, max_epochs=3, min_epochs=1, max_time=None, accelerator='auto', devices=-1, devices_list=None, accumulate_grad_batches=1, auto_lr_find=False, auto_select_gpus=True, check_val_every_n_epoch=1, gradient_clip_val=0.0, overfit_batches=0.0, deterministic=False, profiler=None, early_stopping='valid_loss', early_stopping_min_delta=0.0, early_stopping_mode='min', early_stopping_patience=20, early_stopping_kwargs={}, checkpoints='valid_loss', checkpoints_path='ptabular_checkpoints', checkpoints_every_n_epochs=10, checkpoints_name=None, checkpoints_mode='min', checkpoints_save_top_k=1, checkpoints_kwargs={}, load_best=True, track_grad_norm=-1, progress_bar='rich', precision=32, seed=42, trainer_kwargs={})\n",
      " 10%|█         | 3/30 [00:16<02:14,  4.98s/trial, best loss: -0.9002557033840745]"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:17</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">748</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">146</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:17\u001b[0m,\u001b[1;36m748\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m146\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:17</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">782</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:17\u001b[0m,\u001b[1;36m782\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:17</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">816</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:17\u001b[0m,\u001b[1;36m816\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:17</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">908</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: CategoryEmbeddingModel \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:17\u001b[0m,\u001b[1;36m908\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: CategoryEmbeddingModel \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:17</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">969</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:17\u001b[0m,\u001b[1;36m969\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:17</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">979</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:17\u001b[0m,\u001b[1;36m979\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                      </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ custom_loss      │ CrossEntropyLoss          │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _backbone        │ CategoryEmbeddingBackbone │ 18.5 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _embedding_layer │ Embedding1dLayer          │  1.4 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ head             │ LinearHead                │     66 │ train │\n",
       "└───┴──────────────────┴───────────────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType                     \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ custom_loss      │ CrossEntropyLoss          │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ CategoryEmbeddingBackbone │ 18.5 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer          │  1.4 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ head             │ LinearHead                │     66 │ train │\n",
       "└───┴──────────────────┴───────────────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 20.0 K                                                                                           \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 20.0 K                                                                                               \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 24                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 20.0 K                                                                                           \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 20.0 K                                                                                               \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 24                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "909df42095cb4622918f7efe666dfbcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:21</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">063</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:21\u001b[0m,\u001b[1;36m063\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:21</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">066</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:21\u001b[0m,\u001b[1;36m066\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:21</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">069</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1537</span><span style=\"font-weight: bold\">}</span> - WARNING - No best model available to load. Did you\n",
       "run it more than <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> epoch?<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                                                                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:21\u001b[0m,\u001b[1;36m069\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1537\u001b[0m\u001b[1m}\u001b[0m - WARNING - No best model available to load. Did you\n",
       "run it more than \u001b[1;36m1\u001b[0m epoch?\u001b[33m...\u001b[0m                                                                                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       target_0_probability  target_1_probability  target_prediction             \n",
      "20196              0.956145              0.043855                  0\n",
      "2308               0.227295              0.772705                  1\n",
      "9498               0.147335              0.852665                  1\n",
      "18596              0.085019              0.914981                  1\n",
      "20834              0.881270              0.118730                  0\n",
      "...                     ...                   ...                ...\n",
      "19265              0.916400              0.083600                  0\n",
      "7304               0.001081              0.998919                  1\n",
      "9758               0.878240              0.121760                  0\n",
      "8840               0.765525              0.234475                  0\n",
      "5028               0.950026              0.049974                  0\n",
      "\n",
      "[3663 rows x 3 columns]\n",
      " 10%|█         | 3/30 [00:20<02:14,  4.98s/trial, best loss: -0.9002557033840745]2025-01-31 22:23:21,428 - INFO - CommonStructure.py - CategoryEmbeddingTrainer - Validation metrics: {'accuracy': 0.7917007917007917, 'roc_auc': 0.8868027373960491}\n",
      " 13%|█▎        | 4/30 [00:20<01:57,  4.50s/trial, best loss: -0.9002557033840745]2025-01-31 22:23:21,442 - INFO - CommonStructure.py - CategoryEmbeddingTrainer - Training with hyperparameters: {'activation': 'ReLU', 'batch_size': 896, 'dropout': 0.2568355716453861, 'embedding_dropout': 0.060781227263718644, 'initialization': 'random', 'layers': '64-32', 'optimizer_fn': {'Adam_learning_rate': 0.000800430239720055, 'Adam_weight_decay': 5.536458544160756e-08, 'optimizer_fn': <class 'torch.optim.adam.Adam'>}, 'scheduler_fn': {'ReduceLROnPlateau_factor': 0.01583769328811092, 'ReduceLROnPlateau_patience': 7, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>}, 'use_batch_norm': True}\n",
      "tabular model params                                                             \n",
      "{'activation': 'ReLU', 'batch_size': 896, 'dropout': 0.2568355716453861, 'embedding_dropout': 0.060781227263718644, 'initialization': 'random', 'layers': '64-32', 'optimizer_fn': {'Adam_learning_rate': 0.000800430239720055, 'Adam_weight_decay': 5.536458544160756e-08, 'optimizer_fn': <class 'torch.optim.adam.Adam'>}, 'scheduler_fn': {'ReduceLROnPlateau_factor': 0.01583769328811092, 'ReduceLROnPlateau_patience': 7, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>}, 'use_batch_norm': True}\n",
      "tabular model outer params                                                       \n",
      "{'early_stopping_rounds': 10, 'verbose': False, 'iterations': 20, 'retrain': False, 'auto_lr_find': False, 'max_epochs': 3, 'val_size': 0.15, 'early_stopping_patience': 20}\n",
      " 13%|█▎        | 4/30 [00:20<01:57,  4.50s/trial, best loss: -0.9002557033840745]2025-01-31 22:23:21,459 - WARNING - CommonStructure.py - CategoryEmbeddingTrainer - You are passing some invalid parameters to the model {'batch_size': 896, 'optimizer_fn': {'Adam_learning_rate': 0.000800430239720055, 'Adam_weight_decay': 5.536458544160756e-08, 'optimizer_fn': <class 'torch.optim.adam.Adam'>}, 'scheduler_fn': {'ReduceLROnPlateau_factor': 0.01583769328811092, 'ReduceLROnPlateau_patience': 7, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>}}\n",
      "2025-01-31 22:23:21,461 - DEBUG - CommonStructure.py - CategoryEmbeddingTrainer - compatible parameters: {'activation': 'ReLU', 'dropout': 0.2568355716453861, 'embedding_dropout': 0.060781227263718644, 'initialization': 'random', 'layers': '64-32', 'use_batch_norm': True}\n",
      "DataConfig(target=['target'], continuous_cols=['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week'], categorical_cols=['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country'], date_columns=[], encode_date_columns=True, validation_split=0.2, continuous_feature_transform=None, normalize_continuous_features=True, quantile_noise=0, num_workers=4, pin_memory=True, handle_unknown_categories=True, handle_missing_values=True, dataloader_kwargs={})\n",
      "CategoryEmbeddingModelConfig(task='classification', head='LinearHead', head_config={'layers': ''}, embedding_dims=None, embedding_dropout=0.0, batch_norm_continuous_input=True, learning_rate=0.000800430239720055, loss='CrossEntropyLoss', metrics=['accuracy'], metrics_prob_input=[False], metrics_params=[{}], target_range=None, virtual_batch_size=None, seed=42, _module_src='models.category_embedding', _model_name='CategoryEmbeddingModel', _backbone_name='CategoryEmbeddingBackbone', _config_name='CategoryEmbeddingModelConfig', layers='64-32', activation='ReLU', use_batch_norm=False, initialization='kaiming', dropout=0.0)\n",
      "OptimizerConfig(optimizer='Adam', optimizer_params={'weight_decay': 5.536458544160756e-08}, lr_scheduler='ReduceLROnPlateau', lr_scheduler_params={'factor': 0.01583769328811092, 'patience': 7, 'min_lr': 1e-08, 'verbose': True, 'mode': 'min'}, lr_scheduler_monitor_metric='valid_loss')\n",
      "TrainerConfig(batch_size=896, data_aware_init_batch_size=2000, fast_dev_run=False, max_epochs=3, min_epochs=1, max_time=None, accelerator='auto', devices=-1, devices_list=None, accumulate_grad_batches=1, auto_lr_find=False, auto_select_gpus=True, check_val_every_n_epoch=1, gradient_clip_val=0.0, overfit_batches=0.0, deterministic=False, profiler=None, early_stopping='valid_loss', early_stopping_min_delta=0.0, early_stopping_mode='min', early_stopping_patience=20, early_stopping_kwargs={}, checkpoints='valid_loss', checkpoints_path='ptabular_checkpoints', checkpoints_every_n_epochs=10, checkpoints_name=None, checkpoints_mode='min', checkpoints_save_top_k=1, checkpoints_kwargs={}, load_best=True, track_grad_norm=-1, progress_bar='rich', precision=32, seed=42, trainer_kwargs={})\n",
      " 13%|█▎        | 4/30 [00:20<01:57,  4.50s/trial, best loss: -0.9002557033840745]"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:21</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">502</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">146</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:21\u001b[0m,\u001b[1;36m502\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m146\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:21</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">527</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:21\u001b[0m,\u001b[1;36m527\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:21</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">551</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:21\u001b[0m,\u001b[1;36m551\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:21</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">654</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: CategoryEmbeddingModel \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:21\u001b[0m,\u001b[1;36m654\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: CategoryEmbeddingModel \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:21</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">714</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:21\u001b[0m,\u001b[1;36m714\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:21</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">725</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:21\u001b[0m,\u001b[1;36m725\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                      </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ custom_loss      │ CrossEntropyLoss          │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _backbone        │ CategoryEmbeddingBackbone │  6.2 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _embedding_layer │ Embedding1dLayer          │  1.4 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ head             │ LinearHead                │     66 │ train │\n",
       "└───┴──────────────────┴───────────────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType                     \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ custom_loss      │ CrossEntropyLoss          │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ CategoryEmbeddingBackbone │  6.2 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer          │  1.4 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ head             │ LinearHead                │     66 │ train │\n",
       "└───┴──────────────────┴───────────────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 7.6 K                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 7.6 K                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 22                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 7.6 K                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 7.6 K                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 22                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aac7025c5b3b4c05a7e6e553af409ded",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:25</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">207</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:25\u001b[0m,\u001b[1;36m207\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:25</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">209</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:25\u001b[0m,\u001b[1;36m209\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:25</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">210</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1537</span><span style=\"font-weight: bold\">}</span> - WARNING - No best model available to load. Did you\n",
       "run it more than <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> epoch?<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                                                                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:25\u001b[0m,\u001b[1;36m210\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1537\u001b[0m\u001b[1m}\u001b[0m - WARNING - No best model available to load. Did you\n",
       "run it more than \u001b[1;36m1\u001b[0m epoch?\u001b[33m...\u001b[0m                                                                                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       target_0_probability  target_1_probability  target_prediction             \n",
      "20196              0.878550              0.121450                  0\n",
      "2308               0.272667              0.727333                  1\n",
      "9498               0.067404              0.932596                  1\n",
      "18596              0.163548              0.836452                  1\n",
      "20834              0.831468              0.168532                  0\n",
      "...                     ...                   ...                ...\n",
      "19265              0.766457              0.233543                  0\n",
      "7304               0.195448              0.804552                  1\n",
      "9758               0.944683              0.055317                  0\n",
      "8840               0.455661              0.544339                  1\n",
      "5028               0.825658              0.174342                  0\n",
      "\n",
      "[3663 rows x 3 columns]\n",
      " 13%|█▎        | 4/30 [00:24<01:57,  4.50s/trial, best loss: -0.9002557033840745]2025-01-31 22:23:25,549 - INFO - CommonStructure.py - CategoryEmbeddingTrainer - Validation metrics: {'accuracy': 0.7693147693147693, 'roc_auc': 0.8720737006297187}\n",
      " 17%|█▋        | 5/30 [00:24<01:49,  4.36s/trial, best loss: -0.9002557033840745]2025-01-31 22:23:25,564 - INFO - CommonStructure.py - CategoryEmbeddingTrainer - Training with hyperparameters: {'activation': 'LeakyReLU', 'batch_size': 1600, 'dropout': 0.0015429726747798634, 'embedding_dropout': 0.1911440580637278, 'initialization': 'random', 'layers': '64-32', 'optimizer_fn': {'Adam_learning_rate': 0.00020861115381042228, 'Adam_weight_decay': 3.63319882484052e-08, 'optimizer_fn': <class 'torch.optim.adam.Adam'>}, 'scheduler_fn': {'ExponentialLR_gamma': 0.962575850058027, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>}, 'use_batch_norm': False}\n",
      "tabular model params                                                             \n",
      "{'activation': 'LeakyReLU', 'batch_size': 1600, 'dropout': 0.0015429726747798634, 'embedding_dropout': 0.1911440580637278, 'initialization': 'random', 'layers': '64-32', 'optimizer_fn': {'Adam_learning_rate': 0.00020861115381042228, 'Adam_weight_decay': 3.63319882484052e-08, 'optimizer_fn': <class 'torch.optim.adam.Adam'>}, 'scheduler_fn': {'ExponentialLR_gamma': 0.962575850058027, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>}, 'use_batch_norm': False}\n",
      "tabular model outer params                                                       \n",
      "{'early_stopping_rounds': 10, 'verbose': False, 'iterations': 20, 'retrain': False, 'auto_lr_find': False, 'max_epochs': 3, 'val_size': 0.15, 'early_stopping_patience': 20}\n",
      " 17%|█▋        | 5/30 [00:24<01:49,  4.36s/trial, best loss: -0.9002557033840745]2025-01-31 22:23:25,579 - WARNING - CommonStructure.py - CategoryEmbeddingTrainer - You are passing some invalid parameters to the model {'batch_size': 1600, 'optimizer_fn': {'Adam_learning_rate': 0.00020861115381042228, 'Adam_weight_decay': 3.63319882484052e-08, 'optimizer_fn': <class 'torch.optim.adam.Adam'>}, 'scheduler_fn': {'ExponentialLR_gamma': 0.962575850058027, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>}}\n",
      "2025-01-31 22:23:25,580 - DEBUG - CommonStructure.py - CategoryEmbeddingTrainer - compatible parameters: {'activation': 'LeakyReLU', 'dropout': 0.0015429726747798634, 'embedding_dropout': 0.1911440580637278, 'initialization': 'random', 'layers': '64-32', 'use_batch_norm': False}\n",
      "DataConfig(target=['target'], continuous_cols=['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week'], categorical_cols=['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country'], date_columns=[], encode_date_columns=True, validation_split=0.2, continuous_feature_transform=None, normalize_continuous_features=True, quantile_noise=0, num_workers=4, pin_memory=True, handle_unknown_categories=True, handle_missing_values=True, dataloader_kwargs={})\n",
      "CategoryEmbeddingModelConfig(task='classification', head='LinearHead', head_config={'layers': ''}, embedding_dims=None, embedding_dropout=0.0, batch_norm_continuous_input=True, learning_rate=0.00020861115381042228, loss='CrossEntropyLoss', metrics=['accuracy'], metrics_prob_input=[False], metrics_params=[{}], target_range=None, virtual_batch_size=None, seed=42, _module_src='models.category_embedding', _model_name='CategoryEmbeddingModel', _backbone_name='CategoryEmbeddingBackbone', _config_name='CategoryEmbeddingModelConfig', layers='64-32', activation='LeakyReLU', use_batch_norm=False, initialization='kaiming', dropout=0.0)\n",
      "OptimizerConfig(optimizer='Adam', optimizer_params={'weight_decay': 3.63319882484052e-08}, lr_scheduler='ExponentialLR', lr_scheduler_params={'gamma': 0.962575850058027}, lr_scheduler_monitor_metric='valid_loss')\n",
      "TrainerConfig(batch_size=1600, data_aware_init_batch_size=2000, fast_dev_run=False, max_epochs=3, min_epochs=1, max_time=None, accelerator='auto', devices=-1, devices_list=None, accumulate_grad_batches=1, auto_lr_find=False, auto_select_gpus=True, check_val_every_n_epoch=1, gradient_clip_val=0.0, overfit_batches=0.0, deterministic=False, profiler=None, early_stopping='valid_loss', early_stopping_min_delta=0.0, early_stopping_mode='min', early_stopping_patience=20, early_stopping_kwargs={}, checkpoints='valid_loss', checkpoints_path='ptabular_checkpoints', checkpoints_every_n_epochs=10, checkpoints_name=None, checkpoints_mode='min', checkpoints_save_top_k=1, checkpoints_kwargs={}, load_best=True, track_grad_norm=-1, progress_bar='rich', precision=32, seed=42, trainer_kwargs={})\n",
      " 17%|█▋        | 5/30 [00:24<01:49,  4.36s/trial, best loss: -0.9002557033840745]"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:25</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">611</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">146</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:25\u001b[0m,\u001b[1;36m611\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m146\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:25</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">638</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:25\u001b[0m,\u001b[1;36m638\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:25</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">662</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:25\u001b[0m,\u001b[1;36m662\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:25</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">745</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: CategoryEmbeddingModel \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:25\u001b[0m,\u001b[1;36m745\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: CategoryEmbeddingModel \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:25</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">809</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:25\u001b[0m,\u001b[1;36m809\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:25</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">819</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:25\u001b[0m,\u001b[1;36m819\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                      </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ custom_loss      │ CrossEntropyLoss          │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _backbone        │ CategoryEmbeddingBackbone │  6.2 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _embedding_layer │ Embedding1dLayer          │  1.4 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ head             │ LinearHead                │     66 │ train │\n",
       "└───┴──────────────────┴───────────────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType                     \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ custom_loss      │ CrossEntropyLoss          │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ CategoryEmbeddingBackbone │  6.2 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer          │  1.4 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ head             │ LinearHead                │     66 │ train │\n",
       "└───┴──────────────────┴───────────────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 7.6 K                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 7.6 K                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 22                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 7.6 K                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 7.6 K                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 22                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e84b179102654f9685ce34be70be8a57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:28</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">836</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:28\u001b[0m,\u001b[1;36m836\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:28</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">839</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:28\u001b[0m,\u001b[1;36m839\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:28</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">842</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1537</span><span style=\"font-weight: bold\">}</span> - WARNING - No best model available to load. Did you\n",
       "run it more than <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> epoch?<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                                                                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:28\u001b[0m,\u001b[1;36m842\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1537\u001b[0m\u001b[1m}\u001b[0m - WARNING - No best model available to load. Did you\n",
       "run it more than \u001b[1;36m1\u001b[0m epoch?\u001b[33m...\u001b[0m                                                                                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       target_0_probability  target_1_probability  target_prediction             \n",
      "20196              0.715282              0.284718                  0\n",
      "2308               0.316620              0.683380                  1\n",
      "9498               0.105507              0.894493                  1\n",
      "18596              0.332328              0.667672                  1\n",
      "20834              0.718005              0.281995                  0\n",
      "...                     ...                   ...                ...\n",
      "19265              0.410872              0.589128                  1\n",
      "7304               0.988686              0.011314                  0\n",
      "9758               0.670418              0.329582                  0\n",
      "8840               0.453977              0.546023                  1\n",
      "5028               0.551626              0.448374                  0\n",
      "\n",
      "[3663 rows x 3 columns]\n",
      " 17%|█▋        | 5/30 [00:28<01:49,  4.36s/trial, best loss: -0.9002557033840745]2025-01-31 22:23:29,217 - INFO - CommonStructure.py - CategoryEmbeddingTrainer - Validation metrics: {'accuracy': 0.6276276276276276, 'roc_auc': 0.7119202949068876}\n",
      " 20%|██        | 6/30 [00:28<01:39,  4.13s/trial, best loss: -0.9002557033840745]2025-01-31 22:23:29,240 - INFO - CommonStructure.py - CategoryEmbeddingTrainer - Training with hyperparameters: {'activation': 'ReLU', 'batch_size': 1440, 'dropout': 0.15351841765985155, 'embedding_dropout': 0.0819003372541878, 'initialization': 'xavier', 'layers': '64-32', 'optimizer_fn': {'AdamW_learning_rate': 0.0001803778026919458, 'AdamW_weight_decay': 1.0328378977573959e-08, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>}, 'scheduler_fn': {'ReduceLROnPlateau_factor': 0.0733775521741829, 'ReduceLROnPlateau_patience': 9, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>}, 'use_batch_norm': True}\n",
      "tabular model params                                                             \n",
      "{'activation': 'ReLU', 'batch_size': 1440, 'dropout': 0.15351841765985155, 'embedding_dropout': 0.0819003372541878, 'initialization': 'xavier', 'layers': '64-32', 'optimizer_fn': {'AdamW_learning_rate': 0.0001803778026919458, 'AdamW_weight_decay': 1.0328378977573959e-08, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>}, 'scheduler_fn': {'ReduceLROnPlateau_factor': 0.0733775521741829, 'ReduceLROnPlateau_patience': 9, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>}, 'use_batch_norm': True}\n",
      "tabular model outer params                                                       \n",
      "{'early_stopping_rounds': 10, 'verbose': False, 'iterations': 20, 'retrain': False, 'auto_lr_find': False, 'max_epochs': 3, 'val_size': 0.15, 'early_stopping_patience': 20}\n",
      " 20%|██        | 6/30 [00:28<01:39,  4.13s/trial, best loss: -0.9002557033840745]2025-01-31 22:23:29,255 - WARNING - CommonStructure.py - CategoryEmbeddingTrainer - You are passing some invalid parameters to the model {'batch_size': 1440, 'optimizer_fn': {'AdamW_learning_rate': 0.0001803778026919458, 'AdamW_weight_decay': 1.0328378977573959e-08, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>}, 'scheduler_fn': {'ReduceLROnPlateau_factor': 0.0733775521741829, 'ReduceLROnPlateau_patience': 9, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>}}\n",
      "2025-01-31 22:23:29,257 - DEBUG - CommonStructure.py - CategoryEmbeddingTrainer - compatible parameters: {'activation': 'ReLU', 'dropout': 0.15351841765985155, 'embedding_dropout': 0.0819003372541878, 'initialization': 'xavier', 'layers': '64-32', 'use_batch_norm': True}\n",
      "DataConfig(target=['target'], continuous_cols=['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week'], categorical_cols=['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country'], date_columns=[], encode_date_columns=True, validation_split=0.2, continuous_feature_transform=None, normalize_continuous_features=True, quantile_noise=0, num_workers=4, pin_memory=True, handle_unknown_categories=True, handle_missing_values=True, dataloader_kwargs={})\n",
      "CategoryEmbeddingModelConfig(task='classification', head='LinearHead', head_config={'layers': ''}, embedding_dims=None, embedding_dropout=0.0, batch_norm_continuous_input=True, learning_rate=0.0001803778026919458, loss='CrossEntropyLoss', metrics=['accuracy'], metrics_prob_input=[False], metrics_params=[{}], target_range=None, virtual_batch_size=None, seed=42, _module_src='models.category_embedding', _model_name='CategoryEmbeddingModel', _backbone_name='CategoryEmbeddingBackbone', _config_name='CategoryEmbeddingModelConfig', layers='64-32', activation='ReLU', use_batch_norm=False, initialization='kaiming', dropout=0.0)\n",
      "OptimizerConfig(optimizer='AdamW', optimizer_params={'weight_decay': 1.0328378977573959e-08}, lr_scheduler='ReduceLROnPlateau', lr_scheduler_params={'factor': 0.0733775521741829, 'patience': 9, 'min_lr': 1e-08, 'verbose': True, 'mode': 'min'}, lr_scheduler_monitor_metric='valid_loss')\n",
      "TrainerConfig(batch_size=1440, data_aware_init_batch_size=2000, fast_dev_run=False, max_epochs=3, min_epochs=1, max_time=None, accelerator='auto', devices=-1, devices_list=None, accumulate_grad_batches=1, auto_lr_find=False, auto_select_gpus=True, check_val_every_n_epoch=1, gradient_clip_val=0.0, overfit_batches=0.0, deterministic=False, profiler=None, early_stopping='valid_loss', early_stopping_min_delta=0.0, early_stopping_mode='min', early_stopping_patience=20, early_stopping_kwargs={}, checkpoints='valid_loss', checkpoints_path='ptabular_checkpoints', checkpoints_every_n_epochs=10, checkpoints_name=None, checkpoints_mode='min', checkpoints_save_top_k=1, checkpoints_kwargs={}, load_best=True, track_grad_norm=-1, progress_bar='rich', precision=32, seed=42, trainer_kwargs={})\n",
      " 20%|██        | 6/30 [00:28<01:39,  4.13s/trial, best loss: -0.9002557033840745]"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:29</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">301</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">146</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:29\u001b[0m,\u001b[1;36m301\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m146\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:29</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">337</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:29\u001b[0m,\u001b[1;36m337\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:29</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">363</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:29\u001b[0m,\u001b[1;36m363\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:29</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">466</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: CategoryEmbeddingModel \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:29\u001b[0m,\u001b[1;36m466\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: CategoryEmbeddingModel \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:29</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">526</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:29\u001b[0m,\u001b[1;36m526\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:29</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">536</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:29\u001b[0m,\u001b[1;36m536\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                      </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ custom_loss      │ CrossEntropyLoss          │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _backbone        │ CategoryEmbeddingBackbone │  6.2 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _embedding_layer │ Embedding1dLayer          │  1.4 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ head             │ LinearHead                │     66 │ train │\n",
       "└───┴──────────────────┴───────────────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType                     \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ custom_loss      │ CrossEntropyLoss          │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ CategoryEmbeddingBackbone │  6.2 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer          │  1.4 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ head             │ LinearHead                │     66 │ train │\n",
       "└───┴──────────────────┴───────────────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 7.6 K                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 7.6 K                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 22                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 7.6 K                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 7.6 K                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 22                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faa86d67b0b847c6971fecb0273afb95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:32</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">559</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:32\u001b[0m,\u001b[1;36m559\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:32</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">561</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:32\u001b[0m,\u001b[1;36m561\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:32</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">564</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1537</span><span style=\"font-weight: bold\">}</span> - WARNING - No best model available to load. Did you\n",
       "run it more than <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> epoch?<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                                                                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:32\u001b[0m,\u001b[1;36m564\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1537\u001b[0m\u001b[1m}\u001b[0m - WARNING - No best model available to load. Did you\n",
       "run it more than \u001b[1;36m1\u001b[0m epoch?\u001b[33m...\u001b[0m                                                                                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       target_0_probability  target_1_probability  target_prediction             \n",
      "20196              0.713883              0.286117                  0\n",
      "2308               0.309217              0.690783                  1\n",
      "9498               0.105406              0.894594                  1\n",
      "18596              0.331431              0.668569                  1\n",
      "20834              0.709991              0.290009                  0\n",
      "...                     ...                   ...                ...\n",
      "19265              0.412482              0.587518                  1\n",
      "7304               0.988685              0.011315                  0\n",
      "9758               0.671450              0.328550                  0\n",
      "8840               0.439950              0.560050                  1\n",
      "5028               0.550160              0.449840                  0\n",
      "\n",
      "[3663 rows x 3 columns]\n",
      " 20%|██        | 6/30 [00:31<01:39,  4.13s/trial, best loss: -0.9002557033840745]2025-01-31 22:23:32,920 - INFO - CommonStructure.py - CategoryEmbeddingTrainer - Validation metrics: {'accuracy': 0.627900627900628, 'roc_auc': 0.7120470866040292}\n",
      " 23%|██▎       | 7/30 [00:31<01:31,  3.99s/trial, best loss: -0.9002557033840745]2025-01-31 22:23:32,939 - INFO - CommonStructure.py - CategoryEmbeddingTrainer - Training with hyperparameters: {'activation': 'ReLU', 'batch_size': 384, 'dropout': 0.09745841423897812, 'embedding_dropout': 0.15551217485480062, 'initialization': 'kaiming', 'layers': '32-16', 'optimizer_fn': {'AdamW_learning_rate': 0.0005469061967403905, 'AdamW_weight_decay': 1.041310762183949e-08, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>}, 'scheduler_fn': {'ExponentialLR_gamma': 0.9231586615378904, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>}, 'use_batch_norm': False}\n",
      "tabular model params                                                             \n",
      "{'activation': 'ReLU', 'batch_size': 384, 'dropout': 0.09745841423897812, 'embedding_dropout': 0.15551217485480062, 'initialization': 'kaiming', 'layers': '32-16', 'optimizer_fn': {'AdamW_learning_rate': 0.0005469061967403905, 'AdamW_weight_decay': 1.041310762183949e-08, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>}, 'scheduler_fn': {'ExponentialLR_gamma': 0.9231586615378904, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>}, 'use_batch_norm': False}\n",
      "tabular model outer params                                                       \n",
      "{'early_stopping_rounds': 10, 'verbose': False, 'iterations': 20, 'retrain': False, 'auto_lr_find': False, 'max_epochs': 3, 'val_size': 0.15, 'early_stopping_patience': 20}\n",
      " 23%|██▎       | 7/30 [00:31<01:31,  3.99s/trial, best loss: -0.9002557033840745]2025-01-31 22:23:32,954 - WARNING - CommonStructure.py - CategoryEmbeddingTrainer - You are passing some invalid parameters to the model {'batch_size': 384, 'optimizer_fn': {'AdamW_learning_rate': 0.0005469061967403905, 'AdamW_weight_decay': 1.041310762183949e-08, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>}, 'scheduler_fn': {'ExponentialLR_gamma': 0.9231586615378904, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>}}\n",
      "2025-01-31 22:23:32,955 - DEBUG - CommonStructure.py - CategoryEmbeddingTrainer - compatible parameters: {'activation': 'ReLU', 'dropout': 0.09745841423897812, 'embedding_dropout': 0.15551217485480062, 'initialization': 'kaiming', 'layers': '32-16', 'use_batch_norm': False}\n",
      "DataConfig(target=['target'], continuous_cols=['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week'], categorical_cols=['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country'], date_columns=[], encode_date_columns=True, validation_split=0.2, continuous_feature_transform=None, normalize_continuous_features=True, quantile_noise=0, num_workers=4, pin_memory=True, handle_unknown_categories=True, handle_missing_values=True, dataloader_kwargs={})\n",
      "CategoryEmbeddingModelConfig(task='classification', head='LinearHead', head_config={'layers': ''}, embedding_dims=None, embedding_dropout=0.0, batch_norm_continuous_input=True, learning_rate=0.0005469061967403905, loss='CrossEntropyLoss', metrics=['accuracy'], metrics_prob_input=[False], metrics_params=[{}], target_range=None, virtual_batch_size=None, seed=42, _module_src='models.category_embedding', _model_name='CategoryEmbeddingModel', _backbone_name='CategoryEmbeddingBackbone', _config_name='CategoryEmbeddingModelConfig', layers='32-16', activation='ReLU', use_batch_norm=False, initialization='kaiming', dropout=0.0)\n",
      "OptimizerConfig(optimizer='AdamW', optimizer_params={'weight_decay': 1.041310762183949e-08}, lr_scheduler='ExponentialLR', lr_scheduler_params={'gamma': 0.9231586615378904}, lr_scheduler_monitor_metric='valid_loss')\n",
      "TrainerConfig(batch_size=384, data_aware_init_batch_size=2000, fast_dev_run=False, max_epochs=3, min_epochs=1, max_time=None, accelerator='auto', devices=-1, devices_list=None, accumulate_grad_batches=1, auto_lr_find=False, auto_select_gpus=True, check_val_every_n_epoch=1, gradient_clip_val=0.0, overfit_batches=0.0, deterministic=False, profiler=None, early_stopping='valid_loss', early_stopping_min_delta=0.0, early_stopping_mode='min', early_stopping_patience=20, early_stopping_kwargs={}, checkpoints='valid_loss', checkpoints_path='ptabular_checkpoints', checkpoints_every_n_epochs=10, checkpoints_name=None, checkpoints_mode='min', checkpoints_save_top_k=1, checkpoints_kwargs={}, load_best=True, track_grad_norm=-1, progress_bar='rich', precision=32, seed=42, trainer_kwargs={})\n",
      " 23%|██▎       | 7/30 [00:31<01:31,  3.99s/trial, best loss: -0.9002557033840745]"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:32</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">986</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">146</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:32\u001b[0m,\u001b[1;36m986\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m146\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:33</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">010</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:33\u001b[0m,\u001b[1;36m010\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:33</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">033</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:33\u001b[0m,\u001b[1;36m033\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:33</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">116</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: CategoryEmbeddingModel \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:33\u001b[0m,\u001b[1;36m116\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: CategoryEmbeddingModel \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:33</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">192</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:33\u001b[0m,\u001b[1;36m192\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:33</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">204</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:33\u001b[0m,\u001b[1;36m204\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                      </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ custom_loss      │ CrossEntropyLoss          │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _backbone        │ CategoryEmbeddingBackbone │  2.6 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _embedding_layer │ Embedding1dLayer          │  1.4 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ head             │ LinearHead                │     34 │ train │\n",
       "└───┴──────────────────┴───────────────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType                     \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ custom_loss      │ CrossEntropyLoss          │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ CategoryEmbeddingBackbone │  2.6 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer          │  1.4 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ head             │ LinearHead                │     34 │ train │\n",
       "└───┴──────────────────┴───────────────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 4.0 K                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 4.0 K                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 22                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 4.0 K                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 4.0 K                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 22                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a89ba72e525a4c7b81cbbc77dc9ed661",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:38</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">425</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:38\u001b[0m,\u001b[1;36m425\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:38</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">427</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:38\u001b[0m,\u001b[1;36m427\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:38</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">429</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1537</span><span style=\"font-weight: bold\">}</span> - WARNING - No best model available to load. Did you\n",
       "run it more than <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> epoch?<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                                                                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:38\u001b[0m,\u001b[1;36m429\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1537\u001b[0m\u001b[1m}\u001b[0m - WARNING - No best model available to load. Did you\n",
       "run it more than \u001b[1;36m1\u001b[0m epoch?\u001b[33m...\u001b[0m                                                                                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       target_0_probability  target_1_probability  target_prediction             \n",
      "20196              0.879415              0.120585                  0\n",
      "2308               0.185702              0.814298                  1\n",
      "9498               0.225912              0.774088                  1\n",
      "18596              0.196736              0.803264                  1\n",
      "20834              0.707993              0.292007                  0\n",
      "...                     ...                   ...                ...\n",
      "19265              0.846783              0.153217                  0\n",
      "7304               0.030020              0.969980                  1\n",
      "9758               0.730483              0.269517                  0\n",
      "8840               0.876639              0.123361                  0\n",
      "5028               0.909838              0.090162                  0\n",
      "\n",
      "[3663 rows x 3 columns]\n",
      " 23%|██▎       | 7/30 [00:37<01:31,  3.99s/trial, best loss: -0.9002557033840745]2025-01-31 22:23:38,774 - INFO - CommonStructure.py - CategoryEmbeddingTrainer - Validation metrics: {'accuracy': 0.7996177996177997, 'roc_auc': 0.8843659722069338}\n",
      " 27%|██▋       | 8/30 [00:37<01:40,  4.58s/trial, best loss: -0.9002557033840745]2025-01-31 22:23:38,796 - INFO - CommonStructure.py - CategoryEmbeddingTrainer - Training with hyperparameters: {'activation': 'ReLU', 'batch_size': 704, 'dropout': 0.07782912561981693, 'embedding_dropout': 0.14925848382423976, 'initialization': 'xavier', 'layers': '32-16', 'optimizer_fn': {'SGD_learning_rate': 0.0005408786199714089, 'SGD_momentum': 0.5845497089434242, 'SGD_weight_decay': 6.836821511005707e-08, 'optimizer_fn': <class 'torch.optim.sgd.SGD'>}, 'scheduler_fn': {'ExponentialLR_gamma': 0.9117120425466142, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>}, 'use_batch_norm': False}\n",
      "tabular model params                                                             \n",
      "{'activation': 'ReLU', 'batch_size': 704, 'dropout': 0.07782912561981693, 'embedding_dropout': 0.14925848382423976, 'initialization': 'xavier', 'layers': '32-16', 'optimizer_fn': {'SGD_learning_rate': 0.0005408786199714089, 'SGD_momentum': 0.5845497089434242, 'SGD_weight_decay': 6.836821511005707e-08, 'optimizer_fn': <class 'torch.optim.sgd.SGD'>}, 'scheduler_fn': {'ExponentialLR_gamma': 0.9117120425466142, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>}, 'use_batch_norm': False}\n",
      "tabular model outer params                                                       \n",
      "{'early_stopping_rounds': 10, 'verbose': False, 'iterations': 20, 'retrain': False, 'auto_lr_find': False, 'max_epochs': 3, 'val_size': 0.15, 'early_stopping_patience': 20}\n",
      " 27%|██▋       | 8/30 [00:37<01:40,  4.58s/trial, best loss: -0.9002557033840745]2025-01-31 22:23:38,811 - WARNING - CommonStructure.py - CategoryEmbeddingTrainer - You are passing some invalid parameters to the model {'batch_size': 704, 'optimizer_fn': {'SGD_learning_rate': 0.0005408786199714089, 'SGD_momentum': 0.5845497089434242, 'SGD_weight_decay': 6.836821511005707e-08, 'optimizer_fn': <class 'torch.optim.sgd.SGD'>}, 'scheduler_fn': {'ExponentialLR_gamma': 0.9117120425466142, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>}}\n",
      "2025-01-31 22:23:38,812 - DEBUG - CommonStructure.py - CategoryEmbeddingTrainer - compatible parameters: {'activation': 'ReLU', 'dropout': 0.07782912561981693, 'embedding_dropout': 0.14925848382423976, 'initialization': 'xavier', 'layers': '32-16', 'use_batch_norm': False}\n",
      "DataConfig(target=['target'], continuous_cols=['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week'], categorical_cols=['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country'], date_columns=[], encode_date_columns=True, validation_split=0.2, continuous_feature_transform=None, normalize_continuous_features=True, quantile_noise=0, num_workers=4, pin_memory=True, handle_unknown_categories=True, handle_missing_values=True, dataloader_kwargs={})\n",
      "CategoryEmbeddingModelConfig(task='classification', head='LinearHead', head_config={'layers': ''}, embedding_dims=None, embedding_dropout=0.0, batch_norm_continuous_input=True, learning_rate=0.0005408786199714089, loss='CrossEntropyLoss', metrics=['accuracy'], metrics_prob_input=[False], metrics_params=[{}], target_range=None, virtual_batch_size=None, seed=42, _module_src='models.category_embedding', _model_name='CategoryEmbeddingModel', _backbone_name='CategoryEmbeddingBackbone', _config_name='CategoryEmbeddingModelConfig', layers='32-16', activation='ReLU', use_batch_norm=False, initialization='kaiming', dropout=0.0)\n",
      "OptimizerConfig(optimizer='SGD', optimizer_params={'weight_decay': 6.836821511005707e-08, 'momentum': 0.5845497089434242}, lr_scheduler='ExponentialLR', lr_scheduler_params={'gamma': 0.9117120425466142}, lr_scheduler_monitor_metric='valid_loss')\n",
      "TrainerConfig(batch_size=704, data_aware_init_batch_size=2000, fast_dev_run=False, max_epochs=3, min_epochs=1, max_time=None, accelerator='auto', devices=-1, devices_list=None, accumulate_grad_batches=1, auto_lr_find=False, auto_select_gpus=True, check_val_every_n_epoch=1, gradient_clip_val=0.0, overfit_batches=0.0, deterministic=False, profiler=None, early_stopping='valid_loss', early_stopping_min_delta=0.0, early_stopping_mode='min', early_stopping_patience=20, early_stopping_kwargs={}, checkpoints='valid_loss', checkpoints_path='ptabular_checkpoints', checkpoints_every_n_epochs=10, checkpoints_name=None, checkpoints_mode='min', checkpoints_save_top_k=1, checkpoints_kwargs={}, load_best=True, track_grad_norm=-1, progress_bar='rich', precision=32, seed=42, trainer_kwargs={})\n",
      " 27%|██▋       | 8/30 [00:37<01:40,  4.58s/trial, best loss: -0.9002557033840745]"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:38</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">855</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">146</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:38\u001b[0m,\u001b[1;36m855\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m146\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:38</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">879</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:38\u001b[0m,\u001b[1;36m879\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:38</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">903</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:38\u001b[0m,\u001b[1;36m903\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:38</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">991</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: CategoryEmbeddingModel \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:38\u001b[0m,\u001b[1;36m991\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: CategoryEmbeddingModel \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:39</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">065</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:39\u001b[0m,\u001b[1;36m065\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:39</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">078</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:39\u001b[0m,\u001b[1;36m078\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                      </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ custom_loss      │ CrossEntropyLoss          │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _backbone        │ CategoryEmbeddingBackbone │  2.6 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _embedding_layer │ Embedding1dLayer          │  1.4 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ head             │ LinearHead                │     34 │ train │\n",
       "└───┴──────────────────┴───────────────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType                     \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ custom_loss      │ CrossEntropyLoss          │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ CategoryEmbeddingBackbone │  2.6 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer          │  1.4 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ head             │ LinearHead                │     34 │ train │\n",
       "└───┴──────────────────┴───────────────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 4.0 K                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 4.0 K                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 22                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 4.0 K                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 4.0 K                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 22                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00b3d5c6ed054957904b5dca615256eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:42</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">798</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:42\u001b[0m,\u001b[1;36m798\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:42</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">801</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:42\u001b[0m,\u001b[1;36m801\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:42</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">803</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1537</span><span style=\"font-weight: bold\">}</span> - WARNING - No best model available to load. Did you\n",
       "run it more than <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> epoch?<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                                                                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:42\u001b[0m,\u001b[1;36m803\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1537\u001b[0m\u001b[1m}\u001b[0m - WARNING - No best model available to load. Did you\n",
       "run it more than \u001b[1;36m1\u001b[0m epoch?\u001b[33m...\u001b[0m                                                                                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       target_0_probability  target_1_probability  target_prediction             \n",
      "20196              0.585439              0.414561                  0\n",
      "2308               0.398910              0.601090                  1\n",
      "9498               0.403964              0.596036                  1\n",
      "18596              0.348823              0.651177                  1\n",
      "20834              0.482856              0.517144                  1\n",
      "...                     ...                   ...                ...\n",
      "19265              0.651852              0.348148                  0\n",
      "7304               0.217412              0.782588                  1\n",
      "9758               0.399370              0.600630                  1\n",
      "8840               0.819668              0.180332                  0\n",
      "5028               0.529399              0.470601                  0\n",
      "\n",
      "[3663 rows x 3 columns]\n",
      " 27%|██▋       | 8/30 [00:41<01:40,  4.58s/trial, best loss: -0.9002557033840745]2025-01-31 22:23:43,149 - INFO - CommonStructure.py - CategoryEmbeddingTrainer - Validation metrics: {'accuracy': 0.5986895986895987, 'roc_auc': 0.6748873347732957}\n",
      " 30%|███       | 9/30 [00:41<01:34,  4.52s/trial, best loss: -0.9002557033840745]2025-01-31 22:23:43,161 - INFO - CommonStructure.py - CategoryEmbeddingTrainer - Training with hyperparameters: {'activation': 'ReLU', 'batch_size': 1120, 'dropout': 0.24358438459384602, 'embedding_dropout': 0.18853925963147258, 'initialization': 'kaiming', 'layers': '256-128-64-32', 'optimizer_fn': {'AdamW_learning_rate': 0.0003535962053197063, 'AdamW_weight_decay': 6.81544125224619e-09, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>}, 'scheduler_fn': {'StepLR_gamma': 0.17241687013006984, 'StepLR_step_size': 18, 'scheduler_fn': <class 'torch.optim.lr_scheduler.StepLR'>}, 'use_batch_norm': True}\n",
      "tabular model params                                                             \n",
      "{'activation': 'ReLU', 'batch_size': 1120, 'dropout': 0.24358438459384602, 'embedding_dropout': 0.18853925963147258, 'initialization': 'kaiming', 'layers': '256-128-64-32', 'optimizer_fn': {'AdamW_learning_rate': 0.0003535962053197063, 'AdamW_weight_decay': 6.81544125224619e-09, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>}, 'scheduler_fn': {'StepLR_gamma': 0.17241687013006984, 'StepLR_step_size': 18, 'scheduler_fn': <class 'torch.optim.lr_scheduler.StepLR'>}, 'use_batch_norm': True}\n",
      "tabular model outer params                                                       \n",
      "{'early_stopping_rounds': 10, 'verbose': False, 'iterations': 20, 'retrain': False, 'auto_lr_find': False, 'max_epochs': 3, 'val_size': 0.15, 'early_stopping_patience': 20}\n",
      " 30%|███       | 9/30 [00:42<01:34,  4.52s/trial, best loss: -0.9002557033840745]2025-01-31 22:23:43,175 - WARNING - CommonStructure.py - CategoryEmbeddingTrainer - You are passing some invalid parameters to the model {'batch_size': 1120, 'optimizer_fn': {'AdamW_learning_rate': 0.0003535962053197063, 'AdamW_weight_decay': 6.81544125224619e-09, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>}, 'scheduler_fn': {'StepLR_gamma': 0.17241687013006984, 'StepLR_step_size': 18, 'scheduler_fn': <class 'torch.optim.lr_scheduler.StepLR'>}}\n",
      "2025-01-31 22:23:43,175 - DEBUG - CommonStructure.py - CategoryEmbeddingTrainer - compatible parameters: {'activation': 'ReLU', 'dropout': 0.24358438459384602, 'embedding_dropout': 0.18853925963147258, 'initialization': 'kaiming', 'layers': '256-128-64-32', 'use_batch_norm': True}\n",
      "DataConfig(target=['target'], continuous_cols=['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week'], categorical_cols=['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country'], date_columns=[], encode_date_columns=True, validation_split=0.2, continuous_feature_transform=None, normalize_continuous_features=True, quantile_noise=0, num_workers=4, pin_memory=True, handle_unknown_categories=True, handle_missing_values=True, dataloader_kwargs={})\n",
      "CategoryEmbeddingModelConfig(task='classification', head='LinearHead', head_config={'layers': ''}, embedding_dims=None, embedding_dropout=0.0, batch_norm_continuous_input=True, learning_rate=0.0003535962053197063, loss='CrossEntropyLoss', metrics=['accuracy'], metrics_prob_input=[False], metrics_params=[{}], target_range=None, virtual_batch_size=None, seed=42, _module_src='models.category_embedding', _model_name='CategoryEmbeddingModel', _backbone_name='CategoryEmbeddingBackbone', _config_name='CategoryEmbeddingModelConfig', layers='256-128-64-32', activation='ReLU', use_batch_norm=False, initialization='kaiming', dropout=0.0)\n",
      "OptimizerConfig(optimizer='AdamW', optimizer_params={'weight_decay': 6.81544125224619e-09}, lr_scheduler='StepLR', lr_scheduler_params={'step_size': 18, 'gamma': 0.17241687013006984}, lr_scheduler_monitor_metric='valid_loss')\n",
      "TrainerConfig(batch_size=1120, data_aware_init_batch_size=2000, fast_dev_run=False, max_epochs=3, min_epochs=1, max_time=None, accelerator='auto', devices=-1, devices_list=None, accumulate_grad_batches=1, auto_lr_find=False, auto_select_gpus=True, check_val_every_n_epoch=1, gradient_clip_val=0.0, overfit_batches=0.0, deterministic=False, profiler=None, early_stopping='valid_loss', early_stopping_min_delta=0.0, early_stopping_mode='min', early_stopping_patience=20, early_stopping_kwargs={}, checkpoints='valid_loss', checkpoints_path='ptabular_checkpoints', checkpoints_every_n_epochs=10, checkpoints_name=None, checkpoints_mode='min', checkpoints_save_top_k=1, checkpoints_kwargs={}, load_best=True, track_grad_norm=-1, progress_bar='rich', precision=32, seed=42, trainer_kwargs={})\n",
      " 30%|███       | 9/30 [00:42<01:34,  4.52s/trial, best loss: -0.9002557033840745]"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:43</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">203</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">146</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:43\u001b[0m,\u001b[1;36m203\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m146\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:43</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">226</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:43\u001b[0m,\u001b[1;36m226\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:43</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">251</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:43\u001b[0m,\u001b[1;36m251\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:43</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">335</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: CategoryEmbeddingModel \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:43\u001b[0m,\u001b[1;36m335\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: CategoryEmbeddingModel \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:43</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">409</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:43\u001b[0m,\u001b[1;36m409\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:43</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">424</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:43\u001b[0m,\u001b[1;36m424\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                      </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ custom_loss      │ CrossEntropyLoss          │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _backbone        │ CategoryEmbeddingBackbone │ 59.6 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _embedding_layer │ Embedding1dLayer          │  1.4 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ head             │ LinearHead                │     66 │ train │\n",
       "└───┴──────────────────┴───────────────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType                     \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ custom_loss      │ CrossEntropyLoss          │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ CategoryEmbeddingBackbone │ 59.6 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer          │  1.4 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ head             │ LinearHead                │     66 │ train │\n",
       "└───┴──────────────────┴───────────────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 61.1 K                                                                                           \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 61.1 K                                                                                               \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 26                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 61.1 K                                                                                           \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 61.1 K                                                                                               \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 26                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de3314ba7c694f748584964356b01566",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:46</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">785</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:46\u001b[0m,\u001b[1;36m785\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:46</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">787</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:46\u001b[0m,\u001b[1;36m787\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:46</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">789</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1537</span><span style=\"font-weight: bold\">}</span> - WARNING - No best model available to load. Did you\n",
       "run it more than <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> epoch?<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                                                                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:46\u001b[0m,\u001b[1;36m789\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1537\u001b[0m\u001b[1m}\u001b[0m - WARNING - No best model available to load. Did you\n",
       "run it more than \u001b[1;36m1\u001b[0m epoch?\u001b[33m...\u001b[0m                                                                                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       target_0_probability  target_1_probability  target_prediction             \n",
      "20196              0.946925              0.053075                  0\n",
      "2308               0.181023              0.818977                  1\n",
      "9498               0.295837              0.704163                  1\n",
      "18596              0.049692              0.950308                  1\n",
      "20834              0.607637              0.392363                  0\n",
      "...                     ...                   ...                ...\n",
      "19265              0.906030              0.093970                  0\n",
      "7304               0.000631              0.999369                  1\n",
      "9758               0.864885              0.135115                  0\n",
      "8840               0.648519              0.351481                  0\n",
      "5028               0.985086              0.014914                  0\n",
      "\n",
      "[3663 rows x 3 columns]\n",
      " 30%|███       | 9/30 [00:45<01:34,  4.52s/trial, best loss: -0.9002557033840745]2025-01-31 22:23:47,139 - INFO - CommonStructure.py - CategoryEmbeddingTrainer - Validation metrics: {'accuracy': 0.7892437892437892, 'roc_auc': 0.8956655177952758}\n",
      " 33%|███▎      | 10/30 [00:45<01:27,  4.35s/trial, best loss: -0.9002557033840745]2025-01-31 22:23:47,158 - INFO - CommonStructure.py - CategoryEmbeddingTrainer - Training with hyperparameters: {'activation': 'ReLU', 'batch_size': 352, 'dropout': 0.16786102200456918, 'embedding_dropout': 0.14155887219081373, 'initialization': 'kaiming', 'layers': '128-64-32', 'optimizer_fn': {'Adam_learning_rate': 0.0006464151635461003, 'Adam_weight_decay': 5.293222971422232e-08, 'optimizer_fn': <class 'torch.optim.adam.Adam'>}, 'scheduler_fn': {'ExponentialLR_gamma': 0.9577687295912758, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>}, 'use_batch_norm': False}\n",
      "tabular model params                                                              \n",
      "{'activation': 'ReLU', 'batch_size': 352, 'dropout': 0.16786102200456918, 'embedding_dropout': 0.14155887219081373, 'initialization': 'kaiming', 'layers': '128-64-32', 'optimizer_fn': {'Adam_learning_rate': 0.0006464151635461003, 'Adam_weight_decay': 5.293222971422232e-08, 'optimizer_fn': <class 'torch.optim.adam.Adam'>}, 'scheduler_fn': {'ExponentialLR_gamma': 0.9577687295912758, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>}, 'use_batch_norm': False}\n",
      "tabular model outer params                                                        \n",
      "{'early_stopping_rounds': 10, 'verbose': False, 'iterations': 20, 'retrain': False, 'auto_lr_find': False, 'max_epochs': 3, 'val_size': 0.15, 'early_stopping_patience': 20}\n",
      " 33%|███▎      | 10/30 [00:46<01:27,  4.35s/trial, best loss: -0.9002557033840745]2025-01-31 22:23:47,170 - WARNING - CommonStructure.py - CategoryEmbeddingTrainer - You are passing some invalid parameters to the model {'batch_size': 352, 'optimizer_fn': {'Adam_learning_rate': 0.0006464151635461003, 'Adam_weight_decay': 5.293222971422232e-08, 'optimizer_fn': <class 'torch.optim.adam.Adam'>}, 'scheduler_fn': {'ExponentialLR_gamma': 0.9577687295912758, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>}}\n",
      "2025-01-31 22:23:47,171 - DEBUG - CommonStructure.py - CategoryEmbeddingTrainer - compatible parameters: {'activation': 'ReLU', 'dropout': 0.16786102200456918, 'embedding_dropout': 0.14155887219081373, 'initialization': 'kaiming', 'layers': '128-64-32', 'use_batch_norm': False}\n",
      "DataConfig(target=['target'], continuous_cols=['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week'], categorical_cols=['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country'], date_columns=[], encode_date_columns=True, validation_split=0.2, continuous_feature_transform=None, normalize_continuous_features=True, quantile_noise=0, num_workers=4, pin_memory=True, handle_unknown_categories=True, handle_missing_values=True, dataloader_kwargs={})\n",
      "CategoryEmbeddingModelConfig(task='classification', head='LinearHead', head_config={'layers': ''}, embedding_dims=None, embedding_dropout=0.0, batch_norm_continuous_input=True, learning_rate=0.0006464151635461003, loss='CrossEntropyLoss', metrics=['accuracy'], metrics_prob_input=[False], metrics_params=[{}], target_range=None, virtual_batch_size=None, seed=42, _module_src='models.category_embedding', _model_name='CategoryEmbeddingModel', _backbone_name='CategoryEmbeddingBackbone', _config_name='CategoryEmbeddingModelConfig', layers='128-64-32', activation='ReLU', use_batch_norm=False, initialization='kaiming', dropout=0.0)\n",
      "OptimizerConfig(optimizer='Adam', optimizer_params={'weight_decay': 5.293222971422232e-08}, lr_scheduler='ExponentialLR', lr_scheduler_params={'gamma': 0.9577687295912758}, lr_scheduler_monitor_metric='valid_loss')\n",
      "TrainerConfig(batch_size=352, data_aware_init_batch_size=2000, fast_dev_run=False, max_epochs=3, min_epochs=1, max_time=None, accelerator='auto', devices=-1, devices_list=None, accumulate_grad_batches=1, auto_lr_find=False, auto_select_gpus=True, check_val_every_n_epoch=1, gradient_clip_val=0.0, overfit_batches=0.0, deterministic=False, profiler=None, early_stopping='valid_loss', early_stopping_min_delta=0.0, early_stopping_mode='min', early_stopping_patience=20, early_stopping_kwargs={}, checkpoints='valid_loss', checkpoints_path='ptabular_checkpoints', checkpoints_every_n_epochs=10, checkpoints_name=None, checkpoints_mode='min', checkpoints_save_top_k=1, checkpoints_kwargs={}, load_best=True, track_grad_norm=-1, progress_bar='rich', precision=32, seed=42, trainer_kwargs={})\n",
      " 33%|███▎      | 10/30 [00:46<01:27,  4.35s/trial, best loss: -0.9002557033840745]"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:47</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">208</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">146</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:47\u001b[0m,\u001b[1;36m208\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m146\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:47</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">232</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:47\u001b[0m,\u001b[1;36m232\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:47</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">255</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:47\u001b[0m,\u001b[1;36m255\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:47</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">339</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: CategoryEmbeddingModel \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:47\u001b[0m,\u001b[1;36m339\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: CategoryEmbeddingModel \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:47</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">402</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:47\u001b[0m,\u001b[1;36m402\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:47</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">413</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:47\u001b[0m,\u001b[1;36m413\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                      </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ custom_loss      │ CrossEntropyLoss          │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _backbone        │ CategoryEmbeddingBackbone │ 18.5 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _embedding_layer │ Embedding1dLayer          │  1.4 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ head             │ LinearHead                │     66 │ train │\n",
       "└───┴──────────────────┴───────────────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType                     \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ custom_loss      │ CrossEntropyLoss          │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ CategoryEmbeddingBackbone │ 18.5 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer          │  1.4 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ head             │ LinearHead                │     66 │ train │\n",
       "└───┴──────────────────┴───────────────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 20.0 K                                                                                           \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 20.0 K                                                                                               \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 24                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 20.0 K                                                                                           \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 20.0 K                                                                                               \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 24                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8655099979524857a2126e24ada1e525",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:53</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">084</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:53\u001b[0m,\u001b[1;36m084\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:53</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">086</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:53\u001b[0m,\u001b[1;36m086\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:53</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">088</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1537</span><span style=\"font-weight: bold\">}</span> - WARNING - No best model available to load. Did you\n",
       "run it more than <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> epoch?<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                                                                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:53\u001b[0m,\u001b[1;36m088\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1537\u001b[0m\u001b[1m}\u001b[0m - WARNING - No best model available to load. Did you\n",
       "run it more than \u001b[1;36m1\u001b[0m epoch?\u001b[33m...\u001b[0m                                                                                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: \n",
      "<function _releaseLock at 0x710ef88f7b50>\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/logging/__init__.py\", line 228, in _releaseLock\n",
      "\n",
      "def _releaseLock():\n",
      "KeyboardInterrupt\n",
      ": \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       target_0_probability  target_1_probability  target_prediction              \n",
      "20196              0.952633              0.047367                  0\n",
      "2308               0.163793              0.836207                  1\n",
      "9498               0.131859              0.868141                  1\n",
      "18596              0.077626              0.922374                  1\n",
      "20834              0.879808              0.120192                  0\n",
      "...                     ...                   ...                ...\n",
      "19265              0.940008              0.059992                  0\n",
      "7304               0.000015              0.999985                  1\n",
      "9758               0.928406              0.071594                  0\n",
      "8840               0.693711              0.306289                  0\n",
      "5028               0.950151              0.049849                  0\n",
      "\n",
      "[3663 rows x 3 columns]\n",
      " 33%|███▎      | 10/30 [00:52<01:27,  4.35s/trial, best loss: -0.9002557033840745]2025-01-31 22:23:53,433 - INFO - CommonStructure.py - CategoryEmbeddingTrainer - Validation metrics: {'accuracy': 0.7974337974337974, 'roc_auc': 0.899760359615499}\n",
      " 37%|███▋      | 11/30 [00:52<01:34,  4.95s/trial, best loss: -0.9002557033840745]2025-01-31 22:23:53,448 - INFO - CommonStructure.py - CategoryEmbeddingTrainer - Training with hyperparameters: {'activation': 'ReLU', 'batch_size': 288, 'dropout': 0.08347357139668735, 'embedding_dropout': 0.08812207440759195, 'initialization': 'kaiming', 'layers': '256-128-64-32', 'optimizer_fn': {'SGD_learning_rate': 5.287615484834775e-05, 'SGD_momentum': 0.043511661993051655, 'SGD_weight_decay': 3.5890011770822725e-08, 'optimizer_fn': <class 'torch.optim.sgd.SGD'>}, 'scheduler_fn': {'ExponentialLR_gamma': 0.9430484024184538, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>}, 'use_batch_norm': False}\n",
      "tabular model params                                                              \n",
      "{'activation': 'ReLU', 'batch_size': 288, 'dropout': 0.08347357139668735, 'embedding_dropout': 0.08812207440759195, 'initialization': 'kaiming', 'layers': '256-128-64-32', 'optimizer_fn': {'SGD_learning_rate': 5.287615484834775e-05, 'SGD_momentum': 0.043511661993051655, 'SGD_weight_decay': 3.5890011770822725e-08, 'optimizer_fn': <class 'torch.optim.sgd.SGD'>}, 'scheduler_fn': {'ExponentialLR_gamma': 0.9430484024184538, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>}, 'use_batch_norm': False}\n",
      "tabular model outer params                                                        \n",
      "{'early_stopping_rounds': 10, 'verbose': False, 'iterations': 20, 'retrain': False, 'auto_lr_find': False, 'max_epochs': 3, 'val_size': 0.15, 'early_stopping_patience': 20}\n",
      " 37%|███▋      | 11/30 [00:52<01:34,  4.95s/trial, best loss: -0.9002557033840745]2025-01-31 22:23:53,465 - WARNING - CommonStructure.py - CategoryEmbeddingTrainer - You are passing some invalid parameters to the model {'batch_size': 288, 'optimizer_fn': {'SGD_learning_rate': 5.287615484834775e-05, 'SGD_momentum': 0.043511661993051655, 'SGD_weight_decay': 3.5890011770822725e-08, 'optimizer_fn': <class 'torch.optim.sgd.SGD'>}, 'scheduler_fn': {'ExponentialLR_gamma': 0.9430484024184538, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>}}\n",
      "2025-01-31 22:23:53,466 - DEBUG - CommonStructure.py - CategoryEmbeddingTrainer - compatible parameters: {'activation': 'ReLU', 'dropout': 0.08347357139668735, 'embedding_dropout': 0.08812207440759195, 'initialization': 'kaiming', 'layers': '256-128-64-32', 'use_batch_norm': False}\n",
      "DataConfig(target=['target'], continuous_cols=['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week'], categorical_cols=['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country'], date_columns=[], encode_date_columns=True, validation_split=0.2, continuous_feature_transform=None, normalize_continuous_features=True, quantile_noise=0, num_workers=4, pin_memory=True, handle_unknown_categories=True, handle_missing_values=True, dataloader_kwargs={})\n",
      "CategoryEmbeddingModelConfig(task='classification', head='LinearHead', head_config={'layers': ''}, embedding_dims=None, embedding_dropout=0.0, batch_norm_continuous_input=True, learning_rate=5.287615484834775e-05, loss='CrossEntropyLoss', metrics=['accuracy'], metrics_prob_input=[False], metrics_params=[{}], target_range=None, virtual_batch_size=None, seed=42, _module_src='models.category_embedding', _model_name='CategoryEmbeddingModel', _backbone_name='CategoryEmbeddingBackbone', _config_name='CategoryEmbeddingModelConfig', layers='256-128-64-32', activation='ReLU', use_batch_norm=False, initialization='kaiming', dropout=0.0)\n",
      "OptimizerConfig(optimizer='SGD', optimizer_params={'weight_decay': 3.5890011770822725e-08, 'momentum': 0.043511661993051655}, lr_scheduler='ExponentialLR', lr_scheduler_params={'gamma': 0.9430484024184538}, lr_scheduler_monitor_metric='valid_loss')\n",
      "TrainerConfig(batch_size=288, data_aware_init_batch_size=2000, fast_dev_run=False, max_epochs=3, min_epochs=1, max_time=None, accelerator='auto', devices=-1, devices_list=None, accumulate_grad_batches=1, auto_lr_find=False, auto_select_gpus=True, check_val_every_n_epoch=1, gradient_clip_val=0.0, overfit_batches=0.0, deterministic=False, profiler=None, early_stopping='valid_loss', early_stopping_min_delta=0.0, early_stopping_mode='min', early_stopping_patience=20, early_stopping_kwargs={}, checkpoints='valid_loss', checkpoints_path='ptabular_checkpoints', checkpoints_every_n_epochs=10, checkpoints_name=None, checkpoints_mode='min', checkpoints_save_top_k=1, checkpoints_kwargs={}, load_best=True, track_grad_norm=-1, progress_bar='rich', precision=32, seed=42, trainer_kwargs={})\n",
      " 37%|███▋      | 11/30 [00:52<01:34,  4.95s/trial, best loss: -0.9002557033840745]"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:53</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">495</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">146</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:53\u001b[0m,\u001b[1;36m495\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m146\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:53</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">519</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:53\u001b[0m,\u001b[1;36m519\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:53</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">544</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:53\u001b[0m,\u001b[1;36m544\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:53</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">633</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: CategoryEmbeddingModel \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:53\u001b[0m,\u001b[1;36m633\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: CategoryEmbeddingModel \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:53</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">698</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:53\u001b[0m,\u001b[1;36m698\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:23:53</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">708</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:23:53\u001b[0m,\u001b[1;36m708\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                      </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ custom_loss      │ CrossEntropyLoss          │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _backbone        │ CategoryEmbeddingBackbone │ 59.6 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _embedding_layer │ Embedding1dLayer          │  1.4 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ head             │ LinearHead                │     66 │ train │\n",
       "└───┴──────────────────┴───────────────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType                     \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ custom_loss      │ CrossEntropyLoss          │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ CategoryEmbeddingBackbone │ 59.6 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer          │  1.4 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ head             │ LinearHead                │     66 │ train │\n",
       "└───┴──────────────────┴───────────────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 61.1 K                                                                                           \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 61.1 K                                                                                               \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 26                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 61.1 K                                                                                           \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 61.1 K                                                                                               \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 26                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "307b898c728245409713be88107569fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:24:00</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">074</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:24:00\u001b[0m,\u001b[1;36m074\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:24:00</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">076</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:24:00\u001b[0m,\u001b[1;36m076\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:24:00</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">078</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1537</span><span style=\"font-weight: bold\">}</span> - WARNING - No best model available to load. Did you\n",
       "run it more than <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> epoch?<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                                                                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:24:00\u001b[0m,\u001b[1;36m078\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1537\u001b[0m\u001b[1m}\u001b[0m - WARNING - No best model available to load. Did you\n",
       "run it more than \u001b[1;36m1\u001b[0m epoch?\u001b[33m...\u001b[0m                                                                                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       target_0_probability  target_1_probability  target_prediction              \n",
      "20196              0.562957              0.437044                  0\n",
      "2308               0.540962              0.459038                  0\n",
      "9498               0.734434              0.265566                  0\n",
      "18596              0.460238              0.539762                  1\n",
      "20834              0.036626              0.963374                  1\n",
      "...                     ...                   ...                ...\n",
      "19265              0.529957              0.470043                  0\n",
      "7304               0.069037              0.930963                  1\n",
      "9758               0.321318              0.678682                  1\n",
      "8840               0.259943              0.740057                  1\n",
      "5028               0.510195              0.489805                  0\n",
      "\n",
      "[3663 rows x 3 columns]\n",
      " 37%|███▋      | 11/30 [00:59<01:34,  4.95s/trial, best loss: -0.9002557033840745]2025-01-31 22:24:00,449 - INFO - CommonStructure.py - CategoryEmbeddingTrainer - Validation metrics: {'accuracy': 0.6153426153426154, 'roc_auc': 0.642902396485383}\n",
      " 40%|████      | 12/30 [00:59<01:40,  5.58s/trial, best loss: -0.9002557033840745]2025-01-31 22:24:00,463 - INFO - CommonStructure.py - CategoryEmbeddingTrainer - Training with hyperparameters: {'activation': 'LeakyReLU', 'batch_size': 192, 'dropout': 0.1607517596751419, 'embedding_dropout': 0.12656674474184235, 'initialization': 'xavier', 'layers': '128-64-32', 'optimizer_fn': {'Adam_learning_rate': 0.00038176103812938896, 'Adam_weight_decay': 3.5940908865104037e-09, 'optimizer_fn': <class 'torch.optim.adam.Adam'>}, 'scheduler_fn': {'StepLR_gamma': 0.13245496647897195, 'StepLR_step_size': 14, 'scheduler_fn': <class 'torch.optim.lr_scheduler.StepLR'>}, 'use_batch_norm': True}\n",
      "tabular model params                                                              \n",
      "{'activation': 'LeakyReLU', 'batch_size': 192, 'dropout': 0.1607517596751419, 'embedding_dropout': 0.12656674474184235, 'initialization': 'xavier', 'layers': '128-64-32', 'optimizer_fn': {'Adam_learning_rate': 0.00038176103812938896, 'Adam_weight_decay': 3.5940908865104037e-09, 'optimizer_fn': <class 'torch.optim.adam.Adam'>}, 'scheduler_fn': {'StepLR_gamma': 0.13245496647897195, 'StepLR_step_size': 14, 'scheduler_fn': <class 'torch.optim.lr_scheduler.StepLR'>}, 'use_batch_norm': True}\n",
      "tabular model outer params                                                        \n",
      "{'early_stopping_rounds': 10, 'verbose': False, 'iterations': 20, 'retrain': False, 'auto_lr_find': False, 'max_epochs': 3, 'val_size': 0.15, 'early_stopping_patience': 20}\n",
      " 40%|████      | 12/30 [00:59<01:40,  5.58s/trial, best loss: -0.9002557033840745]2025-01-31 22:24:00,475 - WARNING - CommonStructure.py - CategoryEmbeddingTrainer - You are passing some invalid parameters to the model {'batch_size': 192, 'optimizer_fn': {'Adam_learning_rate': 0.00038176103812938896, 'Adam_weight_decay': 3.5940908865104037e-09, 'optimizer_fn': <class 'torch.optim.adam.Adam'>}, 'scheduler_fn': {'StepLR_gamma': 0.13245496647897195, 'StepLR_step_size': 14, 'scheduler_fn': <class 'torch.optim.lr_scheduler.StepLR'>}}\n",
      "2025-01-31 22:24:00,476 - DEBUG - CommonStructure.py - CategoryEmbeddingTrainer - compatible parameters: {'activation': 'LeakyReLU', 'dropout': 0.1607517596751419, 'embedding_dropout': 0.12656674474184235, 'initialization': 'xavier', 'layers': '128-64-32', 'use_batch_norm': True}\n",
      "DataConfig(target=['target'], continuous_cols=['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week'], categorical_cols=['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country'], date_columns=[], encode_date_columns=True, validation_split=0.2, continuous_feature_transform=None, normalize_continuous_features=True, quantile_noise=0, num_workers=4, pin_memory=True, handle_unknown_categories=True, handle_missing_values=True, dataloader_kwargs={})\n",
      "CategoryEmbeddingModelConfig(task='classification', head='LinearHead', head_config={'layers': ''}, embedding_dims=None, embedding_dropout=0.0, batch_norm_continuous_input=True, learning_rate=0.00038176103812938896, loss='CrossEntropyLoss', metrics=['accuracy'], metrics_prob_input=[False], metrics_params=[{}], target_range=None, virtual_batch_size=None, seed=42, _module_src='models.category_embedding', _model_name='CategoryEmbeddingModel', _backbone_name='CategoryEmbeddingBackbone', _config_name='CategoryEmbeddingModelConfig', layers='128-64-32', activation='LeakyReLU', use_batch_norm=False, initialization='kaiming', dropout=0.0)\n",
      "OptimizerConfig(optimizer='Adam', optimizer_params={'weight_decay': 3.5940908865104037e-09}, lr_scheduler='StepLR', lr_scheduler_params={'step_size': 14, 'gamma': 0.13245496647897195}, lr_scheduler_monitor_metric='valid_loss')\n",
      "TrainerConfig(batch_size=192, data_aware_init_batch_size=2000, fast_dev_run=False, max_epochs=3, min_epochs=1, max_time=None, accelerator='auto', devices=-1, devices_list=None, accumulate_grad_batches=1, auto_lr_find=False, auto_select_gpus=True, check_val_every_n_epoch=1, gradient_clip_val=0.0, overfit_batches=0.0, deterministic=False, profiler=None, early_stopping='valid_loss', early_stopping_min_delta=0.0, early_stopping_mode='min', early_stopping_patience=20, early_stopping_kwargs={}, checkpoints='valid_loss', checkpoints_path='ptabular_checkpoints', checkpoints_every_n_epochs=10, checkpoints_name=None, checkpoints_mode='min', checkpoints_save_top_k=1, checkpoints_kwargs={}, load_best=True, track_grad_norm=-1, progress_bar='rich', precision=32, seed=42, trainer_kwargs={})\n",
      " 40%|████      | 12/30 [00:59<01:40,  5.58s/trial, best loss: -0.9002557033840745]"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:24:00</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">510</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">146</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:24:00\u001b[0m,\u001b[1;36m510\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m146\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:24:00</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">537</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:24:00\u001b[0m,\u001b[1;36m537\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:24:00</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">560</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:24:00\u001b[0m,\u001b[1;36m560\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:24:00</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">653</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: CategoryEmbeddingModel \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:24:00\u001b[0m,\u001b[1;36m653\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: CategoryEmbeddingModel \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:24:00</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">724</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:24:00\u001b[0m,\u001b[1;36m724\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">22:24:00</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">735</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m31\u001b[0m \u001b[1;92m22:24:00\u001b[0m,\u001b[1;36m735\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                      </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ custom_loss      │ CrossEntropyLoss          │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _backbone        │ CategoryEmbeddingBackbone │ 18.5 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _embedding_layer │ Embedding1dLayer          │  1.4 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ head             │ LinearHead                │     66 │ train │\n",
       "└───┴──────────────────┴───────────────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType                     \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ custom_loss      │ CrossEntropyLoss          │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ CategoryEmbeddingBackbone │ 18.5 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer          │  1.4 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ head             │ LinearHead                │     66 │ train │\n",
       "└───┴──────────────────┴───────────────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 20.0 K                                                                                           \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 20.0 K                                                                                               \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 24                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 20.0 K                                                                                           \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 20.0 K                                                                                               \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 24                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d8d32870ea64d02b1e9736625e56e86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define paths to configuration files and data\n",
    "DATA_FOLDER = r\"/home/boom/sdev/repos/AutoDeep/autodeep/examples/testautodata\"\n",
    "OUTPUT_FOLDER = r\"/home/boom/sdev/repos/AutoDeep/autodeep/examples/output\"\n",
    "\n",
    "DEFAULT_MODELS = [\n",
    "    \"categoryembedding\",\n",
    "    \"fttransformer\",\n",
    "    \"tabtransformer\",\n",
    "    \"gandalf\",\n",
    "]\n",
    "\n",
    "DATA_CONFIG = {\n",
    "    \"dataset1\": {\n",
    "        \"dataset_path\": f\"{DATA_FOLDER}/adult.csv\",\n",
    "        \"target_col\": \"target\",\n",
    "        \"problem_type\": \"binary_classification\",\n",
    "        \"test_size\": 0.25,\n",
    "        \"num_targets\": 1,\n",
    "        \"metric\": \"roc_auc\",\n",
    "        \"eval_metrics\": [\"accuracy\", \"roc_auc\", \"lift5\"],\n",
    "    },\n",
    "    \"dataset2\": {\n",
    "        \"dataset_path\": f\"{DATA_FOLDER}/adult_2.csv\",\n",
    "        \"target_col\": \"target\",\n",
    "        \"problem_type\": \"binary_classification\",\n",
    "        \"test_size\": 0.2,\n",
    "        \"num_targets\": 1,\n",
    "        \"metric\": \"roc_auc\",\n",
    "        \"eval_metrics\": [\"accuracy\", \"roc_auc\", \"lift1\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "# Initialize AutoRunner instance with the configuration\n",
    "runner = AutoRunner(\n",
    "    data_config=DATA_CONFIG,\n",
    "    output_folder=OUTPUT_FOLDER,\n",
    "    default_models=DEFAULT_MODELS,\n",
    "    random_state=42,\n",
    "    execution_mode=\"hyperopt\",  # You can change this to other modes like \"cv\" or \"new_mode\"\n",
    "    eval_metrics=[\"accuracy\", \"f1\", \"roc_auc\"],  # Evaluation metrics as needed\n",
    "    max_evals=30,\n",
    "    output_file_format=\"{dataset}_{model}_{timestamp}.yml\",\n",
    ")\n",
    "\n",
    "# Run the AutoML process\n",
    "runner.run()\n",
    "\n",
    "# Print results\n",
    "# Assuming results are saved correctly in the `runner.results` list (adapt as necessary)\n",
    "for result in runner.results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class GatedAdditiveTreeEnsembleConfig in module pytorch_tabular.models.gate.config:\n",
      "\n",
      "class GatedAdditiveTreeEnsembleConfig(pytorch_tabular.config.config.ModelConfig)\n",
      " |  GatedAdditiveTreeEnsembleConfig(task: str, head: Optional[str] = 'LinearHead', head_config: Optional[Dict] = <factory>, embedding_dims: Optional[List] = None, embedding_dropout: float = 0.0, batch_norm_continuous_input: bool = True, learning_rate: float = 0.001, loss: Optional[str] = None, metrics: Optional[List[str]] = None, metrics_prob_input: Optional[List[bool]] = None, metrics_params: Optional[List] = None, target_range: Optional[List] = None, virtual_batch_size: Optional[int] = None, seed: int = 42, _module_src: str = 'models.gate', _model_name: str = 'GatedAdditiveTreeEnsembleModel', _backbone_name: str = 'GatedAdditiveTreesBackbone', _config_name: str = 'GatedAdditiveTreeEnsembleConfig', gflu_stages: int = 6, gflu_dropout: float = 0.0, tree_depth: int = 4, num_trees: int = 10, binning_activation: str = 'sparsemoid', feature_mask_function: str = 't-softmax', gflu_feature_init_sparsity: float = 0.3, tree_feature_init_sparsity: float = 0.8, learnable_sparsity: bool = True, tree_dropout: float = 0.0, chain_trees: bool = True, tree_wise_attention: bool = True, tree_wise_attention_dropout: float = 0.0, share_head_weights: bool = True) -> None\n",
      " |  \n",
      " |  Gated Additive Tree Ensemble configuration.\n",
      " |  \n",
      " |  Args:\n",
      " |      gflu_stages (int): Number of layers in the feature abstraction layer. Defaults to 6\n",
      " |  \n",
      " |      gflu_dropout (float): Dropout rate for the feature abstraction layer. Defaults to 0.0\n",
      " |  \n",
      " |      tree_depth (int): Depth of the tree. Defaults to 5\n",
      " |  \n",
      " |      num_trees (int): Number of trees to use in the ensemble. Defaults to 20\n",
      " |  \n",
      " |      binning_activation (str): The binning function to use. Defaults to entmoid. Defaults to sparsemoid.\n",
      " |              Choices are: [`entmoid`,`sparsemoid`,`sigmoid`].\n",
      " |  \n",
      " |      feature_mask_function (str): The feature mask function to use. Defaults to sparsemax. Choices are:\n",
      " |              [`entmax`,`sparsemax`,`softmax`].\n",
      " |  \n",
      " |      tree_dropout (float): probability of dropout in tree binning transformation. Defaults to 0.0\n",
      " |  \n",
      " |      chain_trees (bool): If True, we will chain the trees together. Synonymous to boosting\n",
      " |          (chaining trees) or bagging (parallel trees). Defaults to True\n",
      " |  \n",
      " |      tree_wise_attention (bool): If True, we will use tree wise attention to combine trees. Defaults to\n",
      " |              True\n",
      " |  \n",
      " |      tree_wise_attention_dropout (float): probability of dropout in the tree wise attention layer.\n",
      " |              Defaults to 0.0\n",
      " |  \n",
      " |      share_head_weights (bool): If True, we will share the weights between the heads. Defaults to True\n",
      " |  \n",
      " |  \n",
      " |      task (str): Specify whether the problem is regression or classification. `backbone` is a task which\n",
      " |              considers the model as a backbone to generate features. Mostly used internally for SSL and related\n",
      " |              tasks. Choices are: [`regression`,`classification`,`backbone`].\n",
      " |  \n",
      " |      head (Optional[str]): The head to be used for the model. Should be one of the heads defined in\n",
      " |              `pytorch_tabular.models.common.heads`. Defaults to  LinearHead. Choices are:\n",
      " |              [`None`,`LinearHead`,`MixtureDensityHead`].\n",
      " |  \n",
      " |      head_config (Optional[Dict]): The config as a dict which defines the head. If left empty, will be\n",
      " |              initialized as default linear head.\n",
      " |  \n",
      " |      embedding_dims (Optional[List]): The dimensions of the embedding for each categorical column as a\n",
      " |              list of tuples (cardinality, embedding_dim). If left empty, will infer using the cardinality of\n",
      " |              the categorical column using the rule min(50, (x + 1) // 2)\n",
      " |  \n",
      " |      embedding_dropout (float): Dropout to be applied to the Categorical Embedding. Defaults to 0.0\n",
      " |  \n",
      " |      batch_norm_continuous_input (bool): If True, we will normalize the continuous layer by passing it\n",
      " |              through a BatchNorm layer.\n",
      " |  \n",
      " |      learning_rate (float): The learning rate of the model. Defaults to 1e-3.\n",
      " |  \n",
      " |      loss (Optional[str]): The loss function to be applied. By Default, it is MSELoss for regression and\n",
      " |              CrossEntropyLoss for classification. Unless you are sure what you are doing, leave it at MSELoss\n",
      " |              or L1Loss for regression and CrossEntropyLoss for classification\n",
      " |  \n",
      " |      metrics (Optional[List[str]]): the list of metrics you need to track during training. The metrics\n",
      " |              should be one of the functional metrics implemented in ``torchmetrics``. By default, it is\n",
      " |              accuracy if classification and mean_squared_error for regression\n",
      " |  \n",
      " |      metrics_params (Optional[List]): The parameters to be passed to the metrics function. `task` is forced to\n",
      " |              be `multiclass` because the multiclass version can handle binary as well and for simplicity we are\n",
      " |              only using `multiclass`.\n",
      " |  \n",
      " |      metrics_prob_input (Optional[List]): Is a mandatory parameter for classification metrics defined in the config.\n",
      " |          This defines whether the input to the metric function is the probability or the class. Length should be\n",
      " |          same as the number of metrics. Defaults to None.\n",
      " |  \n",
      " |      target_range (Optional[List]): The range in which we should limit the output variable. Currently\n",
      " |              ignored for multi-target regression. Typically used for Regression problems. If left empty, will\n",
      " |              not apply any restrictions\n",
      " |  \n",
      " |      seed (int): The seed for reproducibility. Defaults to 42\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      GatedAdditiveTreeEnsembleConfig\n",
      " |      pytorch_tabular.config.config.ModelConfig\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __eq__(self, other)\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __init__(self, task: str, head: Optional[str] = 'LinearHead', head_config: Optional[Dict] = <factory>, embedding_dims: Optional[List] = None, embedding_dropout: float = 0.0, batch_norm_continuous_input: bool = True, learning_rate: float = 0.001, loss: Optional[str] = None, metrics: Optional[List[str]] = None, metrics_prob_input: Optional[List[bool]] = None, metrics_params: Optional[List] = None, target_range: Optional[List] = None, virtual_batch_size: Optional[int] = None, seed: int = 42, _module_src: str = 'models.gate', _model_name: str = 'GatedAdditiveTreeEnsembleModel', _backbone_name: str = 'GatedAdditiveTreesBackbone', _config_name: str = 'GatedAdditiveTreeEnsembleConfig', gflu_stages: int = 6, gflu_dropout: float = 0.0, tree_depth: int = 4, num_trees: int = 10, binning_activation: str = 'sparsemoid', feature_mask_function: str = 't-softmax', gflu_feature_init_sparsity: float = 0.3, tree_feature_init_sparsity: float = 0.8, learnable_sparsity: bool = True, tree_dropout: float = 0.0, chain_trees: bool = True, tree_wise_attention: bool = True, tree_wise_attention_dropout: float = 0.0, share_head_weights: bool = True) -> None\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __post_init__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __annotations__ = {'_backbone_name': <class 'str'>, '_config_name': <c...\n",
      " |  \n",
      " |  __dataclass_fields__ = {'_backbone_name': Field(name='_backbone_name',...\n",
      " |  \n",
      " |  __dataclass_params__ = _DataclassParams(init=True,repr=True,eq=True,or...\n",
      " |  \n",
      " |  __hash__ = None\n",
      " |  \n",
      " |  __match_args__ = ('task', 'head', 'head_config', 'embedding_dims', 'em...\n",
      " |  \n",
      " |  binning_activation = 'sparsemoid'\n",
      " |  \n",
      " |  chain_trees = True\n",
      " |  \n",
      " |  feature_mask_function = 't-softmax'\n",
      " |  \n",
      " |  gflu_dropout = 0.0\n",
      " |  \n",
      " |  gflu_feature_init_sparsity = 0.3\n",
      " |  \n",
      " |  gflu_stages = 6\n",
      " |  \n",
      " |  learnable_sparsity = True\n",
      " |  \n",
      " |  num_trees = 10\n",
      " |  \n",
      " |  share_head_weights = True\n",
      " |  \n",
      " |  tree_depth = 4\n",
      " |  \n",
      " |  tree_dropout = 0.0\n",
      " |  \n",
      " |  tree_feature_init_sparsity = 0.8\n",
      " |  \n",
      " |  tree_wise_attention = True\n",
      " |  \n",
      " |  tree_wise_attention_dropout = 0.0\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pytorch_tabular.config.config.ModelConfig:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from pytorch_tabular.config.config.ModelConfig:\n",
      " |  \n",
      " |  batch_norm_continuous_input = True\n",
      " |  \n",
      " |  embedding_dims = None\n",
      " |  \n",
      " |  embedding_dropout = 0.0\n",
      " |  \n",
      " |  head = 'LinearHead'\n",
      " |  \n",
      " |  learning_rate = 0.001\n",
      " |  \n",
      " |  loss = None\n",
      " |  \n",
      " |  metrics = None\n",
      " |  \n",
      " |  metrics_params = None\n",
      " |  \n",
      " |  metrics_prob_input = None\n",
      " |  \n",
      " |  seed = 42\n",
      " |  \n",
      " |  target_range = None\n",
      " |  \n",
      " |  virtual_batch_size = None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "from pytorch_tabular.models import GatedAdditiveTreeEnsembleConfig\n",
    "\n",
    "help(GatedAdditiveTreeEnsembleConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dok1 = {\n",
    "    \"additional_tree_output_dim\": 3,\n",
    "    \"batch_norm_continuous_input\": True,\n",
    "    \"bin_function\": \"entmoid15\",\n",
    "    \"choice_function\": \"entmax15\",\n",
    "    \"depth\": 5,\n",
    "    \"embed_categorical\": True,\n",
    "    \"embedding_dropout\": 0.06089480159646259,\n",
    "    \"initialize_response\": \"normal\",\n",
    "    \"initialize_selection_logits\": \"normal\",\n",
    "    \"input_dropout\": 0.15466990749662266,\n",
    "    \"max_features\": 32,\n",
    "    \"num_layers\": 1,\n",
    "    \"num_trees\": 736,\n",
    "    \"threshold_init_beta\": 0.6724199121113691,\n",
    "    \"threshold_init_cutoff\": 0.6076965359243615,\n",
    "}\n",
    "dko2 = {\n",
    "    \"additional_tree_output_dim\": 3,\n",
    "    \"batch_norm_continuous_input\": False,\n",
    "    \"bin_function\": \"entmoid15\",\n",
    "    \"choice_function\": \"entmax15\",\n",
    "    \"depth\": 6,\n",
    "    \"embedding_dropout\": 0.05438018363383848,\n",
    "    \"initialize_response\": \"normal\",\n",
    "    \"initialize_selection_logits\": \"normal\",\n",
    "    \"input_dropout\": 0.17230551619837015,\n",
    "    \"max_features\": 21,\n",
    "    \"num_layers\": 1,\n",
    "    \"num_trees\": 626,\n",
    "    \"threshold_init_beta\": 0.9430824174145327,\n",
    "    \"threshold_init_cutoff\": 1.1093300211337618,\n",
    "}\n",
    "\n",
    "dko3 = {\n",
    "    \"additional_tree_output_dim\": 3,\n",
    "    \"batch_norm_continuous_input\": False,\n",
    "    \"bin_function\": \"sparsemoid\",\n",
    "    \"choice_function\": \"entmax15\",\n",
    "    \"depth\": 4,\n",
    "    \"embedding_dropout\": 0.05438018363383848,\n",
    "    \"initialize_response\": \"normal\",\n",
    "    \"initialize_selection_logits\": \"normal\",\n",
    "    \"input_dropout\": 0.17230551619837015,\n",
    "    \"max_features\": 21,\n",
    "    \"num_layers\": 1,\n",
    "    \"num_trees\": 626,\n",
    "    \"threshold_init_beta\": 0.826726207188516,\n",
    "    \"threshold_init_cutoff\": 0.9402437257075205,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddiff = {k: v for k, v in dko2.items() if dko2[k] != dok1[k]}\n",
    "ddiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddiff = {k: v for k, v in dko3.items() if dko3[k] != dok1[k]}\n",
    "ddiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Define the folder to format and lint\n",
    "folder_to_check = \"autodeep\"\n",
    "\n",
    "# Define output files\n",
    "output_files = {\n",
    "    \"isort\": \"isort_output.txt\",\n",
    "    \"black\": \"black_output.txt\",\n",
    "    \"pylint\": \"pylint_output.txt\",\n",
    "    \"flake8\": \"flake8_output.txt\",\n",
    "}\n",
    "\n",
    "# Ensure the output folder exists\n",
    "os.makedirs(\"linting_outputs\", exist_ok=True)\n",
    "\n",
    "# Run isort\n",
    "with open(os.path.join(\"linting_outputs\", output_files[\"isort\"]), \"w\") as f:\n",
    "    subprocess.run([\"isort\", folder_to_check], stdout=f, stderr=f)\n",
    "\n",
    "# Run black\n",
    "with open(os.path.join(\"linting_outputs\", output_files[\"black\"]), \"w\") as f:\n",
    "    subprocess.run([\"black\", folder_to_check], stdout=f, stderr=f)\n",
    "\n",
    "# Run pylint\n",
    "with open(os.path.join(\"linting_outputs\", output_files[\"pylint\"]), \"w\") as f:\n",
    "    subprocess.run([\"pylint\", folder_to_check], stdout=f, stderr=f)\n",
    "\n",
    "# Run flake8\n",
    "with open(os.path.join(\"linting_outputs\", output_files[\"flake8\"]), \"w\") as f:\n",
    "    subprocess.run([\"flake8\", folder_to_check], stdout=f, stderr=f)\n",
    "\n",
    "print(\n",
    "    \"Linting and formatting completed. Outputs are saved in the 'linting_outputs' folder.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install isort black pylint flake8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Define the path to the folder to format and lint (one level up from the current directory)\n",
    "folder_to_check = \"../../autodeep\"\n",
    "\n",
    "# Define the output folder and ensure it exists\n",
    "output_folder = \"linting_outputs\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Define the output files\n",
    "output_files = {\n",
    "    \"isort\": \"isort_output.txt\",\n",
    "    \"black\": \"black_output.txt\",\n",
    "    \"pylint\": \"pylint_output.txt\",\n",
    "    \"flake8\": \"flake8_output.txt\",\n",
    "}\n",
    "\n",
    "# Run isort\n",
    "isort_output_path = os.path.join(output_folder, output_files[\"isort\"])\n",
    "with open(isort_output_path, \"w\") as f:\n",
    "    subprocess.run([\"isort\", folder_to_check], stdout=f, stderr=f)\n",
    "\n",
    "# Run black\n",
    "black_output_path = os.path.join(output_folder, output_files[\"black\"])\n",
    "with open(black_output_path, \"w\") as f:\n",
    "    subprocess.run([\"black\", folder_to_check], stdout=f, stderr=f)\n",
    "\n",
    "# Run pylint\n",
    "pylint_output_path = os.path.join(output_folder, output_files[\"pylint\"])\n",
    "with open(pylint_output_path, \"w\") as f:\n",
    "    subprocess.run([\"pylint\", folder_to_check], stdout=f, stderr=f)\n",
    "\n",
    "# Run flake8\n",
    "flake8_output_path = os.path.join(output_folder, output_files[\"flake8\"])\n",
    "with open(flake8_output_path, \"w\") as f:\n",
    "    subprocess.run([\"flake8\", folder_to_check], stdout=f, stderr=f)\n",
    "\n",
    "print(\n",
    "    f\"Linting and formatting completed. Outputs are saved in the '{output_folder}' folder.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
