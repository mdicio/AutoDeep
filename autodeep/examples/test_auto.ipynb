{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test AutoML Functionality in a Separate Notebook\n",
    "from autodeep.automl import AutoRunner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = [\n",
    "    # \"XGB\",  # Extreme Gradient Boosting\n",
    "    # \"CatBoost\",\n",
    "    \"MLP\",  # Multi,Layer Perceptron\n",
    "    \"TabNet\",  # TabNet Classifier\n",
    "    \"GATE\",\n",
    "    # \"resnet\",\n",
    "    # \"S1DCNN\",\n",
    "    \"CategoryEmbedding\",\n",
    "    \"FTTransformer\",\n",
    "    \"TabTransformer\",\n",
    "    \"GANDALF\",\n",
    "    \"AutoInt\",\n",
    "    \"Node\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#tested with 100 hyperopt iterations did not break on adult dataset:\n",
    "\n",
    "\"autoint\",\n",
    "\"node\",\n",
    "\"mlp\",\n",
    "\"tabnet\",\n",
    "\"categoryembedding\",\n",
    "\"fttransformer\",\n",
    "\"tabtransformer\",\n",
    "\"gandalf\",\n",
    "\"mlp\"\n",
    "\n",
    "\n",
    "# very slow, had to decrease parameters for memory consumption also:\n",
    "\"gate\",\n",
    "\n",
    "# Not tested hyperopt search yet:\n",
    "\n",
    "#catboost\n",
    "#xgb\n",
    "#resnet\n",
    "#s1dcnn\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running resnet on binary...\n",
      "Using dynamic loader for dataset: /home/boom/sdev/repos/AutoDeep/autodeep/examples/testautodata/adult.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 19:46:37,608 - INFO - ResNetModel.py - Device cuda is available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IGTD result file path: IGTD/binary/Euclidean_Euclidean/abs/_index.txt\n",
      "img_rows: 9\n",
      "img_columns: 12\n",
      "{'data_params': {'normalize_features': 'mean_std', 'encode_categorical': True, 'return_extra_info': True}, 'default_params': {'early_stopping': True, 'verbose': False, 'iterations': 20, 'retrain': False, 'auto_lr_find': False, 'max_epochs': 300, 'val_size': 0.2, 'early_stopping_patience': 6}, 'param_grid': {'resnet_depth': ['resnet18', 'resnet34', 'resnet50'], 'batch_size': [1024, 512, 256], 'optimizer_fn': {'Adam': {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}, 'SGD': {'weight_decay': [0.0, 1e-07], 'momentum': [0.0, 0.9], 'learning_rate': [0.001, 1e-05]}, 'AdamW': {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.01], 'patience': [5, 10]}, 'StepLR': {'step_size': [10, 30], 'gamma': [0.1, 0.5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}\n",
      "resnet_depth ['resnet18', 'resnet34', 'resnet50']\n",
      "batch_size [1024, 512, 256]\n",
      "optimizer_fn {'Adam': {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}, 'SGD': {'weight_decay': [0.0, 1e-07], 'momentum': [0.0, 0.9], 'learning_rate': [0.001, 1e-05]}, 'AdamW': {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}}\n",
      "dict_keys(['Adam', 'SGD', 'AdamW'])\n",
      "Adam {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}\n",
      "weight_decay [0.0, 1e-07]\n",
      "learning_rate [0.001, 0.0001]\n",
      "SGD {'weight_decay': [0.0, 1e-07], 'momentum': [0.0, 0.9], 'learning_rate': [0.001, 1e-05]}\n",
      "weight_decay [0.0, 1e-07]\n",
      "momentum [0.0, 0.9]\n",
      "learning_rate [0.001, 1e-05]\n",
      "AdamW {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}\n",
      "weight_decay [0.0, 1e-07]\n",
      "learning_rate [0.001, 0.0001]\n",
      "scheduler_fn {'ReduceLROnPlateau': {'factor': [0.1, 0.01], 'patience': [5, 10]}, 'StepLR': {'step_size': [10, 30], 'gamma': [0.1, 0.5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}\n",
      "dict_keys(['ReduceLROnPlateau', 'StepLR', 'ExponentialLR'])\n",
      "ReduceLROnPlateau {'factor': [0.1, 0.01], 'patience': [5, 10]}\n",
      "factor [0.1, 0.01]\n",
      "patience [5, 10]\n",
      "StepLR {'step_size': [10, 30], 'gamma': [0.1, 0.5]}\n",
      "step_size [10, 30]\n",
      "gamma [0.1, 0.5]\n",
      "ExponentialLR {'gamma': [0.9, 0.99]}\n",
      "gamma [0.9, 0.99]\n",
      "  0%|          | 0/2 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 19:46:37,641 - INFO - ResNetModel.py - Training with hyperparameters: {'AdamW_learning_rate': 0.00041691320143948053, 'AdamW_weight_decay': 5.3327377727838295e-08, 'Adam_learning_rate': 0.000883609493567339, 'Adam_weight_decay': 5.3453713798712174e-08, 'ExponentialLR_gamma': 0.9700428647065971, 'ReduceLROnPlateau_factor': 0.014194472482598669, 'ReduceLROnPlateau_patience': 6, 'SGD_learning_rate': 5.540876168540814e-05, 'SGD_momentum': 0.7753748228926656, 'SGD_weight_decay': 1.1771360216800085e-08, 'StepLR_gamma': 0.1469911132467317, 'StepLR_step_size': 14, 'batch_size': 601, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>, 'resnet_depth': 'resnet34', 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22140, 108)                                         \n",
      "(22140,)                                             \n",
      "9                                                    \n",
      "12                                                   \n",
      "  0%|          | 0/2 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "\n",
      "Training:   0%|                                      | 0/300 [00:00<?, ?epoch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/300],Train Loss: 0.2529,Val Loss: 0.1947    \n",
      "  0%|          | 0/2 [00:03<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:240: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "Training:   0%|1                             | 1/300 [00:03<15:16,  3.06s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/300],Train Loss: 0.1929,Val Loss: 0.2028    \n",
      "  0%|          | 0/2 [00:06<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|2                             | 2/300 [00:06<15:14,  3.07s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/300],Train Loss: 0.1764,Val Loss: 0.1775    \n",
      "  0%|          | 0/2 [00:09<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|3                             | 3/300 [00:09<15:11,  3.07s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/300],Train Loss: 0.1670,Val Loss: 0.1734    \n",
      "  0%|          | 0/2 [00:12<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|4                             | 4/300 [00:12<15:07,  3.06s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/300],Train Loss: 0.1639,Val Loss: 0.1750    \n",
      "  0%|          | 0/2 [00:15<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|5                             | 5/300 [00:15<15:02,  3.06s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/300],Train Loss: 0.1580,Val Loss: 0.1696    \n",
      "  0%|          | 0/2 [00:18<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|6                             | 6/300 [00:18<15:02,  3.07s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/300],Train Loss: 0.1651,Val Loss: 0.1816    \n",
      "  0%|          | 0/2 [00:21<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|7                             | 7/300 [00:21<14:57,  3.06s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/300],Train Loss: 0.1582,Val Loss: 0.1707    \n",
      "  0%|          | 0/2 [00:24<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|8                             | 8/300 [00:24<14:52,  3.06s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/300],Train Loss: 0.1530,Val Loss: 0.1668    \n",
      "  0%|          | 0/2 [00:27<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|9                             | 9/300 [00:27<14:50,  3.06s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/300],Train Loss: 0.1475,Val Loss: 0.1715   \n",
      "  0%|          | 0/2 [00:31<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|9                            | 10/300 [00:30<14:52,  3.08s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/300],Train Loss: 0.1506,Val Loss: 0.1714   \n",
      "  0%|          | 0/2 [00:34<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|#                            | 11/300 [00:33<14:56,  3.10s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/300],Train Loss: 0.1499,Val Loss: 0.1720   \n",
      "  0%|          | 0/2 [00:37<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|#1                           | 12/300 [00:37<15:02,  3.13s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/300],Train Loss: 0.1432,Val Loss: 0.1740   \n",
      "  0%|          | 0/2 [00:40<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|#2                           | 13/300 [00:40<15:01,  3.14s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/300],Train Loss: 0.1443,Val Loss: 0.1760   \n",
      "  0%|          | 0/2 [00:43<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|#3                           | 14/300 [00:43<14:51,  3.12s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/300],Train Loss: 0.1421,Val Loss: 0.1709   \n",
      "Early stopping triggered at epoch 15                 \n",
      "  0%|          | 0/2 [00:46<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|#3                           | 14/300 [00:46<15:48,  3.32s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model loaded from epoch 9                       \n",
      "  0%|          | 0/2 [00:46<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 19:47:27,115 - INFO - ResNetModel.py - Validation metrics roc_auc: 0.8885877786363079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:49<00:49, 49.48s/trial, best loss: -0.8885877786363079]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 19:47:27,125 - INFO - ResNetModel.py - Training with hyperparameters: {'AdamW_learning_rate': 0.0005493747562277502, 'AdamW_weight_decay': 5.979030232767242e-08, 'Adam_learning_rate': 0.00010037826615600942, 'Adam_weight_decay': 2.309091722462173e-08, 'ExponentialLR_gamma': 0.9526834243165615, 'ReduceLROnPlateau_factor': 0.021158305135007868, 'ReduceLROnPlateau_patience': 7, 'SGD_learning_rate': 9.52118823872863e-05, 'SGD_momentum': 0.6960145837348019, 'SGD_weight_decay': 2.4860021513335803e-08, 'StepLR_gamma': 0.2095872419296196, 'StepLR_step_size': 19, 'batch_size': 278, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'resnet_depth': 'resnet18', 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22140, 108)                                                                    \n",
      "(22140,)                                                                        \n",
      "9                                                                               \n",
      "12                                                                              \n",
      " 50%|█████     | 1/2 [00:49<00:49, 49.48s/trial, best loss: -0.8885877786363079]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "\n",
      "Training:   0%|                                      | 0/300 [00:00<?, ?epoch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/300],Train Loss: 0.2428,Val Loss: 0.1984                               \n",
      " 50%|█████     | 1/2 [00:52<00:49, 49.48s/trial, best loss: -0.8885877786363079]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|1                             | 1/300 [00:02<14:29,  2.91s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/300],Train Loss: 0.1913,Val Loss: 0.1948                               \n",
      " 50%|█████     | 1/2 [00:55<00:49, 49.48s/trial, best loss: -0.8885877786363079]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|2                             | 2/300 [00:05<14:15,  2.87s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/300],Train Loss: 0.1791,Val Loss: 0.1856                               \n",
      " 50%|█████     | 1/2 [00:58<00:49, 49.48s/trial, best loss: -0.8885877786363079]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|3                             | 3/300 [00:08<14:02,  2.84s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/300],Train Loss: 0.1699,Val Loss: 0.1839                               \n",
      " 50%|█████     | 1/2 [01:01<00:49, 49.48s/trial, best loss: -0.8885877786363079]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|4                             | 4/300 [00:11<14:13,  2.88s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/300],Train Loss: 0.1643,Val Loss: 0.1822                               \n",
      " 50%|█████     | 1/2 [01:04<00:49, 49.48s/trial, best loss: -0.8885877786363079]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|5                             | 5/300 [00:14<14:26,  2.94s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/300],Train Loss: 0.1600,Val Loss: 0.1813                               \n",
      " 50%|█████     | 1/2 [01:07<00:49, 49.48s/trial, best loss: -0.8885877786363079]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|6                             | 6/300 [00:17<14:21,  2.93s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/300],Train Loss: 0.1517,Val Loss: 0.1867                               \n",
      " 50%|█████     | 1/2 [01:10<00:49, 49.48s/trial, best loss: -0.8885877786363079]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|7                             | 7/300 [00:20<14:12,  2.91s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/300],Train Loss: 0.1474,Val Loss: 0.1814                               \n",
      " 50%|█████     | 1/2 [01:13<00:49, 49.48s/trial, best loss: -0.8885877786363079]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|8                             | 8/300 [00:23<14:20,  2.95s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/300],Train Loss: 0.1430,Val Loss: 0.1877                               \n",
      " 50%|█████     | 1/2 [01:16<00:49, 49.48s/trial, best loss: -0.8885877786363079]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|9                             | 9/300 [00:26<14:18,  2.95s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/300],Train Loss: 0.1415,Val Loss: 0.1854                              \n",
      " 50%|█████     | 1/2 [01:18<00:49, 49.48s/trial, best loss: -0.8885877786363079]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|9                            | 10/300 [00:29<14:05,  2.92s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/300],Train Loss: 0.1358,Val Loss: 0.1914                              \n",
      " 50%|█████     | 1/2 [01:21<00:49, 49.48s/trial, best loss: -0.8885877786363079]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|#                            | 11/300 [00:32<13:59,  2.90s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/300],Train Loss: 0.1326,Val Loss: 0.1902                              \n",
      "Early stopping triggered at epoch 12                                            \n",
      " 50%|█████     | 1/2 [01:24<00:49, 49.48s/trial, best loss: -0.8885877786363079]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|#                            | 11/300 [00:34<15:14,  3.16s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model loaded from epoch 6                                                  \n",
      " 50%|█████     | 1/2 [01:24<00:49, 49.48s/trial, best loss: -0.8885877786363079]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 19:48:04,755 - INFO - ResNetModel.py - Validation metrics roc_auc: 0.8684901418074005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [01:27<00:00, 43.56s/trial, best loss: -0.8885877786363079]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 19:48:04,761 - INFO - ResNetModel.py - Final Validation Metrics: {'accuracy': 0.819364161849711, 'roc_auc': 0.8885877786363079, 'lift5': 3.942376898572469}\n",
      "2025-02-06 19:48:04,762 - INFO - ResNetModel.py - Loading model\n",
      "2025-02-06 19:48:04,763 - INFO - ResNetModel.py - Best hyperparameters: {'AdamW_learning_rate': 0.00041691320143948053, 'AdamW_weight_decay': 5.3327377727838295e-08, 'Adam_learning_rate': 0.000883609493567339, 'Adam_weight_decay': 5.3453713798712174e-08, 'ExponentialLR_gamma': 0.9700428647065971, 'ReduceLROnPlateau_factor': 0.014194472482598669, 'ReduceLROnPlateau_patience': 6, 'SGD_learning_rate': 5.540876168540814e-05, 'SGD_momentum': 0.7753748228926656, 'SGD_weight_decay': 1.1771360216800085e-08, 'StepLR_gamma': 0.1469911132467317, 'StepLR_step_size': 14, 'batch_size': 601, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>, 'resnet_depth': 'resnet34', 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>, 'default_params': {'early_stopping': True, 'verbose': False, 'iterations': 20, 'retrain': False, 'auto_lr_find': False, 'max_epochs': 300, 'val_size': 0.2, 'early_stopping_patience': 6}}\n",
      "2025-02-06 19:48:04,764 - INFO - ResNetModel.py - The best possible score for metric roc_auc is 1.0, we reached roc_auc = 0.8885877786363079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 19:48:06,564 - INFO - MLP.py - Starting hyperopt search with 2 evaluations, optimizing roc_auc metric\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running mlp on binary...\n",
      "Using dynamic loader for dataset: /home/boom/sdev/repos/AutoDeep/autodeep/examples/testautodata/adult.csv\n",
      "  0%|          | 0/2 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 19:48:06,572 - INFO - MLP.py - Training with hyperparameters: {'activation': 'tanh', 'batch_size': 1252, 'hidden_layer_sizes': (128, 64, 32), 'max_iter': 1449, 'n_iter_no_change': 12, 'solver': 'sgd'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:27<00:27, 27.60s/trial, best loss: -0.888210342639594]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 19:48:34,177 - INFO - MLP.py - Training with hyperparameters: {'activation': 'tanh', 'batch_size': 1472, 'hidden_layer_sizes': (64, 32), 'max_iter': 1029, 'n_iter_no_change': 11, 'solver': 'adam'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:31<00:00, 15.81s/trial, best loss: -0.892507296954315]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 19:48:38,192 - INFO - MLP.py - Final best hyperparameters: {'activation': 'tanh', 'batch_size': 1472, 'hidden_layer_sizes': (64, 32), 'max_iter': 1029, 'n_iter_no_change': 11, 'solver': 'adam', 'default_params': {'early_stopping': True, 'n_iter_no_change': 10, 'max_iter': 1000, 'hidden_layer_sizes': [32], 'activation': 'relu', 'solver': 'adam', 'batch_size': 1024, 'val_size': 0.15}}\n",
      "2025-02-06 19:48:38,194 - INFO - MLP.py - Final best roc_auc score: 0.892507296954315\n",
      "2025-02-06 19:48:38,195 - INFO - MLP.py - Loading model\n",
      "2025-02-06 19:48:38,200 - INFO - MLP.py - Computing predictions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running xgb on binary...\n",
      "Using dynamic loader for dataset: /home/boom/sdev/repos/AutoDeep/autodeep/examples/testautodata/adult.csv\n",
      "  0%|          | 0/2 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 19:48:38,359 - INFO - XGBoostTrainer.py - Hyperopt training with hyperparameters: {'colsample_bytree': 0.9317085201666937, 'gamma': 0.023542720433600173, 'learning_rate': 0.02257009318017118, 'max_depth': 5, 'min_child_weight': 5, 'n_estimators': 119, 'subsample': 0.804784757575745}\n",
      "2025-02-06 19:48:38,974 - INFO - XGBoostTrainer.py - Validation metrics: {'accuracy': 0.8654263005780347, 'roc_auc': 0.9205197444971522, 'lift5': 4.153038259564891}\n",
      "2025-02-06 19:48:39,063 - INFO - XGBoostTrainer.py - Train metrics: {'accuracy': 0.8654263005780347, 'roc_auc': 0.9205197444971522, 'lift5': 4.153038259564891}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:00<00:00,  1.41trial/s, best loss: -0.9205197444971522]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 19:48:39,069 - INFO - XGBoostTrainer.py - Hyperopt training with hyperparameters: {'colsample_bytree': 0.8906721612968371, 'gamma': 0.049720043026671615, 'learning_rate': 0.04776774932724804, 'max_depth': 6, 'min_child_weight': 1, 'n_estimators': 82, 'subsample': 0.6447152123951665}\n",
      "2025-02-06 19:48:39,590 - INFO - XGBoostTrainer.py - Validation metrics: {'accuracy': 0.8726517341040463, 'roc_auc': 0.9261790822437944, 'lift5': 4.153038259564891}\n",
      "2025-02-06 19:48:39,679 - INFO - XGBoostTrainer.py - Train metrics: {'accuracy': 0.8726517341040463, 'roc_auc': 0.9261790822437944, 'lift5': 4.153038259564891}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.51trial/s, best loss: -0.9261790822437944]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 19:48:39,682 - INFO - XGBoostTrainer.py - Loading model\n",
      "2025-02-06 19:48:39,682 - INFO - XGBoostTrainer.py - Best hyperparameters: {'colsample_bytree': 0.8906721612968371, 'gamma': 0.049720043026671615, 'learning_rate': 0.04776774932724804, 'max_depth': 6, 'min_child_weight': 1, 'n_estimators': 82, 'subsample': 0.6447152123951665, 'default_params': {'retrain': True, 'val_size': 0.2, 'early_stopping_rounds': 100, 'verbose': False, 'learning_rate': 0.3, 'max_depth': 6, 'n_estimators': 100, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 0.0}}\n",
      "2025-02-06 19:48:39,683 - INFO - XGBoostTrainer.py - The best possible score for metric roc_auc is 1.0, we reached roc_auc = 0.9261790822437944\n",
      "2025-02-06 19:48:39,684 - INFO - XGBoostTrainer.py - Computing predictions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running catboost on binary...\n",
      "Using dynamic loader for dataset: /home/boom/sdev/repos/AutoDeep/autodeep/examples/testautodata/adult.csv\n",
      "  0%|          | 0/2 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 19:48:39,826 - INFO - CatBoostModel.py - Hyperopt training with hyperparameters: {'iterations': 330}\n",
      "2025-02-06 19:48:45,115 - INFO - CatBoostModel.py - Validation metrics: {'accuracy': 0.865606936416185, 'roc_auc': 0.922959856123112, 'lift5': 4.027158098933074}\n",
      "2025-02-06 19:48:45,193 - INFO - CatBoostModel.py - Train metrics: {'accuracy': 0.865606936416185, 'roc_auc': 0.922959856123112, 'lift5': 4.027158098933074}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:05<00:05,  5.37s/trial, best loss: -0.922959856123112]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 19:48:45,195 - INFO - CatBoostModel.py - Hyperopt training with hyperparameters: {'iterations': 156}\n",
      "2025-02-06 19:48:45,979 - INFO - CatBoostModel.py - Validation metrics: {'accuracy': 0.8631984585741811, 'roc_auc': 0.919416542796506, 'lift5': 4.027158098933074}\n",
      "2025-02-06 19:48:46,032 - INFO - CatBoostModel.py - Train metrics: {'accuracy': 0.8631984585741811, 'roc_auc': 0.919416542796506, 'lift5': 4.027158098933074}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:06<00:00,  3.10s/trial, best loss: -0.922959856123112]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 19:48:46,034 - INFO - CatBoostModel.py - Loading model\n",
      "2025-02-06 19:48:46,035 - INFO - CatBoostModel.py - Best hyperparameters: {'iterations': 330, 'default_params': {'retrain': False, 'val_size': 0.15, 'early_stopping_rounds': 100, 'verbose': False, 'iterations': 500}}\n",
      "2025-02-06 19:48:46,036 - INFO - CatBoostModel.py - The best possible score for metric roc_auc is 1.0, we reached roc_auc = -0.922959856123112\n",
      "2025-02-06 19:48:46,037 - INFO - CatBoostModel.py - Computing predictions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running categoryembedding on binary...\n",
      "Using dynamic loader for dataset: /home/boom/sdev/repos/AutoDeep/autodeep/examples/testautodata/adult.csv\n",
      "2025-02-06 19:48:46,138 - INFO - CommonStructure.py - CategoryEmbeddingTrainer - Initialized CategoryEmbeddingTrainer with problem type binary_classification\n",
      "2025-02-06 19:48:46,139 - INFO - CommonStructure.py - CategoryEmbeddingTrainer - Device cuda is available\n",
      "2025-02-06 19:48:46,140 - INFO - CommonStructure.py - CategoryEmbeddingTrainer - Trainer initialized\n",
      "2025-02-06 19:48:46,141 - INFO - CommonStructure.py - CategoryEmbeddingTrainer - Starting hyperopt search 2 evals maximizing roc_auc metric on dataset\n",
      "SPACE ######################################################\n",
      "{'batch_size': <hyperopt.pyll.base.Apply object at 0x7adeac577610>, 'layers': <hyperopt.pyll.base.Apply object at 0x7adeac577910>, 'activation': <hyperopt.pyll.base.Apply object at 0x7adeac575930>, 'use_batch_norm': <hyperopt.pyll.base.Apply object at 0x7adeac577250>, 'initialization': <hyperopt.pyll.base.Apply object at 0x7adeac574190>, 'dropout': <hyperopt.pyll.base.Apply object at 0x7adeac577280>, 'embedding_dropout': <hyperopt.pyll.base.Apply object at 0x7adeac574e20>, 'optimizer_fn': <hyperopt.pyll.base.Apply object at 0x7adeac576b30>, 'scheduler_fn': <hyperopt.pyll.base.Apply object at 0x7adeac575fc0>}\n",
      "2025-02-06 19:48:46,150 - DEBUG - CommonStructure.py - CategoryEmbeddingTrainer - Full dataset shape : (27676, 15)\n",
      "2025-02-06 19:48:46,162 - DEBUG - CommonStructure.py - CategoryEmbeddingTrainer - Train set shape: (23524, 15), Test set shape: (4152, 15)\n",
      "  0%|          | 0/2 [00:00<?, ?trial/s, best loss=?]2025-02-06 19:48:46,183 - INFO - CommonStructure.py - CategoryEmbeddingTrainer - Training with hyperparameters: {'activation': 'ReLU', 'batch_size': 352, 'dropout': 0.07180182756042691, 'embedding_dropout': 0.04456699223511802, 'initialization': 'xavier', 'layers': '256-128-64-32', 'optimizer_fn': {'AdamW_learning_rate': 0.0002369073315019895, 'AdamW_weight_decay': 2.7190091816919235e-08, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>}, 'scheduler_fn': {'StepLR_gamma': 0.24871568886900097, 'StepLR_step_size': 27, 'scheduler_fn': <class 'torch.optim.lr_scheduler.StepLR'>}, 'use_batch_norm': False}\n",
      "tabular model params                                 \n",
      "{'activation': 'ReLU', 'batch_size': 352, 'dropout': 0.07180182756042691, 'embedding_dropout': 0.04456699223511802, 'initialization': 'xavier', 'layers': '256-128-64-32', 'optimizer_fn': {'AdamW_learning_rate': 0.0002369073315019895, 'AdamW_weight_decay': 2.7190091816919235e-08, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>}, 'scheduler_fn': {'StepLR_gamma': 0.24871568886900097, 'StepLR_step_size': 27, 'scheduler_fn': <class 'torch.optim.lr_scheduler.StepLR'>}, 'use_batch_norm': False}\n",
      "tabular model outer params                           \n",
      "{'early_stopping_rounds': 10, 'verbose': False, 'iterations': 20, 'retrain': False, 'auto_lr_find': False, 'max_epochs': 3, 'val_size': 0.15, 'early_stopping_patience': 20}\n",
      "  0%|          | 0/2 [00:00<?, ?trial/s, best loss=?]2025-02-06 19:48:46,193 - WARNING - CommonStructure.py - CategoryEmbeddingTrainer - You are passing some invalid parameters to the model {'batch_size': 352, 'optimizer_fn': {'AdamW_learning_rate': 0.0002369073315019895, 'AdamW_weight_decay': 2.7190091816919235e-08, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>}, 'scheduler_fn': {'StepLR_gamma': 0.24871568886900097, 'StepLR_step_size': 27, 'scheduler_fn': <class 'torch.optim.lr_scheduler.StepLR'>}}\n",
      "2025-02-06 19:48:46,194 - DEBUG - CommonStructure.py - CategoryEmbeddingTrainer - compatible parameters: {'activation': 'ReLU', 'dropout': 0.07180182756042691, 'embedding_dropout': 0.04456699223511802, 'initialization': 'xavier', 'layers': '256-128-64-32', 'use_batch_norm': False}\n",
      "DataConfig(target=['target'], continuous_cols=['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week'], categorical_cols=['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country'], date_columns=[], encode_date_columns=True, validation_split=0.2, continuous_feature_transform=None, normalize_continuous_features=True, quantile_noise=0, num_workers=4, pin_memory=True, handle_unknown_categories=True, handle_missing_values=True, dataloader_kwargs={})\n",
      "CategoryEmbeddingModelConfig(task='classification', head='LinearHead', head_config={'layers': ''}, embedding_dims=None, embedding_dropout=0.0, batch_norm_continuous_input=True, learning_rate=0.0002369073315019895, loss='CrossEntropyLoss', metrics=['accuracy'], metrics_prob_input=[False], metrics_params=[{}], target_range=None, virtual_batch_size=None, seed=42, _module_src='models.category_embedding', _model_name='CategoryEmbeddingModel', _backbone_name='CategoryEmbeddingBackbone', _config_name='CategoryEmbeddingModelConfig', layers='256-128-64-32', activation='ReLU', use_batch_norm=False, initialization='kaiming', dropout=0.0)\n",
      "OptimizerConfig(optimizer='AdamW', optimizer_params={'weight_decay': 2.7190091816919235e-08}, lr_scheduler='StepLR', lr_scheduler_params={'step_size': 27, 'gamma': 0.24871568886900097}, lr_scheduler_monitor_metric='valid_loss')\n",
      "TrainerConfig(batch_size=352, data_aware_init_batch_size=2000, fast_dev_run=False, max_epochs=3, min_epochs=1, max_time=None, accelerator='auto', devices=-1, devices_list=None, accumulate_grad_batches=1, auto_lr_find=False, auto_select_gpus=True, check_val_every_n_epoch=1, gradient_clip_val=0.0, overfit_batches=0.0, deterministic=False, profiler=None, early_stopping='valid_loss', early_stopping_min_delta=0.0, early_stopping_mode='min', early_stopping_patience=20, early_stopping_kwargs={}, checkpoints='valid_loss', checkpoints_path='ptabular_checkpoints', checkpoints_every_n_epochs=10, checkpoints_name=None, checkpoints_mode='min', checkpoints_save_top_k=1, checkpoints_kwargs={}, load_best=True, track_grad_norm=-1, progress_bar='rich', precision=32, seed=42, trainer_kwargs={})\n",
      "  0%|          | 0/2 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:48:46</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">224</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">146</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m19:48:46\u001b[0m,\u001b[1;36m224\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m146\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:48:46</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">259</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m19:48:46\u001b[0m,\u001b[1;36m259\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:48:46</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">283</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m19:48:46\u001b[0m,\u001b[1;36m283\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:48:46</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">381</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: CategoryEmbeddingModel \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m19:48:46\u001b[0m,\u001b[1;36m381\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: CategoryEmbeddingModel \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:48:46</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">446</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m19:48:46\u001b[0m,\u001b[1;36m446\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:48:46</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">460</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m19:48:46\u001b[0m,\u001b[1;36m460\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/boom/sdev/repos/AutoDeep/autodeep/examples/ptabular_checkpoints exists and is not empty.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                      </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ custom_loss      │ CrossEntropyLoss          │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _backbone        │ CategoryEmbeddingBackbone │ 59.6 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _embedding_layer │ Embedding1dLayer          │  1.4 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ head             │ LinearHead                │     66 │ train │\n",
       "└───┴──────────────────┴───────────────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType                     \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ custom_loss      │ CrossEntropyLoss          │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ CategoryEmbeddingBackbone │ 59.6 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer          │  1.4 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ head             │ LinearHead                │     66 │ train │\n",
       "└───┴──────────────────┴───────────────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 61.1 K                                                                                           \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 61.1 K                                                                                               \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 26                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 61.1 K                                                                                           \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 61.1 K                                                                                               \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 26                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f4cf1e87a824cebb5c6316b69b26347",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:48:52</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">589</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m19:48:52\u001b[0m,\u001b[1;36m589\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:48:52</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">591</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m19:48:52\u001b[0m,\u001b[1;36m591\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:48:52</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">592</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1537</span><span style=\"font-weight: bold\">}</span> - WARNING - No best model available to load. Did you\n",
       "run it more than <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> epoch?<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                                                                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m19:48:52\u001b[0m,\u001b[1;36m592\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1537\u001b[0m\u001b[1m}\u001b[0m - WARNING - No best model available to load. Did you\n",
       "run it more than \u001b[1;36m1\u001b[0m epoch?\u001b[33m...\u001b[0m                                                                                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-06 19:48:52,917 - INFO - CommonStructure.py - CategoryEmbeddingTrainer - Validation metrics: {'accuracy': 0.8029865125240848, 'roc_auc': 0.8870954949238579, 'lift5': 3.7708985507246378}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:07<00:07,  7.30s/trial, best loss: -0.8870954949238579]2025-02-06 19:48:53,488 - INFO - CommonStructure.py - CategoryEmbeddingTrainer - Training with hyperparameters: {'activation': 'ReLU', 'batch_size': 608, 'dropout': 0.13793074406282088, 'embedding_dropout': 0.08748838326419968, 'initialization': 'random', 'layers': '256-128', 'optimizer_fn': {'Adam_learning_rate': 0.0003929327884259557, 'Adam_weight_decay': 3.044740079823129e-08, 'optimizer_fn': <class 'torch.optim.adam.Adam'>}, 'scheduler_fn': {'ReduceLROnPlateau_factor': 0.054041101815896615, 'ReduceLROnPlateau_patience': 9, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>}, 'use_batch_norm': True}\n",
      "tabular model params                                                            \n",
      "{'activation': 'ReLU', 'batch_size': 608, 'dropout': 0.13793074406282088, 'embedding_dropout': 0.08748838326419968, 'initialization': 'random', 'layers': '256-128', 'optimizer_fn': {'Adam_learning_rate': 0.0003929327884259557, 'Adam_weight_decay': 3.044740079823129e-08, 'optimizer_fn': <class 'torch.optim.adam.Adam'>}, 'scheduler_fn': {'ReduceLROnPlateau_factor': 0.054041101815896615, 'ReduceLROnPlateau_patience': 9, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>}, 'use_batch_norm': True}\n",
      "tabular model outer params                                                      \n",
      "{'early_stopping_rounds': 10, 'verbose': False, 'iterations': 20, 'retrain': False, 'auto_lr_find': False, 'max_epochs': 3, 'val_size': 0.15, 'early_stopping_patience': 20}\n",
      " 50%|█████     | 1/2 [00:07<00:07,  7.30s/trial, best loss: -0.8870954949238579]2025-02-06 19:48:53,504 - WARNING - CommonStructure.py - CategoryEmbeddingTrainer - You are passing some invalid parameters to the model {'batch_size': 608, 'optimizer_fn': {'Adam_learning_rate': 0.0003929327884259557, 'Adam_weight_decay': 3.044740079823129e-08, 'optimizer_fn': <class 'torch.optim.adam.Adam'>}, 'scheduler_fn': {'ReduceLROnPlateau_factor': 0.054041101815896615, 'ReduceLROnPlateau_patience': 9, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>}}\n",
      "2025-02-06 19:48:53,505 - DEBUG - CommonStructure.py - CategoryEmbeddingTrainer - compatible parameters: {'activation': 'ReLU', 'dropout': 0.13793074406282088, 'embedding_dropout': 0.08748838326419968, 'initialization': 'random', 'layers': '256-128', 'use_batch_norm': True}\n",
      "DataConfig(target=['target'], continuous_cols=['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week'], categorical_cols=['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country'], date_columns=[], encode_date_columns=True, validation_split=0.2, continuous_feature_transform=None, normalize_continuous_features=True, quantile_noise=0, num_workers=4, pin_memory=True, handle_unknown_categories=True, handle_missing_values=True, dataloader_kwargs={})\n",
      "CategoryEmbeddingModelConfig(task='classification', head='LinearHead', head_config={'layers': ''}, embedding_dims=None, embedding_dropout=0.0, batch_norm_continuous_input=True, learning_rate=0.0003929327884259557, loss='CrossEntropyLoss', metrics=['accuracy'], metrics_prob_input=[False], metrics_params=[{}], target_range=None, virtual_batch_size=None, seed=42, _module_src='models.category_embedding', _model_name='CategoryEmbeddingModel', _backbone_name='CategoryEmbeddingBackbone', _config_name='CategoryEmbeddingModelConfig', layers='256-128', activation='ReLU', use_batch_norm=False, initialization='kaiming', dropout=0.0)\n",
      "OptimizerConfig(optimizer='Adam', optimizer_params={'weight_decay': 3.044740079823129e-08}, lr_scheduler='ReduceLROnPlateau', lr_scheduler_params={'factor': 0.054041101815896615, 'patience': 9, 'min_lr': 1e-08, 'verbose': True, 'mode': 'min'}, lr_scheduler_monitor_metric='valid_loss')\n",
      "TrainerConfig(batch_size=608, data_aware_init_batch_size=2000, fast_dev_run=False, max_epochs=3, min_epochs=1, max_time=None, accelerator='auto', devices=-1, devices_list=None, accumulate_grad_batches=1, auto_lr_find=False, auto_select_gpus=True, check_val_every_n_epoch=1, gradient_clip_val=0.0, overfit_batches=0.0, deterministic=False, profiler=None, early_stopping='valid_loss', early_stopping_min_delta=0.0, early_stopping_mode='min', early_stopping_patience=20, early_stopping_kwargs={}, checkpoints='valid_loss', checkpoints_path='ptabular_checkpoints', checkpoints_every_n_epochs=10, checkpoints_name=None, checkpoints_mode='min', checkpoints_save_top_k=1, checkpoints_kwargs={}, load_best=True, track_grad_norm=-1, progress_bar='rich', precision=32, seed=42, trainer_kwargs={})\n",
      " 50%|█████     | 1/2 [00:07<00:07,  7.30s/trial, best loss: -0.8870954949238579]"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:48:53</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">534</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">146</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m19:48:53\u001b[0m,\u001b[1;36m534\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m146\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:48:53</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">561</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m19:48:53\u001b[0m,\u001b[1;36m561\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:48:53</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">588</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m19:48:53\u001b[0m,\u001b[1;36m588\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:48:53</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">681</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: CategoryEmbeddingModel \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m19:48:53\u001b[0m,\u001b[1;36m681\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: CategoryEmbeddingModel \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:48:53</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">753</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m19:48:53\u001b[0m,\u001b[1;36m753\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:48:53</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">764</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m19:48:53\u001b[0m,\u001b[1;36m764\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/boom/sdev/repos/AutoDeep/autodeep/examples/ptabular_checkpoints exists and is not empty.\n",
      "\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                      </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ custom_loss      │ CrossEntropyLoss          │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _backbone        │ CategoryEmbeddingBackbone │ 49.3 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _embedding_layer │ Embedding1dLayer          │  1.4 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ head             │ LinearHead                │    258 │ train │\n",
       "└───┴──────────────────┴───────────────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType                     \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ custom_loss      │ CrossEntropyLoss          │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ CategoryEmbeddingBackbone │ 49.3 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer          │  1.4 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ head             │ LinearHead                │    258 │ train │\n",
       "└───┴──────────────────┴───────────────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 50.9 K                                                                                           \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 50.9 K                                                                                               \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 22                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 50.9 K                                                                                           \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 50.9 K                                                                                               \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 22                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3a8e17492be47cf8dc7255aa3fe29ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number \n",
       "of training batches (39) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for \n",
       "log_every_n_steps if you want to see logs for the training epoch.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number \n",
       "of training batches (39) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for \n",
       "log_every_n_steps if you want to see logs for the training epoch.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:48:58</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">118</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m19:48:58\u001b[0m,\u001b[1;36m118\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:48:58</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">122</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m19:48:58\u001b[0m,\u001b[1;36m122\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:48:58</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">126</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1537</span><span style=\"font-weight: bold\">}</span> - WARNING - No best model available to load. Did you\n",
       "run it more than <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> epoch?<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                                                                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m19:48:58\u001b[0m,\u001b[1;36m126\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1537\u001b[0m\u001b[1m}\u001b[0m - WARNING - No best model available to load. Did you\n",
       "run it more than \u001b[1;36m1\u001b[0m epoch?\u001b[33m...\u001b[0m                                                                                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-06 19:48:58,467 - INFO - CommonStructure.py - CategoryEmbeddingTrainer - Validation metrics: {'accuracy': 0.8046724470134875, 'roc_auc': 0.8849232233502538, 'lift5': 3.79095652173913}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:12<00:00,  6.42s/trial, best loss: -0.8870954949238579]\n",
      "2025-02-06 19:48:59,015 - INFO - CommonStructure.py - CategoryEmbeddingTrainer - Final validation metrics: {'accuracy': 0.8029865125240848, 'roc_auc': 0.8870954949238579, 'lift5': 3.7708985507246378}\n",
      "2025-02-06 19:48:59,016 - INFO - CommonStructure.py - CategoryEmbeddingTrainer - Loading model\n",
      "2025-02-06 19:48:59,016 - DEBUG - CommonStructure.py - CategoryEmbeddingTrainer - Model loaded successfully\n",
      "2025-02-06 19:48:59,017 - INFO - CommonStructure.py - CategoryEmbeddingTrainer - Best hyperparameters: {'activation': 'ReLU', 'batch_size': 352, 'dropout': 0.07180182756042691, 'embedding_dropout': 0.04456699223511802, 'initialization': 'xavier', 'layers': '256-128-64-32', 'optimizer_fn': {'AdamW_learning_rate': 0.0002369073315019895, 'AdamW_weight_decay': 2.7190091816919235e-08, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>}, 'scheduler_fn': {'StepLR_gamma': 0.24871568886900097, 'StepLR_step_size': 27, 'scheduler_fn': <class 'torch.optim.lr_scheduler.StepLR'>}, 'use_batch_norm': False, 'default_params': {'early_stopping_rounds': 10, 'verbose': False, 'iterations': 20, 'retrain': False, 'auto_lr_find': False, 'max_epochs': 3, 'val_size': 0.15, 'early_stopping_patience': 20}}\n",
      "2025-02-06 19:48:59,018 - INFO - CommonStructure.py - CategoryEmbeddingTrainer - The best possible score for metric roc_auc is 1.0, we reached roc_auc = 0.8870954949238579\n",
      "2025-02-06 19:48:59,020 - INFO - CommonStructure.py - CategoryEmbeddingTrainer - Computing predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-06 19:48:59,342 - DEBUG - CommonStructure.py - CategoryEmbeddingTrainer - [0 1 0 1 1 1 0 1 0 0]\n",
      "2025-02-06 19:48:59,343 - DEBUG - CommonStructure.py - CategoryEmbeddingTrainer - Computed predictions successfully\n",
      "Running s1dcnn on binary...\n",
      "Using dynamic loader for dataset: /home/boom/sdev/repos/AutoDeep/autodeep/examples/testautodata/adult.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 19:48:59,548 - INFO - SoftOrdering1DCNN.py - Device cuda is available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size [1024, 512, 256]\n",
      "hidden_size [4096, 2048, 1024]\n",
      "optimizer_fn {'Adam': {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}, 'SGD': {'weight_decay': [0.0, 1e-07], 'momentum': [0.0, 0.9], 'learning_rate': [0.001, 1e-05]}, 'AdamW': {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}}\n",
      "dict_keys(['Adam', 'SGD', 'AdamW'])\n",
      "Adam {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}\n",
      "weight_decay [0.0, 1e-07]\n",
      "learning_rate [0.001, 0.0001]\n",
      "SGD {'weight_decay': [0.0, 1e-07], 'momentum': [0.0, 0.9], 'learning_rate': [0.001, 1e-05]}\n",
      "weight_decay [0.0, 1e-07]\n",
      "momentum [0.0, 0.9]\n",
      "learning_rate [0.001, 1e-05]\n",
      "AdamW {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}\n",
      "weight_decay [0.0, 1e-07]\n",
      "learning_rate [0.001, 0.0001]\n",
      "scheduler_fn {'ReduceLROnPlateau': {'factor': [0.1, 0.01], 'patience': [5, 10]}, 'StepLR': {'step_size': [10, 30], 'gamma': [0.1, 0.5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}\n",
      "dict_keys(['ReduceLROnPlateau', 'StepLR', 'ExponentialLR'])\n",
      "ReduceLROnPlateau {'factor': [0.1, 0.01], 'patience': [5, 10]}\n",
      "factor [0.1, 0.01]\n",
      "patience [5, 10]\n",
      "StepLR {'step_size': [10, 30], 'gamma': [0.1, 0.5]}\n",
      "step_size [10, 30]\n",
      "gamma [0.1, 0.5]\n",
      "ExponentialLR {'gamma': [0.9, 0.99]}\n",
      "gamma [0.9, 0.99]\n",
      "  0%|          | 0/2 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 19:48:59,608 - INFO - SoftOrdering1DCNN.py - Training with hyperparameters: {'AdamW_learning_rate': 0.00041691320143948053, 'AdamW_weight_decay': 5.3327377727838295e-08, 'Adam_learning_rate': 0.000883609493567339, 'Adam_weight_decay': 5.3453713798712174e-08, 'ExponentialLR_gamma': 0.9700428647065971, 'ReduceLROnPlateau_factor': 0.014194472482598669, 'ReduceLROnPlateau_patience': 6, 'SGD_learning_rate': 5.540876168540814e-05, 'SGD_momentum': 0.7753748228926656, 'SGD_weight_decay': 1.1771360216800085e-08, 'StepLR_gamma': 0.1469911132467317, 'StepLR_step_size': 14, 'batch_size': 601, 'hidden_size': 1024, 'optimizer_fn': <class 'torch.optim.sgd.SGD'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>}\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n",
      "\n",
      "Training:   0%|                                        | 0/1 [00:00<?, ?epoch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Train Loss: 1.1026, Val Loss: 1.0998    \n",
      "  0%|          | 0/2 [00:01<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:240: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "Training: 100%|################################| 1/1 [00:01<00:00,  1.90s/epoch]\n",
      "Training: 100%|################################| 1/1 [00:01<00:00,  1.90s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model loaded from epoch 1                       \n",
      "  0%|          | 0/2 [00:01<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 19:49:04,552 - INFO - SoftOrdering1DCNN.py - Validation metrics: {'accuracy': 0.5604527938342967, 'roc_auc': 0.4543561230964467, 'lift5': 0.7020289855072464}\n",
      "2025-02-06 19:49:04,553 - INFO - SoftOrdering1DCNN.py - Training metrics: {'accuracy': 0.5630419996599217, 'roc_auc': 0.4575361811091858, 'lift5': 0.685023806521726}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:04<00:04,  4.95s/trial, best loss: -0.4543561230964467]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 19:49:04,566 - INFO - SoftOrdering1DCNN.py - Training with hyperparameters: {'AdamW_learning_rate': 0.0005493747562277502, 'AdamW_weight_decay': 5.979030232767242e-08, 'Adam_learning_rate': 0.00010037826615600942, 'Adam_weight_decay': 2.309091722462173e-08, 'ExponentialLR_gamma': 0.9526834243165615, 'ReduceLROnPlateau_factor': 0.021158305135007868, 'ReduceLROnPlateau_patience': 7, 'SGD_learning_rate': 9.52118823872863e-05, 'SGD_momentum': 0.6960145837348019, 'SGD_weight_decay': 2.4860021513335803e-08, 'StepLR_gamma': 0.2095872419296196, 'StepLR_step_size': 19, 'batch_size': 278, 'hidden_size': 4096, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>}\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n",
      "\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "\n",
      "Training:   0%|                                        | 0/1 [00:00<?, ?epoch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Train Loss: 0.9413, Val Loss: 0.9214                               \n",
      " 50%|█████     | 1/2 [00:07<00:04,  4.95s/trial, best loss: -0.4543561230964467]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|################################| 1/1 [00:02<00:00,  2.57s/epoch]\n",
      "Training: 100%|################################| 1/1 [00:02<00:00,  2.57s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model loaded from epoch 1                                                  \n",
      " 50%|█████     | 1/2 [00:07<00:04,  4.95s/trial, best loss: -0.4543561230964467]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 19:49:10,388 - INFO - SoftOrdering1DCNN.py - Validation metrics: {'accuracy': 0.7938342967244701, 'roc_auc': 0.8696822652284264, 'lift5': 3.269449275362319}\n",
      "2025-02-06 19:49:10,389 - INFO - SoftOrdering1DCNN.py - Training metrics: {'accuracy': 0.8102363543615031, 'roc_auc': 0.884282365437172, 'lift5': 3.3721532743724145}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:10<00:00,  5.40s/trial, best loss: -0.8696822652284264]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 19:49:10,393 - INFO - SoftOrdering1DCNN.py - Final Validation Metrics: {'accuracy': 0.7938342967244701, 'roc_auc': 0.8696822652284264, 'lift5': 3.269449275362319}\n",
      "2025-02-06 19:49:10,394 - INFO - SoftOrdering1DCNN.py - Final Training Metrics: {'accuracy': 0.8102363543615031, 'roc_auc': 0.884282365437172, 'lift5': 3.3721532743724145}\n",
      "2025-02-06 19:49:10,395 - INFO - SoftOrdering1DCNN.py - Loading model\n",
      "2025-02-06 19:49:10,396 - INFO - SoftOrdering1DCNN.py - Best hyperparameters: {'AdamW_learning_rate': 0.0005493747562277502, 'AdamW_weight_decay': 5.979030232767242e-08, 'Adam_learning_rate': 0.00010037826615600942, 'Adam_weight_decay': 2.309091722462173e-08, 'ExponentialLR_gamma': 0.9526834243165615, 'ReduceLROnPlateau_factor': 0.021158305135007868, 'ReduceLROnPlateau_patience': 7, 'SGD_learning_rate': 9.52118823872863e-05, 'SGD_momentum': 0.6960145837348019, 'SGD_weight_decay': 2.4860021513335803e-08, 'StepLR_gamma': 0.2095872419296196, 'StepLR_step_size': 19, 'batch_size': 278, 'hidden_size': 4096, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'default_params': {'early_stopping_rounds': 10, 'verbose': False, 'iterations': 20, 'retrain': False, 'auto_lr_find': False, 'max_epochs': 1, 'val_size': 0.15, 'early_stopping_patience': 5}}\n",
      "2025-02-06 19:49:10,396 - INFO - SoftOrdering1DCNN.py - Best metric roc_auc: 0.8696822652284264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 19:49:11,906 - INFO - ResNetModel.py - Device cuda is available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running resnet on regression...\n",
      "Using dynamic loader for dataset: /home/boom/sdev/repos/AutoDeep/autodeep/examples/testautodata/cal_housing.csv\n",
      "IGTD result file path: IGTD/regression/Euclidean_Euclidean/abs/_index.txt\n",
      "img_rows: 3\n",
      "img_columns: 3\n",
      "{'data_params': {'normalize_features': 'mean_std', 'encode_categorical': True, 'return_extra_info': True}, 'default_params': {'early_stopping': True, 'verbose': False, 'iterations': 20, 'retrain': False, 'auto_lr_find': False, 'max_epochs': 300, 'val_size': 0.2, 'early_stopping_patience': 6}, 'param_grid': {'resnet_depth': ['resnet18', 'resnet34', 'resnet50'], 'batch_size': [1024, 512, 256], 'optimizer_fn': {'Adam': {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}, 'SGD': {'weight_decay': [0.0, 1e-07], 'momentum': [0.0, 0.9], 'learning_rate': [0.001, 1e-05]}, 'AdamW': {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.01], 'patience': [5, 10]}, 'StepLR': {'step_size': [10, 30], 'gamma': [0.1, 0.5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}\n",
      "resnet_depth ['resnet18', 'resnet34', 'resnet50']\n",
      "batch_size [1024, 512, 256]\n",
      "optimizer_fn {'Adam': {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}, 'SGD': {'weight_decay': [0.0, 1e-07], 'momentum': [0.0, 0.9], 'learning_rate': [0.001, 1e-05]}, 'AdamW': {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}}\n",
      "dict_keys(['Adam', 'SGD', 'AdamW'])\n",
      "Adam {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}\n",
      "weight_decay [0.0, 1e-07]\n",
      "learning_rate [0.001, 0.0001]\n",
      "SGD {'weight_decay': [0.0, 1e-07], 'momentum': [0.0, 0.9], 'learning_rate': [0.001, 1e-05]}\n",
      "weight_decay [0.0, 1e-07]\n",
      "momentum [0.0, 0.9]\n",
      "learning_rate [0.001, 1e-05]\n",
      "AdamW {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}\n",
      "weight_decay [0.0, 1e-07]\n",
      "learning_rate [0.001, 0.0001]\n",
      "scheduler_fn {'ReduceLROnPlateau': {'factor': [0.1, 0.01], 'patience': [5, 10]}, 'StepLR': {'step_size': [10, 30], 'gamma': [0.1, 0.5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}\n",
      "dict_keys(['ReduceLROnPlateau', 'StepLR', 'ExponentialLR'])\n",
      "ReduceLROnPlateau {'factor': [0.1, 0.01], 'patience': [5, 10]}\n",
      "factor [0.1, 0.01]\n",
      "patience [5, 10]\n",
      "StepLR {'step_size': [10, 30], 'gamma': [0.1, 0.5]}\n",
      "step_size [10, 30]\n",
      "gamma [0.1, 0.5]\n",
      "ExponentialLR {'gamma': [0.9, 0.99]}\n",
      "gamma [0.9, 0.99]\n",
      "  0%|          | 0/2 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 19:49:11,925 - INFO - ResNetModel.py - Training with hyperparameters: {'AdamW_learning_rate': 0.00041691320143948053, 'AdamW_weight_decay': 5.3327377727838295e-08, 'Adam_learning_rate': 0.000883609493567339, 'Adam_weight_decay': 5.3453713798712174e-08, 'ExponentialLR_gamma': 0.9700428647065971, 'ReduceLROnPlateau_factor': 0.014194472482598669, 'ReduceLROnPlateau_patience': 6, 'SGD_learning_rate': 5.540876168540814e-05, 'SGD_momentum': 0.7753748228926656, 'SGD_weight_decay': 1.1771360216800085e-08, 'StepLR_gamma': 0.1469911132467317, 'StepLR_step_size': 14, 'batch_size': 601, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>, 'resnet_depth': 'resnet34', 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13209, 9)                                           \n",
      "(13209,)                                             \n",
      "3                                                    \n",
      "3                                                    \n",
      "  0%|          | 0/2 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "\n",
      "Training:   0%|                                      | 0/300 [00:00<?, ?epoch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/300],Train Loss: 1.5687,Val Loss: 1.5952    \n",
      "  0%|          | 0/2 [00:02<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:240: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "Training:   0%|1                             | 1/300 [00:02<11:42,  2.35s/epoch]\n",
      "Exception ignored in: \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "Exception ignored in: \n",
      "Exception ignored in: \n",
      "Exception ignored in: \n",
      "Exception ignored in: \n",
      "Exception ignored in: \n",
      "Exception ignored in: \n",
      "Exception ignored in: \n",
      "self._shutdown_workers()\n",
      "Exception ignored in: \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "Traceback (most recent call last):\n",
      "\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "Exception ignored in: \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "Traceback (most recent call last):\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "Traceback (most recent call last):\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "if w.is_alive():\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "self._shutdown_workers()\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "self._shutdown_workers()\n",
      "self._shutdown_workers()\n",
      "self._shutdown_workers()\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "self._shutdown_workers()\n",
      "self._shutdown_workers()\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "self._shutdown_workers()\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "if w.is_alive():\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "if w.is_alive():\n",
      "self._shutdown_workers()\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "AssertionError\n",
      "self._shutdown_workers()\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "if w.is_alive():\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "if w.is_alive():\n",
      "if w.is_alive():\n",
      ": \n",
      "can only test a child process\n",
      "if w.is_alive():\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError\n",
      ": \n",
      "can only test a child process\n",
      "if w.is_alive():\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "AssertionError\n",
      "AssertionError\n",
      "Exception ignored in: \n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "if w.is_alive():\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "if w.is_alive():\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "Exception ignored in: \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      ": \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "AssertionError\n",
      ": \n",
      "Traceback (most recent call last):\n",
      "\n",
      "can only test a child process\n",
      "Traceback (most recent call last):\n",
      "\n",
      "AssertionError\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError\n",
      "AssertionError\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      ": \n",
      "can only test a child process\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      ": \n",
      "AssertionError\n",
      "Exception ignored in: \n",
      ": \n",
      ": \n",
      "AssertionError\n",
      "can only test a child process\n",
      "self._shutdown_workers()\n",
      "self._shutdown_workers()\n",
      "can only test a child process\n",
      "Exception ignored in: \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "can only test a child process\n",
      "can only test a child process\n",
      ": \n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "Exception ignored in: \n",
      "Exception ignored in: \n",
      ": \n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "can only test a child process\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "if w.is_alive():\n",
      "Exception ignored in: \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "self._shutdown_workers()\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "if w.is_alive():\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError\n",
      ": \n",
      "can only test a child process\n",
      "Exception ignored in: \n",
      "self._shutdown_workers()\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "if w.is_alive():\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "Exception ignored in: \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "Traceback (most recent call last):\n",
      "\n",
      "can only test a child process\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "if w.is_alive():\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError\n",
      ": \n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "Exception ignored in: \n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "Traceback (most recent call last):\n",
      "\n",
      "can only test a child process\n",
      "self._shutdown_workers()\n",
      "self._shutdown_workers()\n",
      "self._shutdown_workers()\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError\n",
      ": \n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "AssertionError\n",
      ": \n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "self._shutdown_workers()\n",
      "if w.is_alive():\n",
      "if w.is_alive():\n",
      "if w.is_alive():\n",
      "Traceback (most recent call last):\n",
      "\n",
      "can only test a child process\n",
      "can only test a child process\n",
      "self._shutdown_workers()\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "if w.is_alive():\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "AssertionError\n",
      ": \n",
      "if w.is_alive():\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "self._shutdown_workers()\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError\n",
      "AssertionError\n",
      "can only test a child process\n",
      "if w.is_alive():\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "AssertionError\n",
      ": \n",
      "can only test a child process\n",
      "AssertionError\n",
      ": \n",
      ": \n",
      "can only test a child process\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError\n",
      ": \n",
      "can only test a child process\n",
      ": \n",
      "can only test a child process\n",
      "can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/300],Train Loss: 0.9753,Val Loss: 0.7687    \n",
      "  0%|          | 0/2 [00:05<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|2                             | 2/300 [00:05<13:54,  2.80s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/300],Train Loss: 0.6714,Val Loss: 0.6492    \n",
      "  0%|          | 0/2 [00:08<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|3                             | 3/300 [00:07<12:38,  2.55s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/300],Train Loss: 0.5811,Val Loss: 0.5895    \n",
      "  0%|          | 0/2 [00:10<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|4                             | 4/300 [00:10<12:09,  2.46s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/300],Train Loss: 0.5678,Val Loss: 0.6086    \n",
      "  0%|          | 0/2 [00:12<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|5                             | 5/300 [00:12<11:51,  2.41s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/300],Train Loss: 0.5335,Val Loss: 0.5457    \n",
      "  0%|          | 0/2 [00:15<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|6                             | 6/300 [00:14<11:40,  2.38s/epoch]\n",
      "Exception ignored in: \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "self._shutdown_workers()\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "if w.is_alive():\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError\n",
      ": \n",
      "can only test a child process\n",
      "Exception ignored in: \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "Exception ignored in: \n",
      "Traceback (most recent call last):\n",
      "\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "self._shutdown_workers()\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "self._shutdown_workers()\n",
      "if w.is_alive():\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "if w.is_alive():\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      ": \n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "can only test a child process\n",
      "AssertionError\n",
      ": \n",
      "can only test a child process\n",
      "Exception ignored in: \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "Exception ignored in: \n",
      "self._shutdown_workers()\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "if w.is_alive():\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError\n",
      ": \n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "can only test a child process\n",
      "self._shutdown_workers()\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "if w.is_alive():\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError\n",
      ": \n",
      "can only test a child process\n",
      "Exception ignored in: \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "self._shutdown_workers()\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "if w.is_alive():\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError\n",
      ": \n",
      "can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/300],Train Loss: 0.5198,Val Loss: 0.5553    \n",
      "  0%|          | 0/2 [00:17<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|7                             | 7/300 [00:17<11:39,  2.39s/epoch]\n",
      "Exception ignored in: \n",
      "Exception ignored in: \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "Exception ignored in: \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "self._shutdown_workers()\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "Exception ignored in: \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "self._shutdown_workers()\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "if w.is_alive():\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "Exception ignored in: \n",
      "if w.is_alive():\n",
      "Exception ignored in: \n",
      "Exception ignored in: \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "Exception ignored in: \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "Traceback (most recent call last):\n",
      "\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "Exception ignored in: \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "Exception ignored in: \n",
      "self._shutdown_workers()\n",
      "self._shutdown_workers()\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "Exception ignored in: \n",
      "Traceback (most recent call last):\n",
      "\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "self._shutdown_workers()\n",
      "self._shutdown_workers()\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "self._shutdown_workers()\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "Exception ignored in: \n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "AssertionError\n",
      "Traceback (most recent call last):\n",
      "\n",
      "if w.is_alive():\n",
      "if w.is_alive():\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "AssertionError\n",
      ": \n",
      "self._shutdown_workers()\n",
      "Traceback (most recent call last):\n",
      "\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "self._shutdown_workers()\n",
      ": \n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "if w.is_alive():\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "can only test a child process\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "can only test a child process\n",
      "self._shutdown_workers()\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "if w.is_alive():\n",
      "AssertionError\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "if w.is_alive():\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "self._shutdown_workers()\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "Exception ignored in: \n",
      "if w.is_alive():\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "AssertionError\n",
      "Exception ignored in: \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      ": \n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "if w.is_alive():\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "self._shutdown_workers()\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "if w.is_alive():\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "can only test a child process\n",
      "AssertionError\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "AssertionError\n",
      "if w.is_alive():\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "if w.is_alive():\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      ": \n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError\n",
      ": \n",
      "can only test a child process\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError\n",
      ": \n",
      "can only test a child process\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "self._shutdown_workers()\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError\n",
      ": \n",
      ": \n",
      "Exception ignored in: \n",
      "Exception ignored in: \n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "AssertionError\n",
      ": \n",
      "can only test a child process\n",
      "if w.is_alive():\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "can only test a child process\n",
      "can only test a child process\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "Traceback (most recent call last):\n",
      "\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "Exception ignored in: \n",
      "can only test a child process\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      ": \n",
      "can only test a child process\n",
      "AssertionError\n",
      "Traceback (most recent call last):\n",
      "\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError\n",
      ": \n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "AssertionError\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "self._shutdown_workers()\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "Exception ignored in: \n",
      ": \n",
      "can only test a child process\n",
      "Exception ignored in: \n",
      "Exception ignored in: \n",
      "Exception ignored in: \n",
      "can only test a child process\n",
      "self._shutdown_workers()\n",
      ": \n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "if w.is_alive():\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "Traceback (most recent call last):\n",
      "\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "can only test a child process\n",
      "Exception ignored in: \n",
      "Exception ignored in: \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "self._shutdown_workers()\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "if w.is_alive():\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "self._shutdown_workers()\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "self._shutdown_workers()\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "Exception ignored in: \n",
      "if w.is_alive():\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "self._shutdown_workers()\n",
      "self._shutdown_workers()\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "self._shutdown_workers()\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "AssertionError\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "if w.is_alive():\n",
      "if w.is_alive():\n",
      "self._shutdown_workers()\n",
      "if w.is_alive():\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "if w.is_alive():\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      ": \n",
      "if w.is_alive():\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "AssertionError\n",
      "self._shutdown_workers()\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "AssertionError\n",
      "can only test a child process\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "AssertionError\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      ": \n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "AssertionError\n",
      "self._shutdown_workers()\n",
      ": \n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError\n",
      "if w.is_alive():\n",
      ": \n",
      "AssertionError\n",
      "can only test a child process\n",
      "if w.is_alive():\n",
      ": \n",
      "can only test a child process\n",
      "can only test a child process\n",
      "AssertionError\n",
      ": \n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "can only test a child process\n",
      ": \n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      ": \n",
      "can only test a child process\n",
      "can only test a child process\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError\n",
      ": \n",
      "can only test a child process\n",
      "can only test a child process\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "if w.is_alive():\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "AssertionError\n",
      ": \n",
      "can only test a child process\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError\n",
      ": \n",
      "can only test a child process\n",
      "Exception ignored in: \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "Exception ignored in: \n",
      "Exception ignored in: \n",
      "Traceback (most recent call last):\n",
      "\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "self._shutdown_workers()\n",
      "Traceback (most recent call last):\n",
      "\n",
      "self._shutdown_workers()\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "if w.is_alive():\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "if w.is_alive():\n",
      "Exception ignored in: \n",
      "self._shutdown_workers()\n",
      "Exception ignored in: \n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "if w.is_alive():\n",
      "AssertionError\n",
      ": \n",
      "self._shutdown_workers()\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "can only test a child process\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "self._shutdown_workers()\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError\n",
      ": \n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "AssertionError\n",
      "Exception ignored in: \n",
      "if w.is_alive():\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      ": \n",
      "can only test a child process\n",
      "can only test a child process\n",
      "if w.is_alive():\n",
      "AssertionError\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "Traceback (most recent call last):\n",
      "\n",
      "Exception ignored in: \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "Exception ignored in: \n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      ": \n",
      "Traceback (most recent call last):\n",
      "\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "Traceback (most recent call last):\n",
      "\n",
      "self._shutdown_workers()\n",
      "can only test a child process\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError\n",
      ": \n",
      "self._shutdown_workers()\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "Exception ignored in: \n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "can only test a child process\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "self._shutdown_workers()\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "if w.is_alive():\n",
      "if w.is_alive():\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "if w.is_alive():\n",
      "Exception ignored in: \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "self._shutdown_workers()\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      ": \n",
      "if w.is_alive():\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "self._shutdown_workers()\n",
      "can only test a child process\n",
      "AssertionError\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError\n",
      ": \n",
      ": \n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "can only test a child process\n",
      "can only test a child process\n",
      "AssertionError\n",
      "if w.is_alive():\n",
      ": \n",
      "can only test a child process\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError\n",
      ": \n",
      "can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/300],Train Loss: 0.4741,Val Loss: 0.5226    \n",
      "  0%|          | 0/2 [00:21<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|8                             | 8/300 [00:21<14:00,  2.88s/epoch]\n",
      "Exception ignored in: \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "Exception ignored in: \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "self._shutdown_workers()\n",
      "self._shutdown_workers()\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "if w.is_alive():\n",
      "if w.is_alive():\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError\n",
      "AssertionError\n",
      ": \n",
      ": \n",
      "can only test a child process\n",
      "can only test a child process\n",
      "Exception ignored in: \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "Traceback (most recent call last):\n",
      "\n",
      "Exception ignored in: \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "self._shutdown_workers()\n",
      "self._shutdown_workers()\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "if w.is_alive():\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "if w.is_alive():\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "AssertionError\n",
      ": \n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError\n",
      ": \n",
      "can only test a child process\n",
      "can only test a child process\n",
      "Exception ignored in: \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "Exception ignored in: \n",
      "Exception ignored in: \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "Traceback (most recent call last):\n",
      "\n",
      "Exception ignored in: \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "Exception ignored in: \n",
      "Exception ignored in: \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "self._shutdown_workers()\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "Exception ignored in: \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "Exception ignored in: \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "self._shutdown_workers()\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "self._shutdown_workers()\n",
      "if w.is_alive():\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "Exception ignored in: \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "self._shutdown_workers()\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "if w.is_alive():\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "if w.is_alive():\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError\n",
      ": \n",
      "can only test a child process\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "if w.is_alive():\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "self._shutdown_workers()\n",
      "Exception ignored in: \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "Exception ignored in: \n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "Traceback (most recent call last):\n",
      "\n",
      "AssertionError\n",
      ": \n",
      "can only test a child process\n",
      "Traceback (most recent call last):\n",
      "\n",
      "self._shutdown_workers()\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "self._shutdown_workers()\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "AssertionError\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "self._shutdown_workers()\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "Exception ignored in: \n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      ": \n",
      "self._shutdown_workers()\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "if w.is_alive():\n",
      "self._shutdown_workers()\n",
      "if w.is_alive():\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "AssertionError\n",
      "if w.is_alive():\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "can only test a child process\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "if w.is_alive():\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      ": \n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "self._shutdown_workers()\n",
      "if w.is_alive():\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "Exception ignored in: \n",
      "if w.is_alive():\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "can only test a child process\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "AssertionError\n",
      ": \n",
      "AssertionError\n",
      "if w.is_alive():\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "Exception ignored in: \n",
      "AssertionError\n",
      ": \n",
      "Traceback (most recent call last):\n",
      "\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "self._shutdown_workers()\n",
      "can only test a child process\n",
      ": \n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "AssertionError\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      ": \n",
      "can only test a child process\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "AssertionError\n",
      ": \n",
      "can only test a child process\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      ": \n",
      "Exception ignored in: \n",
      "Traceback (most recent call last):\n",
      "\n",
      "can only test a child process\n",
      "self._shutdown_workers()\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "can only test a child process\n",
      "Exception ignored in: \n",
      "AssertionError\n",
      "can only test a child process\n",
      "Exception ignored in: \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "Exception ignored in: \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      ": \n",
      "can only test a child process\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "Traceback (most recent call last):\n",
      "\n",
      "Exception ignored in: \n",
      "self._shutdown_workers()\n",
      "if w.is_alive():\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "Exception ignored in: \n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "if w.is_alive():\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "Traceback (most recent call last):\n",
      "\n",
      "self._shutdown_workers()\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ade643f7130>\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "self._shutdown_workers()\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "if w.is_alive():\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "AssertionError\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "self._shutdown_workers()\n",
      "Traceback (most recent call last):\n",
      "\n",
      "if w.is_alive():\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      ": \n",
      "self._shutdown_workers()\n",
      "if w.is_alive():\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError\n",
      "can only test a child process\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "self._shutdown_workers()\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "self._shutdown_workers()\n",
      "  File \"/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "if w.is_alive():\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError\n",
      ": \n",
      "can only test a child process\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError\n",
      ": \n",
      "can only test a child process\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "if w.is_alive():\n",
      "if w.is_alive():\n",
      "AssertionError\n",
      ": \n",
      "if w.is_alive():\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      ": \n",
      "can only test a child process\n",
      "AssertionError\n",
      "  File \"/home/boom/.pyenv/versions/3.10.0/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "AssertionError\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "can only test a child process\n",
      ": \n",
      "can only test a child process\n",
      ": \n",
      "AssertionError\n",
      ": \n",
      "can only test a child process\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "can only test a child process\n",
      "AssertionError\n",
      ": \n",
      "can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/300],Train Loss: 0.4727,Val Loss: 0.5236    \n",
      "  0%|          | 0/2 [00:25<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|9                             | 9/300 [00:24<15:06,  3.12s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/300],Train Loss: 0.4492,Val Loss: 0.4753   \n",
      "  0%|          | 0/2 [00:27<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|9                            | 10/300 [00:26<13:46,  2.85s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/300],Train Loss: 0.4171,Val Loss: 0.4612   \n",
      "  0%|          | 0/2 [00:29<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|#                            | 11/300 [00:29<12:53,  2.68s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/300],Train Loss: 0.3969,Val Loss: 0.4598   \n",
      "  0%|          | 0/2 [00:31<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|#1                           | 12/300 [00:31<12:11,  2.54s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/300],Train Loss: 0.4097,Val Loss: 0.5639   \n",
      "  0%|          | 0/2 [00:34<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|#2                           | 13/300 [00:33<11:45,  2.46s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/300],Train Loss: 0.3893,Val Loss: 0.4081   \n",
      "  0%|          | 0/2 [00:36<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|#3                           | 14/300 [00:35<11:28,  2.41s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/300],Train Loss: 0.3500,Val Loss: 0.4283   \n",
      "  0%|          | 0/2 [00:38<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|#4                           | 15/300 [00:38<11:15,  2.37s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/300],Train Loss: 0.3553,Val Loss: 0.3875   \n",
      "  0%|          | 0/2 [00:40<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|#5                           | 16/300 [00:40<11:04,  2.34s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/300],Train Loss: 0.3300,Val Loss: 0.3641   \n",
      "  0%|          | 0/2 [00:43<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|#6                           | 17/300 [00:42<10:52,  2.30s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/300],Train Loss: 0.3283,Val Loss: 0.3434   \n",
      "  0%|          | 0/2 [00:45<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|#7                           | 18/300 [00:45<10:48,  2.30s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/300],Train Loss: 0.3469,Val Loss: 0.4062   \n",
      "  0%|          | 0/2 [00:47<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|#8                           | 19/300 [00:47<10:39,  2.28s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/300],Train Loss: 0.2952,Val Loss: 0.3305   \n",
      "  0%|          | 0/2 [00:49<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|#9                           | 20/300 [00:49<10:40,  2.29s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/300],Train Loss: 0.2971,Val Loss: 0.3412   \n",
      "  0%|          | 0/2 [00:52<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|##                           | 21/300 [00:51<10:35,  2.28s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/300],Train Loss: 0.2830,Val Loss: 0.3246   \n",
      "  0%|          | 0/2 [00:54<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|##1                          | 22/300 [00:54<10:34,  2.28s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/300],Train Loss: 0.2752,Val Loss: 0.3692   \n",
      "  0%|          | 0/2 [00:56<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|##2                          | 23/300 [00:56<10:34,  2.29s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/300],Train Loss: 0.3031,Val Loss: 0.3229   \n",
      "  0%|          | 0/2 [00:59<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|##3                          | 24/300 [00:58<10:33,  2.30s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/300],Train Loss: 0.2677,Val Loss: 0.3422   \n",
      "  0%|          | 0/2 [01:01<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|##4                          | 25/300 [01:01<10:30,  2.29s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/300],Train Loss: 0.2726,Val Loss: 0.3151   \n",
      "  0%|          | 0/2 [01:03<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|##5                          | 26/300 [01:03<10:25,  2.28s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/300],Train Loss: 0.2511,Val Loss: 0.3170   \n",
      "  0%|          | 0/2 [01:05<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|##6                          | 27/300 [01:05<10:22,  2.28s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/300],Train Loss: 0.2630,Val Loss: 0.3489   \n",
      "  0%|          | 0/2 [01:08<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|##7                          | 28/300 [01:07<10:20,  2.28s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/300],Train Loss: 0.2603,Val Loss: 0.3192   \n",
      "  0%|          | 0/2 [01:10<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|##8                          | 29/300 [01:10<10:16,  2.28s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/300],Train Loss: 0.2644,Val Loss: 0.3815   \n",
      "  0%|          | 0/2 [01:12<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|##9                          | 30/300 [01:12<10:13,  2.27s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/300],Train Loss: 0.2447,Val Loss: 0.3168   \n",
      "  0%|          | 0/2 [01:14<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|##9                          | 31/300 [01:14<10:09,  2.27s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/300],Train Loss: 0.2413,Val Loss: 0.3171   \n",
      "Early stopping triggered at epoch 32                 \n",
      "  0%|          | 0/2 [01:17<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|##9                          | 31/300 [01:16<11:07,  2.48s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model loaded from epoch 26                      \n",
      "  0%|          | 0/2 [01:17<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 19:50:31,098 - INFO - ResNetModel.py - Validation metrics rmse: 0.5631123955228351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [01:19<01:19, 79.18s/trial, best loss: 0.5631123955228351]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 19:50:31,110 - INFO - ResNetModel.py - Training with hyperparameters: {'AdamW_learning_rate': 0.0005493747562277502, 'AdamW_weight_decay': 5.979030232767242e-08, 'Adam_learning_rate': 0.00010037826615600942, 'Adam_weight_decay': 2.309091722462173e-08, 'ExponentialLR_gamma': 0.9526834243165615, 'ReduceLROnPlateau_factor': 0.021158305135007868, 'ReduceLROnPlateau_patience': 7, 'SGD_learning_rate': 9.52118823872863e-05, 'SGD_momentum': 0.6960145837348019, 'SGD_weight_decay': 2.4860021513335803e-08, 'StepLR_gamma': 0.2095872419296196, 'StepLR_step_size': 19, 'batch_size': 278, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'resnet_depth': 'resnet18', 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13209, 9)                                                                     \n",
      "(13209,)                                                                       \n",
      "3                                                                              \n",
      "3                                                                              \n",
      " 50%|█████     | 1/2 [01:19<01:19, 79.18s/trial, best loss: 0.5631123955228351]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "\n",
      "Training:   0%|                                      | 0/300 [00:00<?, ?epoch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/300],Train Loss: 1.4306,Val Loss: 1.1744                              \n",
      " 50%|█████     | 1/2 [01:21<01:19, 79.18s/trial, best loss: 0.5631123955228351]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|1                             | 1/300 [00:02<10:44,  2.15s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/300],Train Loss: 0.8152,Val Loss: 0.9333                              \n",
      " 50%|█████     | 1/2 [01:23<01:19, 79.18s/trial, best loss: 0.5631123955228351]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|2                             | 2/300 [00:04<10:36,  2.14s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/300],Train Loss: 0.6107,Val Loss: 0.6072                              \n",
      " 50%|█████     | 1/2 [01:25<01:19, 79.18s/trial, best loss: 0.5631123955228351]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|3                             | 3/300 [00:06<10:30,  2.12s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/300],Train Loss: 0.5102,Val Loss: 0.5618                              \n",
      " 50%|█████     | 1/2 [01:27<01:19, 79.18s/trial, best loss: 0.5631123955228351]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|4                             | 4/300 [00:08<10:25,  2.11s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/300],Train Loss: 0.4431,Val Loss: 0.5472                              \n",
      " 50%|█████     | 1/2 [01:29<01:19, 79.18s/trial, best loss: 0.5631123955228351]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|5                             | 5/300 [00:10<10:21,  2.11s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/300],Train Loss: 0.3958,Val Loss: 0.5425                              \n",
      " 50%|█████     | 1/2 [01:32<01:19, 79.18s/trial, best loss: 0.5631123955228351]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|6                             | 6/300 [00:12<10:17,  2.10s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/300],Train Loss: 0.3542,Val Loss: 0.5101                              \n",
      " 50%|█████     | 1/2 [01:34<01:19, 79.18s/trial, best loss: 0.5631123955228351]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|7                             | 7/300 [00:14<10:15,  2.10s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/300],Train Loss: 0.3279,Val Loss: 0.4908                              \n",
      " 50%|█████     | 1/2 [01:36<01:19, 79.18s/trial, best loss: 0.5631123955228351]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|8                             | 8/300 [00:16<10:11,  2.10s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/300],Train Loss: 0.2920,Val Loss: 0.4750                              \n",
      " 50%|█████     | 1/2 [01:38<01:19, 79.18s/trial, best loss: 0.5631123955228351]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|9                             | 9/300 [00:18<10:08,  2.09s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/300],Train Loss: 0.2643,Val Loss: 0.4670                             \n",
      " 50%|█████     | 1/2 [01:40<01:19, 79.18s/trial, best loss: 0.5631123955228351]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|9                            | 10/300 [00:21<10:06,  2.09s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/300],Train Loss: 0.2402,Val Loss: 0.4787                             \n",
      " 50%|█████     | 1/2 [01:42<01:19, 79.18s/trial, best loss: 0.5631123955228351]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|#                            | 11/300 [00:23<10:04,  2.09s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/300],Train Loss: 0.2277,Val Loss: 0.4809                             \n",
      " 50%|█████     | 1/2 [01:44<01:19, 79.18s/trial, best loss: 0.5631123955228351]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|#1                           | 12/300 [00:25<10:02,  2.09s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/300],Train Loss: 0.2134,Val Loss: 0.4582                             \n",
      " 50%|█████     | 1/2 [01:46<01:19, 79.18s/trial, best loss: 0.5631123955228351]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|#2                           | 13/300 [00:27<10:01,  2.09s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/300],Train Loss: 0.1987,Val Loss: 0.4974                             \n",
      " 50%|█████     | 1/2 [01:48<01:19, 79.18s/trial, best loss: 0.5631123955228351]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|#3                           | 14/300 [00:29<09:57,  2.09s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/300],Train Loss: 0.1929,Val Loss: 0.4551                             \n",
      " 50%|█████     | 1/2 [01:50<01:19, 79.18s/trial, best loss: 0.5631123955228351]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|#4                           | 15/300 [00:31<09:57,  2.10s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/300],Train Loss: 0.1600,Val Loss: 0.4403                             \n",
      " 50%|█████     | 1/2 [01:53<01:19, 79.18s/trial, best loss: 0.5631123955228351]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|#5                           | 16/300 [00:33<09:55,  2.10s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/300],Train Loss: 0.1504,Val Loss: 0.4422                             \n",
      " 50%|█████     | 1/2 [01:55<01:19, 79.18s/trial, best loss: 0.5631123955228351]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|#6                           | 17/300 [00:35<09:56,  2.11s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/300],Train Loss: 0.1472,Val Loss: 0.4551                             \n",
      " 50%|█████     | 1/2 [01:57<01:19, 79.18s/trial, best loss: 0.5631123955228351]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|#7                           | 18/300 [00:37<09:51,  2.10s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/300],Train Loss: 0.1423,Val Loss: 0.4325                             \n",
      " 50%|█████     | 1/2 [01:59<01:19, 79.18s/trial, best loss: 0.5631123955228351]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|#8                           | 19/300 [00:39<09:57,  2.12s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/300],Train Loss: 0.1319,Val Loss: 0.4527                             \n",
      " 50%|█████     | 1/2 [02:01<01:19, 79.18s/trial, best loss: 0.5631123955228351]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|#9                           | 20/300 [00:42<09:55,  2.13s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/300],Train Loss: 0.1278,Val Loss: 0.4379                             \n",
      " 50%|█████     | 1/2 [02:03<01:19, 79.18s/trial, best loss: 0.5631123955228351]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|##                           | 21/300 [00:44<09:52,  2.12s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/300],Train Loss: 0.1166,Val Loss: 0.4558                             \n",
      " 50%|█████     | 1/2 [02:05<01:19, 79.18s/trial, best loss: 0.5631123955228351]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|##1                          | 22/300 [00:46<09:48,  2.12s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/300],Train Loss: 0.1028,Val Loss: 0.4294                             \n",
      " 50%|█████     | 1/2 [02:07<01:19, 79.18s/trial, best loss: 0.5631123955228351]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|##2                          | 23/300 [00:48<09:40,  2.10s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/300],Train Loss: 0.0953,Val Loss: 0.4381                             \n",
      " 50%|█████     | 1/2 [02:09<01:19, 79.18s/trial, best loss: 0.5631123955228351]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|##3                          | 24/300 [00:50<09:33,  2.08s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/300],Train Loss: 0.0963,Val Loss: 0.4339                             \n",
      " 50%|█████     | 1/2 [02:11<01:19, 79.18s/trial, best loss: 0.5631123955228351]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|##4                          | 25/300 [00:52<09:28,  2.07s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/300],Train Loss: 0.0881,Val Loss: 0.4387                             \n",
      " 50%|█████     | 1/2 [02:13<01:19, 79.18s/trial, best loss: 0.5631123955228351]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|##5                          | 26/300 [00:54<09:22,  2.05s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/300],Train Loss: 0.0881,Val Loss: 0.4466                             \n",
      " 50%|█████     | 1/2 [02:15<01:19, 79.18s/trial, best loss: 0.5631123955228351]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|##6                          | 27/300 [00:56<09:16,  2.04s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/300],Train Loss: 0.0912,Val Loss: 0.4382                             \n",
      " 50%|█████     | 1/2 [02:17<01:19, 79.18s/trial, best loss: 0.5631123955228351]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|##7                          | 28/300 [00:58<09:13,  2.03s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/300],Train Loss: 0.0766,Val Loss: 0.4426                             \n",
      "Early stopping triggered at epoch 29                                           \n",
      " 50%|█████     | 1/2 [02:19<01:19, 79.18s/trial, best loss: 0.5631123955228351]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|##7                          | 28/300 [01:00<09:48,  2.16s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model loaded from epoch 23                                                \n",
      " 50%|█████     | 1/2 [02:19<01:19, 79.18s/trial, best loss: 0.5631123955228351]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 19:51:33,624 - INFO - ResNetModel.py - Validation metrics rmse: 0.665299706753578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [02:21<00:00, 70.85s/trial, best loss: 0.5631123955228351]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 19:51:33,629 - INFO - ResNetModel.py - Final Validation Metrics: {'mse': 0.31709556999146593, 'rmse': 0.5631123955228351, 'r2_score': 0.7702185824747919}\n",
      "2025-02-06 19:51:33,630 - INFO - ResNetModel.py - Loading model\n",
      "2025-02-06 19:51:33,631 - INFO - ResNetModel.py - Best hyperparameters: {'AdamW_learning_rate': 0.00041691320143948053, 'AdamW_weight_decay': 5.3327377727838295e-08, 'Adam_learning_rate': 0.000883609493567339, 'Adam_weight_decay': 5.3453713798712174e-08, 'ExponentialLR_gamma': 0.9700428647065971, 'ReduceLROnPlateau_factor': 0.014194472482598669, 'ReduceLROnPlateau_patience': 6, 'SGD_learning_rate': 5.540876168540814e-05, 'SGD_momentum': 0.7753748228926656, 'SGD_weight_decay': 1.1771360216800085e-08, 'StepLR_gamma': 0.1469911132467317, 'StepLR_step_size': 14, 'batch_size': 601, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>, 'resnet_depth': 'resnet34', 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>, 'default_params': {'early_stopping': True, 'verbose': False, 'iterations': 20, 'retrain': False, 'auto_lr_find': False, 'max_epochs': 300, 'val_size': 0.2, 'early_stopping_patience': 6}}\n",
      "2025-02-06 19:51:33,631 - INFO - ResNetModel.py - The best possible score for metric rmse is 0.0, we reached rmse = 0.5631123955228351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 19:51:34,700 - INFO - MLP.py - Starting hyperopt search with 2 evaluations, optimizing rmse metric\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running mlp on regression...\n",
      "Using dynamic loader for dataset: /home/boom/sdev/repos/AutoDeep/autodeep/examples/testautodata/cal_housing.csv\n",
      "  0%|          | 0/2 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 19:51:34,708 - INFO - MLP.py - Training with hyperparameters: {'activation': 'tanh', 'batch_size': 1252, 'hidden_layer_sizes': (128, 64, 32), 'max_iter': 1449, 'n_iter_no_change': 12, 'solver': 'sgd'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [01:25<01:25, 85.75s/trial, best loss: 0.5920209658152624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 19:53:00,465 - INFO - MLP.py - Training with hyperparameters: {'activation': 'tanh', 'batch_size': 1472, 'hidden_layer_sizes': (64, 32), 'max_iter': 1029, 'n_iter_no_change': 11, 'solver': 'adam'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [01:39<00:00, 49.66s/trial, best loss: 0.5725525237975416]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 19:53:14,023 - INFO - MLP.py - Final best hyperparameters: {'activation': 'tanh', 'batch_size': 1472, 'hidden_layer_sizes': (64, 32), 'max_iter': 1029, 'n_iter_no_change': 11, 'solver': 'adam', 'default_params': {'early_stopping': True, 'n_iter_no_change': 10, 'max_iter': 1000, 'hidden_layer_sizes': [32], 'activation': 'relu', 'solver': 'adam', 'batch_size': 1024, 'val_size': 0.15}}\n",
      "2025-02-06 19:53:14,025 - INFO - MLP.py - Final best rmse score: 0.5725525237975416\n",
      "2025-02-06 19:53:14,025 - INFO - MLP.py - Loading model\n",
      "2025-02-06 19:53:14,026 - INFO - MLP.py - Computing predictions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running xgb on regression...\n",
      "Using dynamic loader for dataset: /home/boom/sdev/repos/AutoDeep/autodeep/examples/testautodata/cal_housing.csv\n",
      "  0%|          | 0/2 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 19:53:14,127 - INFO - XGBoostTrainer.py - Hyperopt training with hyperparameters: {'colsample_bytree': 0.9317085201666937, 'gamma': 0.023542720433600173, 'learning_rate': 0.02257009318017118, 'max_depth': 5, 'min_child_weight': 5, 'n_estimators': 119, 'subsample': 0.804784757575745}\n",
      "2025-02-06 19:53:14,288 - INFO - XGBoostTrainer.py - Validation metrics: {'mse': 0.2972458835643864, 'rmse': 0.5452026078114323, 'r2_score': 0.7756801244917906}\n",
      "2025-02-06 19:53:14,300 - INFO - XGBoostTrainer.py - Train metrics: {'mse': 0.2972458835643864, 'rmse': 0.5452026078114323, 'r2_score': 0.7756801244917906}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:00<00:00,  5.57trial/s, best loss: 0.5452026078114323]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 19:53:14,305 - INFO - XGBoostTrainer.py - Hyperopt training with hyperparameters: {'colsample_bytree': 0.8906721612968371, 'gamma': 0.049720043026671615, 'learning_rate': 0.04776774932724804, 'max_depth': 6, 'min_child_weight': 1, 'n_estimators': 82, 'subsample': 0.6447152123951665}\n",
      "2025-02-06 19:53:14,445 - INFO - XGBoostTrainer.py - Validation metrics: {'mse': 0.23713864146837446, 'rmse': 0.4869688300788609, 'r2_score': 0.8210407158730286}\n",
      "2025-02-06 19:53:14,455 - INFO - XGBoostTrainer.py - Train metrics: {'mse': 0.23713864146837446, 'rmse': 0.4869688300788609, 'r2_score': 0.8210407158730286}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  5.98trial/s, best loss: 0.4869688300788609]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 19:53:14,458 - INFO - XGBoostTrainer.py - Loading model\n",
      "2025-02-06 19:53:14,459 - INFO - XGBoostTrainer.py - Best hyperparameters: {'colsample_bytree': 0.8906721612968371, 'gamma': 0.049720043026671615, 'learning_rate': 0.04776774932724804, 'max_depth': 6, 'min_child_weight': 1, 'n_estimators': 82, 'subsample': 0.6447152123951665, 'default_params': {'retrain': True, 'val_size': 0.2, 'early_stopping_rounds': 100, 'verbose': False, 'learning_rate': 0.3, 'max_depth': 6, 'n_estimators': 100, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 0.0}}\n",
      "2025-02-06 19:53:14,459 - INFO - XGBoostTrainer.py - The best possible score for metric rmse is 0.0, we reached rmse = 0.4869688300788609\n",
      "2025-02-06 19:53:14,460 - INFO - XGBoostTrainer.py - Computing predictions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running catboost on regression...\n",
      "Using dynamic loader for dataset: /home/boom/sdev/repos/AutoDeep/autodeep/examples/testautodata/cal_housing.csv\n",
      "  0%|          | 0/2 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 19:53:14,496 - INFO - CatBoostModel.py - Hyperopt training with hyperparameters: {'iterations': 330}\n",
      "2025-02-06 19:53:15,223 - INFO - CatBoostModel.py - Validation metrics: {'mse': 0.2073060838582827, 'rmse': 0.4553087785868868, 'r2_score': 0.8416215935347845}\n",
      "2025-02-06 19:53:15,228 - INFO - CatBoostModel.py - Train metrics: {'mse': 0.2073060838582827, 'rmse': 0.4553087785868868, 'r2_score': 0.8416215935347845}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:00<00:00,  1.36trial/s, best loss: 0.4553087785868868]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 19:53:15,230 - INFO - CatBoostModel.py - Hyperopt training with hyperparameters: {'iterations': 156}\n",
      "2025-02-06 19:53:15,839 - INFO - CatBoostModel.py - Validation metrics: {'mse': 0.21881765714810242, 'rmse': 0.46777949628869203, 'r2_score': 0.8328269426513326}\n",
      "2025-02-06 19:53:15,844 - INFO - CatBoostModel.py - Train metrics: {'mse': 0.21881765714810242, 'rmse': 0.46777949628869203, 'r2_score': 0.8328269426513326}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.48trial/s, best loss: 0.4553087785868868]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 19:53:15,846 - INFO - CatBoostModel.py - Loading model\n",
      "2025-02-06 19:53:15,847 - INFO - CatBoostModel.py - Best hyperparameters: {'iterations': 330, 'default_params': {'retrain': False, 'val_size': 0.15, 'early_stopping_rounds': 100, 'verbose': False, 'iterations': 500}}\n",
      "2025-02-06 19:53:15,848 - INFO - CatBoostModel.py - The best possible score for metric rmse is 0.0, we reached rmse = 0.4553087785868868\n",
      "2025-02-06 19:53:15,848 - INFO - CatBoostModel.py - Computing predictions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running categoryembedding on regression...\n",
      "Using dynamic loader for dataset: /home/boom/sdev/repos/AutoDeep/autodeep/examples/testautodata/cal_housing.csv\n",
      "2025-02-06 19:53:15,882 - INFO - CommonStructure.py - CategoryEmbeddingTrainer - Initialized CategoryEmbeddingTrainer with problem type regression\n",
      "2025-02-06 19:53:15,883 - INFO - CommonStructure.py - CategoryEmbeddingTrainer - Device cuda is available\n",
      "2025-02-06 19:53:15,884 - INFO - CommonStructure.py - CategoryEmbeddingTrainer - Trainer initialized\n",
      "2025-02-06 19:53:15,884 - INFO - CommonStructure.py - CategoryEmbeddingTrainer - Starting hyperopt search 2 evals maximizing rmse metric on dataset\n",
      "SPACE ######################################################\n",
      "{'batch_size': <hyperopt.pyll.base.Apply object at 0x7adea178a7a0>, 'layers': <hyperopt.pyll.base.Apply object at 0x7adea1789a20>, 'activation': <hyperopt.pyll.base.Apply object at 0x7adea178b070>, 'use_batch_norm': <hyperopt.pyll.base.Apply object at 0x7adea17897e0>, 'initialization': <hyperopt.pyll.base.Apply object at 0x7adea1789ea0>, 'dropout': <hyperopt.pyll.base.Apply object at 0x7adea1788d60>, 'embedding_dropout': <hyperopt.pyll.base.Apply object at 0x7adea178a0b0>, 'optimizer_fn': <hyperopt.pyll.base.Apply object at 0x7adea17892d0>, 'scheduler_fn': <hyperopt.pyll.base.Apply object at 0x7adea169f490>}\n",
      "2025-02-06 19:53:15,888 - DEBUG - CommonStructure.py - CategoryEmbeddingTrainer - Full dataset shape : (16512, 10)\n",
      "2025-02-06 19:53:15,891 - DEBUG - CommonStructure.py - CategoryEmbeddingTrainer - Train set shape: (14035, 10), Test set shape: (2477, 10)\n",
      "  0%|          | 0/2 [00:00<?, ?trial/s, best loss=?]2025-02-06 19:53:15,917 - INFO - CommonStructure.py - CategoryEmbeddingTrainer - Training with hyperparameters: {'activation': 'ReLU', 'batch_size': 352, 'dropout': 0.07180182756042691, 'embedding_dropout': 0.04456699223511802, 'initialization': 'xavier', 'layers': '256-128-64-32', 'optimizer_fn': {'AdamW_learning_rate': 0.0002369073315019895, 'AdamW_weight_decay': 2.7190091816919235e-08, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>}, 'scheduler_fn': {'StepLR_gamma': 0.24871568886900097, 'StepLR_step_size': 27, 'scheduler_fn': <class 'torch.optim.lr_scheduler.StepLR'>}, 'use_batch_norm': False}\n",
      "tabular model params                                 \n",
      "{'activation': 'ReLU', 'batch_size': 352, 'dropout': 0.07180182756042691, 'embedding_dropout': 0.04456699223511802, 'initialization': 'xavier', 'layers': '256-128-64-32', 'optimizer_fn': {'AdamW_learning_rate': 0.0002369073315019895, 'AdamW_weight_decay': 2.7190091816919235e-08, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>}, 'scheduler_fn': {'StepLR_gamma': 0.24871568886900097, 'StepLR_step_size': 27, 'scheduler_fn': <class 'torch.optim.lr_scheduler.StepLR'>}, 'use_batch_norm': False}\n",
      "tabular model outer params                           \n",
      "{'early_stopping_rounds': 10, 'verbose': False, 'iterations': 20, 'retrain': False, 'auto_lr_find': False, 'max_epochs': 3, 'val_size': 0.15, 'early_stopping_patience': 20}\n",
      "  0%|          | 0/2 [00:00<?, ?trial/s, best loss=?]2025-02-06 19:53:15,931 - WARNING - CommonStructure.py - CategoryEmbeddingTrainer - You are passing some invalid parameters to the model {'batch_size': 352, 'optimizer_fn': {'AdamW_learning_rate': 0.0002369073315019895, 'AdamW_weight_decay': 2.7190091816919235e-08, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>}, 'scheduler_fn': {'StepLR_gamma': 0.24871568886900097, 'StepLR_step_size': 27, 'scheduler_fn': <class 'torch.optim.lr_scheduler.StepLR'>}}\n",
      "2025-02-06 19:53:15,932 - DEBUG - CommonStructure.py - CategoryEmbeddingTrainer - compatible parameters: {'activation': 'ReLU', 'dropout': 0.07180182756042691, 'embedding_dropout': 0.04456699223511802, 'initialization': 'xavier', 'layers': '256-128-64-32', 'use_batch_norm': False, 'target_range': [(0.11999200000000002, 6.000011999999999)]}\n",
      "DataConfig(target=['target'], continuous_cols=['Unnamed: 0', 'MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude'], categorical_cols=[], date_columns=[], encode_date_columns=True, validation_split=0.2, continuous_feature_transform=None, normalize_continuous_features=True, quantile_noise=0, num_workers=4, pin_memory=True, handle_unknown_categories=True, handle_missing_values=True, dataloader_kwargs={})\n",
      "CategoryEmbeddingModelConfig(task='regression', head='LinearHead', head_config={'layers': ''}, embedding_dims=None, embedding_dropout=0.0, batch_norm_continuous_input=True, learning_rate=0.0002369073315019895, loss='MSELoss', metrics=['mean_squared_error'], metrics_prob_input=[False], metrics_params=[{}], target_range=None, virtual_batch_size=None, seed=42, _module_src='models.category_embedding', _model_name='CategoryEmbeddingModel', _backbone_name='CategoryEmbeddingBackbone', _config_name='CategoryEmbeddingModelConfig', layers='256-128-64-32', activation='ReLU', use_batch_norm=False, initialization='kaiming', dropout=0.0)\n",
      "OptimizerConfig(optimizer='AdamW', optimizer_params={'weight_decay': 2.7190091816919235e-08}, lr_scheduler='StepLR', lr_scheduler_params={'step_size': 27, 'gamma': 0.24871568886900097}, lr_scheduler_monitor_metric='valid_loss')\n",
      "TrainerConfig(batch_size=352, data_aware_init_batch_size=2000, fast_dev_run=False, max_epochs=3, min_epochs=1, max_time=None, accelerator='auto', devices=-1, devices_list=None, accumulate_grad_batches=1, auto_lr_find=False, auto_select_gpus=True, check_val_every_n_epoch=1, gradient_clip_val=0.0, overfit_batches=0.0, deterministic=False, profiler=None, early_stopping='valid_loss', early_stopping_min_delta=0.0, early_stopping_mode='min', early_stopping_patience=20, early_stopping_kwargs={}, checkpoints='valid_loss', checkpoints_path='ptabular_checkpoints', checkpoints_every_n_epochs=10, checkpoints_name=None, checkpoints_mode='min', checkpoints_save_top_k=1, checkpoints_kwargs={}, load_best=True, track_grad_norm=-1, progress_bar='rich', precision=32, seed=42, trainer_kwargs={})\n",
      "  0%|          | 0/2 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:53:15</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">972</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">146</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m19:53:15\u001b[0m,\u001b[1;36m972\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m146\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:53:16</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">005</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m19:53:16\u001b[0m,\u001b[1;36m005\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:53:16</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">010</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m19:53:16\u001b[0m,\u001b[1;36m010\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:53:16</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">035</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: CategoryEmbeddingModel \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m19:53:16\u001b[0m,\u001b[1;36m035\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: CategoryEmbeddingModel \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:53:16</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">077</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m19:53:16\u001b[0m,\u001b[1;36m077\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:53:16</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">090</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m19:53:16\u001b[0m,\u001b[1;36m090\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/boom/sdev/repos/AutoDeep/autodeep/examples/ptabular_checkpoints exists and is not empty.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                      </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ custom_loss      │ MSELoss                   │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _backbone        │ CategoryEmbeddingBackbone │ 45.8 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _embedding_layer │ Embedding1dLayer          │     18 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ head             │ LinearHead                │     33 │ train │\n",
       "└───┴──────────────────┴───────────────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType                     \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ custom_loss      │ MSELoss                   │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ CategoryEmbeddingBackbone │ 45.8 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer          │     18 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ head             │ LinearHead                │     33 │ train │\n",
       "└───┴──────────────────┴───────────────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 45.8 K                                                                                           \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 45.8 K                                                                                               \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 18                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 45.8 K                                                                                           \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 45.8 K                                                                                               \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 18                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be7483bfa7164e24a8f16034985f546d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number \n",
       "of training batches (40) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for \n",
       "log_every_n_steps if you want to see logs for the training epoch.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number \n",
       "of training batches (40) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for \n",
       "log_every_n_steps if you want to see logs for the training epoch.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:53:20</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">120</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m19:53:20\u001b[0m,\u001b[1;36m120\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:53:20</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">123</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m19:53:20\u001b[0m,\u001b[1;36m123\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:53:20</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">126</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1537</span><span style=\"font-weight: bold\">}</span> - WARNING - No best model available to load. Did you\n",
       "run it more than <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> epoch?<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                                                                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m19:53:20\u001b[0m,\u001b[1;36m126\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1537\u001b[0m\u001b[1m}\u001b[0m - WARNING - No best model available to load. Did you\n",
       "run it more than \u001b[1;36m1\u001b[0m epoch?\u001b[33m...\u001b[0m                                                                                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-06 19:53:20,455 - INFO - CommonStructure.py - CategoryEmbeddingTrainer - Validation metrics: {'mse': 0.7976088493869462, 'rmse': 0.8930894968517692, 'r2_score': 0.42312124142851226}\n",
      " 50%|█████     | 1/2 [00:04<00:04,  4.91s/trial, best loss: 0.8930894968517692]2025-02-06 19:53:20,826 - INFO - CommonStructure.py - CategoryEmbeddingTrainer - Training with hyperparameters: {'activation': 'ReLU', 'batch_size': 608, 'dropout': 0.13793074406282088, 'embedding_dropout': 0.08748838326419968, 'initialization': 'random', 'layers': '256-128', 'optimizer_fn': {'Adam_learning_rate': 0.0003929327884259557, 'Adam_weight_decay': 3.044740079823129e-08, 'optimizer_fn': <class 'torch.optim.adam.Adam'>}, 'scheduler_fn': {'ReduceLROnPlateau_factor': 0.054041101815896615, 'ReduceLROnPlateau_patience': 9, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>}, 'use_batch_norm': True}\n",
      "tabular model params                                                           \n",
      "{'activation': 'ReLU', 'batch_size': 608, 'dropout': 0.13793074406282088, 'embedding_dropout': 0.08748838326419968, 'initialization': 'random', 'layers': '256-128', 'optimizer_fn': {'Adam_learning_rate': 0.0003929327884259557, 'Adam_weight_decay': 3.044740079823129e-08, 'optimizer_fn': <class 'torch.optim.adam.Adam'>}, 'scheduler_fn': {'ReduceLROnPlateau_factor': 0.054041101815896615, 'ReduceLROnPlateau_patience': 9, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>}, 'use_batch_norm': True}\n",
      "tabular model outer params                                                     \n",
      "{'early_stopping_rounds': 10, 'verbose': False, 'iterations': 20, 'retrain': False, 'auto_lr_find': False, 'max_epochs': 3, 'val_size': 0.15, 'early_stopping_patience': 20}\n",
      " 50%|█████     | 1/2 [00:04<00:04,  4.91s/trial, best loss: 0.8930894968517692]2025-02-06 19:53:20,839 - WARNING - CommonStructure.py - CategoryEmbeddingTrainer - You are passing some invalid parameters to the model {'batch_size': 608, 'optimizer_fn': {'Adam_learning_rate': 0.0003929327884259557, 'Adam_weight_decay': 3.044740079823129e-08, 'optimizer_fn': <class 'torch.optim.adam.Adam'>}, 'scheduler_fn': {'ReduceLROnPlateau_factor': 0.054041101815896615, 'ReduceLROnPlateau_patience': 9, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>}}\n",
      "2025-02-06 19:53:20,840 - DEBUG - CommonStructure.py - CategoryEmbeddingTrainer - compatible parameters: {'activation': 'ReLU', 'dropout': 0.13793074406282088, 'embedding_dropout': 0.08748838326419968, 'initialization': 'random', 'layers': '256-128', 'use_batch_norm': True, 'target_range': [(0.11999200000000002, 6.000011999999999)]}\n",
      "DataConfig(target=['target'], continuous_cols=['Unnamed: 0', 'MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude'], categorical_cols=[], date_columns=[], encode_date_columns=True, validation_split=0.2, continuous_feature_transform=None, normalize_continuous_features=True, quantile_noise=0, num_workers=4, pin_memory=True, handle_unknown_categories=True, handle_missing_values=True, dataloader_kwargs={})\n",
      "CategoryEmbeddingModelConfig(task='regression', head='LinearHead', head_config={'layers': ''}, embedding_dims=None, embedding_dropout=0.0, batch_norm_continuous_input=True, learning_rate=0.0003929327884259557, loss='MSELoss', metrics=['mean_squared_error'], metrics_prob_input=[False], metrics_params=[{}], target_range=None, virtual_batch_size=None, seed=42, _module_src='models.category_embedding', _model_name='CategoryEmbeddingModel', _backbone_name='CategoryEmbeddingBackbone', _config_name='CategoryEmbeddingModelConfig', layers='256-128', activation='ReLU', use_batch_norm=False, initialization='kaiming', dropout=0.0)\n",
      "OptimizerConfig(optimizer='Adam', optimizer_params={'weight_decay': 3.044740079823129e-08}, lr_scheduler='ReduceLROnPlateau', lr_scheduler_params={'factor': 0.054041101815896615, 'patience': 9, 'min_lr': 1e-08, 'verbose': True, 'mode': 'min'}, lr_scheduler_monitor_metric='valid_loss')\n",
      "TrainerConfig(batch_size=608, data_aware_init_batch_size=2000, fast_dev_run=False, max_epochs=3, min_epochs=1, max_time=None, accelerator='auto', devices=-1, devices_list=None, accumulate_grad_batches=1, auto_lr_find=False, auto_select_gpus=True, check_val_every_n_epoch=1, gradient_clip_val=0.0, overfit_batches=0.0, deterministic=False, profiler=None, early_stopping='valid_loss', early_stopping_min_delta=0.0, early_stopping_mode='min', early_stopping_patience=20, early_stopping_kwargs={}, checkpoints='valid_loss', checkpoints_path='ptabular_checkpoints', checkpoints_every_n_epochs=10, checkpoints_name=None, checkpoints_mode='min', checkpoints_save_top_k=1, checkpoints_kwargs={}, load_best=True, track_grad_norm=-1, progress_bar='rich', precision=32, seed=42, trainer_kwargs={})\n",
      " 50%|█████     | 1/2 [00:04<00:04,  4.91s/trial, best loss: 0.8930894968517692]"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:53:20</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">872</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">146</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m19:53:20\u001b[0m,\u001b[1;36m872\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m146\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:53:20</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">897</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m19:53:20\u001b[0m,\u001b[1;36m897\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:53:20</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">901</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m19:53:20\u001b[0m,\u001b[1;36m901\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:53:20</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">922</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: CategoryEmbeddingModel \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m19:53:20\u001b[0m,\u001b[1;36m922\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: CategoryEmbeddingModel \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:53:20</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">953</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m19:53:20\u001b[0m,\u001b[1;36m953\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:53:20</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">964</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m19:53:20\u001b[0m,\u001b[1;36m964\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/boom/sdev/repos/AutoDeep/autodeep/examples/ptabular_checkpoints exists and is not empty.\n",
      "\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                      </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ custom_loss      │ MSELoss                   │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _backbone        │ CategoryEmbeddingBackbone │ 35.5 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _embedding_layer │ Embedding1dLayer          │     18 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ head             │ LinearHead                │    129 │ train │\n",
       "└───┴──────────────────┴───────────────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType                     \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ custom_loss      │ MSELoss                   │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ CategoryEmbeddingBackbone │ 35.5 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer          │     18 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ head             │ LinearHead                │    129 │ train │\n",
       "└───┴──────────────────┴───────────────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 35.6 K                                                                                           \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 35.6 K                                                                                               \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 14                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 35.6 K                                                                                           \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 35.6 K                                                                                               \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 14                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f93899df0954166acde692588935310",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number \n",
       "of training batches (24) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for \n",
       "log_every_n_steps if you want to see logs for the training epoch.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number \n",
       "of training batches (24) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for \n",
       "log_every_n_steps if you want to see logs for the training epoch.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:53:24</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">179</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m19:53:24\u001b[0m,\u001b[1;36m179\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:53:24</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">182</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m19:53:24\u001b[0m,\u001b[1;36m182\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:53:24</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">184</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1537</span><span style=\"font-weight: bold\">}</span> - WARNING - No best model available to load. Did you\n",
       "run it more than <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> epoch?<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                                                                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m19:53:24\u001b[0m,\u001b[1;36m184\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1537\u001b[0m\u001b[1m}\u001b[0m - WARNING - No best model available to load. Did you\n",
       "run it more than \u001b[1;36m1\u001b[0m epoch?\u001b[33m...\u001b[0m                                                                                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-06 19:53:24,463 - INFO - CommonStructure.py - CategoryEmbeddingTrainer - Validation metrics: {'mse': 0.6092189092900453, 'rmse': 0.780524765327818, 'r2_score': 0.5593761925289028}\n",
      "100%|██████████| 2/2 [00:08<00:00,  4.47s/trial, best loss: 0.780524765327818] \n",
      "2025-02-06 19:53:24,845 - INFO - CommonStructure.py - CategoryEmbeddingTrainer - Final validation metrics: {'mse': 0.6092189092900453, 'rmse': 0.780524765327818, 'r2_score': 0.5593761925289028}\n",
      "2025-02-06 19:53:24,845 - INFO - CommonStructure.py - CategoryEmbeddingTrainer - Loading model\n",
      "2025-02-06 19:53:24,846 - DEBUG - CommonStructure.py - CategoryEmbeddingTrainer - Model loaded successfully\n",
      "2025-02-06 19:53:24,847 - INFO - CommonStructure.py - CategoryEmbeddingTrainer - Best hyperparameters: {'activation': 'ReLU', 'batch_size': 608, 'dropout': 0.13793074406282088, 'embedding_dropout': 0.08748838326419968, 'initialization': 'random', 'layers': '256-128', 'optimizer_fn': {'Adam_learning_rate': 0.0003929327884259557, 'Adam_weight_decay': 3.044740079823129e-08, 'optimizer_fn': <class 'torch.optim.adam.Adam'>}, 'scheduler_fn': {'ReduceLROnPlateau_factor': 0.054041101815896615, 'ReduceLROnPlateau_patience': 9, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>}, 'use_batch_norm': True, 'default_params': {'early_stopping_rounds': 10, 'verbose': False, 'iterations': 20, 'retrain': False, 'auto_lr_find': False, 'max_epochs': 3, 'val_size': 0.15, 'early_stopping_patience': 20}}\n",
      "2025-02-06 19:53:24,847 - INFO - CommonStructure.py - CategoryEmbeddingTrainer - The best possible score for metric rmse is 0.0, we reached rmse = 0.780524765327818\n",
      "2025-02-06 19:53:24,848 - INFO - CommonStructure.py - CategoryEmbeddingTrainer - Computing predictions\n",
      "2025-02-06 19:53:25,134 - DEBUG - CommonStructure.py - CategoryEmbeddingTrainer - [0.70382917 0.9932026  3.063837   2.6122823  1.6807697  1.5114846\n",
      " 2.8048086  1.9617125  2.5558012  3.853316  ]\n",
      "2025-02-06 19:53:25,135 - DEBUG - CommonStructure.py - CategoryEmbeddingTrainer - Computed predictions successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 19:53:25,172 - INFO - SoftOrdering1DCNN.py - Device cuda is available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running s1dcnn on regression...\n",
      "Using dynamic loader for dataset: /home/boom/sdev/repos/AutoDeep/autodeep/examples/testautodata/cal_housing.csv\n",
      "batch_size [1024, 512, 256]\n",
      "hidden_size [4096, 2048, 1024]\n",
      "optimizer_fn {'Adam': {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}, 'SGD': {'weight_decay': [0.0, 1e-07], 'momentum': [0.0, 0.9], 'learning_rate': [0.001, 1e-05]}, 'AdamW': {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}}\n",
      "dict_keys(['Adam', 'SGD', 'AdamW'])\n",
      "Adam {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}\n",
      "weight_decay [0.0, 1e-07]\n",
      "learning_rate [0.001, 0.0001]\n",
      "SGD {'weight_decay': [0.0, 1e-07], 'momentum': [0.0, 0.9], 'learning_rate': [0.001, 1e-05]}\n",
      "weight_decay [0.0, 1e-07]\n",
      "momentum [0.0, 0.9]\n",
      "learning_rate [0.001, 1e-05]\n",
      "AdamW {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}\n",
      "weight_decay [0.0, 1e-07]\n",
      "learning_rate [0.001, 0.0001]\n",
      "scheduler_fn {'ReduceLROnPlateau': {'factor': [0.1, 0.01], 'patience': [5, 10]}, 'StepLR': {'step_size': [10, 30], 'gamma': [0.1, 0.5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}\n",
      "dict_keys(['ReduceLROnPlateau', 'StepLR', 'ExponentialLR'])\n",
      "ReduceLROnPlateau {'factor': [0.1, 0.01], 'patience': [5, 10]}\n",
      "factor [0.1, 0.01]\n",
      "patience [5, 10]\n",
      "StepLR {'step_size': [10, 30], 'gamma': [0.1, 0.5]}\n",
      "step_size [10, 30]\n",
      "gamma [0.1, 0.5]\n",
      "ExponentialLR {'gamma': [0.9, 0.99]}\n",
      "gamma [0.9, 0.99]\n",
      "  0%|          | 0/2 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 19:53:25,195 - INFO - SoftOrdering1DCNN.py - Training with hyperparameters: {'AdamW_learning_rate': 0.00041691320143948053, 'AdamW_weight_decay': 5.3327377727838295e-08, 'Adam_learning_rate': 0.000883609493567339, 'Adam_weight_decay': 5.3453713798712174e-08, 'ExponentialLR_gamma': 0.9700428647065971, 'ReduceLROnPlateau_factor': 0.014194472482598669, 'ReduceLROnPlateau_patience': 6, 'SGD_learning_rate': 5.540876168540814e-05, 'SGD_momentum': 0.7753748228926656, 'SGD_weight_decay': 1.1771360216800085e-08, 'StepLR_gamma': 0.1469911132467317, 'StepLR_step_size': 14, 'batch_size': 601, 'hidden_size': 1024, 'optimizer_fn': <class 'torch.optim.sgd.SGD'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>}\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n",
      "\n",
      "Training:   0%|                                        | 0/1 [00:00<?, ?epoch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Train Loss: 5.6209, Val Loss: 9.6070    \n",
      "  0%|          | 0/2 [00:01<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:240: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "Training: 100%|################################| 1/1 [00:01<00:00,  1.63s/epoch]\n",
      "Training: 100%|################################| 1/1 [00:01<00:00,  1.63s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model loaded from epoch 1                       \n",
      "  0%|          | 0/2 [00:01<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 19:53:28,587 - INFO - SoftOrdering1DCNN.py - Validation metrics: {'mse': 9.607042136512048, 'rmse': 3.0995228885284987, 'r2_score': -5.948391489781966}\n",
      "2025-02-06 19:53:28,588 - INFO - SoftOrdering1DCNN.py - Training metrics: {'mse': 5.644722580951538, 'rmse': 2.375862492012435, 'r2_score': -3.2486446629613237}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:03<00:03,  3.40s/trial, best loss: 3.0995228885284987]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 19:53:28,603 - INFO - SoftOrdering1DCNN.py - Training with hyperparameters: {'AdamW_learning_rate': 0.0005493747562277502, 'AdamW_weight_decay': 5.979030232767242e-08, 'Adam_learning_rate': 0.00010037826615600942, 'Adam_weight_decay': 2.309091722462173e-08, 'ExponentialLR_gamma': 0.9526834243165615, 'ReduceLROnPlateau_factor': 0.021158305135007868, 'ReduceLROnPlateau_patience': 7, 'SGD_learning_rate': 9.52118823872863e-05, 'SGD_momentum': 0.6960145837348019, 'SGD_weight_decay': 2.4860021513335803e-08, 'StepLR_gamma': 0.2095872419296196, 'StepLR_step_size': 19, 'batch_size': 278, 'hidden_size': 4096, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>}\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n",
      "\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "\n",
      "Training:   0%|                                        | 0/1 [00:00<?, ?epoch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Train Loss: 4.9044, Val Loss: 101.0335                            \n",
      " 50%|█████     | 1/2 [00:05<00:03,  3.40s/trial, best loss: 3.0995228885284987]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|################################| 1/1 [00:02<00:00,  2.03s/epoch]\n",
      "Training: 100%|################################| 1/1 [00:02<00:00,  2.03s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model loaded from epoch 1                                                 \n",
      " 50%|█████     | 1/2 [00:05<00:03,  3.40s/trial, best loss: 3.0995228885284987]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 19:53:32,534 - INFO - SoftOrdering1DCNN.py - Validation metrics: {'mse': 101.03354609038692, 'rmse': 10.051544462936375, 'r2_score': -72.07354562013148}\n",
      "2025-02-06 19:53:32,535 - INFO - SoftOrdering1DCNN.py - Training metrics: {'mse': 7.0042868707471, 'rmse': 2.6465613294890975, 'r2_score': -4.271955460073871}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:07<00:00,  3.67s/trial, best loss: 3.0995228885284987]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 19:53:32,539 - INFO - SoftOrdering1DCNN.py - Final Validation Metrics: {'mse': 9.607042136512048, 'rmse': 3.0995228885284987, 'r2_score': -5.948391489781966}\n",
      "2025-02-06 19:53:32,539 - INFO - SoftOrdering1DCNN.py - Final Training Metrics: {'mse': 5.644722580951538, 'rmse': 2.375862492012435, 'r2_score': -3.2486446629613237}\n",
      "2025-02-06 19:53:32,540 - INFO - SoftOrdering1DCNN.py - Loading model\n",
      "2025-02-06 19:53:32,540 - INFO - SoftOrdering1DCNN.py - Best hyperparameters: {'AdamW_learning_rate': 0.00041691320143948053, 'AdamW_weight_decay': 5.3327377727838295e-08, 'Adam_learning_rate': 0.000883609493567339, 'Adam_weight_decay': 5.3453713798712174e-08, 'ExponentialLR_gamma': 0.9700428647065971, 'ReduceLROnPlateau_factor': 0.014194472482598669, 'ReduceLROnPlateau_patience': 6, 'SGD_learning_rate': 5.540876168540814e-05, 'SGD_momentum': 0.7753748228926656, 'SGD_weight_decay': 1.1771360216800085e-08, 'StepLR_gamma': 0.1469911132467317, 'StepLR_step_size': 14, 'batch_size': 601, 'hidden_size': 1024, 'optimizer_fn': <class 'torch.optim.sgd.SGD'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>, 'default_params': {'early_stopping_rounds': 10, 'verbose': False, 'iterations': 20, 'retrain': False, 'auto_lr_find': False, 'max_epochs': 1, 'val_size': 0.15, 'early_stopping_patience': 5}}\n",
      "2025-02-06 19:53:32,541 - INFO - SoftOrdering1DCNN.py - Best metric rmse: 3.0995228885284987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running resnet on multiclass...\n",
      "Using dynamic loader for dataset: /home/boom/sdev/repos/AutoDeep/autodeep/examples/testautodata/iris.csv\n",
      "Step 0 err: 9.0\n",
      "Step 100 err: 9.0\n",
      "Step 200 err: 9.0\n",
      "Step 300 err: 9.0\n",
      "Step 400 err: 9.0\n",
      "Step 500 err: 9.0\n",
      "Step 600 err: 9.0\n",
      "Step 700 err: 9.0\n",
      "Step 800 err: 9.0\n",
      "Step 900 err: 9.0\n",
      "Step 1000 err: 9.0\n",
      "IGTD/multiclass/Euclidean_Euclidean/abs\n",
      "RUNTIME 0.00011467933654785156\n",
      "Skipping single image txt and png generation, returning dataframe sorted by IGTD...\n",
      "Step 0 err: 17.5\n",
      "Step 100 err: 17.5\n",
      "Step 200 err: 17.5\n",
      "Step 300 err: 17.5\n",
      "Step 400 err: 17.5\n",
      "Step 500 err: 17.5\n",
      "Step 600 err: 17.5\n",
      "Step 700 err: 17.5\n",
      "Step 800 err: 17.5\n",
      "Step 900 err: 17.5\n",
      "Step 1000 err: 17.5\n",
      "SAVE FOLDER IGTD/multiclass/Pearson_Manhattan/squared\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 19:53:34,800 - INFO - ResNetModel.py - Device cuda is available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNTIME 8.96453857421875e-05\n",
      "Skipping single image txt and png generation, returning dataframe sorted by IGTD...\n",
      "IGTD result file path: IGTD/multiclass/Pearson_Manhattan/squared/_index.txt\n",
      "img_rows: 2\n",
      "img_columns: 2\n",
      "{'data_params': {'normalize_features': 'mean_std', 'encode_categorical': True, 'return_extra_info': True}, 'default_params': {'early_stopping': True, 'verbose': False, 'iterations': 20, 'retrain': False, 'auto_lr_find': False, 'max_epochs': 300, 'val_size': 0.2, 'early_stopping_patience': 6}, 'param_grid': {'resnet_depth': ['resnet18', 'resnet34', 'resnet50'], 'batch_size': [1024, 512, 256], 'optimizer_fn': {'Adam': {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}, 'SGD': {'weight_decay': [0.0, 1e-07], 'momentum': [0.0, 0.9], 'learning_rate': [0.001, 1e-05]}, 'AdamW': {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.01], 'patience': [5, 10]}, 'StepLR': {'step_size': [10, 30], 'gamma': [0.1, 0.5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}\n",
      "resnet_depth ['resnet18', 'resnet34', 'resnet50']\n",
      "batch_size [1024, 512, 256]\n",
      "optimizer_fn {'Adam': {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}, 'SGD': {'weight_decay': [0.0, 1e-07], 'momentum': [0.0, 0.9], 'learning_rate': [0.001, 1e-05]}, 'AdamW': {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}}\n",
      "dict_keys(['Adam', 'SGD', 'AdamW'])\n",
      "Adam {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}\n",
      "weight_decay [0.0, 1e-07]\n",
      "learning_rate [0.001, 0.0001]\n",
      "SGD {'weight_decay': [0.0, 1e-07], 'momentum': [0.0, 0.9], 'learning_rate': [0.001, 1e-05]}\n",
      "weight_decay [0.0, 1e-07]\n",
      "momentum [0.0, 0.9]\n",
      "learning_rate [0.001, 1e-05]\n",
      "AdamW {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}\n",
      "weight_decay [0.0, 1e-07]\n",
      "learning_rate [0.001, 0.0001]\n",
      "scheduler_fn {'ReduceLROnPlateau': {'factor': [0.1, 0.01], 'patience': [5, 10]}, 'StepLR': {'step_size': [10, 30], 'gamma': [0.1, 0.5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}\n",
      "dict_keys(['ReduceLROnPlateau', 'StepLR', 'ExponentialLR'])\n",
      "ReduceLROnPlateau {'factor': [0.1, 0.01], 'patience': [5, 10]}\n",
      "factor [0.1, 0.01]\n",
      "patience [5, 10]\n",
      "StepLR {'step_size': [10, 30], 'gamma': [0.1, 0.5]}\n",
      "step_size [10, 30]\n",
      "gamma [0.1, 0.5]\n",
      "ExponentialLR {'gamma': [0.9, 0.99]}\n",
      "gamma [0.9, 0.99]\n",
      "  0%|          | 0/2 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 19:53:34,820 - INFO - ResNetModel.py - Training with hyperparameters: {'AdamW_learning_rate': 0.00041691320143948053, 'AdamW_weight_decay': 5.3327377727838295e-08, 'Adam_learning_rate': 0.000883609493567339, 'Adam_weight_decay': 5.3453713798712174e-08, 'ExponentialLR_gamma': 0.9700428647065971, 'ReduceLROnPlateau_factor': 0.014194472482598669, 'ReduceLROnPlateau_patience': 6, 'SGD_learning_rate': 5.540876168540814e-05, 'SGD_momentum': 0.7753748228926656, 'SGD_weight_decay': 1.1771360216800085e-08, 'StepLR_gamma': 0.1469911132467317, 'StepLR_step_size': 14, 'batch_size': 601, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>, 'resnet_depth': 'resnet34', 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96, 4)                                              \n",
      "(96,)                                                \n",
      "2                                                    \n",
      "2                                                    \n",
      "  0%|          | 0/2 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "\n",
      "Training:   0%|                                      | 0/300 [00:00<?, ?epoch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/300],Train Loss: 1.3144,Val Loss: 1.1357    \n",
      "  0%|          | 0/2 [00:01<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:240: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "Training:   0%|1                             | 1/300 [00:01<06:29,  1.30s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/300],Train Loss: 1.1356,Val Loss: 2.2714    \n",
      "  0%|          | 0/2 [00:02<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|2                             | 2/300 [00:02<06:25,  1.29s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/300],Train Loss: 2.2759,Val Loss: 1.4657    \n",
      "  0%|          | 0/2 [00:04<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|3                             | 3/300 [00:03<06:17,  1.27s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/300],Train Loss: 1.4619,Val Loss: 1.1470    \n",
      "  0%|          | 0/2 [00:05<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|4                             | 4/300 [00:05<06:12,  1.26s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/300],Train Loss: 1.1421,Val Loss: 1.2600    \n",
      "  0%|          | 0/2 [00:06<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|5                             | 5/300 [00:06<06:11,  1.26s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/300],Train Loss: 1.2526,Val Loss: 1.0239    \n",
      "  0%|          | 0/2 [00:07<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|6                             | 6/300 [00:07<06:09,  1.26s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/300],Train Loss: 1.0215,Val Loss: 0.9629    \n",
      "  0%|          | 0/2 [00:09<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|7                             | 7/300 [00:08<06:10,  1.26s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/300],Train Loss: 0.9648,Val Loss: 0.9846    \n",
      "  0%|          | 0/2 [00:10<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|8                             | 8/300 [00:10<06:07,  1.26s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/300],Train Loss: 0.9899,Val Loss: 0.9396    \n",
      "  0%|          | 0/2 [00:11<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|9                             | 9/300 [00:11<06:06,  1.26s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/300],Train Loss: 0.9461,Val Loss: 0.8601   \n",
      "  0%|          | 0/2 [00:12<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|9                            | 10/300 [00:12<06:05,  1.26s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/300],Train Loss: 0.8655,Val Loss: 0.7974   \n",
      "  0%|          | 0/2 [00:14<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|#                            | 11/300 [00:13<06:05,  1.27s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/300],Train Loss: 0.8006,Val Loss: 0.7425   \n",
      "  0%|          | 0/2 [00:15<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|#1                           | 12/300 [00:15<06:04,  1.26s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/300],Train Loss: 0.7430,Val Loss: 0.6838   \n",
      "  0%|          | 0/2 [00:16<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|#2                           | 13/300 [00:16<06:01,  1.26s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/300],Train Loss: 0.6846,Val Loss: 0.6218   \n",
      "  0%|          | 0/2 [00:17<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|#3                           | 14/300 [00:17<05:58,  1.25s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/300],Train Loss: 0.6275,Val Loss: 0.5501   \n",
      "  0%|          | 0/2 [00:19<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|#4                           | 15/300 [00:18<05:58,  1.26s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/300],Train Loss: 0.5588,Val Loss: 0.4842   \n",
      "  0%|          | 0/2 [00:20<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|#5                           | 16/300 [00:20<05:53,  1.25s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/300],Train Loss: 0.4906,Val Loss: 0.4484   \n",
      "  0%|          | 0/2 [00:21<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|#6                           | 17/300 [00:21<05:55,  1.26s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/300],Train Loss: 0.4525,Val Loss: 0.4272   \n",
      "  0%|          | 0/2 [00:22<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|#7                           | 18/300 [00:22<05:54,  1.26s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/300],Train Loss: 0.4302,Val Loss: 0.4056   \n",
      "  0%|          | 0/2 [00:24<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|#8                           | 19/300 [00:23<05:52,  1.26s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/300],Train Loss: 0.4052,Val Loss: 0.3868   \n",
      "  0%|          | 0/2 [00:25<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|#9                           | 20/300 [00:25<05:54,  1.27s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/300],Train Loss: 0.3833,Val Loss: 0.3602   \n",
      "  0%|          | 0/2 [00:26<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|##                           | 21/300 [00:26<05:52,  1.26s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/300],Train Loss: 0.3583,Val Loss: 0.3336   \n",
      "  0%|          | 0/2 [00:28<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|##1                          | 22/300 [00:27<05:51,  1.27s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/300],Train Loss: 0.3382,Val Loss: 0.3186   \n",
      "  0%|          | 0/2 [00:29<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|##2                          | 23/300 [00:29<05:49,  1.26s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/300],Train Loss: 0.3164,Val Loss: 0.3121   \n",
      "  0%|          | 0/2 [00:30<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|##3                          | 24/300 [00:30<05:49,  1.27s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/300],Train Loss: 0.2955,Val Loss: 0.2722   \n",
      "  0%|          | 0/2 [00:31<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|##4                          | 25/300 [00:31<05:48,  1.27s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/300],Train Loss: 0.2738,Val Loss: 0.2904   \n",
      "  0%|          | 0/2 [00:33<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|##5                          | 26/300 [00:32<05:44,  1.26s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/300],Train Loss: 0.2535,Val Loss: 0.2474   \n",
      "  0%|          | 0/2 [00:34<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|##6                          | 27/300 [00:34<05:41,  1.25s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/300],Train Loss: 0.2385,Val Loss: 0.3021   \n",
      "  0%|          | 0/2 [00:35<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|##7                          | 28/300 [00:35<05:42,  1.26s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/300],Train Loss: 0.2289,Val Loss: 0.2047   \n",
      "  0%|          | 0/2 [00:36<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|##8                          | 29/300 [00:36<05:38,  1.25s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/300],Train Loss: 0.2339,Val Loss: 0.4635   \n",
      "  0%|          | 0/2 [00:38<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|##9                          | 30/300 [00:37<05:38,  1.25s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/300],Train Loss: 0.2654,Val Loss: 0.1719   \n",
      "  0%|          | 0/2 [00:39<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|##9                          | 31/300 [00:39<05:36,  1.25s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/300],Train Loss: 0.2791,Val Loss: 0.3084   \n",
      "  0%|          | 0/2 [00:40<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|###                          | 32/300 [00:40<05:38,  1.26s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/300],Train Loss: 0.1947,Val Loss: 0.4267   \n",
      "  0%|          | 0/2 [00:41<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|###1                         | 33/300 [00:41<05:35,  1.26s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/300],Train Loss: 0.2245,Val Loss: 0.1656   \n",
      "  0%|          | 0/2 [00:43<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|###2                         | 34/300 [00:42<05:33,  1.25s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/300],Train Loss: 0.2254,Val Loss: 0.2308   \n",
      "  0%|          | 0/2 [00:44<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|###3                         | 35/300 [00:44<05:33,  1.26s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/300],Train Loss: 0.1695,Val Loss: 0.4519   \n",
      "  0%|          | 0/2 [00:45<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|###4                         | 36/300 [00:45<05:32,  1.26s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/300],Train Loss: 0.2160,Val Loss: 0.1843   \n",
      "  0%|          | 0/2 [00:46<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|###5                         | 37/300 [00:46<05:32,  1.27s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/300],Train Loss: 0.1670,Val Loss: 0.1681   \n",
      "  0%|          | 0/2 [00:48<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|###6                         | 38/300 [00:47<05:30,  1.26s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/300],Train Loss: 0.1673,Val Loss: 0.3887   \n",
      "  0%|          | 0/2 [00:49<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|###7                         | 39/300 [00:49<05:28,  1.26s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/300],Train Loss: 0.1706,Val Loss: 0.2532   \n",
      "Early stopping triggered at epoch 40                 \n",
      "  0%|          | 0/2 [00:50<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|###7                         | 39/300 [00:50<05:37,  1.29s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model loaded from epoch 34                      \n",
      "  0%|          | 0/2 [00:50<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 19:54:26,844 - INFO - ResNetModel.py - Validation metrics accuracy: 0.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:52<00:52, 52.03s/trial, best loss: -0.875]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 19:54:26,859 - INFO - ResNetModel.py - Training with hyperparameters: {'AdamW_learning_rate': 0.0005493747562277502, 'AdamW_weight_decay': 5.979030232767242e-08, 'Adam_learning_rate': 0.00010037826615600942, 'Adam_weight_decay': 2.309091722462173e-08, 'ExponentialLR_gamma': 0.9526834243165615, 'ReduceLROnPlateau_factor': 0.021158305135007868, 'ReduceLROnPlateau_patience': 7, 'SGD_learning_rate': 9.52118823872863e-05, 'SGD_momentum': 0.6960145837348019, 'SGD_weight_decay': 2.4860021513335803e-08, 'StepLR_gamma': 0.2095872419296196, 'StepLR_step_size': 19, 'batch_size': 278, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'resnet_depth': 'resnet18', 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96, 4)                                                            \n",
      "(96,)                                                              \n",
      "2                                                                  \n",
      "2                                                                  \n",
      " 50%|█████     | 1/2 [00:52<00:52, 52.03s/trial, best loss: -0.875]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "\n",
      "Training:   0%|                                      | 0/300 [00:00<?, ?epoch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/300],Train Loss: 1.3332,Val Loss: 1.1073                  \n",
      " 50%|█████     | 1/2 [00:53<00:52, 52.03s/trial, best loss: -0.875]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|1                             | 1/300 [00:01<06:36,  1.33s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/300],Train Loss: 1.1057,Val Loss: 1.0839                  \n",
      " 50%|█████     | 1/2 [00:54<00:52, 52.03s/trial, best loss: -0.875]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|2                             | 2/300 [00:02<06:18,  1.27s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/300],Train Loss: 1.0836,Val Loss: 1.0771                  \n",
      " 50%|█████     | 1/2 [00:56<00:52, 52.03s/trial, best loss: -0.875]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|3                             | 3/300 [00:03<06:17,  1.27s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/300],Train Loss: 1.0771,Val Loss: 1.0664                  \n",
      " 50%|█████     | 1/2 [00:57<00:52, 52.03s/trial, best loss: -0.875]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|4                             | 4/300 [00:05<06:12,  1.26s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/300],Train Loss: 1.0670,Val Loss: 1.0549                  \n",
      " 50%|█████     | 1/2 [00:58<00:52, 52.03s/trial, best loss: -0.875]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|5                             | 5/300 [00:06<06:14,  1.27s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/300],Train Loss: 1.0555,Val Loss: 1.0478                  \n",
      " 50%|█████     | 1/2 [00:59<00:52, 52.03s/trial, best loss: -0.875]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|6                             | 6/300 [00:07<06:10,  1.26s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/300],Train Loss: 1.0484,Val Loss: 1.0390                  \n",
      " 50%|█████     | 1/2 [01:01<00:52, 52.03s/trial, best loss: -0.875]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|7                             | 7/300 [00:08<06:10,  1.26s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/300],Train Loss: 1.0401,Val Loss: 1.0252                  \n",
      " 50%|█████     | 1/2 [01:02<00:52, 52.03s/trial, best loss: -0.875]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|8                             | 8/300 [00:10<06:09,  1.26s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/300],Train Loss: 1.0267,Val Loss: 1.0106                  \n",
      " 50%|█████     | 1/2 [01:03<00:52, 52.03s/trial, best loss: -0.875]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|9                             | 9/300 [00:11<06:06,  1.26s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/300],Train Loss: 1.0127,Val Loss: 0.9949                 \n",
      " 50%|█████     | 1/2 [01:04<00:52, 52.03s/trial, best loss: -0.875]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|9                            | 10/300 [00:12<06:06,  1.27s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/300],Train Loss: 0.9981,Val Loss: 0.9778                 \n",
      " 50%|█████     | 1/2 [01:06<00:52, 52.03s/trial, best loss: -0.875]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|#                            | 11/300 [00:13<06:05,  1.26s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/300],Train Loss: 0.9820,Val Loss: 0.9567                 \n",
      " 50%|█████     | 1/2 [01:07<00:52, 52.03s/trial, best loss: -0.875]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|#1                           | 12/300 [00:15<06:04,  1.27s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/300],Train Loss: 0.9620,Val Loss: 0.9332                 \n",
      " 50%|█████     | 1/2 [01:08<00:52, 52.03s/trial, best loss: -0.875]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|#2                           | 13/300 [00:16<06:03,  1.27s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/300],Train Loss: 0.9390,Val Loss: 0.9079                 \n",
      " 50%|█████     | 1/2 [01:09<00:52, 52.03s/trial, best loss: -0.875]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|#3                           | 14/300 [00:17<05:59,  1.26s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/300],Train Loss: 0.9141,Val Loss: 0.8801                 \n",
      " 50%|█████     | 1/2 [01:11<00:52, 52.03s/trial, best loss: -0.875]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|#4                           | 15/300 [00:18<05:59,  1.26s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/300],Train Loss: 0.8869,Val Loss: 0.8496                 \n",
      " 50%|█████     | 1/2 [01:12<00:52, 52.03s/trial, best loss: -0.875]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|#5                           | 16/300 [00:20<05:56,  1.26s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/300],Train Loss: 0.8581,Val Loss: 0.8171                 \n",
      " 50%|█████     | 1/2 [01:13<00:52, 52.03s/trial, best loss: -0.875]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|#6                           | 17/300 [00:21<05:58,  1.27s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/300],Train Loss: 0.8273,Val Loss: 0.7817                 \n",
      " 50%|█████     | 1/2 [01:14<00:52, 52.03s/trial, best loss: -0.875]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|#7                           | 18/300 [00:22<05:56,  1.26s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/300],Train Loss: 0.7928,Val Loss: 0.7436                 \n",
      " 50%|█████     | 1/2 [01:16<00:52, 52.03s/trial, best loss: -0.875]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|#8                           | 19/300 [00:24<05:55,  1.26s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/300],Train Loss: 0.7550,Val Loss: 0.7011                 \n",
      " 50%|█████     | 1/2 [01:17<00:52, 52.03s/trial, best loss: -0.875]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|#9                           | 20/300 [00:25<05:54,  1.27s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/300],Train Loss: 0.7126,Val Loss: 0.6542                 \n",
      " 50%|█████     | 1/2 [01:18<00:52, 52.03s/trial, best loss: -0.875]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|##                           | 21/300 [00:26<05:51,  1.26s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/300],Train Loss: 0.6664,Val Loss: 0.6045                 \n",
      " 50%|█████     | 1/2 [01:20<00:52, 52.03s/trial, best loss: -0.875]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|##1                          | 22/300 [00:27<05:48,  1.25s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/300],Train Loss: 0.6190,Val Loss: 0.5550                 \n",
      " 50%|█████     | 1/2 [01:21<00:52, 52.03s/trial, best loss: -0.875]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|##2                          | 23/300 [00:29<05:47,  1.25s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/300],Train Loss: 0.5714,Val Loss: 0.5082                 \n",
      " 50%|█████     | 1/2 [01:22<00:52, 52.03s/trial, best loss: -0.875]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|##3                          | 24/300 [00:30<05:46,  1.26s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/300],Train Loss: 0.5236,Val Loss: 0.4639                 \n",
      " 50%|█████     | 1/2 [01:23<00:52, 52.03s/trial, best loss: -0.875]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|##4                          | 25/300 [00:31<05:47,  1.26s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/300],Train Loss: 0.4777,Val Loss: 0.4183                 \n",
      " 50%|█████     | 1/2 [01:25<00:52, 52.03s/trial, best loss: -0.875]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|##5                          | 26/300 [00:32<05:46,  1.27s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/300],Train Loss: 0.4335,Val Loss: 0.3756                 \n",
      " 50%|█████     | 1/2 [01:26<00:52, 52.03s/trial, best loss: -0.875]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|##6                          | 27/300 [00:34<05:43,  1.26s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/300],Train Loss: 0.3923,Val Loss: 0.3441                 \n",
      " 50%|█████     | 1/2 [01:27<00:52, 52.03s/trial, best loss: -0.875]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|##7                          | 28/300 [00:35<05:40,  1.25s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/300],Train Loss: 0.3541,Val Loss: 0.3200                 \n",
      " 50%|█████     | 1/2 [01:28<00:52, 52.03s/trial, best loss: -0.875]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|##8                          | 29/300 [00:36<05:42,  1.26s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/300],Train Loss: 0.3210,Val Loss: 0.2924                 \n",
      " 50%|█████     | 1/2 [01:30<00:52, 52.03s/trial, best loss: -0.875]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|##9                          | 30/300 [00:37<05:40,  1.26s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/300],Train Loss: 0.2925,Val Loss: 0.2752                 \n",
      " 50%|█████     | 1/2 [01:31<00:52, 52.03s/trial, best loss: -0.875]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|##9                          | 31/300 [00:39<05:39,  1.26s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/300],Train Loss: 0.2697,Val Loss: 0.2723                 \n",
      " 50%|█████     | 1/2 [01:32<00:52, 52.03s/trial, best loss: -0.875]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|###                          | 32/300 [00:40<05:36,  1.26s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/300],Train Loss: 0.2520,Val Loss: 0.2607                 \n",
      " 50%|█████     | 1/2 [01:33<00:52, 52.03s/trial, best loss: -0.875]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|###1                         | 33/300 [00:41<05:35,  1.26s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/300],Train Loss: 0.2374,Val Loss: 0.2553                 \n",
      " 50%|█████     | 1/2 [01:35<00:52, 52.03s/trial, best loss: -0.875]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|###2                         | 34/300 [00:42<05:34,  1.26s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/300],Train Loss: 0.2254,Val Loss: 0.2678                 \n",
      " 50%|█████     | 1/2 [01:36<00:52, 52.03s/trial, best loss: -0.875]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|###3                         | 35/300 [00:44<05:33,  1.26s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/300],Train Loss: 0.2153,Val Loss: 0.2559                 \n",
      " 50%|█████     | 1/2 [01:37<00:52, 52.03s/trial, best loss: -0.875]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|###4                         | 36/300 [00:45<05:31,  1.26s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/300],Train Loss: 0.2062,Val Loss: 0.2682                 \n",
      " 50%|█████     | 1/2 [01:38<00:52, 52.03s/trial, best loss: -0.875]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|###5                         | 37/300 [00:46<05:30,  1.26s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/300],Train Loss: 0.1976,Val Loss: 0.2685                 \n",
      " 50%|█████     | 1/2 [01:40<00:52, 52.03s/trial, best loss: -0.875]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|###6                         | 38/300 [00:47<05:28,  1.25s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/300],Train Loss: 0.1892,Val Loss: 0.2662                 \n",
      " 50%|█████     | 1/2 [01:41<00:52, 52.03s/trial, best loss: -0.875]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|###7                         | 39/300 [00:49<05:27,  1.25s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/300],Train Loss: 0.1807,Val Loss: 0.2811                 \n",
      "Early stopping triggered at epoch 40                               \n",
      " 50%|█████     | 1/2 [01:42<00:52, 52.03s/trial, best loss: -0.875]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|###7                         | 39/300 [00:50<05:37,  1.29s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model loaded from epoch 34                                    \n",
      " 50%|█████     | 1/2 [01:42<00:52, 52.03s/trial, best loss: -0.875]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 19:55:18,749 - INFO - ResNetModel.py - Validation metrics accuracy: 0.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [01:43<00:00, 51.97s/trial, best loss: -0.875]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 19:55:18,753 - INFO - ResNetModel.py - Final Validation Metrics: {'accuracy': 0.875}\n",
      "2025-02-06 19:55:18,754 - INFO - ResNetModel.py - Loading model\n",
      "2025-02-06 19:55:18,755 - INFO - ResNetModel.py - Best hyperparameters: {'AdamW_learning_rate': 0.00041691320143948053, 'AdamW_weight_decay': 5.3327377727838295e-08, 'Adam_learning_rate': 0.000883609493567339, 'Adam_weight_decay': 5.3453713798712174e-08, 'ExponentialLR_gamma': 0.9700428647065971, 'ReduceLROnPlateau_factor': 0.014194472482598669, 'ReduceLROnPlateau_patience': 6, 'SGD_learning_rate': 5.540876168540814e-05, 'SGD_momentum': 0.7753748228926656, 'SGD_weight_decay': 1.1771360216800085e-08, 'StepLR_gamma': 0.1469911132467317, 'StepLR_step_size': 14, 'batch_size': 601, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>, 'resnet_depth': 'resnet34', 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>, 'default_params': {'early_stopping': True, 'verbose': False, 'iterations': 20, 'retrain': False, 'auto_lr_find': False, 'max_epochs': 300, 'val_size': 0.2, 'early_stopping_patience': 6}}\n",
      "2025-02-06 19:55:18,755 - INFO - ResNetModel.py - The best possible score for metric accuracy is 1.0, we reached accuracy = 0.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 19:55:19,407 - INFO - MLP.py - Starting hyperopt search with 2 evaluations, optimizing accuracy metric\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running mlp on multiclass...\n",
      "Using dynamic loader for dataset: /home/boom/sdev/repos/AutoDeep/autodeep/examples/testautodata/iris.csv\n",
      "  0%|          | 0/2 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 19:55:19,416 - INFO - MLP.py - Training with hyperparameters: {'activation': 'tanh', 'batch_size': 1252, 'hidden_layer_sizes': (128, 64, 32), 'max_iter': 1449, 'n_iter_no_change': 12, 'solver': 'sgd'}\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:609: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped\n",
      "  warnings.warn(\n",
      "\n",
      "2025-02-06 19:55:19,478 - INFO - MLP.py - Training with hyperparameters: {'activation': 'tanh', 'batch_size': 1472, 'hidden_layer_sizes': (64, 32), 'max_iter': 1029, 'n_iter_no_change': 11, 'solver': 'adam'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 20.37trial/s, best loss: -0.8333333333333334]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:609: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped\n",
      "  warnings.warn(\n",
      "\n",
      "2025-02-06 19:55:19,512 - INFO - MLP.py - Final best hyperparameters: {'activation': 'tanh', 'batch_size': 1472, 'hidden_layer_sizes': (64, 32), 'max_iter': 1029, 'n_iter_no_change': 11, 'solver': 'adam', 'default_params': {'early_stopping': True, 'n_iter_no_change': 10, 'max_iter': 1000, 'hidden_layer_sizes': [32], 'activation': 'relu', 'solver': 'adam', 'batch_size': 1024, 'val_size': 0.15}}\n",
      "2025-02-06 19:55:19,512 - INFO - MLP.py - Final best accuracy score: 0.8333333333333334\n",
      "2025-02-06 19:55:19,513 - INFO - MLP.py - Loading model\n",
      "2025-02-06 19:55:19,515 - INFO - MLP.py - Computing predictions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running xgb on multiclass...\n",
      "Using dynamic loader for dataset: /home/boom/sdev/repos/AutoDeep/autodeep/examples/testautodata/iris.csv\n",
      "  0%|          | 0/2 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 19:55:19,533 - INFO - XGBoostTrainer.py - Hyperopt training with hyperparameters: {'colsample_bytree': 0.9317085201666937, 'gamma': 0.023542720433600173, 'learning_rate': 0.02257009318017118, 'max_depth': 5, 'min_child_weight': 5, 'n_estimators': 119, 'subsample': 0.804784757575745}\n",
      "2025-02-06 19:55:19,609 - INFO - XGBoostTrainer.py - Validation metrics: {'accuracy': 0.9583333333333334}\n",
      "2025-02-06 19:55:19,614 - INFO - XGBoostTrainer.py - Train metrics: {'accuracy': 0.9583333333333334}\n",
      "2025-02-06 19:55:19,620 - INFO - XGBoostTrainer.py - Hyperopt training with hyperparameters: {'colsample_bytree': 0.8906721612968371, 'gamma': 0.049720043026671615, 'learning_rate': 0.04776774932724804, 'max_depth': 6, 'min_child_weight': 1, 'n_estimators': 82, 'subsample': 0.6447152123951665}\n",
      "2025-02-06 19:55:19,670 - INFO - XGBoostTrainer.py - Validation metrics: {'accuracy': 0.9583333333333334}\n",
      "2025-02-06 19:55:19,676 - INFO - XGBoostTrainer.py - Train metrics: {'accuracy': 0.9583333333333334}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 13.42trial/s, best loss: -0.9583333333333334]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 19:55:19,679 - INFO - XGBoostTrainer.py - Loading model\n",
      "2025-02-06 19:55:19,680 - INFO - XGBoostTrainer.py - Best hyperparameters: {'colsample_bytree': 0.9317085201666937, 'gamma': 0.023542720433600173, 'learning_rate': 0.02257009318017118, 'max_depth': 5, 'min_child_weight': 5, 'n_estimators': 119, 'subsample': 0.804784757575745, 'default_params': {'retrain': True, 'val_size': 0.2, 'early_stopping_rounds': 100, 'verbose': False, 'learning_rate': 0.3, 'max_depth': 6, 'n_estimators': 100, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 0.0}}\n",
      "2025-02-06 19:55:19,680 - INFO - XGBoostTrainer.py - The best possible score for metric accuracy is 1.0, we reached accuracy = 0.9583333333333334\n",
      "2025-02-06 19:55:19,681 - INFO - XGBoostTrainer.py - Computing predictions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running catboost on multiclass...\n",
      "Using dynamic loader for dataset: /home/boom/sdev/repos/AutoDeep/autodeep/examples/testautodata/iris.csv\n",
      "  0%|          | 0/2 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 19:55:19,697 - INFO - CatBoostModel.py - Hyperopt training with hyperparameters: {'iterations': 330}\n",
      "2025-02-06 19:55:20,738 - INFO - CatBoostModel.py - Validation metrics: {'accuracy': 1.0}\n",
      "2025-02-06 19:55:20,740 - INFO - CatBoostModel.py - Train metrics: {'accuracy': 1.0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EARLY STOPPING                                       \n",
      "-1.0                                                 \n",
      "-1.0                                                 \n",
      " 50%|█████     | 1/2 [00:01<00:01,  1.05s/trial, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 19:55:20,747 - INFO - CatBoostModel.py - Loading model\n",
      "2025-02-06 19:55:20,747 - INFO - CatBoostModel.py - Best hyperparameters: {'iterations': 330, 'default_params': {'retrain': False, 'val_size': 0.15, 'early_stopping_rounds': 100, 'verbose': False, 'iterations': 500}}\n",
      "2025-02-06 19:55:20,748 - INFO - CatBoostModel.py - The best possible score for metric accuracy is 1.0, we reached accuracy = -1.0\n",
      "2025-02-06 19:55:20,748 - INFO - CatBoostModel.py - Computing predictions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running categoryembedding on multiclass...\n",
      "Using dynamic loader for dataset: /home/boom/sdev/repos/AutoDeep/autodeep/examples/testautodata/iris.csv\n",
      "2025-02-06 19:55:20,769 - INFO - CommonStructure.py - CategoryEmbeddingTrainer - Initialized CategoryEmbeddingTrainer with problem type multiclass_classification\n",
      "2025-02-06 19:55:20,771 - INFO - CommonStructure.py - CategoryEmbeddingTrainer - Device cuda is available\n",
      "2025-02-06 19:55:20,771 - INFO - CommonStructure.py - CategoryEmbeddingTrainer - Trainer initialized\n",
      "2025-02-06 19:55:20,772 - INFO - CommonStructure.py - CategoryEmbeddingTrainer - Starting hyperopt search 2 evals maximizing accuracy metric on dataset\n",
      "SPACE ######################################################\n",
      "{'batch_size': <hyperopt.pyll.base.Apply object at 0x7adea166f220>, 'layers': <hyperopt.pyll.base.Apply object at 0x7adea166db40>, 'activation': <hyperopt.pyll.base.Apply object at 0x7adea173f280>, 'use_batch_norm': <hyperopt.pyll.base.Apply object at 0x7adeaf994d90>, 'initialization': <hyperopt.pyll.base.Apply object at 0x7adeac762da0>, 'dropout': <hyperopt.pyll.base.Apply object at 0x7adea169ee60>, 'embedding_dropout': <hyperopt.pyll.base.Apply object at 0x7adeac3865f0>, 'optimizer_fn': <hyperopt.pyll.base.Apply object at 0x7adeac9dd8a0>, 'scheduler_fn': <hyperopt.pyll.base.Apply object at 0x7adeac956860>}\n",
      "2025-02-06 19:55:20,778 - DEBUG - CommonStructure.py - CategoryEmbeddingTrainer - Full dataset shape : (120, 5)\n",
      "2025-02-06 19:55:20,780 - DEBUG - CommonStructure.py - CategoryEmbeddingTrainer - Train set shape: (102, 5), Test set shape: (18, 5)\n",
      "  0%|          | 0/2 [00:00<?, ?trial/s, best loss=?]2025-02-06 19:55:20,811 - INFO - CommonStructure.py - CategoryEmbeddingTrainer - Training with hyperparameters: {'activation': 'ReLU', 'batch_size': 352, 'dropout': 0.07180182756042691, 'embedding_dropout': 0.04456699223511802, 'initialization': 'xavier', 'layers': '256-128-64-32', 'optimizer_fn': {'AdamW_learning_rate': 0.0002369073315019895, 'AdamW_weight_decay': 2.7190091816919235e-08, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>}, 'scheduler_fn': {'StepLR_gamma': 0.24871568886900097, 'StepLR_step_size': 27, 'scheduler_fn': <class 'torch.optim.lr_scheduler.StepLR'>}, 'use_batch_norm': False}\n",
      "tabular model params                                 \n",
      "{'activation': 'ReLU', 'batch_size': 352, 'dropout': 0.07180182756042691, 'embedding_dropout': 0.04456699223511802, 'initialization': 'xavier', 'layers': '256-128-64-32', 'optimizer_fn': {'AdamW_learning_rate': 0.0002369073315019895, 'AdamW_weight_decay': 2.7190091816919235e-08, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>}, 'scheduler_fn': {'StepLR_gamma': 0.24871568886900097, 'StepLR_step_size': 27, 'scheduler_fn': <class 'torch.optim.lr_scheduler.StepLR'>}, 'use_batch_norm': False}\n",
      "tabular model outer params                           \n",
      "{'early_stopping_rounds': 10, 'verbose': False, 'iterations': 20, 'retrain': False, 'auto_lr_find': False, 'max_epochs': 3, 'val_size': 0.15, 'early_stopping_patience': 20}\n",
      "  0%|          | 0/2 [00:00<?, ?trial/s, best loss=?]2025-02-06 19:55:20,818 - WARNING - CommonStructure.py - CategoryEmbeddingTrainer - You are passing some invalid parameters to the model {'batch_size': 352, 'optimizer_fn': {'AdamW_learning_rate': 0.0002369073315019895, 'AdamW_weight_decay': 2.7190091816919235e-08, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>}, 'scheduler_fn': {'StepLR_gamma': 0.24871568886900097, 'StepLR_step_size': 27, 'scheduler_fn': <class 'torch.optim.lr_scheduler.StepLR'>}}\n",
      "2025-02-06 19:55:20,819 - DEBUG - CommonStructure.py - CategoryEmbeddingTrainer - compatible parameters: {'activation': 'ReLU', 'dropout': 0.07180182756042691, 'embedding_dropout': 0.04456699223511802, 'initialization': 'xavier', 'layers': '256-128-64-32', 'use_batch_norm': False}\n",
      "DataConfig(target=['target'], continuous_cols=['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)'], categorical_cols=[], date_columns=[], encode_date_columns=True, validation_split=0.2, continuous_feature_transform=None, normalize_continuous_features=True, quantile_noise=0, num_workers=4, pin_memory=True, handle_unknown_categories=True, handle_missing_values=True, dataloader_kwargs={})\n",
      "CategoryEmbeddingModelConfig(task='classification', head='LinearHead', head_config={'layers': ''}, embedding_dims=None, embedding_dropout=0.0, batch_norm_continuous_input=True, learning_rate=0.0002369073315019895, loss='CrossEntropyLoss', metrics=['accuracy'], metrics_prob_input=[False], metrics_params=[{}], target_range=None, virtual_batch_size=None, seed=42, _module_src='models.category_embedding', _model_name='CategoryEmbeddingModel', _backbone_name='CategoryEmbeddingBackbone', _config_name='CategoryEmbeddingModelConfig', layers='256-128-64-32', activation='ReLU', use_batch_norm=False, initialization='kaiming', dropout=0.0)\n",
      "OptimizerConfig(optimizer='AdamW', optimizer_params={'weight_decay': 2.7190091816919235e-08}, lr_scheduler='StepLR', lr_scheduler_params={'step_size': 27, 'gamma': 0.24871568886900097}, lr_scheduler_monitor_metric='valid_loss')\n",
      "TrainerConfig(batch_size=352, data_aware_init_batch_size=2000, fast_dev_run=False, max_epochs=3, min_epochs=1, max_time=None, accelerator='auto', devices=-1, devices_list=None, accumulate_grad_batches=1, auto_lr_find=False, auto_select_gpus=True, check_val_every_n_epoch=1, gradient_clip_val=0.0, overfit_batches=0.0, deterministic=False, profiler=None, early_stopping='valid_loss', early_stopping_min_delta=0.0, early_stopping_mode='min', early_stopping_patience=20, early_stopping_kwargs={}, checkpoints='valid_loss', checkpoints_path='ptabular_checkpoints', checkpoints_every_n_epochs=10, checkpoints_name=None, checkpoints_mode='min', checkpoints_save_top_k=1, checkpoints_kwargs={}, load_best=True, track_grad_norm=-1, progress_bar='rich', precision=32, seed=42, trainer_kwargs={})\n",
      "  0%|          | 0/2 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:55:20</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">841</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">146</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m19:55:20\u001b[0m,\u001b[1;36m841\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m146\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:55:20</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">873</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m19:55:20\u001b[0m,\u001b[1;36m873\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:55:20</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">880</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m19:55:20\u001b[0m,\u001b[1;36m880\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:55:20</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">905</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: CategoryEmbeddingModel \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m19:55:20\u001b[0m,\u001b[1;36m905\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: CategoryEmbeddingModel \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:55:20</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">944</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m19:55:20\u001b[0m,\u001b[1;36m944\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:55:20</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">953</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m19:55:20\u001b[0m,\u001b[1;36m953\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/boom/sdev/repos/AutoDeep/autodeep/examples/ptabular_checkpoints exists and is not empty.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                      </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ custom_loss      │ CrossEntropyLoss          │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _backbone        │ CategoryEmbeddingBackbone │ 44.5 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _embedding_layer │ Embedding1dLayer          │      8 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ head             │ LinearHead                │     99 │ train │\n",
       "└───┴──────────────────┴───────────────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType                     \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ custom_loss      │ CrossEntropyLoss          │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ CategoryEmbeddingBackbone │ 44.5 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer          │      8 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ head             │ LinearHead                │     99 │ train │\n",
       "└───┴──────────────────┴───────────────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 44.6 K                                                                                           \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 44.6 K                                                                                               \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 18                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 44.6 K                                                                                           \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 44.6 K                                                                                               \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 18                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1772bf590f94f5e9f7f50f70c3ba1d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number \n",
       "of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for \n",
       "log_every_n_steps if you want to see logs for the training epoch.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number \n",
       "of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for \n",
       "log_every_n_steps if you want to see logs for the training epoch.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:55:22</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">996</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m19:55:22\u001b[0m,\u001b[1;36m996\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:55:22</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">999</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m19:55:22\u001b[0m,\u001b[1;36m999\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:55:23</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">002</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1537</span><span style=\"font-weight: bold\">}</span> - WARNING - No best model available to load. Did you\n",
       "run it more than <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> epoch?<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                                                                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m19:55:23\u001b[0m,\u001b[1;36m002\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1537\u001b[0m\u001b[1m}\u001b[0m - WARNING - No best model available to load. Did you\n",
       "run it more than \u001b[1;36m1\u001b[0m epoch?\u001b[33m...\u001b[0m                                                                                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-06 19:55:23,300 - INFO - CommonStructure.py - CategoryEmbeddingTrainer - Validation metrics: {'accuracy': 0.5555555555555556}\n",
      " 50%|█████     | 1/2 [00:02<00:02,  2.77s/trial, best loss: -0.5555555555555556]2025-02-06 19:55:23,576 - INFO - CommonStructure.py - CategoryEmbeddingTrainer - Training with hyperparameters: {'activation': 'ReLU', 'batch_size': 608, 'dropout': 0.13793074406282088, 'embedding_dropout': 0.08748838326419968, 'initialization': 'random', 'layers': '256-128', 'optimizer_fn': {'Adam_learning_rate': 0.0003929327884259557, 'Adam_weight_decay': 3.044740079823129e-08, 'optimizer_fn': <class 'torch.optim.adam.Adam'>}, 'scheduler_fn': {'ReduceLROnPlateau_factor': 0.054041101815896615, 'ReduceLROnPlateau_patience': 9, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>}, 'use_batch_norm': True}\n",
      "tabular model params                                                            \n",
      "{'activation': 'ReLU', 'batch_size': 608, 'dropout': 0.13793074406282088, 'embedding_dropout': 0.08748838326419968, 'initialization': 'random', 'layers': '256-128', 'optimizer_fn': {'Adam_learning_rate': 0.0003929327884259557, 'Adam_weight_decay': 3.044740079823129e-08, 'optimizer_fn': <class 'torch.optim.adam.Adam'>}, 'scheduler_fn': {'ReduceLROnPlateau_factor': 0.054041101815896615, 'ReduceLROnPlateau_patience': 9, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>}, 'use_batch_norm': True}\n",
      "tabular model outer params                                                      \n",
      "{'early_stopping_rounds': 10, 'verbose': False, 'iterations': 20, 'retrain': False, 'auto_lr_find': False, 'max_epochs': 3, 'val_size': 0.15, 'early_stopping_patience': 20}\n",
      " 50%|█████     | 1/2 [00:02<00:02,  2.77s/trial, best loss: -0.5555555555555556]2025-02-06 19:55:23,592 - WARNING - CommonStructure.py - CategoryEmbeddingTrainer - You are passing some invalid parameters to the model {'batch_size': 608, 'optimizer_fn': {'Adam_learning_rate': 0.0003929327884259557, 'Adam_weight_decay': 3.044740079823129e-08, 'optimizer_fn': <class 'torch.optim.adam.Adam'>}, 'scheduler_fn': {'ReduceLROnPlateau_factor': 0.054041101815896615, 'ReduceLROnPlateau_patience': 9, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>}}\n",
      "2025-02-06 19:55:23,594 - DEBUG - CommonStructure.py - CategoryEmbeddingTrainer - compatible parameters: {'activation': 'ReLU', 'dropout': 0.13793074406282088, 'embedding_dropout': 0.08748838326419968, 'initialization': 'random', 'layers': '256-128', 'use_batch_norm': True}\n",
      "DataConfig(target=['target'], continuous_cols=['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)'], categorical_cols=[], date_columns=[], encode_date_columns=True, validation_split=0.2, continuous_feature_transform=None, normalize_continuous_features=True, quantile_noise=0, num_workers=4, pin_memory=True, handle_unknown_categories=True, handle_missing_values=True, dataloader_kwargs={})\n",
      "CategoryEmbeddingModelConfig(task='classification', head='LinearHead', head_config={'layers': ''}, embedding_dims=None, embedding_dropout=0.0, batch_norm_continuous_input=True, learning_rate=0.0003929327884259557, loss='CrossEntropyLoss', metrics=['accuracy'], metrics_prob_input=[False], metrics_params=[{}], target_range=None, virtual_batch_size=None, seed=42, _module_src='models.category_embedding', _model_name='CategoryEmbeddingModel', _backbone_name='CategoryEmbeddingBackbone', _config_name='CategoryEmbeddingModelConfig', layers='256-128', activation='ReLU', use_batch_norm=False, initialization='kaiming', dropout=0.0)\n",
      "OptimizerConfig(optimizer='Adam', optimizer_params={'weight_decay': 3.044740079823129e-08}, lr_scheduler='ReduceLROnPlateau', lr_scheduler_params={'factor': 0.054041101815896615, 'patience': 9, 'min_lr': 1e-08, 'verbose': True, 'mode': 'min'}, lr_scheduler_monitor_metric='valid_loss')\n",
      "TrainerConfig(batch_size=608, data_aware_init_batch_size=2000, fast_dev_run=False, max_epochs=3, min_epochs=1, max_time=None, accelerator='auto', devices=-1, devices_list=None, accumulate_grad_batches=1, auto_lr_find=False, auto_select_gpus=True, check_val_every_n_epoch=1, gradient_clip_val=0.0, overfit_batches=0.0, deterministic=False, profiler=None, early_stopping='valid_loss', early_stopping_min_delta=0.0, early_stopping_mode='min', early_stopping_patience=20, early_stopping_kwargs={}, checkpoints='valid_loss', checkpoints_path='ptabular_checkpoints', checkpoints_every_n_epochs=10, checkpoints_name=None, checkpoints_mode='min', checkpoints_save_top_k=1, checkpoints_kwargs={}, load_best=True, track_grad_norm=-1, progress_bar='rich', precision=32, seed=42, trainer_kwargs={})\n",
      " 50%|█████     | 1/2 [00:02<00:02,  2.77s/trial, best loss: -0.5555555555555556]"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:55:23</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">633</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">146</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m19:55:23\u001b[0m,\u001b[1;36m633\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m146\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:55:23</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">656</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m19:55:23\u001b[0m,\u001b[1;36m656\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:55:23</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">662</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m19:55:23\u001b[0m,\u001b[1;36m662\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:55:23</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">684</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: CategoryEmbeddingModel \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m19:55:23\u001b[0m,\u001b[1;36m684\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: CategoryEmbeddingModel \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:55:23</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">719</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m19:55:23\u001b[0m,\u001b[1;36m719\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:55:23</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">730</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m19:55:23\u001b[0m,\u001b[1;36m730\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/boom/sdev/repos/AutoDeep/autodeep/examples/ptabular_checkpoints exists and is not empty.\n",
      "\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                      </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ custom_loss      │ CrossEntropyLoss          │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _backbone        │ CategoryEmbeddingBackbone │ 34.2 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _embedding_layer │ Embedding1dLayer          │      8 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ head             │ LinearHead                │    387 │ train │\n",
       "└───┴──────────────────┴───────────────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType                     \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ custom_loss      │ CrossEntropyLoss          │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ CategoryEmbeddingBackbone │ 34.2 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer          │      8 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ head             │ LinearHead                │    387 │ train │\n",
       "└───┴──────────────────┴───────────────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 34.6 K                                                                                           \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 34.6 K                                                                                               \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 14                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 34.6 K                                                                                           \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 34.6 K                                                                                               \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 14                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97f5cb6357ec4e11a97422c0f1b9fb3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number \n",
       "of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for \n",
       "log_every_n_steps if you want to see logs for the training epoch.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number \n",
       "of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for \n",
       "log_every_n_steps if you want to see logs for the training epoch.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:55:25</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">745</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m19:55:25\u001b[0m,\u001b[1;36m745\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:55:25</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">748</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m19:55:25\u001b[0m,\u001b[1;36m748\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:55:25</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">750</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1537</span><span style=\"font-weight: bold\">}</span> - WARNING - No best model available to load. Did you\n",
       "run it more than <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> epoch?<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                                                                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m19:55:25\u001b[0m,\u001b[1;36m750\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1537\u001b[0m\u001b[1m}\u001b[0m - WARNING - No best model available to load. Did you\n",
       "run it more than \u001b[1;36m1\u001b[0m epoch?\u001b[33m...\u001b[0m                                                                                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-06 19:55:26,013 - INFO - CommonStructure.py - CategoryEmbeddingTrainer - Validation metrics: {'accuracy': 0.5555555555555556}\n",
      "100%|██████████| 2/2 [00:05<00:00,  2.73s/trial, best loss: -0.5555555555555556]\n",
      "2025-02-06 19:55:26,266 - INFO - CommonStructure.py - CategoryEmbeddingTrainer - Final validation metrics: {'accuracy': 0.5555555555555556}\n",
      "2025-02-06 19:55:26,267 - INFO - CommonStructure.py - CategoryEmbeddingTrainer - Loading model\n",
      "2025-02-06 19:55:26,267 - DEBUG - CommonStructure.py - CategoryEmbeddingTrainer - Model loaded successfully\n",
      "2025-02-06 19:55:26,268 - INFO - CommonStructure.py - CategoryEmbeddingTrainer - Best hyperparameters: {'activation': 'ReLU', 'batch_size': 352, 'dropout': 0.07180182756042691, 'embedding_dropout': 0.04456699223511802, 'initialization': 'xavier', 'layers': '256-128-64-32', 'optimizer_fn': {'AdamW_learning_rate': 0.0002369073315019895, 'AdamW_weight_decay': 2.7190091816919235e-08, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>}, 'scheduler_fn': {'StepLR_gamma': 0.24871568886900097, 'StepLR_step_size': 27, 'scheduler_fn': <class 'torch.optim.lr_scheduler.StepLR'>}, 'use_batch_norm': False, 'default_params': {'early_stopping_rounds': 10, 'verbose': False, 'iterations': 20, 'retrain': False, 'auto_lr_find': False, 'max_epochs': 3, 'val_size': 0.15, 'early_stopping_patience': 20}}\n",
      "2025-02-06 19:55:26,268 - INFO - CommonStructure.py - CategoryEmbeddingTrainer - The best possible score for metric accuracy is 1.0, we reached accuracy = 0.5555555555555556\n",
      "2025-02-06 19:55:26,269 - INFO - CommonStructure.py - CategoryEmbeddingTrainer - Computing predictions\n",
      "2025-02-06 19:55:26,514 - DEBUG - CommonStructure.py - CategoryEmbeddingTrainer - [0 2 0 0 0 2 2 0 2 1]\n",
      "2025-02-06 19:55:26,516 - DEBUG - CommonStructure.py - CategoryEmbeddingTrainer - Computed predictions successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 19:55:26,528 - INFO - SoftOrdering1DCNN.py - Device cuda is available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running s1dcnn on multiclass...\n",
      "Using dynamic loader for dataset: /home/boom/sdev/repos/AutoDeep/autodeep/examples/testautodata/iris.csv\n",
      "batch_size [1024, 512, 256]\n",
      "hidden_size [4096, 2048, 1024]\n",
      "optimizer_fn {'Adam': {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}, 'SGD': {'weight_decay': [0.0, 1e-07], 'momentum': [0.0, 0.9], 'learning_rate': [0.001, 1e-05]}, 'AdamW': {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}}\n",
      "dict_keys(['Adam', 'SGD', 'AdamW'])\n",
      "Adam {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}\n",
      "weight_decay [0.0, 1e-07]\n",
      "learning_rate [0.001, 0.0001]\n",
      "SGD {'weight_decay': [0.0, 1e-07], 'momentum': [0.0, 0.9], 'learning_rate': [0.001, 1e-05]}\n",
      "weight_decay [0.0, 1e-07]\n",
      "momentum [0.0, 0.9]\n",
      "learning_rate [0.001, 1e-05]\n",
      "AdamW {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}\n",
      "weight_decay [0.0, 1e-07]\n",
      "learning_rate [0.001, 0.0001]\n",
      "scheduler_fn {'ReduceLROnPlateau': {'factor': [0.1, 0.01], 'patience': [5, 10]}, 'StepLR': {'step_size': [10, 30], 'gamma': [0.1, 0.5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}\n",
      "dict_keys(['ReduceLROnPlateau', 'StepLR', 'ExponentialLR'])\n",
      "ReduceLROnPlateau {'factor': [0.1, 0.01], 'patience': [5, 10]}\n",
      "factor [0.1, 0.01]\n",
      "patience [5, 10]\n",
      "StepLR {'step_size': [10, 30], 'gamma': [0.1, 0.5]}\n",
      "step_size [10, 30]\n",
      "gamma [0.1, 0.5]\n",
      "ExponentialLR {'gamma': [0.9, 0.99]}\n",
      "gamma [0.9, 0.99]\n",
      "CLASSES tensor([0, 1, 2])\n",
      "tensor([1., 1., 1.], device='cuda:0')\n",
      "  0%|          | 0/2 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 19:55:26,615 - INFO - SoftOrdering1DCNN.py - Training with hyperparameters: {'AdamW_learning_rate': 0.00041691320143948053, 'AdamW_weight_decay': 5.3327377727838295e-08, 'Adam_learning_rate': 0.000883609493567339, 'Adam_weight_decay': 5.3453713798712174e-08, 'ExponentialLR_gamma': 0.9700428647065971, 'ReduceLROnPlateau_factor': 0.014194472482598669, 'ReduceLROnPlateau_patience': 6, 'SGD_learning_rate': 5.540876168540814e-05, 'SGD_momentum': 0.7753748228926656, 'SGD_weight_decay': 1.1771360216800085e-08, 'StepLR_gamma': 0.1469911132467317, 'StepLR_step_size': 14, 'batch_size': 601, 'hidden_size': 1024, 'optimizer_fn': <class 'torch.optim.sgd.SGD'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>}\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n",
      "\n",
      "Training:   0%|                                        | 0/1 [00:00<?, ?epoch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Train Loss: 1.2877, Val Loss: 1.0990    \n",
      "  0%|          | 0/2 [00:01<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:240: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "\n",
      "Training: 100%|################################| 1/1 [00:01<00:00,  1.28s/epoch]\n",
      "Training: 100%|################################| 1/1 [00:01<00:00,  1.28s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model loaded from epoch 1                       \n",
      "  0%|          | 0/2 [00:01<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 19:55:29,183 - INFO - SoftOrdering1DCNN.py - Validation metrics: {'accuracy': 0.3333333333333333}\n",
      "2025-02-06 19:55:29,184 - INFO - SoftOrdering1DCNN.py - Training metrics: {'accuracy': 0.3333333333333333}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:02<00:02,  2.58s/trial, best loss: -0.3333333333333333]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 19:55:29,193 - INFO - SoftOrdering1DCNN.py - Training with hyperparameters: {'AdamW_learning_rate': 0.0005493747562277502, 'AdamW_weight_decay': 5.979030232767242e-08, 'Adam_learning_rate': 0.00010037826615600942, 'Adam_weight_decay': 2.309091722462173e-08, 'ExponentialLR_gamma': 0.9526834243165615, 'ReduceLROnPlateau_factor': 0.021158305135007868, 'ReduceLROnPlateau_patience': 7, 'SGD_learning_rate': 9.52118823872863e-05, 'SGD_momentum': 0.6960145837348019, 'SGD_weight_decay': 2.4860021513335803e-08, 'StepLR_gamma': 0.2095872419296196, 'StepLR_step_size': 19, 'batch_size': 278, 'hidden_size': 4096, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>}\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n",
      "\n",
      "/home/boom/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "\n",
      "Training:   0%|                                        | 0/1 [00:00<?, ?epoch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Train Loss: 1.1490, Val Loss: 1.0982                               \n",
      " 50%|█████     | 1/2 [00:03<00:02,  2.58s/trial, best loss: -0.3333333333333333]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|################################| 1/1 [00:01<00:00,  1.27s/epoch]\n",
      "Training: 100%|################################| 1/1 [00:01<00:00,  1.27s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model loaded from epoch 1                                                  \n",
      " 50%|█████     | 1/2 [00:03<00:02,  2.58s/trial, best loss: -0.3333333333333333]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 19:55:31,705 - INFO - SoftOrdering1DCNN.py - Validation metrics: {'accuracy': 0.3333333333333333}\n",
      "2025-02-06 19:55:31,706 - INFO - SoftOrdering1DCNN.py - Training metrics: {'accuracy': 0.3333333333333333}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:05<00:00,  2.55s/trial, best loss: -0.3333333333333333]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 19:55:31,711 - INFO - SoftOrdering1DCNN.py - Final Validation Metrics: {'accuracy': 0.3333333333333333}\n",
      "2025-02-06 19:55:31,712 - INFO - SoftOrdering1DCNN.py - Final Training Metrics: {'accuracy': 0.3333333333333333}\n",
      "2025-02-06 19:55:31,712 - INFO - SoftOrdering1DCNN.py - Loading model\n",
      "2025-02-06 19:55:31,713 - INFO - SoftOrdering1DCNN.py - Best hyperparameters: {'AdamW_learning_rate': 0.00041691320143948053, 'AdamW_weight_decay': 5.3327377727838295e-08, 'Adam_learning_rate': 0.000883609493567339, 'Adam_weight_decay': 5.3453713798712174e-08, 'ExponentialLR_gamma': 0.9700428647065971, 'ReduceLROnPlateau_factor': 0.014194472482598669, 'ReduceLROnPlateau_patience': 6, 'SGD_learning_rate': 5.540876168540814e-05, 'SGD_momentum': 0.7753748228926656, 'SGD_weight_decay': 1.1771360216800085e-08, 'StepLR_gamma': 0.1469911132467317, 'StepLR_step_size': 14, 'batch_size': 601, 'hidden_size': 1024, 'optimizer_fn': <class 'torch.optim.sgd.SGD'>, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>, 'default_params': {'early_stopping_rounds': 10, 'verbose': False, 'iterations': 20, 'retrain': False, 'auto_lr_find': False, 'max_epochs': 1, 'val_size': 0.15, 'early_stopping_patience': 5}}\n",
      "2025-02-06 19:55:31,714 - INFO - SoftOrdering1DCNN.py - Best metric accuracy: 0.3333333333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No results collected. Check if `_save_results` is appending correctly.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Define paths to configuration files and data\n",
    "DATA_FOLDER = Path(\"/home/boom/sdev/repos/AutoDeep/autodeep/examples/testautodata\")\n",
    "OUTPUT_FOLDER = Path(\"/home/boom/sdev/repos/AutoDeep/autodeep/examples/output\")\n",
    "\n",
    "DEFAULT_MODELS = [\n",
    "   \n",
    "    \"resnet\",\n",
    "    \"mlp\",\n",
    "    \"xgb\",\n",
    "    \"catboost\",\n",
    "    \"categoryembedding\",\n",
    "    \"s1dcnn\",\n",
    "]  # Ensure all model names are lowercase\n",
    "\n",
    "\n",
    "DATA_CONFIG = {\n",
    "    \"binary\": {\n",
    "        \"dataset_path\": DATA_FOLDER / \"adult.csv\",\n",
    "        \"target_col\": \"target\",\n",
    "        \"problem_type\": \"binary_classification\",\n",
    "        \"test_size\": 0.15,\n",
    "        \"num_targets\": 1,\n",
    "        \"metric\": \"roc_auc\",\n",
    "        \"eval_metrics\": [\"accuracy\", \"roc_auc\", \"lift5\"],\n",
    "    },\n",
    "    \"regression\": {\n",
    "        \"dataset_path\": DATA_FOLDER / \"cal_housing.csv\",\n",
    "        \"target_col\": \"target\",\n",
    "        \"problem_type\": \"regression\",\n",
    "        \"test_size\": 0.2,\n",
    "        \"num_targets\": 1,\n",
    "        \"metric\": \"rmse\",\n",
    "        \"eval_metrics\": [\"mse\", \"rmse\", \"r2_score\"],\n",
    "    },\n",
    "    \"multiclass\": {\n",
    "        \"dataset_path\": DATA_FOLDER / \"iris.csv\",\n",
    "        \"target_col\": \"target\",\n",
    "        \"problem_type\": \"multiclass_classification\",\n",
    "        \"test_size\": 0.2,\n",
    "        \"num_targets\": 3,\n",
    "        \"metric\": \"accuracy\",\n",
    "        \"eval_metrics\": [\"accuracy\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "# Initialize AutoRunner instance with the configuration\n",
    "runner = AutoRunner(\n",
    "    data_config=DATA_CONFIG,\n",
    "    output_folder=OUTPUT_FOLDER,\n",
    "    default_models=DEFAULT_MODELS,\n",
    "    random_state=42,\n",
    "    execution_mode=\"hyperopt\",  # Adjust if needed\n",
    "    max_evals=2,\n",
    ")\n",
    "\n",
    "# Run the AutoML process\n",
    "runner.run()\n",
    "\n",
    "# Print results from saved outputs\n",
    "if runner.results:\n",
    "    for result in runner.results:\n",
    "        print(result)\n",
    "else:\n",
    "    print(\"No results collected. Check if `_save_results` is appending correctly.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Package(s) not found: sklearn\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip show sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "from pytorch_tabular.models import GatedAdditiveTreeEnsembleConfig\n",
    "\n",
    "help(GatedAdditiveTreeEnsembleConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dok1 = {\n",
    "    \"additional_tree_output_dim\": 3,\n",
    "    \"batch_norm_continuous_input\": True,\n",
    "    \"bin_function\": \"entmoid15\",\n",
    "    \"choice_function\": \"entmax15\",\n",
    "    \"depth\": 5,\n",
    "    \"embed_categorical\": True,\n",
    "    \"embedding_dropout\": 0.06089480159646259,\n",
    "    \"initialize_response\": \"normal\",\n",
    "    \"initialize_selection_logits\": \"normal\",\n",
    "    \"input_dropout\": 0.15466990749662266,\n",
    "    \"max_features\": 32,\n",
    "    \"num_layers\": 1,\n",
    "    \"num_trees\": 736,\n",
    "    \"threshold_init_beta\": 0.6724199121113691,\n",
    "    \"threshold_init_cutoff\": 0.6076965359243615,\n",
    "}\n",
    "dko2 = {\n",
    "    \"additional_tree_output_dim\": 3,\n",
    "    \"batch_norm_continuous_input\": False,\n",
    "    \"bin_function\": \"entmoid15\",\n",
    "    \"choice_function\": \"entmax15\",\n",
    "    \"depth\": 6,\n",
    "    \"embedding_dropout\": 0.05438018363383848,\n",
    "    \"initialize_response\": \"normal\",\n",
    "    \"initialize_selection_logits\": \"normal\",\n",
    "    \"input_dropout\": 0.17230551619837015,\n",
    "    \"max_features\": 21,\n",
    "    \"num_layers\": 1,\n",
    "    \"num_trees\": 626,\n",
    "    \"threshold_init_beta\": 0.9430824174145327,\n",
    "    \"threshold_init_cutoff\": 1.1093300211337618,\n",
    "}\n",
    "\n",
    "dko3 = {\n",
    "    \"additional_tree_output_dim\": 3,\n",
    "    \"batch_norm_continuous_input\": False,\n",
    "    \"bin_function\": \"sparsemoid\",\n",
    "    \"choice_function\": \"entmax15\",\n",
    "    \"depth\": 4,\n",
    "    \"embedding_dropout\": 0.05438018363383848,\n",
    "    \"initialize_response\": \"normal\",\n",
    "    \"initialize_selection_logits\": \"normal\",\n",
    "    \"input_dropout\": 0.17230551619837015,\n",
    "    \"max_features\": 21,\n",
    "    \"num_layers\": 1,\n",
    "    \"num_trees\": 626,\n",
    "    \"threshold_init_beta\": 0.826726207188516,\n",
    "    \"threshold_init_cutoff\": 0.9402437257075205,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddiff = {k: v for k, v in dko2.items() if dko2[k] != dok1[k]}\n",
    "ddiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddiff = {k: v for k, v in dko3.items() if dko3[k] != dok1[k]}\n",
    "ddiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Define the folder to format and lint\n",
    "folder_to_check = \"autodeep\"\n",
    "\n",
    "# Define output files\n",
    "output_files = {\n",
    "    \"isort\": \"isort_output.txt\",\n",
    "    \"black\": \"black_output.txt\",\n",
    "    \"pylint\": \"pylint_output.txt\",\n",
    "    \"flake8\": \"flake8_output.txt\",\n",
    "}\n",
    "\n",
    "# Ensure the output folder exists\n",
    "os.makedirs(\"linting_outputs\", exist_ok=True)\n",
    "\n",
    "# Run isort\n",
    "with open(os.path.join(\"linting_outputs\", output_files[\"isort\"]), \"w\") as f:\n",
    "    subprocess.run([\"isort\", folder_to_check], stdout=f, stderr=f)\n",
    "\n",
    "# Run black\n",
    "with open(os.path.join(\"linting_outputs\", output_files[\"black\"]), \"w\") as f:\n",
    "    subprocess.run([\"black\", folder_to_check], stdout=f, stderr=f)\n",
    "\n",
    "# Run pylint\n",
    "with open(os.path.join(\"linting_outputs\", output_files[\"pylint\"]), \"w\") as f:\n",
    "    subprocess.run([\"pylint\", folder_to_check], stdout=f, stderr=f)\n",
    "\n",
    "# Run flake8\n",
    "with open(os.path.join(\"linting_outputs\", output_files[\"flake8\"]), \"w\") as f:\n",
    "    subprocess.run([\"flake8\", folder_to_check], stdout=f, stderr=f)\n",
    "\n",
    "print(\n",
    "    \"Linting and formatting completed. Outputs are saved in the 'linting_outputs' folder.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install isort black pylint flake8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Define the path to the folder to format and lint (one level up from the current directory)\n",
    "folder_to_check = \"../../autodeep\"\n",
    "\n",
    "# Define the output folder and ensure it exists\n",
    "output_folder = \"linting_outputs\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Define the output files\n",
    "output_files = {\n",
    "    \"isort\": \"isort_output.txt\",\n",
    "    \"black\": \"black_output.txt\",\n",
    "    \"pylint\": \"pylint_output.txt\",\n",
    "    \"flake8\": \"flake8_output.txt\",\n",
    "}\n",
    "\n",
    "# Run isort\n",
    "isort_output_path = os.path.join(output_folder, output_files[\"isort\"])\n",
    "with open(isort_output_path, \"w\") as f:\n",
    "    subprocess.run([\"isort\", folder_to_check], stdout=f, stderr=f)\n",
    "\n",
    "# Run black\n",
    "black_output_path = os.path.join(output_folder, output_files[\"black\"])\n",
    "with open(black_output_path, \"w\") as f:\n",
    "    subprocess.run([\"black\", folder_to_check], stdout=f, stderr=f)\n",
    "\n",
    "# Run pylint\n",
    "pylint_output_path = os.path.join(output_folder, output_files[\"pylint\"])\n",
    "with open(pylint_output_path, \"w\") as f:\n",
    "    subprocess.run([\"pylint\", folder_to_check], stdout=f, stderr=f)\n",
    "\n",
    "# Run flake8\n",
    "flake8_output_path = os.path.join(output_folder, output_files[\"flake8\"])\n",
    "with open(flake8_output_path, \"w\") as f:\n",
    "    subprocess.run([\"flake8\", folder_to_check], stdout=f, stderr=f)\n",
    "\n",
    "print(\n",
    "    f\"Linting and formatting completed. Outputs are saved in the '{output_folder}' folder.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
