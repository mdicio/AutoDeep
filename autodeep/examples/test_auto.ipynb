{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test AutoML Functionality in a Separate Notebook\n",
    "from autodeep.automl import AutoRunner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataConfig(\n",
    "    target=[\"target\"],\n",
    "    continuous_cols=[\n",
    "        \"Unnamed: 0\",\n",
    "        \"age\",\n",
    "        \"fnlwgt\",\n",
    "        \"education-num\",\n",
    "        \"capital-gain\",\n",
    "        \"capital-loss\",\n",
    "        \"hours-per-week\",\n",
    "    ],\n",
    "    categorical_cols=[\n",
    "        \"workclass\",\n",
    "        \"education\",\n",
    "        \"marital-status\",\n",
    "        \"occupation\",\n",
    "        \"relationship\",\n",
    "        \"race\",\n",
    "        \"sex\",\n",
    "        \"native-country\",\n",
    "    ],\n",
    "    date_columns=[],\n",
    "    encode_date_columns=True,\n",
    "    validation_split=0.2,\n",
    "    continuous_feature_transform=None,\n",
    "    normalize_continuous_features=True,\n",
    "    quantile_noise=0,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    handle_unknown_categories=True,\n",
    "    handle_missing_values=True,\n",
    ")\n",
    "CategoryEmbeddingModelConfig(\n",
    "    task=\"classification\",\n",
    "    head=\"LinearHead\",\n",
    "    head_config={\"layers\": \"\"},\n",
    "    embedding_dims=None,\n",
    "    embedding_dropout=0.0,\n",
    "    batch_norm_continuous_input=True,\n",
    "    learning_rate=0.001,\n",
    "    loss=\"CrossEntropyLoss\",\n",
    "    metrics=[\"accuracy\"],\n",
    "    metrics_prob_input=[False],\n",
    "    metrics_params=[{}],\n",
    "    target_range=None,\n",
    "    seed=42,\n",
    "    _module_src=\"models.category_embedding\",\n",
    "    _model_name=\"CategoryEmbeddingModel\",\n",
    "    _backbone_name=\"CategoryEmbeddingBackbone\",\n",
    "    _config_name=\"CategoryEmbeddingModelConfig\",\n",
    "    layers=\"128-64-32\",\n",
    "    activation=\"ReLU\",\n",
    "    use_batch_norm=False,\n",
    "    initialization=\"kaiming\",\n",
    "    dropout=0.0,\n",
    ")\n",
    "OptimizerConfig(\n",
    "    optimizer=\"Adam\",\n",
    "    optimizer_params={\"weight_decay\": 2.228349611755901e-09},\n",
    "    lr_scheduler=\"ReduceLROnPlateau\",\n",
    "    lr_scheduler_params={\n",
    "        \"factor\": 0.028109779164095607,\n",
    "        \"patience\": 7,\n",
    "        \"min_lr\": 1e-07,\n",
    "        \"verbose\": True,\n",
    "        \"mode\": \"min\",\n",
    "    },\n",
    "    lr_scheduler_monitor_metric=\"valid_loss\",\n",
    ")\n",
    "TrainerConfig(\n",
    "    batch_size=1613,\n",
    "    data_aware_init_batch_size=2000,\n",
    "    fast_dev_run=False,\n",
    "    max_epochs=1000,\n",
    "    min_epochs=1,\n",
    "    max_time=None,\n",
    "    gpus=None,\n",
    "    accelerator=\"auto\",\n",
    "    devices=None,\n",
    "    devices_list=None,\n",
    "    accumulate_grad_batches=1,\n",
    "    auto_lr_find=False,\n",
    "    auto_select_gpus=True,\n",
    "    check_val_every_n_epoch=1,\n",
    "    gradient_clip_val=0.0,\n",
    "    overfit_batches=0.0,\n",
    "    deterministic=False,\n",
    "    profiler=None,\n",
    "    early_stopping=\"valid_loss\",\n",
    "    early_stopping_min_delta=0.0,\n",
    "    early_stopping_mode=\"min\",\n",
    "    early_stopping_patience=2,\n",
    "    early_stopping_kwargs={},\n",
    "    checkpoints=\"valid_loss\",\n",
    "    checkpoints_path=\"ptabular_checkpoints\",\n",
    "    checkpoints_every_n_epochs=1,\n",
    "    checkpoints_name=None,\n",
    "    checkpoints_mode=\"min\",\n",
    "    checkpoints_save_top_k=1,\n",
    "    checkpoints_kwargs={},\n",
    "    load_best=True,\n",
    "    track_grad_norm=-1,\n",
    "    progress_bar=\"rich\",\n",
    "    precision=32,\n",
    "    seed=42,\n",
    "    trainer_kwargs={},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-30 19:09:09,896 - INFO - CommonStructure.py - Device cuda is available\n",
      "2025-01-30 19:09:09,896 - INFO - CommonStructure.py - Starting hyperopt search 2 evals maximizing roc_auc metric on dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running node on dataset1...\n",
      "{'random_state': 4200, 'retrain': True, 'include_models': ['XGB', 'CatBoost', 'MLP', 'TabNet', 'GATE', 'resnet', 'S1DCNN', 'CategoryEmbedding', 'FTTransformer', 'TabTransformer', 'GANDALF', 'AutoInt', 'Node'], 'model_configs': {'catboost': {'data_params': {'normalize_features': 'mean_std', 'encode_categorical': False, 'return_extra_info': True}, 'default_params': {'retrain': False, 'validation_fraction': 0.15, 'early_stopping_rounds': 100, 'verbose': False, 'iterations': 500}, 'param_grid': {'early_stopping_rounds': [100, 50], 'iterations': [100, 500]}}, 'categoryembedding': {'data_params': {'normalize_features': 'mean_std', 'encode_categorical': False, 'return_extra_info': True}, 'default_params': {'early_stopping_rounds': 10, 'verbose': False, 'iterations': 20, 'retrain': False, 'auto_lr_find': False, 'max_epochs': 10, 'val_size': 0.15, 'early_stopping_patience': 20}, 'param_grid': {'batch_size': [128, 1024], 'layers': ['128-64-32', '256-128', '256-128-64-32', '32-16', '64-32-16', '64-32'], 'activation': ['ReLU', 'LeakyReLU'], 'use_batch_norm': [True, False], 'initialization': ['kaiming', 'xavier', 'random'], 'dropout': [0.0, 0.3], 'embedding_dropout': [0.0, 0.2], 'optimizer_fn': {'Adam': {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}, 'SGD': {'weight_decay': [0.0, 1e-07], 'momentum': [0.0, 0.9], 'learning_rate': [0.001, 1e-05]}, 'AdamW': {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.01], 'patience': [5, 10]}, 'StepLR': {'step_size': [10, 30], 'gamma': [0.1, 0.5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}, 'gandalf': {'data_params': {'normalize_features': 'mean_std', 'encode_categorical': False, 'return_extra_info': True}, 'default_params': {'early_stopping_rounds': 10, 'verbose': False, 'iterations': 20, 'retrain': False, 'auto_lr_find': False, 'max_epochs': 10, 'val_size': 0.15, 'early_stopping_patience': 20}, 'param_grid': {'batch_size': [128, 1024], 'layers': ['128-64-32', '256-128', '256-128-64-32', '32-16', '64-32-16', '64-32'], 'activation': ['ReLU', 'LeakyReLU'], 'gflu_stages': [2, 8], 'gflu_dropout': [0.0, 0.1], 'embedding_dropout': [0.0, 0.1], 'optimizer_fn': {'Adam': {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}, 'SGD': {'weight_decay': [0.0, 1e-07], 'momentum': [0.0, 0.9], 'learning_rate': [0.001, 1e-05]}, 'AdamW': {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.01], 'patience': [5, 10]}, 'StepLR': {'step_size': [10, 30], 'gamma': [0.1, 0.5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}, 'autoint': {'data_params': {'normalize_features': 'mean_std', 'encode_categorical': False, 'return_extra_info': True}, 'default_params': {'early_stopping_rounds': 10, 'verbose': False, 'iterations': 20, 'retrain': False, 'auto_lr_find': False, 'max_epochs': 10, 'val_size': 0.15, 'early_stopping_patience': 20}, 'param_grid': {'batch_size': [64, 1024], 'attn_embed_dim': [16, 64], 'num_heads': [1, 4], 'num_attn_blocks': [1, 3], 'attn_dropouts': [0.0, 0.2], 'embedding_dim': [8, 32], 'shared_embedding_fraction': [0.1, 0.4], 'layers': ['64-32', '128-64-32', '256-128-64-32'], 'activation': ['ReLU', 'LeakyReLU', 'TanH'], 'dropout': [0.0, 0.2], 'attention_pooling': [True, False], 'embedding_initialization': ['kaiming_uniform', 'kaiming_normal'], 'share_embedding_strategy': ['add', 'fraction'], 'embedding_dropout': [0.05, 0.2], 'batch_norm_continuous_input': [True, False], 'initialization': ['kaiming', 'xavier', 'random'], 'optimizer_fn': {'Adam': {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}, 'SGD': {'weight_decay': [0.0, 1e-07], 'momentum': [0.0, 0.9], 'learning_rate': [0.001, 1e-05]}, 'AdamW': {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.01], 'patience': [5, 10]}, 'StepLR': {'step_size': [10, 30], 'gamma': [0.1, 0.5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}, 'fttransformer': {'data_params': {'normalize_features': 'mean_std', 'encode_categorical': False, 'return_extra_info': True}, 'default_params': {'early_stopping_rounds': 10, 'verbose': False, 'iterations': 20, 'retrain': False, 'auto_lr_find': False, 'max_epochs': 10, 'val_size': 0.15, 'early_stopping_patience': 20}, 'param_grid': {'batch_size': [64, 1024], 'input_embed_dim': [16, 64], 'num_heads': [4, 16], 'num_attn_blocks': [3, 8], 'attn_dropout': [0.0, 0.2], 'add_norm_dropout': [0.0, 0.2], 'ff_dropout': [0.0, 0.2], 'ff_hidden_multiplier': [2, 6], 'shared_embedding_fraction': [0.1, 0.4], 'learning_rate': [0.0005, 0.005], 'transformer_activation': ['GEGLU', 'ReGLU', 'SwiGLU', 'ReLU'], 'embedding_initialization': ['kaiming_uniform', 'kaiming_normal'], 'share_embedding_strategy': ['add', 'fraction'], 'embedding_dropout': [0.05, 0.2], 'batch_norm_continuous_input': [True, False], 'attention_pooling': [True, False], 'optimizer_fn': {'Adam': {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}, 'SGD': {'weight_decay': [0.0, 1e-07], 'momentum': [0.0, 0.9], 'learning_rate': [0.001, 1e-05]}, 'AdamW': {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.01], 'patience': [5, 10]}, 'StepLR': {'step_size': [10, 30], 'gamma': [0.1, 0.5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}, 'gate': {'data_params': {'normalize_features': 'mean_std', 'encode_categorical': False, 'return_extra_info': True}, 'default_params': {'early_stopping_rounds': 10, 'verbose': False, 'iterations': 20, 'retrain': False, 'auto_lr_find': False, 'max_epochs': 10, 'val_size': 0.15, 'early_stopping_patience': 20}, 'param_grid': {'batch_size': [64, 1024], 'gflu_stages': [4, 8], 'gflu_dropout': [0.0, 0.2], 'tree_depth': [3, 6], 'num_trees': [5, 20], 'binning_activation': ['sparsemoid', 'entmoid'], 'feature_mask_function': ['sparsemax', 'entmax'], 'tree_dropout': [0.0, 0.2], 'tree_wise_attention': [True, False], 'tree_wise_attention_dropout': [0.0, 0.2], 'share_head_weights': [True, False], 'learning_rate': [0.0005, 0.005], 'embedding_dropout': [0.05, 0.2], 'batch_norm_continuous_input': [True, False], 'optimizer_fn': {'Adam': {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}, 'SGD': {'weight_decay': [0.0, 1e-07], 'momentum': [0.0, 0.9], 'learning_rate': [0.001, 1e-05]}, 'AdamW': {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.01], 'patience': [5, 10]}, 'StepLR': {'step_size': [10, 30], 'gamma': [0.1, 0.5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}, 'node': {'data_params': {'normalize_features': 'mean_std', 'encode_categorical': False, 'return_extra_info': True}, 'default_params': {'early_stopping_rounds': 10, 'verbose': False, 'iterations': 20, 'retrain': False, 'auto_lr_find': False, 'max_epochs': 10, 'val_size': 0.15, 'early_stopping_patience': 20}, 'param_grid': {'batch_size': [64, 512], 'num_layers': [1, 2], 'num_trees': [512, 1024], 'additional_tree_output_dim': [2, 4], 'depth': [4, 6], 'choice_function': ['entmax15', 'sparsemax'], 'bin_function': ['entmoid15', 'sparsemoid'], 'max_features': [10, 50, 100], 'input_dropout': [0.0, 0.2], 'initialize_response': ['normal', 'uniform'], 'initialize_selection_logits': ['normal', 'uniform'], 'threshold_init_beta': [0.5, 1.0, 2.0], 'threshold_init_cutoff': [0.5, 1.0, 2.0], 'embedding_dropout': [0.0, 0.2], 'batch_norm_continuous_input': [True, False], 'embed_categorical': [True, False], 'optimizer_fn': {'Adam': {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}, 'SGD': {'weight_decay': [0.0, 1e-07], 'momentum': [0.0, 0.9], 'learning_rate': [0.001, 1e-05]}, 'AdamW': {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.01], 'patience': [5, 10]}, 'StepLR': {'step_size': [10, 30], 'gamma': [0.1, 0.5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}, 'tabnet': {'data_params': {'normalize_features': 'mean_std', 'encode_categorical': False, 'return_extra_info': True}, 'default_params': {'early_stopping_rounds': 10, 'verbose': False, 'iterations': 20, 'retrain': False, 'auto_lr_find': False, 'max_epochs': 10, 'val_size': 0.15, 'early_stopping_patience': 20}, 'param_grid': {'batch_size': [64, 512, 1024], 'n_d': [8, 16, 32, 64], 'n_a': [8, 16, 32, 64], 'n_steps': [3, 4, 5, 6], 'gamma': [1.1, 1.3, 1.5], 'n_independent': [1, 2, 3], 'n_shared': [1, 2, 3], 'virtual_batch_size': [32, 64, 128], 'mask_type': ['sparsemax', 'entmax'], 'learning_rate': [0.0005, 0.001, 0.005], 'embedding_dropout': [0.0, 0.1, 0.2], 'batch_norm_continuous_input': [True, False], 'head': ['LinearHead', 'MixtureDensityHead'], 'optimizer_fn': {'Adam': {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}, 'SGD': {'weight_decay': [0.0, 1e-07], 'momentum': [0.0, 0.9], 'learning_rate': [0.001, 1e-05]}, 'AdamW': {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.01], 'patience': [5, 10]}, 'StepLR': {'step_size': [10, 30], 'gamma': [0.1, 0.5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}, 'tabtransformer': {'data_params': {'normalize_features': 'mean_std', 'encode_categorical': False, 'return_extra_info': True}, 'default_params': {'early_stopping_rounds': 10, 'verbose': False, 'iterations': 20, 'retrain': False, 'auto_lr_find': False, 'max_epochs': 10, 'val_size': 0.15, 'early_stopping_patience': 20}, 'param_grid': {'batch_size': [64, 512, 1024], 'input_embed_dim': [32, 64, 128], 'embedding_initialization': ['kaiming_uniform', 'kaiming_normal'], 'embedding_bias': [True, False], 'share_embedding': [True, False], 'share_embedding_strategy': ['add', 'fraction'], 'shared_embedding_fraction': [0.25, 0.5, 0.75], 'num_heads': [4, 8, 16], 'num_attn_blocks': [4, 6, 8], 'transformer_head_dim': [32, 64, 128], 'attn_dropout': [0.1, 0.2, 0.3], 'add_norm_dropout': [0.1, 0.2], 'ff_dropout': [0.1, 0.2], 'ff_hidden_multiplier': [2, 4, 8], 'transformer_activation': ['GEGLU', 'ReLU', 'SwiGLU'], 'out_ff_layers': ['128-64-32', '256-128-64'], 'out_ff_activation': ['ReLU', 'LeakyReLU'], 'out_ff_dropout': [0.0, 0.1, 0.2], 'out_ff_initialization': ['kaiming', 'xavier', 'random'], 'learning_rate': [0.0005, 0.001, 0.005], 'embedding_dropout': [0.0, 0.1, 0.2], 'batch_norm_continuous_input': [True, False], 'head': ['LinearHead', 'MixtureDensityHead'], 'optimizer_fn': {'Adam': {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}, 'SGD': {'weight_decay': [0.0, 1e-07], 'momentum': [0.0, 0.9], 'learning_rate': [0.001, 1e-05]}, 'AdamW': {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.01], 'patience': [5, 10]}, 'StepLR': {'step_size': [10, 30], 'gamma': [0.1, 0.5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}, 'resnet': {'data_params': {'normalize_features': 'mean_std', 'encode_categorical': True, 'return_extra_info': True}, 'default_params': {'early_stopping_rounds': 10, 'verbose': False, 'iterations': 20, 'retrain': False, 'auto_lr_find': False, 'max_epochs': 1000, 'val_size': 0.2, 'early_stopping_patience': 6}, 'param_grid': {'resnet_depth': ['resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152'], 'batch_size': [1024, 512, 256], 'optimizer_fn': {'Adam': {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}, 'SGD': {'weight_decay': [0.0, 1e-07], 'momentum': [0.0, 0.9], 'learning_rate': [0.001, 1e-05]}, 'AdamW': {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.01], 'patience': [5, 10]}, 'StepLR': {'step_size': [10, 30], 'gamma': [0.1, 0.5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}, 's1dcnn': {'data_params': {'normalize_features': 'mean_std', 'encode_categorical': False, 'return_extra_info': True}, 'default_params': {'early_stopping_rounds': 10, 'verbose': False, 'iterations': 20, 'retrain': False, 'auto_lr_find': False, 'max_epochs': 1, 'val_size': 0.15, 'early_stopping_patience': 5}, 'param_grid': {'batch_size': [1024, 512, 256], 'hidden_size': [4096, 2048, 1024], 'optimizer_fn': {'Adam': {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}, 'SGD': {'weight_decay': [0.0, 1e-07], 'momentum': [0.0, 0.9], 'learning_rate': [0.001, 1e-05]}, 'AdamW': {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.01], 'patience': [5, 10]}, 'StepLR': {'step_size': [10, 30], 'gamma': [0.1, 0.5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}, 'xgb': {'data_params': {'normalize_features': False, 'encode_categorical': True, 'return_extra_info': False}, 'default_params': {'retrain': True, 'early_stopping_rounds': 30, 'verbose': False, 'learning_rate': 0.3, 'max_depth': 6, 'n_estimators': 100, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 0.0}, 'param_grid': {'early_stopping_rounds': [30, 50], 'learning_rate': [0.3, 0.01], 'max_depth': [4, 6, 8], 'n_estimators': [50, 100, 200], 'min_child_weight': [1, 5, 10], 'subsample': [0.6, 0.8, 1.0], 'colsample_bytree': [0.6, 0.8, 1.0], 'gamma': [0.0, 0.1, 0.2]}}, 'mlp': {'data_params': {'normalize_features': 'mean_std', 'encode_categorical': True, 'return_extra_info': False}, 'default_params': {'early_stopping': True, 'n_iter_no_change': 10, 'max_iter': 1000, 'hidden_layer_sizes': [32], 'activation': 'relu', 'solver': 'adam', 'batch_size': 1024}, 'param_grid': {'n_iter_no_change': [10, 15], 'max_iter': [1000, 2000], 'hidden_layer_sizes': [[64, 32], [128, 64, 32]], 'activation': ['relu', 'tanh'], 'solver': ['adam', 'sgd'], 'batch_size': [1024, 2048]}}}}\n",
      "{'data_params': {'normalize_features': 'mean_std', 'encode_categorical': False, 'return_extra_info': True}, 'default_params': {'early_stopping_rounds': 10, 'verbose': False, 'iterations': 20, 'retrain': False, 'auto_lr_find': False, 'max_epochs': 10, 'val_size': 0.15, 'early_stopping_patience': 20}, 'param_grid': {'batch_size': [64, 512], 'num_layers': [1, 2], 'num_trees': [512, 1024], 'additional_tree_output_dim': [2, 4], 'depth': [4, 6], 'choice_function': ['entmax15', 'sparsemax'], 'bin_function': ['entmoid15', 'sparsemoid'], 'max_features': [10, 50, 100], 'input_dropout': [0.0, 0.2], 'initialize_response': ['normal', 'uniform'], 'initialize_selection_logits': ['normal', 'uniform'], 'threshold_init_beta': [0.5, 1.0, 2.0], 'threshold_init_cutoff': [0.5, 1.0, 2.0], 'embedding_dropout': [0.0, 0.2], 'batch_norm_continuous_input': [True, False], 'embed_categorical': [True, False], 'optimizer_fn': {'Adam': {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}, 'SGD': {'weight_decay': [0.0, 1e-07], 'momentum': [0.0, 0.9], 'learning_rate': [0.001, 1e-05]}, 'AdamW': {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.01], 'patience': [5, 10]}, 'StepLR': {'step_size': [10, 30], 'gamma': [0.1, 0.5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}\n",
      "Using dynamic loader for dataset: /home/boom/sdev/repos/AutoDeep/autodeep/examples/testautodata/adult.csv\n",
      "SPACE ######################################################\n",
      "{'batch_size': <hyperopt.pyll.base.Apply object at 0x73db26a989d0>, 'num_layers': <hyperopt.pyll.base.Apply object at 0x73db1bd9b100>, 'num_trees': <hyperopt.pyll.base.Apply object at 0x73db1bd9b0a0>, 'additional_tree_output_dim': <hyperopt.pyll.base.Apply object at 0x73db1bd9b730>, 'depth': <hyperopt.pyll.base.Apply object at 0x73db1bd9b7c0>, 'choice_function': <hyperopt.pyll.base.Apply object at 0x73db1bc038b0>, 'bin_function': <hyperopt.pyll.base.Apply object at 0x73db1ba88220>, 'max_features': <hyperopt.pyll.base.Apply object at 0x73db1ba882e0>, 'input_dropout': <hyperopt.pyll.base.Apply object at 0x73db1ba88490>, 'initialize_response': <hyperopt.pyll.base.Apply object at 0x73db1ba88580>, 'initialize_selection_logits': <hyperopt.pyll.base.Apply object at 0x73db1ba886d0>, 'threshold_init_beta': <hyperopt.pyll.base.Apply object at 0x73db1ba88880>, 'threshold_init_cutoff': <hyperopt.pyll.base.Apply object at 0x73db1ba889d0>, 'embedding_dropout': <hyperopt.pyll.base.Apply object at 0x73db1ba88b20>, 'batch_norm_continuous_input': <hyperopt.pyll.base.Apply object at 0x73db1ba88c10>, 'embed_categorical': <hyperopt.pyll.base.Apply object at 0x73db1ba88d60>, 'optimizer_fn': <hyperopt.pyll.base.Apply object at 0x73db1ba89690>, 'scheduler_fn': <hyperopt.pyll.base.Apply object at 0x73db1ba89f00>}\n",
      "  0%|          | 0/2 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-30 19:09:09,955 - INFO - CommonStructure.py - Training with hyperparameters: {'additional_tree_output_dim': 3, 'batch_norm_continuous_input': False, 'batch_size': 488, 'bin_function': 'entmoid15', 'choice_function': 'entmax15', 'depth': 6, 'embed_categorical': False, 'embedding_dropout': 0.05438018363383848, 'initialize_response': 'normal', 'initialize_selection_logits': 'normal', 'input_dropout': 0.17230551619837015, 'max_features': 21, 'num_layers': 1, 'num_trees': 626, 'optimizer_fn': {'SGD_learning_rate': 0.0008958109541859922, 'SGD_momentum': 0.7310334553909785, 'SGD_weight_decay': 5.483165026112475e-08, 'optimizer_fn': <class 'torch.optim.sgd.SGD'>}, 'scheduler_fn': {'StepLR_gamma': 0.2228559482775585, 'StepLR_step_size': 22, 'scheduler_fn': <class 'torch.optim.lr_scheduler.StepLR'>}, 'threshold_init_beta': 0.9430824174145327, 'threshold_init_cutoff': 1.1093300211337618}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tabular model params                                 \n",
      "{'additional_tree_output_dim': 3, 'batch_norm_continuous_input': False, 'batch_size': 488, 'bin_function': 'entmoid15', 'choice_function': 'entmax15', 'depth': 6, 'embed_categorical': False, 'embedding_dropout': 0.05438018363383848, 'initialize_response': 'normal', 'initialize_selection_logits': 'normal', 'input_dropout': 0.17230551619837015, 'max_features': 21, 'num_layers': 1, 'num_trees': 626, 'optimizer_fn': {'SGD_learning_rate': 0.0008958109541859922, 'SGD_momentum': 0.7310334553909785, 'SGD_weight_decay': 5.483165026112475e-08, 'optimizer_fn': <class 'torch.optim.sgd.SGD'>}, 'scheduler_fn': {'StepLR_gamma': 0.2228559482775585, 'StepLR_step_size': 22, 'scheduler_fn': <class 'torch.optim.lr_scheduler.StepLR'>}, 'threshold_init_beta': 0.9430824174145327, 'threshold_init_cutoff': 1.1093300211337618}\n",
      "tabular model outer params                           \n",
      "{'early_stopping_rounds': 10, 'verbose': False, 'iterations': 20, 'retrain': False, 'auto_lr_find': False, 'max_epochs': 10, 'val_size': 0.15, 'early_stopping_patience': 20}\n",
      "  0%|          | 0/2 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-30 19:09:09,964 - WARNING - CommonStructure.py - You are passing some invalid parameters to the model {'batch_size': 488, 'optimizer_fn': {'SGD_learning_rate': 0.0008958109541859922, 'SGD_momentum': 0.7310334553909785, 'SGD_weight_decay': 5.483165026112475e-08, 'optimizer_fn': <class 'torch.optim.sgd.SGD'>}, 'scheduler_fn': {'StepLR_gamma': 0.2228559482775585, 'StepLR_step_size': 22, 'scheduler_fn': <class 'torch.optim.lr_scheduler.StepLR'>}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataConfig(target=['target'], continuous_cols=['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week'], categorical_cols=['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country'], date_columns=[], encode_date_columns=True, validation_split=0.2, continuous_feature_transform=None, normalize_continuous_features=True, quantile_noise=0, num_workers=4, pin_memory=True, handle_unknown_categories=True, handle_missing_values=True)\n",
      "NodeConfig(task='classification', head='LinearHead', head_config={'layers': ''}, embedding_dims=None, embedding_dropout=0.05438018363383848, batch_norm_continuous_input=False, learning_rate=0.0008958109541859922, loss='CrossEntropyLoss', metrics=['accuracy'], metrics_prob_input=[False], metrics_params=[{}], target_range=None, seed=42, _module_src='models.node', _model_name='NODEModel', _backbone_name='NODEBackbone', _config_name='NodeConfig', num_layers=1, num_trees=626, additional_tree_output_dim=3, depth=6, choice_function='entmax15', bin_function='entmoid15', max_features=21, input_dropout=0.17230551619837015, initialize_response='normal', initialize_selection_logits='normal', threshold_init_beta=0.9430824174145327, threshold_init_cutoff=1.1093300211337618, cat_embedding_dropout=0.0, embed_categorical=False)\n",
      "OptimizerConfig(optimizer='SGD', optimizer_params={'weight_decay': 5.483165026112475e-08, 'momentum': 0.7310334553909785}, lr_scheduler='StepLR', lr_scheduler_params={'step_size': 22, 'gamma': 0.2228559482775585}, lr_scheduler_monitor_metric='valid_loss')\n",
      "TrainerConfig(batch_size=488, data_aware_init_batch_size=2000, fast_dev_run=False, max_epochs=10, min_epochs=1, max_time=None, gpus=None, accelerator='auto', devices=None, devices_list=None, accumulate_grad_batches=1, auto_lr_find=False, auto_select_gpus=True, check_val_every_n_epoch=1, gradient_clip_val=0.0, overfit_batches=0.0, deterministic=False, profiler=None, early_stopping='valid_loss', early_stopping_min_delta=0.0, early_stopping_mode='min', early_stopping_patience=20, early_stopping_kwargs={}, checkpoints='valid_loss', checkpoints_path='ptabular_checkpoints', checkpoints_every_n_epochs=10, checkpoints_name=None, checkpoints_mode='min', checkpoints_save_top_k=1, checkpoints_kwargs={}, load_best=True, track_grad_norm=-1, progress_bar='rich', precision=32, seed=42, trainer_kwargs={})\n",
      "  0%|          | 0/2 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:09:09</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">989</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">105</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m30\u001b[0m \u001b[1;92m19:09:09\u001b[0m,\u001b[1;36m989\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m105\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:09:10</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">016</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">473</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m30\u001b[0m \u001b[1;92m19:09:10\u001b[0m,\u001b[1;36m016\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m473\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:09:10</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">019</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:290</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m30\u001b[0m \u001b[1;92m19:09:10\u001b[0m,\u001b[1;36m019\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:290\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:09:10</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">168</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">521</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: NODEModel              \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m30\u001b[0m \u001b[1;92m19:09:10\u001b[0m,\u001b[1;36m168\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m521\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: NODEModel              \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:09:10</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">194</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.models.node.node_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">83</span><span style=\"font-weight: bold\">}</span> - INFO - Data Aware Initialization of NODE   \n",
       "using a forward pass with <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2000</span> batch size<span style=\"color: #808000; text-decoration-color: #808000\">...</span>.                                                                      \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m30\u001b[0m \u001b[1;92m19:09:10\u001b[0m,\u001b[1;36m194\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.models.node.node_model:\u001b[1;36m83\u001b[0m\u001b[1m}\u001b[0m - INFO - Data Aware Initialization of NODE   \n",
       "using a forward pass with \u001b[1;36m2000\u001b[0m batch size\u001b[33m...\u001b[0m.                                                                      \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:09:12</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">385</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">268</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m30\u001b[0m \u001b[1;92m19:09:12\u001b[0m,\u001b[1;36m385\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m268\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:09:12</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">412</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">582</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m30\u001b[0m \u001b[1;92m19:09:12\u001b[0m,\u001b[1;36m412\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m582\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type              </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ custom_loss      │ CrossEntropyLoss  │      0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _backbone        │ NODEBackbone      │  261 K │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _embedding_layer │ PreEncoded1dLayer │      0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ _head            │ Lambda            │      0 │\n",
       "└───┴──────────────────┴───────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType             \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ custom_loss      │ CrossEntropyLoss  │      0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ NODEBackbone      │  261 K │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ PreEncoded1dLayer │      0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ _head            │ Lambda            │      0 │\n",
       "└───┴──────────────────┴───────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 260 K                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 769                                                                                          \n",
       "<span style=\"font-weight: bold\">Total params</span>: 261 K                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 1                                                                          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 260 K                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 769                                                                                          \n",
       "\u001b[1mTotal params\u001b[0m: 261 K                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 1                                                                          \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2f6672b502b4f949ef2736bd4f3f363",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:09:40</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">529</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">584</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m30\u001b[0m \u001b[1;92m19:09:40\u001b[0m,\u001b[1;36m529\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m584\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:09:40</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">532</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1258</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m30\u001b[0m \u001b[1;92m19:09:40\u001b[0m,\u001b[1;36m532\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1258\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0f0837d1be148d3a340ecea219ec49b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-30 19:09:42,506 - INFO - CommonStructure.py - Validation metrics: {'accuracy': 0.24002047082906858, 'roc_auc': 0.3198760578191492}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:32<00:32, 32.56s/trial, best loss: -0.3198760578191492]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-30 19:09:42,527 - INFO - CommonStructure.py - Training with hyperparameters: {'additional_tree_output_dim': 3, 'batch_norm_continuous_input': True, 'batch_size': 65, 'bin_function': 'entmoid15', 'choice_function': 'entmax15', 'depth': 5, 'embed_categorical': True, 'embedding_dropout': 0.06089480159646259, 'initialize_response': 'normal', 'initialize_selection_logits': 'normal', 'input_dropout': 0.15466990749662266, 'max_features': 32, 'num_layers': 1, 'num_trees': 736, 'optimizer_fn': {'Adam_learning_rate': 0.0005649482516821863, 'Adam_weight_decay': 8.73329962552733e-08, 'optimizer_fn': <class 'torch.optim.adam.Adam'>}, 'scheduler_fn': {'ExponentialLR_gamma': 0.9665881829738847, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>}, 'threshold_init_beta': 0.6724199121113691, 'threshold_init_cutoff': 0.6076965359243615}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tabular model params                                                            \n",
      "{'additional_tree_output_dim': 3, 'batch_norm_continuous_input': True, 'batch_size': 65, 'bin_function': 'entmoid15', 'choice_function': 'entmax15', 'depth': 5, 'embed_categorical': True, 'embedding_dropout': 0.06089480159646259, 'initialize_response': 'normal', 'initialize_selection_logits': 'normal', 'input_dropout': 0.15466990749662266, 'max_features': 32, 'num_layers': 1, 'num_trees': 736, 'optimizer_fn': {'Adam_learning_rate': 0.0005649482516821863, 'Adam_weight_decay': 8.73329962552733e-08, 'optimizer_fn': <class 'torch.optim.adam.Adam'>}, 'scheduler_fn': {'ExponentialLR_gamma': 0.9665881829738847, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>}, 'threshold_init_beta': 0.6724199121113691, 'threshold_init_cutoff': 0.6076965359243615}\n",
      "tabular model outer params                                                      \n",
      "{'early_stopping_rounds': 10, 'verbose': False, 'iterations': 20, 'retrain': False, 'auto_lr_find': False, 'max_epochs': 10, 'val_size': 0.15, 'early_stopping_patience': 20}\n",
      " 50%|█████     | 1/2 [00:32<00:32, 32.56s/trial, best loss: -0.3198760578191492]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-30 19:09:42,541 - WARNING - CommonStructure.py - You are passing some invalid parameters to the model {'batch_size': 65, 'optimizer_fn': {'Adam_learning_rate': 0.0005649482516821863, 'Adam_weight_decay': 8.73329962552733e-08, 'optimizer_fn': <class 'torch.optim.adam.Adam'>}, 'scheduler_fn': {'ExponentialLR_gamma': 0.9665881829738847, 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataConfig(target=['target'], continuous_cols=['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week'], categorical_cols=['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country'], date_columns=[], encode_date_columns=True, validation_split=0.2, continuous_feature_transform=None, normalize_continuous_features=True, quantile_noise=0, num_workers=4, pin_memory=True, handle_unknown_categories=True, handle_missing_values=True)\n",
      "NodeConfig(task='classification', head='LinearHead', head_config={'layers': ''}, embedding_dims=None, embedding_dropout=0.06089480159646259, batch_norm_continuous_input=True, learning_rate=0.0005649482516821863, loss='CrossEntropyLoss', metrics=['accuracy'], metrics_prob_input=[False], metrics_params=[{}], target_range=None, seed=42, _module_src='models.node', _model_name='NODEModel', _backbone_name='NODEBackbone', _config_name='NodeConfig', num_layers=1, num_trees=736, additional_tree_output_dim=3, depth=5, choice_function='entmax15', bin_function='entmoid15', max_features=32, input_dropout=0.15466990749662266, initialize_response='normal', initialize_selection_logits='normal', threshold_init_beta=0.6724199121113691, threshold_init_cutoff=0.6076965359243615, cat_embedding_dropout=0.0, embed_categorical=True)\n",
      "OptimizerConfig(optimizer='Adam', optimizer_params={'weight_decay': 8.73329962552733e-08}, lr_scheduler='ExponentialLR', lr_scheduler_params={'gamma': 0.9665881829738847}, lr_scheduler_monitor_metric='valid_loss')\n",
      "TrainerConfig(batch_size=65, data_aware_init_batch_size=2000, fast_dev_run=False, max_epochs=10, min_epochs=1, max_time=None, gpus=None, accelerator='auto', devices=None, devices_list=None, accumulate_grad_batches=1, auto_lr_find=False, auto_select_gpus=True, check_val_every_n_epoch=1, gradient_clip_val=0.0, overfit_batches=0.0, deterministic=False, profiler=None, early_stopping='valid_loss', early_stopping_min_delta=0.0, early_stopping_mode='min', early_stopping_patience=20, early_stopping_kwargs={}, checkpoints='valid_loss', checkpoints_path='ptabular_checkpoints', checkpoints_every_n_epochs=10, checkpoints_name=None, checkpoints_mode='min', checkpoints_save_top_k=1, checkpoints_kwargs={}, load_best=True, track_grad_norm=-1, progress_bar='rich', precision=32, seed=42, trainer_kwargs={})\n",
      " 50%|█████     | 1/2 [00:32<00:32, 32.56s/trial, best loss: -0.3198760578191492]"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:09:42</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">575</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">105</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m30\u001b[0m \u001b[1;92m19:09:42\u001b[0m,\u001b[1;36m575\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m105\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:09:42</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">600</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">473</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m30\u001b[0m \u001b[1;92m19:09:42\u001b[0m,\u001b[1;36m600\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m473\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:09:42</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">603</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:290</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m30\u001b[0m \u001b[1;92m19:09:42\u001b[0m,\u001b[1;36m603\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:290\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:09:42</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">683</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">521</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: NODEModel              \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m30\u001b[0m \u001b[1;92m19:09:42\u001b[0m,\u001b[1;36m683\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m521\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: NODEModel              \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:09:42</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">726</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.models.node.node_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">83</span><span style=\"font-weight: bold\">}</span> - INFO - Data Aware Initialization of NODE   \n",
       "using a forward pass with <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2000</span> batch size<span style=\"color: #808000; text-decoration-color: #808000\">...</span>.                                                                      \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m30\u001b[0m \u001b[1;92m19:09:42\u001b[0m,\u001b[1;36m726\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.models.node.node_model:\u001b[1;36m83\u001b[0m\u001b[1m}\u001b[0m - INFO - Data Aware Initialization of NODE   \n",
       "using a forward pass with \u001b[1;36m2000\u001b[0m batch size\u001b[33m...\u001b[0m.                                                                      \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: einsum(): subscript i has size 63 for operand 1 which does not broadcast with previously seen size 95\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:33<00:33, 33.20s/trial, best loss: -0.3198760578191492]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "einsum(): subscript i has size 63 for operand 1 which does not broadcast with previously seen size 95",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 57\u001b[0m\n\u001b[1;32m     45\u001b[0m runner \u001b[38;5;241m=\u001b[39m AutoRunner(\n\u001b[1;32m     46\u001b[0m     data_config\u001b[38;5;241m=\u001b[39mDATA_CONFIG,\n\u001b[1;32m     47\u001b[0m     output_folder\u001b[38;5;241m=\u001b[39mOUTPUT_FOLDER,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     53\u001b[0m     output_file_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{dataset}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{model}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{timestamp}\u001b[39;00m\u001b[38;5;124m.yml\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     54\u001b[0m )\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# Run the AutoML process\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Print results\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# Assuming results are saved correctly in the `runner.results` list (adapt as necessary)\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mresults:\n",
      "File \u001b[0;32m~/sdev/repos/AutoDeep/autodeep/automl.py:145\u001b[0m, in \u001b[0;36mAutoRunner.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;66;03m# Handle new execution modes\u001b[39;00m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m execution_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhyperopt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    141\u001b[0m     (\n\u001b[1;32m    142\u001b[0m         best_params,\n\u001b[1;32m    143\u001b[0m         best_score,\n\u001b[1;32m    144\u001b[0m         full_metrics,\n\u001b[0;32m--> 145\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhyperopt_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[43mval_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_config\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdefault_params\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mval_size\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_config\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetric\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_config\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meval_metrics\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproblem_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_config\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mproblem_type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    157\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain(X_train, y_train)\n",
      "File \u001b[0;32m~/sdev/repos/AutoDeep/autodeep/modelsdefinition/CommonStructure.py:342\u001b[0m, in \u001b[0;36mPytorchTabularTrainer.hyperopt_search\u001b[0;34m(self, X, y, model_config, metric, eval_metrics, val_size, max_evals, problem_type, extra_info)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluator \u001b[38;5;241m=\u001b[39m Evaluator(problem_type\u001b[38;5;241m=\u001b[39mproblem_type)\n\u001b[1;32m    340\u001b[0m threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluator\u001b[38;5;241m.\u001b[39mmaximize[metric][\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m--> 342\u001b[0m best \u001b[38;5;241m=\u001b[39m \u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtpe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuggest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault_rng\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stop_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop_on_perfect_lossCondition\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    352\u001b[0m best_params \u001b[38;5;241m=\u001b[39m space_eval(space, best)\n\u001b[1;32m    353\u001b[0m best_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault_params\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_params\n",
      "File \u001b[0;32m~/.pyenv/versions/thesis/lib/python3.10/site-packages/hyperopt/fmin.py:540\u001b[0m, in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    537\u001b[0m     fn \u001b[38;5;241m=\u001b[39m __objective_fmin_wrapper(fn)\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m allow_trials_fmin \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(trials, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfmin\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 540\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrials\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    542\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[43m        \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malgo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    547\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_queue_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    548\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_argmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_argmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progressbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progressbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[43m        \u001b[49m\u001b[43mearly_stop_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stop_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrials_save_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrials_save_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trials \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    559\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(trials_save_file):\n",
      "File \u001b[0;32m~/.pyenv/versions/thesis/lib/python3.10/site-packages/hyperopt/base.py:671\u001b[0m, in \u001b[0;36mTrials.fmin\u001b[0;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;66;03m# -- Stop-gap implementation!\u001b[39;00m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;66;03m#    fmin should have been a Trials method in the first place\u001b[39;00m\n\u001b[1;32m    668\u001b[0m \u001b[38;5;66;03m#    but for now it's still sitting in another file.\u001b[39;00m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfmin\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fmin\n\u001b[0;32m--> 671\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malgo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_trials_fmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# -- prevent recursion\u001b[39;49;00m\n\u001b[1;32m    683\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_argmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_argmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progressbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progressbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stop_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stop_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrials_save_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrials_save_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/thesis/lib/python3.10/site-packages/hyperopt/fmin.py:586\u001b[0m, in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    583\u001b[0m rval\u001b[38;5;241m.\u001b[39mcatch_eval_exceptions \u001b[38;5;241m=\u001b[39m catch_eval_exceptions\n\u001b[1;32m    585\u001b[0m \u001b[38;5;66;03m# next line is where the fmin is actually executed\u001b[39;00m\n\u001b[0;32m--> 586\u001b[0m \u001b[43mrval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexhaust\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_argmin:\n\u001b[1;32m    589\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(trials\u001b[38;5;241m.\u001b[39mtrials) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/.pyenv/versions/thesis/lib/python3.10/site-packages/hyperopt/fmin.py:364\u001b[0m, in \u001b[0;36mFMinIter.exhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexhaust\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    363\u001b[0m     n_done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials)\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_done\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock_until_done\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masynchronous\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[1;32m    366\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/thesis/lib/python3.10/site-packages/hyperopt/fmin.py:300\u001b[0m, in \u001b[0;36mFMinIter.run\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    297\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpoll_interval_secs)\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;66;03m# -- loop over trials and do the jobs directly\u001b[39;00m\n\u001b[0;32m--> 300\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserial_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials_save_file \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.pyenv/versions/thesis/lib/python3.10/site-packages/hyperopt/fmin.py:178\u001b[0m, in \u001b[0;36mFMinIter.serial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    176\u001b[0m ctrl \u001b[38;5;241m=\u001b[39m base\u001b[38;5;241m.\u001b[39mCtrl(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials, current_trial\u001b[38;5;241m=\u001b[39mtrial)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 178\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdomain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctrl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    180\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjob exception: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mstr\u001b[39m(e))\n",
      "File \u001b[0;32m~/.pyenv/versions/thesis/lib/python3.10/site-packages/hyperopt/base.py:892\u001b[0m, in \u001b[0;36mDomain.evaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    884\u001b[0m     \u001b[38;5;66;03m# -- the \"work\" of evaluating `config` can be written\u001b[39;00m\n\u001b[1;32m    885\u001b[0m     \u001b[38;5;66;03m#    either into the pyll part (self.expr)\u001b[39;00m\n\u001b[1;32m    886\u001b[0m     \u001b[38;5;66;03m#    or the normal Python part (self.fn)\u001b[39;00m\n\u001b[1;32m    887\u001b[0m     pyll_rval \u001b[38;5;241m=\u001b[39m pyll\u001b[38;5;241m.\u001b[39mrec_eval(\n\u001b[1;32m    888\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpr,\n\u001b[1;32m    889\u001b[0m         memo\u001b[38;5;241m=\u001b[39mmemo,\n\u001b[1;32m    890\u001b[0m         print_node_on_error\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrec_eval_print_node_on_error,\n\u001b[1;32m    891\u001b[0m     )\n\u001b[0;32m--> 892\u001b[0m     rval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpyll_rval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rval, (\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mint\u001b[39m, np\u001b[38;5;241m.\u001b[39mnumber)):\n\u001b[1;32m    895\u001b[0m     dict_rval \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(rval), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m\"\u001b[39m: STATUS_OK}\n",
      "File \u001b[0;32m~/sdev/repos/AutoDeep/autodeep/modelsdefinition/CommonStructure.py:311\u001b[0m, in \u001b[0;36mPytorchTabularTrainer.hyperopt_search.<locals>.objective\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_range \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    302\u001b[0m         (\n\u001b[1;32m    303\u001b[0m             \u001b[38;5;28mfloat\u001b[39m(np\u001b[38;5;241m.\u001b[39mmin(train_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.8\u001b[39m),\n\u001b[1;32m    304\u001b[0m             \u001b[38;5;28mfloat\u001b[39m(np\u001b[38;5;241m.\u001b[39mmax(train_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1.2\u001b[39m),\n\u001b[1;32m    305\u001b[0m         )\n\u001b[1;32m    306\u001b[0m     ]\n\u001b[1;32m    308\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_tabular_model(\n\u001b[1;32m    309\u001b[0m     params, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_params, default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault\n\u001b[1;32m    310\u001b[0m )\n\u001b[0;32m--> 311\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    313\u001b[0m pred_df \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(test_data)\n\u001b[1;32m    314\u001b[0m predictions \u001b[38;5;241m=\u001b[39m pred_df[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_col]\u001b[38;5;241m.\u001b[39mvalues\n",
      "File \u001b[0;32m~/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/tabular_model.py:685\u001b[0m, in \u001b[0;36mTabularModel.fit\u001b[0;34m(self, train, validation, test, loss, metrics, metrics_prob_inputs, optimizer, optimizer_params, train_sampler, target_transform, max_epochs, min_epochs, seed, callbacks, datamodule)\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m test \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    681\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    682\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProviding test data in `fit` is deprecated and will be removed in next major release.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    683\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Plese use `evaluate` for evaluating on test data\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    684\u001b[0m         )\n\u001b[0;32m--> 685\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetrics_prob_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain(model, datamodule, callbacks, max_epochs, min_epochs)\n",
      "File \u001b[0;32m~/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/tabular_model.py:534\u001b[0m, in \u001b[0;36mTabularModel.prepare_model\u001b[0;34m(self, datamodule, loss, metrics, metrics_prob_inputs, optimizer, optimizer_params)\u001b[0m\n\u001b[1;32m    524\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_callable(\n\u001b[1;32m    525\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig,\n\u001b[1;32m    526\u001b[0m     custom_loss\u001b[38;5;241m=\u001b[39mloss,  \u001b[38;5;66;03m# Unused in SSL tasks\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    531\u001b[0m     inferred_config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minferred_config,\n\u001b[1;32m    532\u001b[0m )\n\u001b[1;32m    533\u001b[0m \u001b[38;5;66;03m# Data Aware Initialization(for the models that need it)\u001b[39;00m\n\u001b[0;32m--> 534\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_aware_initialization\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_state_dict_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_weights(model, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_state_dict_path)\n",
      "File \u001b[0;32m~/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/models/node/node_model.py:96\u001b[0m, in \u001b[0;36mNODEModel.data_aware_initialization\u001b[0;34m(self, datamodule)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# single forward pass to initialize the ODST\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/models/base_model.py:387\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"The forward pass of the model.\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \n\u001b[1;32m    383\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;124;03m    x (Dict): The input of the model with 'continuous' and 'categorical' keys\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    386\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_input(x)\n\u001b[0;32m--> 387\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_backbone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_head(x)\n",
      "File \u001b[0;32m~/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/models/base_model.py:329\u001b[0m, in \u001b[0;36mBaseModel.compute_backbone\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_backbone\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Dict) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m    328\u001b[0m     \u001b[38;5;66;03m# Returns output\u001b[39;00m\n\u001b[0;32m--> 329\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackbone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/models/node/node_model.py:70\u001b[0m, in \u001b[0;36mNODEBackbone.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor):  \u001b[38;5;66;03m# TODO factor out target encoding option.\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/models/node/architecture_blocks.py:57\u001b[0m, in \u001b[0;36mDenseODSTBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_dropout:\n\u001b[1;32m     56\u001b[0m         layer_inp \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mdropout(layer_inp, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_dropout)\n\u001b[0;32m---> 57\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer_inp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([x, h], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     60\u001b[0m outputs \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, initial_features:]\n",
      "File \u001b[0;32m~/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/models/common/layers/misc.py:52\u001b[0m, in \u001b[0;36mModuleWithInit.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_initialized_bool \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbool\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_initialized_tensor\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_initialized_bool:\n\u001b[0;32m---> 52\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_initialized_tensor\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_initialized_bool \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/thesis/lib/python3.10/site-packages/pytorch_tabular/models/common/layers/soft_trees.py:147\u001b[0m, in \u001b[0;36mODST.initialize\u001b[0;34m(self, input, eps)\u001b[0m\n\u001b[1;32m    144\u001b[0m feature_selectors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchoice_function(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_selection_logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    145\u001b[0m \u001b[38;5;66;03m# ^--[in_features, num_trees, depth]\u001b[39;00m\n\u001b[0;32m--> 147\u001b[0m feature_values \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbi,ind->bnd\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_selectors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;66;03m# ^--[batch_size, num_trees, depth]\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m# initialize thresholds: sample random percentiles of data\u001b[39;00m\n\u001b[1;32m    151\u001b[0m percentiles_q \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mbeta(\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthreshold_init_beta,\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthreshold_init_beta,\n\u001b[1;32m    154\u001b[0m     size\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_trees, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdepth],\n\u001b[1;32m    155\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/thesis/lib/python3.10/site-packages/torch/functional.py:378\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m einsum(equation, \u001b[38;5;241m*\u001b[39m_operands)\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(operands) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_einsum\u001b[38;5;241m.\u001b[39menabled:\n\u001b[1;32m    376\u001b[0m     \u001b[38;5;66;03m# the path for contracting 0 or 1 time(s) is already optimized\u001b[39;00m\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;66;03m# or the user has disabled using opt_einsum\u001b[39;00m\n\u001b[0;32m--> 378\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mequation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperands\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    380\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m opt_einsum\u001b[38;5;241m.\u001b[39mis_available():\n",
      "\u001b[0;31mRuntimeError\u001b[0m: einsum(): subscript i has size 63 for operand 1 which does not broadcast with previously seen size 95"
     ]
    }
   ],
   "source": [
    "# Define paths to configuration files and data\n",
    "DATA_FOLDER = r\"/home/boom/sdev/repos/AutoDeep/autodeep/examples/testautodata\"\n",
    "OUTPUT_FOLDER = r\"/home/boom/sdev/repos/AutoDeep/autodeep/examples/output\"\n",
    "\n",
    "DEFAULT_MODELS = [\"node\"]\n",
    "# Add any new models here\n",
    "# WORKING ONES (BARELY WORKING [xgb\", \"catboost\", \"mlp\", ])\n",
    "# Define the configuration dictionary for datasets\n",
    "DATA_CONFIG = {\n",
    "    \"dataset1\": {\n",
    "        \"dataset_path\": f\"{DATA_FOLDER}/adult.csv\",\n",
    "        \"target_col\": \"target\",\n",
    "        \"problem_type\": \"binary_classification\",\n",
    "        \"test_size\": 0.25,\n",
    "        \"num_targets\": 1,\n",
    "        \"metric\": \"roc_auc\",\n",
    "        \"eval_metrics\": [\"accuracy\", \"roc_auc\", \"lift5\"],\n",
    "    },\n",
    "    \"dataset2\": {\n",
    "        \"dataset_path\": f\"{DATA_FOLDER}/adult_2.csv\",\n",
    "        \"target_col\": \"target\",\n",
    "        \"problem_type\": \"binary_classification\",\n",
    "        \"test_size\": 0.2,\n",
    "        \"num_targets\": 1,\n",
    "        \"metric\": \"roc_auc\",\n",
    "        \"eval_metrics\": [\"accuracy\", \"roc_auc\", \"lift1\"],\n",
    "    },\n",
    "    # Add more datasets as needed\n",
    "}\n",
    "\n",
    "DATA_CONFIG = {\n",
    "    \"dataset1\": {\n",
    "        \"dataset_path\": f\"{DATA_FOLDER}/adult.csv\",\n",
    "        \"target_col\": \"target\",\n",
    "        \"problem_type\": \"binary_classification\",\n",
    "        \"test_size\": 0.2,\n",
    "        \"num_targets\": 1,\n",
    "        \"metric\": \"roc_auc\",\n",
    "        \"eval_metrics\": [\"accuracy\", \"roc_auc\", \"lift5\"],\n",
    "    }\n",
    "    # Add more datasets as needed\n",
    "}\n",
    "\n",
    "# Initialize AutoRunner instance with the configuration\n",
    "runner = AutoRunner(\n",
    "    data_config=DATA_CONFIG,\n",
    "    output_folder=OUTPUT_FOLDER,\n",
    "    default_models=DEFAULT_MODELS,\n",
    "    random_state=42,\n",
    "    execution_mode=\"hyperopt\",  # You can change this to other modes like \"cv\" or \"new_mode\"\n",
    "    eval_metrics=[\"accuracy\", \"f1\", \"roc_auc\"],  # Evaluation metrics as needed\n",
    "    max_evals=2,\n",
    "    output_file_format=\"{dataset}_{model}_{timestamp}.yml\",\n",
    ")\n",
    "\n",
    "# Run the AutoML process\n",
    "runner.run()\n",
    "\n",
    "# Print results\n",
    "# Assuming results are saved correctly in the `runner.results` list (adapt as necessary)\n",
    "for result in runner.results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect \n",
    "from pytorch_tabular.models import TabTransformerConfig\n",
    "help(TabTransformerConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Define the folder to format and lint\n",
    "folder_to_check = \"autodeep\"\n",
    "\n",
    "# Define output files\n",
    "output_files = {\n",
    "    \"isort\": \"isort_output.txt\",\n",
    "    \"black\": \"black_output.txt\",\n",
    "    \"pylint\": \"pylint_output.txt\",\n",
    "    \"flake8\": \"flake8_output.txt\",\n",
    "}\n",
    "\n",
    "# Ensure the output folder exists\n",
    "os.makedirs(\"linting_outputs\", exist_ok=True)\n",
    "\n",
    "# Run isort\n",
    "with open(os.path.join(\"linting_outputs\", output_files[\"isort\"]), \"w\") as f:\n",
    "    subprocess.run([\"isort\", folder_to_check], stdout=f, stderr=f)\n",
    "\n",
    "# Run black\n",
    "with open(os.path.join(\"linting_outputs\", output_files[\"black\"]), \"w\") as f:\n",
    "    subprocess.run([\"black\", folder_to_check], stdout=f, stderr=f)\n",
    "\n",
    "# Run pylint\n",
    "with open(os.path.join(\"linting_outputs\", output_files[\"pylint\"]), \"w\") as f:\n",
    "    subprocess.run([\"pylint\", folder_to_check], stdout=f, stderr=f)\n",
    "\n",
    "# Run flake8\n",
    "with open(os.path.join(\"linting_outputs\", output_files[\"flake8\"]), \"w\") as f:\n",
    "    subprocess.run([\"flake8\", folder_to_check], stdout=f, stderr=f)\n",
    "\n",
    "print(\n",
    "    \"Linting and formatting completed. Outputs are saved in the 'linting_outputs' folder.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install isort black pylint flake8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Define the path to the folder to format and lint (one level up from the current directory)\n",
    "folder_to_check = \"../../autodeep\"\n",
    "\n",
    "# Define the output folder and ensure it exists\n",
    "output_folder = \"linting_outputs\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Define the output files\n",
    "output_files = {\n",
    "    \"isort\": \"isort_output.txt\",\n",
    "    \"black\": \"black_output.txt\",\n",
    "    \"pylint\": \"pylint_output.txt\",\n",
    "    \"flake8\": \"flake8_output.txt\",\n",
    "}\n",
    "\n",
    "# Run isort\n",
    "isort_output_path = os.path.join(output_folder, output_files[\"isort\"])\n",
    "with open(isort_output_path, \"w\") as f:\n",
    "    subprocess.run([\"isort\", folder_to_check], stdout=f, stderr=f)\n",
    "\n",
    "# Run black\n",
    "black_output_path = os.path.join(output_folder, output_files[\"black\"])\n",
    "with open(black_output_path, \"w\") as f:\n",
    "    subprocess.run([\"black\", folder_to_check], stdout=f, stderr=f)\n",
    "\n",
    "# Run pylint\n",
    "pylint_output_path = os.path.join(output_folder, output_files[\"pylint\"])\n",
    "with open(pylint_output_path, \"w\") as f:\n",
    "    subprocess.run([\"pylint\", folder_to_check], stdout=f, stderr=f)\n",
    "\n",
    "# Run flake8\n",
    "flake8_output_path = os.path.join(output_folder, output_files[\"flake8\"])\n",
    "with open(flake8_output_path, \"w\") as f:\n",
    "    subprocess.run([\"flake8\", folder_to_check], stdout=f, stderr=f)\n",
    "\n",
    "print(\n",
    "    f\"Linting and formatting completed. Outputs are saved in the '{output_folder}' folder.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
