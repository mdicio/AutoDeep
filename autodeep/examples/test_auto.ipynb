{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test AutoML Functionality in a Separate Notebook\n",
    "from autodeep.automl import AutoRunner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = [\n",
    "    # \"XGB\",  # Extreme Gradient Boosting\n",
    "    # \"CatBoost\",\n",
    "    \"MLP\",  # Multi,Layer Perceptron\n",
    "    \"TabNet\",  # TabNet Classifier\n",
    "    \"GATE\",\n",
    "    # \"resnet\",\n",
    "    # \"S1DCNN\",\n",
    "    \"CategoryEmbedding\",\n",
    "    \"FTTransformer\",\n",
    "    \"TabTransformer\",\n",
    "    \"GANDALF\",\n",
    "    \"AutoInt\",\n",
    "    \"Node\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#tested with 100 hyperopt iterations did not break on adult dataset:\n",
    "\n",
    "\"autoint\",\n",
    "\"node\",\n",
    "\"mlp\",\n",
    "\"tabnet\",\n",
    "\"categoryembedding\",\n",
    "\"fttransformer\",\n",
    "\"tabtransformer\",\n",
    "\"gandalf\",\n",
    "\"mlp\"\n",
    "\n",
    "\n",
    "# very slow, had to decrease parameters for memory consumption also:\n",
    "\"gate\",\n",
    "\n",
    "# Not tested hyperopt search yet:\n",
    "\n",
    "#catboost\n",
    "#xgb\n",
    "#resnet\n",
    "#s1dcnn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running resnet on dataset1...\n",
      "Using dynamic loader for dataset: /home/boom/sdev/repos/AutoDeep/autodeep/examples/testautodata/adult.csv\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(24420, 108)\n",
      "9\n",
      "12\n",
      "Step 0 err: 11128754.0\n",
      "Step 100 err: 7631126.0\n",
      "Step 200 err: 7122780.0\n",
      "Step 300 err: 7050513.0\n",
      "Step 400 err: 7019514.0\n",
      "Step 500 err: 7018759.0\n",
      "Step 600 err: 7018091.0\n",
      "Step 700 err: 7016658.0\n",
      "Step 800 err: 7015215.0\n",
      "Step 900 err: 7015215.0\n",
      "Step 1000 err: 7015215.0\n",
      "Step 1100 err: 7015215.0\n",
      "Step 1200 err: 7015215.0\n",
      "IGTD/dataset1/Euclidean_Euclidean/abs\n",
      "RUNTIME 0.0001010894775390625\n",
      "Skipping single image txt and png generation, returning dataframe sorted by IGTD...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(24420, 108)\n",
      "9\n",
      "12\n",
      "Step 0 err: 31636430460.0\n",
      "Step 100 err: 18649189232.0\n",
      "Step 200 err: 16742205029.5\n",
      "Step 300 err: 16329522635.5\n",
      "Step 400 err: 16240517482.5\n",
      "Step 500 err: 16157923117.0\n",
      "Step 600 err: 16139949535.5\n",
      "Step 700 err: 16139949535.5\n",
      "Step 800 err: 16139949535.5\n",
      "Step 900 err: 16139949535.5\n",
      "Step 1000 err: 16139949535.5\n",
      "Step 1100 err: 16139949535.5\n",
      "Step 1200 err: 16139949535.5\n",
      "Step 1300 err: 16139949535.5\n",
      "SAVE FOLDER IGTD/dataset1/Pearson_Manhattan/squared\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-05 16:05:22,430 - INFO - ResNetModel.py - Device cuda is available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNTIME 0.00010204315185546875\n",
      "Skipping single image txt and png generation, returning dataframe sorted by IGTD...\n",
      "IGTD RESULTS OUTPUT\n",
      "{'Euclidean_Euclidean': 'IGTD/dataset1/Euclidean_Euclidean/abs/_index.txt', 'Pearson_Manhattan': 'IGTD/dataset1/Pearson_Manhattan/squared/_index.txt'}\n",
      "PATH NOT EXISTED THIS IS THE IGTD PATH INDEX IGTD/dataset1/Pearson_Manhattan/squared/_index.txt\n",
      "{'data_params': {'normalize_features': 'mean_std', 'encode_categorical': True, 'return_extra_info': True}, 'default_params': {'early_stopping': True, 'verbose': False, 'iterations': 20, 'retrain': False, 'auto_lr_find': False, 'max_epochs': 300, 'val_size': 0.2, 'early_stopping_patience': 6}, 'param_grid': {'resnet_depth': ['resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152'], 'batch_size': [1024, 512, 256], 'optimizer_fn': {'Adam': {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}, 'SGD': {'weight_decay': [0.0, 1e-07], 'momentum': [0.0, 0.9], 'learning_rate': [0.001, 1e-05]}, 'AdamW': {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}}, 'scheduler_fn': {'ReduceLROnPlateau': {'factor': [0.1, 0.01], 'patience': [5, 10]}, 'StepLR': {'step_size': [10, 30], 'gamma': [0.1, 0.5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}}}\n",
      "resnet_depth ['resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152']\n",
      "batch_size [1024, 512, 256]\n",
      "optimizer_fn {'Adam': {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}, 'SGD': {'weight_decay': [0.0, 1e-07], 'momentum': [0.0, 0.9], 'learning_rate': [0.001, 1e-05]}, 'AdamW': {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}}\n",
      "dict_keys(['Adam', 'SGD', 'AdamW'])\n",
      "Adam {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}\n",
      "weight_decay [0.0, 1e-07]\n",
      "learning_rate [0.001, 0.0001]\n",
      "SGD {'weight_decay': [0.0, 1e-07], 'momentum': [0.0, 0.9], 'learning_rate': [0.001, 1e-05]}\n",
      "weight_decay [0.0, 1e-07]\n",
      "momentum [0.0, 0.9]\n",
      "learning_rate [0.001, 1e-05]\n",
      "AdamW {'weight_decay': [0.0, 1e-07], 'learning_rate': [0.001, 0.0001]}\n",
      "weight_decay [0.0, 1e-07]\n",
      "learning_rate [0.001, 0.0001]\n",
      "scheduler_fn {'ReduceLROnPlateau': {'factor': [0.1, 0.01], 'patience': [5, 10]}, 'StepLR': {'step_size': [10, 30], 'gamma': [0.1, 0.5]}, 'ExponentialLR': {'gamma': [0.9, 0.99]}}\n",
      "dict_keys(['ReduceLROnPlateau', 'StepLR', 'ExponentialLR'])\n",
      "ReduceLROnPlateau {'factor': [0.1, 0.01], 'patience': [5, 10]}\n",
      "factor [0.1, 0.01]\n",
      "patience [5, 10]\n",
      "StepLR {'step_size': [10, 30], 'gamma': [0.1, 0.5]}\n",
      "step_size [10, 30]\n",
      "gamma [0.1, 0.5]\n",
      "ExponentialLR {'gamma': [0.9, 0.99]}\n",
      "gamma [0.9, 0.99]\n",
      "  0%|          | 0/3 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-05 16:07:22,887 - INFO - ResNetModel.py - Training with hyperparameters: {'AdamW_learning_rate': 0.00041691320143948053, 'AdamW_weight_decay': 5.3327377727838295e-08, 'Adam_learning_rate': 0.000883609493567339, 'Adam_weight_decay': 5.3453713798712174e-08, 'ExponentialLR_gamma': 0.9700428647065971, 'ReduceLROnPlateau_factor': 0.014194472482598669, 'ReduceLROnPlateau_patience': 6, 'SGD_learning_rate': 5.540876168540814e-05, 'SGD_momentum': 0.7753748228926656, 'SGD_weight_decay': 1.1771360216800085e-08, 'StepLR_gamma': 0.1469911132467317, 'StepLR_step_size': 14, 'batch_size': 601, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>, 'resnet_depth': 'resnet50', 'scheduler_fn': <class 'torch.optim.lr_scheduler.ExponentialLR'>}\n",
      "Training:   0%|                                      | 0/300 [00:00<?, ?epoch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/300],Train Loss: 0.2380,Val Loss: 0.2174    \n",
      "  0%|          | 0/3 [00:04<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|1                             | 1/300 [00:04<20:03,  4.02s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/300],Train Loss: 0.1935,Val Loss: 0.1864    \n",
      "  0%|          | 0/3 [00:08<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|2                             | 2/300 [00:07<19:04,  3.84s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/300],Train Loss: 0.1751,Val Loss: 0.1802    \n",
      "  0%|          | 0/3 [00:11<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|3                             | 3/300 [00:11<18:28,  3.73s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/300],Train Loss: 0.1654,Val Loss: 0.1738    \n",
      "  0%|          | 0/3 [00:15<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|4                             | 4/300 [00:14<18:08,  3.68s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/300],Train Loss: 0.1669,Val Loss: 0.1773    \n",
      "  0%|          | 0/3 [00:19<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|5                             | 5/300 [00:18<18:03,  3.67s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/300],Train Loss: 0.1599,Val Loss: 0.1771    \n",
      "  0%|          | 0/3 [00:22<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|6                             | 6/300 [00:22<17:59,  3.67s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/300],Train Loss: 0.1544,Val Loss: 0.1719    \n",
      "  0%|          | 0/3 [00:26<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|7                             | 7/300 [00:26<18:02,  3.70s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/300],Train Loss: 0.1498,Val Loss: 0.1697    \n",
      "  0%|          | 0/3 [00:30<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|8                             | 8/300 [00:29<17:53,  3.68s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/300],Train Loss: 0.1459,Val Loss: 0.1680    \n",
      "  0%|          | 0/3 [00:33<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|9                             | 9/300 [00:33<17:53,  3.69s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/300],Train Loss: 0.1446,Val Loss: 0.1796   \n",
      "  0%|          | 0/3 [00:37<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|9                            | 10/300 [00:36<17:42,  3.66s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/300],Train Loss: 0.1404,Val Loss: 0.1745   \n",
      "  0%|          | 0/3 [00:41<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|#                            | 11/300 [00:40<17:41,  3.67s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/300],Train Loss: 0.1374,Val Loss: 0.1790   \n",
      "  0%|          | 0/3 [00:44<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|#1                           | 12/300 [00:44<17:32,  3.65s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/300],Train Loss: 0.1368,Val Loss: 0.1868   \n",
      "  0%|          | 0/3 [00:48<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|#2                           | 13/300 [00:47<17:31,  3.66s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/300],Train Loss: 0.1335,Val Loss: 0.1814   \n",
      "  0%|          | 0/3 [00:52<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|#3                           | 14/300 [00:51<17:25,  3.66s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/300],Train Loss: 0.1289,Val Loss: 0.1852   \n",
      "Early stopping triggered at epoch 15                 \n",
      "  0%|          | 0/3 [00:55<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|#3                           | 14/300 [00:55<18:48,  3.94s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model loaded from epoch 9                       \n",
      "  0%|          | 0/3 [00:55<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-05 16:08:19,503 - INFO - ResNetModel.py - Validation metrics roc_auc: 0.887311815233105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:56<01:53, 56.63s/trial, best loss: -0.887311815233105]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-05 16:08:19,514 - INFO - ResNetModel.py - Training with hyperparameters: {'AdamW_learning_rate': 0.0005493747562277502, 'AdamW_weight_decay': 5.979030232767242e-08, 'Adam_learning_rate': 0.00010037826615600942, 'Adam_weight_decay': 2.309091722462173e-08, 'ExponentialLR_gamma': 0.9526834243165615, 'ReduceLROnPlateau_factor': 0.021158305135007868, 'ReduceLROnPlateau_patience': 7, 'SGD_learning_rate': 9.52118823872863e-05, 'SGD_momentum': 0.6960145837348019, 'SGD_weight_decay': 2.4860021513335803e-08, 'StepLR_gamma': 0.2095872419296196, 'StepLR_step_size': 19, 'batch_size': 278, 'optimizer_fn': <class 'torch.optim.adam.Adam'>, 'resnet_depth': 'resnet18', 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>}\n",
      "Training:   0%|                                      | 0/300 [00:00<?, ?epoch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/300],Train Loss: 0.3332,Val Loss: 0.2077                              \n",
      " 33%|███▎      | 1/3 [00:59<01:53, 56.63s/trial, best loss: -0.887311815233105]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|1                             | 1/300 [00:02<12:19,  2.47s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/300],Train Loss: 0.1966,Val Loss: 0.1920                              \n",
      " 33%|███▎      | 1/3 [01:01<01:53, 56.63s/trial, best loss: -0.887311815233105]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|2                             | 2/300 [00:04<11:50,  2.38s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/300],Train Loss: 0.1824,Val Loss: 0.1893                              \n",
      " 33%|███▎      | 1/3 [01:03<01:53, 56.63s/trial, best loss: -0.887311815233105]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|3                             | 3/300 [00:07<11:37,  2.35s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/300],Train Loss: 0.1747,Val Loss: 0.1858                              \n",
      " 33%|███▎      | 1/3 [01:06<01:53, 56.63s/trial, best loss: -0.887311815233105]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|4                             | 4/300 [00:09<11:28,  2.33s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/300],Train Loss: 0.1702,Val Loss: 0.1809                              \n",
      " 33%|███▎      | 1/3 [01:08<01:53, 56.63s/trial, best loss: -0.887311815233105]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|5                             | 5/300 [00:11<11:26,  2.33s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/300],Train Loss: 0.1642,Val Loss: 0.1830                              \n",
      " 33%|███▎      | 1/3 [01:10<01:53, 56.63s/trial, best loss: -0.887311815233105]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|6                             | 6/300 [00:14<11:28,  2.34s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/300],Train Loss: 0.1612,Val Loss: 0.1803                              \n",
      " 33%|███▎      | 1/3 [01:13<01:53, 56.63s/trial, best loss: -0.887311815233105]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|7                             | 7/300 [00:16<11:26,  2.34s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/300],Train Loss: 0.1561,Val Loss: 0.1858                              \n",
      " 33%|███▎      | 1/3 [01:15<01:53, 56.63s/trial, best loss: -0.887311815233105]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|8                             | 8/300 [00:18<11:20,  2.33s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/300],Train Loss: 0.1533,Val Loss: 0.1813                              \n",
      " 33%|███▎      | 1/3 [01:17<01:53, 56.63s/trial, best loss: -0.887311815233105]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|9                             | 9/300 [00:21<11:17,  2.33s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/300],Train Loss: 0.1515,Val Loss: 0.1861                             \n",
      " 33%|███▎      | 1/3 [01:20<01:53, 56.63s/trial, best loss: -0.887311815233105]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|9                            | 10/300 [00:23<11:14,  2.33s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/300],Train Loss: 0.1468,Val Loss: 0.1935                             \n",
      " 33%|███▎      | 1/3 [01:22<01:53, 56.63s/trial, best loss: -0.887311815233105]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|#                            | 11/300 [00:25<11:12,  2.33s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/300],Train Loss: 0.1413,Val Loss: 0.1891                             \n",
      " 33%|███▎      | 1/3 [01:24<01:53, 56.63s/trial, best loss: -0.887311815233105]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|#1                           | 12/300 [00:28<11:09,  2.33s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/300],Train Loss: 0.1424,Val Loss: 0.1942                             \n",
      "Early stopping triggered at epoch 13                                           \n",
      " 33%|███▎      | 1/3 [01:27<01:53, 56.63s/trial, best loss: -0.887311815233105]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|#1                           | 12/300 [00:30<12:09,  2.53s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model loaded from epoch 7                                                 \n",
      " 33%|███▎      | 1/3 [01:27<01:53, 56.63s/trial, best loss: -0.887311815233105]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-05 16:08:50,877 - INFO - ResNetModel.py - Validation metrics roc_auc: 0.8747864976627113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [01:28<00:41, 41.77s/trial, best loss: -0.887311815233105]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-05 16:08:50,889 - INFO - ResNetModel.py - Training with hyperparameters: {'AdamW_learning_rate': 0.0004075143374264702, 'AdamW_weight_decay': 1.705619046081085e-08, 'Adam_learning_rate': 0.0002787250488969445, 'Adam_weight_decay': 5.8503136589228095e-08, 'ExponentialLR_gamma': 0.9784967729694466, 'ReduceLROnPlateau_factor': 0.035366290883172516, 'ReduceLROnPlateau_patience': 7, 'SGD_learning_rate': 0.0002362036859304049, 'SGD_momentum': 0.5399775189278528, 'SGD_weight_decay': 9.223794406882684e-08, 'StepLR_gamma': 0.47672489990655614, 'StepLR_step_size': 29, 'batch_size': 946, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>, 'resnet_depth': 'resnet18', 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>}\n",
      "Training:   0%|                                      | 0/300 [00:00<?, ?epoch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/300],Train Loss: 0.3109,Val Loss: 0.4896                              \n",
      " 67%|██████▋   | 2/3 [01:30<00:41, 41.77s/trial, best loss: -0.887311815233105]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|1                             | 1/300 [00:02<11:30,  2.31s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/300],Train Loss: 0.2665,Val Loss: 0.2221                              \n",
      " 67%|██████▋   | 2/3 [01:32<00:41, 41.77s/trial, best loss: -0.887311815233105]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|2                             | 2/300 [00:04<11:28,  2.31s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/300],Train Loss: 0.2083,Val Loss: 0.1915                              \n",
      " 67%|██████▋   | 2/3 [01:35<00:41, 41.77s/trial, best loss: -0.887311815233105]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|3                             | 3/300 [00:06<11:31,  2.33s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/300],Train Loss: 0.1852,Val Loss: 0.1990                              \n",
      " 67%|██████▋   | 2/3 [01:37<00:41, 41.77s/trial, best loss: -0.887311815233105]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|4                             | 4/300 [00:09<11:26,  2.32s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/300],Train Loss: 0.1833,Val Loss: 0.1799                              \n",
      " 67%|██████▋   | 2/3 [01:39<00:41, 41.77s/trial, best loss: -0.887311815233105]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|5                             | 5/300 [00:11<11:21,  2.31s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/300],Train Loss: 0.1774,Val Loss: 0.1790                              \n",
      " 67%|██████▋   | 2/3 [01:42<00:41, 41.77s/trial, best loss: -0.887311815233105]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|6                             | 6/300 [00:13<11:15,  2.30s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/300],Train Loss: 0.1708,Val Loss: 0.1766                              \n",
      " 67%|██████▋   | 2/3 [01:44<00:41, 41.77s/trial, best loss: -0.887311815233105]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|7                             | 7/300 [00:16<11:21,  2.33s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/300],Train Loss: 0.1693,Val Loss: 0.1736                              \n",
      " 67%|██████▋   | 2/3 [01:46<00:41, 41.77s/trial, best loss: -0.887311815233105]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|8                             | 8/300 [00:18<11:22,  2.34s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/300],Train Loss: 0.1674,Val Loss: 0.1790                              \n",
      " 67%|██████▋   | 2/3 [01:49<00:41, 41.77s/trial, best loss: -0.887311815233105]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|9                             | 9/300 [00:20<11:17,  2.33s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/300],Train Loss: 0.1685,Val Loss: 0.1796                             \n",
      " 67%|██████▋   | 2/3 [01:51<00:41, 41.77s/trial, best loss: -0.887311815233105]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|9                            | 10/300 [00:23<11:10,  2.31s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/300],Train Loss: 0.1639,Val Loss: 0.1715                             \n",
      " 67%|██████▋   | 2/3 [01:53<00:41, 41.77s/trial, best loss: -0.887311815233105]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|#                            | 11/300 [00:25<11:10,  2.32s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/300],Train Loss: 0.1618,Val Loss: 0.1751                             \n",
      " 67%|██████▋   | 2/3 [01:56<00:41, 41.77s/trial, best loss: -0.887311815233105]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|#1                           | 12/300 [00:27<11:07,  2.32s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/300],Train Loss: 0.1632,Val Loss: 0.1771                             \n",
      " 67%|██████▋   | 2/3 [01:58<00:41, 41.77s/trial, best loss: -0.887311815233105]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|#2                           | 13/300 [00:30<11:07,  2.33s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/300],Train Loss: 0.1595,Val Loss: 0.1808                             \n",
      " 67%|██████▋   | 2/3 [02:00<00:41, 41.77s/trial, best loss: -0.887311815233105]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|#3                           | 14/300 [00:32<11:09,  2.34s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/300],Train Loss: 0.1565,Val Loss: 0.1716                             \n",
      " 67%|██████▋   | 2/3 [02:03<00:41, 41.77s/trial, best loss: -0.887311815233105]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|#4                           | 15/300 [00:34<11:08,  2.35s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/300],Train Loss: 0.1534,Val Loss: 0.1735                             \n",
      " 67%|██████▋   | 2/3 [02:05<00:41, 41.77s/trial, best loss: -0.887311815233105]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|#5                           | 16/300 [00:37<11:05,  2.34s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/300],Train Loss: 0.1555,Val Loss: 0.1741                             \n",
      "Early stopping triggered at epoch 17                                           \n",
      " 67%|██████▋   | 2/3 [02:07<00:41, 41.77s/trial, best loss: -0.887311815233105]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|#5                           | 16/300 [00:39<11:43,  2.48s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model loaded from epoch 11                                                \n",
      " 67%|██████▋   | 2/3 [02:07<00:41, 41.77s/trial, best loss: -0.887311815233105]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-05 16:09:31,471 - INFO - ResNetModel.py - Validation metrics roc_auc: 0.8965334650580836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [02:08<00:00, 42.87s/trial, best loss: -0.8965334650580836]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-05 16:09:31,476 - INFO - ResNetModel.py - Final Validation Metrics: {'accuracy': [0.8276003276003276], 'roc_auc': [0.8965334650580836]}\n",
      "2025-02-05 16:09:31,477 - INFO - ResNetModel.py - Loading model\n",
      "2025-02-05 16:09:31,478 - INFO - ResNetModel.py - Best hyperparameters: {'AdamW_learning_rate': 0.0004075143374264702, 'AdamW_weight_decay': 1.705619046081085e-08, 'Adam_learning_rate': 0.0002787250488969445, 'Adam_weight_decay': 5.8503136589228095e-08, 'ExponentialLR_gamma': 0.9784967729694466, 'ReduceLROnPlateau_factor': 0.035366290883172516, 'ReduceLROnPlateau_patience': 7, 'SGD_learning_rate': 0.0002362036859304049, 'SGD_momentum': 0.5399775189278528, 'SGD_weight_decay': 9.223794406882684e-08, 'StepLR_gamma': 0.47672489990655614, 'StepLR_step_size': 29, 'batch_size': 946, 'optimizer_fn': <class 'torch.optim.adamw.AdamW'>, 'resnet_depth': 'resnet18', 'scheduler_fn': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'default_params': {'early_stopping': True, 'verbose': False, 'iterations': 20, 'retrain': False, 'auto_lr_find': False, 'max_epochs': 300, 'val_size': 0.2, 'early_stopping_patience': 6}}\n",
      "2025-02-05 16:09:31,478 - INFO - ResNetModel.py - The best possible score for metric roc_auc is 1.0, we reached roc_auc = 0.8965334650580836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "OutputWriter.__init__() got an unexpected keyword argument 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 42\u001b[0m\n\u001b[1;32m     31\u001b[0m runner \u001b[38;5;241m=\u001b[39m AutoRunner(\n\u001b[1;32m     32\u001b[0m     data_config\u001b[38;5;241m=\u001b[39mDATA_CONFIG,\n\u001b[1;32m     33\u001b[0m     output_folder\u001b[38;5;241m=\u001b[39mOUTPUT_FOLDER,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     38\u001b[0m     max_evals\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m     39\u001b[0m )\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Run the AutoML process\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Print results from saved outputs\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mresults:\n",
      "File \u001b[0;32m~/sdev/repos/AutoDeep/autodeep/automl.py:145\u001b[0m, in \u001b[0;36mAutoRunner.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    142\u001b[0m y_pred, y_prob \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_predictions(model, X_test, data_config)\n\u001b[1;32m    143\u001b[0m output_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evaluate(y_test, y_pred, y_prob, data_config)\n\u001b[0;32m--> 145\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_results\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_metrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbest_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbest_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfull_metrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sdev/repos/AutoDeep/autodeep/automl.py:219\u001b[0m, in \u001b[0;36mAutoRunner._save_results\u001b[0;34m(self, run_id, dataset_name, model_name, metrics, best_params, best_score, full_metrics, y_pred, y_true)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_save_results\u001b[39m(\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    208\u001b[0m     run_id,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    216\u001b[0m     y_true,\n\u001b[1;32m    217\u001b[0m ):\n\u001b[1;32m    218\u001b[0m     output_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_folder, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_filename)\n\u001b[0;32m--> 219\u001b[0m     output_writer \u001b[38;5;241m=\u001b[39m \u001b[43mOutputWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mappend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m     result_data \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_id,\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m\"\u001b[39m: dataset_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mground_truth\u001b[39m\u001b[38;5;124m\"\u001b[39m: y_true[:\u001b[38;5;241m10\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist(),\n\u001b[1;32m    231\u001b[0m     }\n\u001b[1;32m    233\u001b[0m     output_writer\u001b[38;5;241m.\u001b[39mwrite(result_data)\n",
      "\u001b[0;31mTypeError\u001b[0m: OutputWriter.__init__() got an unexpected keyword argument 'append'"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Define paths to configuration files and data\n",
    "DATA_FOLDER = Path(\"/home/boom/sdev/repos/AutoDeep/autodeep/examples/testautodata\")\n",
    "OUTPUT_FOLDER = Path(\"/home/boom/sdev/repos/AutoDeep/autodeep/examples/output\")\n",
    "\n",
    "DEFAULT_MODELS = [\"resnet\"]  # Ensure all model names are lowercase\n",
    "\n",
    "DATA_CONFIG = {\n",
    "    \"dataset1\": {\n",
    "        \"dataset_path\": DATA_FOLDER / \"adult.csv\",\n",
    "        \"target_col\": \"target\",\n",
    "        \"problem_type\": \"binary_classification\",\n",
    "        \"test_size\": 0.25,\n",
    "        \"num_targets\": 1,\n",
    "        \"metric\": \"roc_auc\",\n",
    "        \"eval_metrics\": [\"accuracy\", \"roc_auc\", \"lift5\"],\n",
    "    },\n",
    "    \"dataset2\": {\n",
    "        \"dataset_path\": DATA_FOLDER / \"adult_2.csv\",\n",
    "        \"target_col\": \"target\",\n",
    "        \"problem_type\": \"binary_classification\",\n",
    "        \"test_size\": 0.2,\n",
    "        \"num_targets\": 1,\n",
    "        \"metric\": \"roc_auc\",\n",
    "        \"eval_metrics\": [\"accuracy\", \"roc_auc\", \"lift1\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "# Initialize AutoRunner instance with the configuration\n",
    "runner = AutoRunner(\n",
    "    data_config=DATA_CONFIG,\n",
    "    output_folder=OUTPUT_FOLDER,\n",
    "    default_models=DEFAULT_MODELS,\n",
    "    random_state=42,\n",
    "    execution_mode=\"hyperopt\",  # Adjust if needed\n",
    "    eval_metrics=[\"accuracy\", \"f1\", \"roc_auc\"],  # Ensure consistency with data_config\n",
    "    max_evals=3,\n",
    ")\n",
    "\n",
    "# Run the AutoML process\n",
    "runner.run()\n",
    "\n",
    "# Print results from saved outputs\n",
    "if runner.results:\n",
    "    for result in runner.results:\n",
    "        print(result)\n",
    "else:\n",
    "    print(\"No results collected. Check if `_save_results` is appending correctly.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "from pytorch_tabular.models import GatedAdditiveTreeEnsembleConfig\n",
    "\n",
    "help(GatedAdditiveTreeEnsembleConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dok1 = {\n",
    "    \"additional_tree_output_dim\": 3,\n",
    "    \"batch_norm_continuous_input\": True,\n",
    "    \"bin_function\": \"entmoid15\",\n",
    "    \"choice_function\": \"entmax15\",\n",
    "    \"depth\": 5,\n",
    "    \"embed_categorical\": True,\n",
    "    \"embedding_dropout\": 0.06089480159646259,\n",
    "    \"initialize_response\": \"normal\",\n",
    "    \"initialize_selection_logits\": \"normal\",\n",
    "    \"input_dropout\": 0.15466990749662266,\n",
    "    \"max_features\": 32,\n",
    "    \"num_layers\": 1,\n",
    "    \"num_trees\": 736,\n",
    "    \"threshold_init_beta\": 0.6724199121113691,\n",
    "    \"threshold_init_cutoff\": 0.6076965359243615,\n",
    "}\n",
    "dko2 = {\n",
    "    \"additional_tree_output_dim\": 3,\n",
    "    \"batch_norm_continuous_input\": False,\n",
    "    \"bin_function\": \"entmoid15\",\n",
    "    \"choice_function\": \"entmax15\",\n",
    "    \"depth\": 6,\n",
    "    \"embedding_dropout\": 0.05438018363383848,\n",
    "    \"initialize_response\": \"normal\",\n",
    "    \"initialize_selection_logits\": \"normal\",\n",
    "    \"input_dropout\": 0.17230551619837015,\n",
    "    \"max_features\": 21,\n",
    "    \"num_layers\": 1,\n",
    "    \"num_trees\": 626,\n",
    "    \"threshold_init_beta\": 0.9430824174145327,\n",
    "    \"threshold_init_cutoff\": 1.1093300211337618,\n",
    "}\n",
    "\n",
    "dko3 = {\n",
    "    \"additional_tree_output_dim\": 3,\n",
    "    \"batch_norm_continuous_input\": False,\n",
    "    \"bin_function\": \"sparsemoid\",\n",
    "    \"choice_function\": \"entmax15\",\n",
    "    \"depth\": 4,\n",
    "    \"embedding_dropout\": 0.05438018363383848,\n",
    "    \"initialize_response\": \"normal\",\n",
    "    \"initialize_selection_logits\": \"normal\",\n",
    "    \"input_dropout\": 0.17230551619837015,\n",
    "    \"max_features\": 21,\n",
    "    \"num_layers\": 1,\n",
    "    \"num_trees\": 626,\n",
    "    \"threshold_init_beta\": 0.826726207188516,\n",
    "    \"threshold_init_cutoff\": 0.9402437257075205,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddiff = {k: v for k, v in dko2.items() if dko2[k] != dok1[k]}\n",
    "ddiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddiff = {k: v for k, v in dko3.items() if dko3[k] != dok1[k]}\n",
    "ddiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Define the folder to format and lint\n",
    "folder_to_check = \"autodeep\"\n",
    "\n",
    "# Define output files\n",
    "output_files = {\n",
    "    \"isort\": \"isort_output.txt\",\n",
    "    \"black\": \"black_output.txt\",\n",
    "    \"pylint\": \"pylint_output.txt\",\n",
    "    \"flake8\": \"flake8_output.txt\",\n",
    "}\n",
    "\n",
    "# Ensure the output folder exists\n",
    "os.makedirs(\"linting_outputs\", exist_ok=True)\n",
    "\n",
    "# Run isort\n",
    "with open(os.path.join(\"linting_outputs\", output_files[\"isort\"]), \"w\") as f:\n",
    "    subprocess.run([\"isort\", folder_to_check], stdout=f, stderr=f)\n",
    "\n",
    "# Run black\n",
    "with open(os.path.join(\"linting_outputs\", output_files[\"black\"]), \"w\") as f:\n",
    "    subprocess.run([\"black\", folder_to_check], stdout=f, stderr=f)\n",
    "\n",
    "# Run pylint\n",
    "with open(os.path.join(\"linting_outputs\", output_files[\"pylint\"]), \"w\") as f:\n",
    "    subprocess.run([\"pylint\", folder_to_check], stdout=f, stderr=f)\n",
    "\n",
    "# Run flake8\n",
    "with open(os.path.join(\"linting_outputs\", output_files[\"flake8\"]), \"w\") as f:\n",
    "    subprocess.run([\"flake8\", folder_to_check], stdout=f, stderr=f)\n",
    "\n",
    "print(\n",
    "    \"Linting and formatting completed. Outputs are saved in the 'linting_outputs' folder.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install isort black pylint flake8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Define the path to the folder to format and lint (one level up from the current directory)\n",
    "folder_to_check = \"../../autodeep\"\n",
    "\n",
    "# Define the output folder and ensure it exists\n",
    "output_folder = \"linting_outputs\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Define the output files\n",
    "output_files = {\n",
    "    \"isort\": \"isort_output.txt\",\n",
    "    \"black\": \"black_output.txt\",\n",
    "    \"pylint\": \"pylint_output.txt\",\n",
    "    \"flake8\": \"flake8_output.txt\",\n",
    "}\n",
    "\n",
    "# Run isort\n",
    "isort_output_path = os.path.join(output_folder, output_files[\"isort\"])\n",
    "with open(isort_output_path, \"w\") as f:\n",
    "    subprocess.run([\"isort\", folder_to_check], stdout=f, stderr=f)\n",
    "\n",
    "# Run black\n",
    "black_output_path = os.path.join(output_folder, output_files[\"black\"])\n",
    "with open(black_output_path, \"w\") as f:\n",
    "    subprocess.run([\"black\", folder_to_check], stdout=f, stderr=f)\n",
    "\n",
    "# Run pylint\n",
    "pylint_output_path = os.path.join(output_folder, output_files[\"pylint\"])\n",
    "with open(pylint_output_path, \"w\") as f:\n",
    "    subprocess.run([\"pylint\", folder_to_check], stdout=f, stderr=f)\n",
    "\n",
    "# Run flake8\n",
    "flake8_output_path = os.path.join(output_folder, output_files[\"flake8\"])\n",
    "with open(flake8_output_path, \"w\") as f:\n",
    "    subprocess.run([\"flake8\", folder_to_check], stdout=f, stderr=f)\n",
    "\n",
    "print(\n",
    "    f\"Linting and formatting completed. Outputs are saved in the '{output_folder}' folder.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
